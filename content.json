{"meta":{"title":"zhiqiuyuan's blog","subtitle":"Spend Time on things I am willing to do my best","description":"grapher","author":"zhiqiuyuan","url":"http://example.com","root":"/"},"pages":[{"title":"日报","date":"2024-02-27T14:33:26.639Z","updated":"2023-01-02T14:24:37.000Z","comments":true,"path":"daily/index.html","permalink":"http://example.com/daily/index.html","excerpt":"","text":""},{"title":"","date":"2024-02-27T14:33:26.638Z","updated":"2022-12-07T16:26:51.000Z","comments":true,"path":"404.html","permalink":"http://example.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"所有分类","date":"2024-02-27T14:33:26.639Z","updated":"2022-12-07T16:24:12.000Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"日报归档","date":"2024-02-27T14:33:26.639Z","updated":"2023-01-02T14:57:17.000Z","comments":true,"path":"daily_archives/index.html","permalink":"http://example.com/daily_archives/index.html","excerpt":"","text":""},{"title":"","date":"2024-02-27T14:33:26.639Z","updated":"2022-12-07T16:22:59.000Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"我的朋友们","date":"2024-02-27T14:33:26.640Z","updated":"2022-12-07T16:27:27.000Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"所有随笔","date":"2024-02-27T14:33:26.639Z","updated":"2023-01-01T14:46:03.000Z","comments":true,"path":"writing/index.html","permalink":"http://example.com/writing/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2024-02-27T14:33:26.640Z","updated":"2022-12-07T16:23:46.000Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"python shap summary_plot","slug":"python-shap-summary-plot","date":"2024-02-27T14:22:17.000Z","updated":"2024-02-27T14:32:51.549Z","comments":true,"path":"2024/02/27/python-shap-summary-plot/","link":"","permalink":"http://example.com/2024/02/27/python-shap-summary-plot/","excerpt":"","text":"官方文档：https://shap-lrjball.readthedocs.io/en/latest/generated/shap.summary_plot.html简介（还有其他的功能）：https://mp.weixin.qq.com/s/8e-_YQc94NPMheB2aXcOsQ保存shap的图片：https://stackoverflow.com/questions/52137579/save-shap-summary-plot-as-pdf-svg 安装： pip install shap 举例： import shap rf = AdaBoostClassifier() rf = rf.fit(X_train, y_train) explainer = shap.TreeExplainer(rf) shap_values = explainer.shap_values(X_test) shap.summary_plot(shap_values[1], X_test, show=False, feature_names=[&quot;sex&quot;, &quot;age&quot;, &quot;weight&quot;]) # show=False for save plt.savefig(&quot;shap.pdf&quot;, format=&quot;pdf&quot;) （目前要修改下snap源码来支持adaboost，搜博客 shap不支持adaboost）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python snap库不支持adaboost解决","slug":"python-snap库不支持adaboost解决","date":"2024-02-27T14:10:29.000Z","updated":"2024-02-27T14:29:38.794Z","comments":true,"path":"2024/02/27/python-snap库不支持adaboost解决/","link":"","permalink":"http://example.com/2024/02/27/python-snap%E5%BA%93%E4%B8%8D%E6%94%AF%E6%8C%81adaboost%E8%A7%A3%E5%86%B3/","excerpt":"","text":"https://blog.csdn.net/wangxiancao/article/details/123487557 报错： Traceback (most recent call last): File &quot;view_adaboost.py&quot;, line 84, in &lt;module&gt; y_test, y_pred, y_probas = train_eval_adaboost() File &quot;view_adaboost.py&quot;, line 64, in train_eval_adaboost explainer = shap.TreeExplainer(rf) File &quot;/home/yuanzhiqiu/.local/lib/python3.8/site-packages/shap/explainers/_tree.py&quot;, line 175, in __init__ self.model = TreeEnsemble(model, self.data, self.data_missing, model_output) File &quot;/home/yuanzhiqiu/.local/lib/python3.8/site-packages/shap/explainers/_tree.py&quot;, line 1226, in __init__ raise InvalidModelError(&quot;Model type not yet supported by TreeExplainer: &quot; + str(type(model))) shap.utils._exceptions.InvalidModelError: Model type not yet supported by TreeExplainer: &lt;class &#39;sklearn.ensemble._weight_boosting.AdaBoostClassifier&#39;&gt; 从中知道要修改的源文件：/home/yuanzhiqiu/.local/lib/python3.8/site-packages/shap/explainers/_tree.py，以及要修改的位置大概在第1226行上边添加代码： elif safe_isinstance(model, [&quot;sklearn.ensemble.AdaBoostClassifier&quot;, &quot;sklearn.ensemble._weighted_boosting.AdaBoostClassifier&quot;]): assert hasattr(model, &quot;estimators_&quot;), &quot;Model has no `estimators_`! Have you called `model.fit`?&quot; self.internal_dtype = model.estimators_[0].tree_.value.dtype.type self.input_dtype = np.float32 scaling = 1.0 / len(model.estimators_) # output is average of trees self.trees = [SingleTree(e.tree_, normalize=True, scaling=scaling, data=data, data_missing=data_missing) for e in model.estimators_] self.objective = objective_name_map.get(model.estimator_.criterion, None) #This line is done to get the decision criteria, for example gini. self.tree_output = &quot;probability&quot; #This is the last line added 然后就可以啦 import shap rf = AdaBoostClassifier() rf = rf.fit(X_train, y_train) explainer = shap.TreeExplainer(rf) shap_values = explainer.shap_values(X_test) shap.summary_plot(shap_values[1], X_test, show=False, feature_names=[&quot;sex&quot;, &quot;age&quot;, &quot;weight&quot;]) # show=False for save plt.savefig(&quot;shap.pdf&quot;, format=&quot;pdf&quot;)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"github仓库用在线vscode打开 online vscode","slug":"github仓库用在线vscode打开-online-vscode","date":"2024-02-27T14:01:32.000Z","updated":"2024-02-27T14:02:40.570Z","comments":true,"path":"2024/02/27/github仓库用在线vscode打开-online-vscode/","link":"","permalink":"http://example.com/2024/02/27/github%E4%BB%93%E5%BA%93%E7%94%A8%E5%9C%A8%E7%BA%BFvscode%E6%89%93%E5%BC%80-online-vscode/","excerpt":"","text":"比如说原来的仓库地址是 https://github.com/Gerapy/Gerapy，那么新转到的网站就是 https://github.dev/Gerapy/Gerapy进入的快捷键：键盘上的.这个按键","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"scikit-plot python画图 除了plt还可以用的库","slug":"scikit-plot-python画图-除了plt还可以用的库","date":"2024-02-27T13:27:07.000Z","updated":"2024-02-27T14:33:16.618Z","comments":true,"path":"2024/02/27/scikit-plot-python画图-除了plt还可以用的库/","link":"","permalink":"http://example.com/2024/02/27/scikit-plot-python%E7%94%BB%E5%9B%BE-%E9%99%A4%E4%BA%86plt%E8%BF%98%E5%8F%AF%E4%BB%A5%E7%94%A8%E7%9A%84%E5%BA%93/","excerpt":"","text":"简介：https://mp.weixin.qq.com/s/FPULCKCFOYs6_uSRlbPuBQhttps://zhuanlan.zhihu.com/p/628903022 api接口：（官方文档）https://scikit-plot.readthedocs.io/en/stable/functionsapidocs.html 安装：pip install scikit-plot","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python pip 替换已经安装的模块 安装旧版本模块 安装新版本模块","slug":"python-pip-替换已经安装的模块-安装旧版本模块-安装新版本模块","date":"2024-02-27T13:16:26.000Z","updated":"2024-02-27T13:17:55.775Z","comments":true,"path":"2024/02/27/python-pip-替换已经安装的模块-安装旧版本模块-安装新版本模块/","link":"","permalink":"http://example.com/2024/02/27/python-pip-%E6%9B%BF%E6%8D%A2%E5%B7%B2%E7%BB%8F%E5%AE%89%E8%A3%85%E7%9A%84%E6%A8%A1%E5%9D%97-%E5%AE%89%E8%A3%85%E6%97%A7%E7%89%88%E6%9C%AC%E6%A8%A1%E5%9D%97-%E5%AE%89%E8%A3%85%E6%96%B0%E7%89%88%E6%9C%AC%E6%A8%A1%E5%9D%97/","excerpt":"","text":"pip很好用，想安装不同于已经安装版本的包直接指明版本即可，会自动卸载之前装的版本然后装你指定的版本 pip install scipy==1.11.4 查看已经装了哪些包以及版本 pip list","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python同名模块import","slug":"python同名模块import","date":"2024-02-27T12:46:42.000Z","updated":"2024-02-27T13:15:31.675Z","comments":true,"path":"2024/02/27/python同名模块import/","link":"","permalink":"http://example.com/2024/02/27/python%E5%90%8C%E5%90%8D%E6%A8%A1%E5%9D%97import/","excerpt":"","text":"和系统模块同名：比如本地有个模块叫code.py，从该模块导入的话在前面加路径. from .code import load_train_test https://blog.csdn.net/lipei1220/article/details/46506703 例如，在bc目录下的 test.py中 我想import 和bc同级test目录下的 abc： bc&#x2F;test.pytest&#x2F;abc.py 在test.py中： from __future__ import absolute_import # 导入test目录中的abc模块 from test.abc import Function_test # 导入当前 from .test import ...","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"deep GNN的一些insight","slug":"deep-GNN的一些insight","date":"2024-02-27T11:59:33.000Z","updated":"2024-02-27T12:03:02.821Z","comments":true,"path":"2024/02/27/deep-GNN的一些insight/","link":"","permalink":"http://example.com/2024/02/27/deep-GNN%E7%9A%84%E4%B8%80%E4%BA%9Binsight/","excerpt":"","text":"来自论文https://dl.acm.org/doi/10.1145/3292500.3330925和一些听说的经验 便签：意思是一些优化可能会导致最开始层的信息无法传达到深层（离一个顶点很多跳的邻居的信息，在加一些优化之后可能无法达到这个顶点了） 层数多了会有过拟合的问题，所有节点学到的embedding差不多 而层数不多的话，那用到的图的信息挺不够的 bias特别强，因为训练数据是那个图，你学的时候针对这个图学","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"cmake的g++ gcc c++编译器版本不对","slug":"cmake的g-gcc-c-编译器版本不对","date":"2024-02-27T04:39:29.000Z","updated":"2024-02-27T04:46:36.079Z","comments":true,"path":"2024/02/27/cmake的g-gcc-c-编译器版本不对/","link":"","permalink":"http://example.com/2024/02/27/cmake%E7%9A%84g-gcc-c-%E7%BC%96%E8%AF%91%E5%99%A8%E7%89%88%E6%9C%AC%E4%B8%8D%E5%AF%B9/","excerpt":"","text":"https://blog.csdn.net/m0_37876242/article/details/121300805在环境下有多个g++的时候，不（在CMakeLists.txt中显示或cmake指令执行时）指定g++的位置，cmake会自己找g++，这个g++的版本可能会是低版本的 运行cmake命令从其输出中可以看到其使用的编译器路径和版本 [root@localhost linux]# cmake .. -- The C compiler identification is GNU 9.3.0 # c编译器版本 -- The CXX compiler identification is GNU 9.3.0 # c++编译器版本 -- Check for working C compiler: /usr/bin/cc # c编译器路径 -- Check for working C compiler: /usr/bin/cc - works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Check for working CXX compiler: /usr/local/bin/c++ # c++编译器路径 -- Check for working CXX compiler: /usr/local/bin/c++ - works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done 指定使用的编译器的路径，使用如下方式来指定； cmake .. -DCMAKE_CXX_COMPILER=c++编译器的绝对路径 附：如果编译器版本对了，还是出现疑似不是c++17（即c++版本不对）的问题，注意检查CMakeLists.txt中是否有set(CMAKE_CXX_STANDARD 17)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"lmdb c++库和头文件 安装","slug":"lmdb-c-库和头文件-安装","date":"2024-02-27T03:10:09.000Z","updated":"2024-02-27T03:13:53.712Z","comments":true,"path":"2024/02/27/lmdb-c-库和头文件-安装/","link":"","permalink":"http://example.com/2024/02/27/lmdb-c-%E5%BA%93%E5%92%8C%E5%A4%B4%E6%96%87%E4%BB%B6-%E5%AE%89%E8%A3%85/","excerpt":"","text":"https://blog.csdn.net/quantum7/article/details/82697588 下载代码git clone https://github.com/LMDB/lmdb.git 进入目录cd lmdb&#x2F;libraries&#x2F;liblmdb 编译和安装make -jsudo make install 得感叹一句，lmdb好优雅，编译和安装眨眼就完成","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"GNN数学简介","slug":"GNN数学简介","date":"2024-02-26T07:51:29.000Z","updated":"2024-02-27T11:00:54.433Z","comments":true,"path":"2024/02/26/GNN数学简介/","link":"","permalink":"http://example.com/2024/02/26/GNN%E6%95%B0%E5%AD%A6%E7%AE%80%E4%BB%8B/","excerpt":"","text":"full batch论文https://dl.acm.org/doi/10.14778/3538598.3538614的背景知识部分介绍的 简而言之：每轮epoch：在所有训练数据上计算得到loss关于权重的梯度，更新权重 第一处便签：(4)来自：把(3)代入(2)，然后对(2)求导的感觉 第二处便签：如果是多层的GNN，前向计算要前向走这么多层，反向传播也是，权重更新的地方更多一些 mini batch论文https://dl.acm.org/doi/10.1145/3292500.3330925的背景知识部分和算法motivation部分介绍的 原理&#x2F;过程简而言之：每轮epoch：对每个mini-batch（一个mini-batch是一部分训练数据），在mini-batch上计算得到loss关于权重的梯度，更新权重 先介绍full batch SGD the final embedding is: (A帽’替换成A’) 存在的问题简而言之：一个mini-batch中顶点要更新embedding，其需要其多跳邻居的embedding，这些邻居不一定都在这个mini-batch中，但是我们又需要的话那它们也要一起随着层次深入更新embedding（意思是，比如当前mini-batch在计算第k层，需要邻居的k-1层的embedding，因此邻居的embedding也得跟着更新，确保其现在是k-1层的embedding）， 而对于full batch来讲，batch是全体顶点，batch中顶点更新embedding需要的多跳邻居都在这个batch中，本来就是在随着岑歌词深入更新embedding的，相较于mini-batch来讲不会有重复计算 第一处便签：因为从大的稀疏图中随机采样选取出一个mini-batch，这个mini-batch中的顶点之间的邻居重合可能非常少 第二处便签：共L层，每层都是全图每个顶点更新一下embedding，所以每层是O(N)次embedding计算 第一处便签：这样相较于full-neighborhood，embedding利用率就更低了，因为不同顶点需要的neighborhood间重合的可能性更低了（不过这个方法也不是没有意义，neighborhood的大小毕竟是小了的，更新一个node embedding的开销比full neighborhood要小） 第二处便签：每层把全图所有顶点的embedding存下来（每个mini-batch可以来访问这个存储），这样在下一层对每个mini-batch更新embedding时，对于需要的、但是不在当前mini-batch中的邻居的embedding就可以从存储中读取，而不用这个mini-batch中从第0层开始一直计算了，不过这要求每层都同步，所有mini-batch完成当前层后才能进入下一层 【TODO】这个表格我没有每一项都去推导为啥","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win新建桌面和桌面切换笔记本","slug":"win新建桌面和桌面切换笔记本","date":"2024-02-26T07:31:51.000Z","updated":"2024-02-27T06:10:36.616Z","comments":true,"path":"2024/02/26/win新建桌面和桌面切换笔记本/","link":"","permalink":"http://example.com/2024/02/26/win%E6%96%B0%E5%BB%BA%E6%A1%8C%E9%9D%A2%E5%92%8C%E6%A1%8C%E9%9D%A2%E5%88%87%E6%8D%A2%E7%AC%94%E8%AE%B0%E6%9C%AC/","excerpt":"","text":"四指触摸触摸板：左右：切换桌面向下：显示有多少桌面，可以点击来新建桌面 每个桌面都可以设置不一样的壁纸，不过在设置不一样的壁纸的桌面之间切换会稍微慢一点，不是那么丝滑，个人不是很推荐，还是都用一样的壁纸切换迅速 附加：三指左右：当前桌面切换顶层应用","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"latex数学符号","slug":"latex数学符号","date":"2024-02-26T07:14:30.000Z","updated":"2024-02-26T07:33:55.441Z","comments":true,"path":"2024/02/26/latex数学符号/","link":"","permalink":"http://example.com/2024/02/26/latex%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7/","excerpt":"","text":"https://zinglix.xyz/2017/08/23/latex-maths-cheatsheet/h","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"sshkey ssh密匙","slug":"sshkey-ssh密匙","date":"2024-02-25T10:12:29.000Z","updated":"2024-02-25T10:21:07.671Z","comments":true,"path":"2024/02/25/sshkey-ssh密匙/","link":"","permalink":"http://example.com/2024/02/25/sshkey-ssh%E5%AF%86%E5%8C%99/","excerpt":"","text":"A想免密登录B，则 在A上生成ssh key ssh-keygen win的话装git然后在git bash中执行上述命令可以加的选项：指定生成哪种密匙 [-t dsa | ecdsa | ecdsa-sk | ed25519 | ed25519-sk | rsa] 将A的公匙（xxx.pub，通常一路默认生成的ssh key在A的~/.ssh/目录下）追加到B的~/.ssh/authorized_keys中","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"火绒服务异常解决","slug":"火绒服务异常解决","date":"2024-02-25T01:44:09.000Z","updated":"2024-02-25T01:46:46.932Z","comments":true,"path":"2024/02/25/火绒服务异常解决/","link":"","permalink":"http://example.com/2024/02/25/%E7%81%AB%E7%BB%92%E6%9C%8D%E5%8A%A1%E5%BC%82%E5%B8%B8%E8%A7%A3%E5%86%B3/","excerpt":"","text":"该博客中记录了很多种现象和对应的解决方案：https://bbs.huorong.cn/thread-75900-1-1.html 某现象：每次开机服务异常，点击修复按钮可修复成功如果您的电脑每次开机后都会出现异常情况，且可手动启动服务或修复成功。此情况为火绒安全服务模块（HipsDaemon.exe）由于某些原因未能开机自启导致的，可能的原因如下： 【原因1】火绒安装在非系统盘符且开启了BitLocker或设备加密资源管理器中看加密了的盘上会有一把锁，这把锁可能关了也可能开着解决方案：win+R组合键，调出运行窗口，输入cmd，按下Ctrl+Shift+Enter以管理员身份打开命令提示符，输入 manage-bde -off D: （以火绒安装在D盘为例），待执行完毕，即解决解锁之后资源管理器中看锁会消失","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"gperftools内存泄漏检测","slug":"gperftools内存泄漏检测","date":"2024-02-24T08:37:01.000Z","updated":"2024-02-24T08:37:33.928Z","comments":true,"path":"2024/02/24/gperftools内存泄漏检测/","link":"","permalink":"http://example.com/2024/02/24/gperftools%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%A3%80%E6%B5%8B/","excerpt":"","text":"https://cloud.tencent.com/developer/article/1383795 https://fuchencong.com/2021/04/22/develop-tools-1/","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"dmesg 格式化输出 可读模式","slug":"dmesg-格式化输出-可读模式","date":"2024-02-24T03:25:07.000Z","updated":"2024-02-24T03:31:23.319Z","comments":true,"path":"2024/02/24/dmesg-格式化输出-可读模式/","link":"","permalink":"http://example.com/2024/02/24/dmesg-%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA-%E5%8F%AF%E8%AF%BB%E6%A8%A1%E5%BC%8F/","excerpt":"","text":"https://www.myfreax.com/dmesg-command-in-linux/#google_vignette dmesg -H -P 以人类可读模式，且不使用pager（pager会从最开始开始显示，你可以用上下键翻页） -H, –human Enable human-readable output. See also –color, –reltime and –nopager.-P, –nopager Do not pipe output into a pager. A pager is enabled by default for –human output 输出比如： [Feb23 21:05] gldbc_local_ops[4115205]: segfault at 0 ip 000055f7b28fa975 sp 00007eafaa5fc9e0 error 4 in gldbc_local_ops[55f7b265b000+4a4000] [ +0.000007] Code: 8b 44 24 08 48 89 44 24 38 48 85 c0 74 12 48 83 3d 2f 36 34 00 00 0f 84 49 01 00 00 f0 ff 40 08 48 8b 44 24 28 48 8b 54 24 08 &lt;8b&gt; 30 48 8d 4c 24 30 4c 89 ef e8 8c 7c 05 00 48 8b 7c 24 38 48 85 [Feb24 10:33] gldbc_local_ops[627595]: segfault at 0 ip 00005610dbd7b975 sp 00007e63391fa9e0 error 4 in gldbc_local_ops[5610dbadc000+4a4000] [ +0.000007] Code: 8b 44 24 08 48 89 44 24 38 48 85 c0 74 12 48 83 3d 2f 36 34 00 00 0f 84 49 01 00 00 f0 ff 40 08 48 8b 44 24 28 48 8b 54 24 08 &lt;8b&gt; 30 48 8d 4c 24 30 4c 89 ef e8 8c 7c 05 00 48 8b 7c 24 38 48 85","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"笔记本电脑切换fn功能键","slug":"笔记本电脑切换fn功能键","date":"2024-02-24T02:45:45.000Z","updated":"2024-02-24T02:47:07.673Z","comments":true,"path":"2024/02/24/笔记本电脑切换fn功能键/","link":"","permalink":"http://example.com/2024/02/24/%E7%AC%94%E8%AE%B0%E6%9C%AC%E7%94%B5%E8%84%91%E5%88%87%E6%8D%A2fn%E5%8A%9F%E8%83%BD%E9%94%AE/","excerpt":"","text":"https://blog.csdn.net/NSJim/article/details/125494940 fn+esc切换f1-f12的功能是标准功能还是特殊功能 如果f1-f12为标准功能，则fn+f1等启动的是特殊功能","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win强制重新识别usb设备 win无法识别usb设备不重新插拔设备","slug":"win强制重新识别usb设备-win无法识别usb设备不重新插拔设备","date":"2024-02-24T01:44:20.000Z","updated":"2024-02-24T02:06:15.640Z","comments":true,"path":"2024/02/24/win强制重新识别usb设备-win无法识别usb设备不重新插拔设备/","link":"","permalink":"http://example.com/2024/02/24/win%E5%BC%BA%E5%88%B6%E9%87%8D%E6%96%B0%E8%AF%86%E5%88%ABusb%E8%AE%BE%E5%A4%87-win%E6%97%A0%E6%B3%95%E8%AF%86%E5%88%ABusb%E8%AE%BE%E5%A4%87%E4%B8%8D%E9%87%8D%E6%96%B0%E6%8F%92%E6%8B%94%E8%AE%BE%E5%A4%87/","excerpt":"","text":"步骤https://knowledge.ni.com/KnowledgeArticleDetails?id=kA00Z000000P7bZSAS&amp;l=zh-CN 通过设备管理器找到无法识别的usb设备连接到的根集线器 设备管理器-通用串行总线xxx，会看到多个根集线器，双击-power，查看设备列表找设备 如果只有一个根集线器，那就是它 确定是哪个根集线器之后，双击-详细信息-属性-设备实例路径 用devcon工具来执行重新识别 devcon的替代工具PnPUtil（win系统自带）不过，下载devcon的界面建议用PnPUtil来代替devcon PnPUtil ships with every release of Windows and makes use of the most reliable and secure APIs available and its use is recommended. For more information on using PnPutil instead of devcon, see Replacing DevCon. PnPUtil is an inbox tool that allows the user to view information on and change the state of devices and drivers. See PnPUtil for an in-depth usage guide. PnPUtil is included in the %windir%\\system32 directory of every version of Windows Vista and later. There isn’t a separate PnPUtil download package. Open a Command Prompt window (Run as administrator). Type pnputil /? to view command options. See PnPUtil Command Syntax for more information. PnPUtil常用命令重启设备: pnputil &#x2F;restart-device “USB\\VID_045E&amp;PID_00DB\\6&amp;870CE29&amp;0&amp;1”","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"bash 数组长度","slug":"bash-数组长度","date":"2024-02-23T13:21:13.000Z","updated":"2024-02-23T13:21:55.408Z","comments":true,"path":"2024/02/23/bash-数组长度/","link":"","permalink":"http://example.com/2024/02/23/bash-%E6%95%B0%E7%BB%84%E9%95%BF%E5%BA%A6/","excerpt":"","text":"&#96;&#96;&#96;bash$","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"linux find -size 查找/删除所有空文件","slug":"linux-find-size-查找-删除所有空文件","date":"2024-02-23T12:58:44.000Z","updated":"2024-02-24T03:52:13.108Z","comments":true,"path":"2024/02/23/linux-find-size-查找-删除所有空文件/","link":"","permalink":"http://example.com/2024/02/23/linux-find-size-%E6%9F%A5%E6%89%BE-%E5%88%A0%E9%99%A4%E6%89%80%E6%9C%89%E7%A9%BA%E6%96%87%E4%BB%B6/","excerpt":"","text":"列出当前目录下（递归）所有空文件 find -type f -size 0c 加-delete则是删除所有空文件 列出当前目录下（递归）所有非空文件 find -type f -size +0c -size n[cwbkMG]File uses n units of space, rounding up. The following suffixes can be used: &#96;b’ for 512-byte blocks (this is the default if no suffix is used) &#96;c’ for bytes &#96;w’ for two-byte words &#96;k’ for kibibytes (KiB, units of 1024 bytes) &#96;M’ for mebibytes (MiB, units of 1024 * 1024 &#x3D; 1048576 bytes) &#96;G’ for gibibytes (GiB, units of 1024 * 1024 * 1024 &#x3D; 1073741824 bytes) The size is simply the st_size member of the struct stat populated by the lstat (or stat) system call,rounded up as shown above. In other words, it’s consistent with the result you get for ls -l. Bear inmind that the %k&#39; and %b’ format specifiers of -printf handle sparse files differently. The &#96;b’ suf‐fix always denotes 512-byte blocks and never 1024-byte blocks, which is different to the behaviour of-ls. The + and - prefixes signify greater than and less than, as usual; i.e., an exact size of n units doesnot match. Bear in mind that the size is rounded up to the next unit. Therefore -size -1M is notequivalent to -size -1048576c. The former only matches empty files, the latter matches files from 0 to1,048,575 bytes.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"T-GNN简介 时态GNN简介 动态GNN简介","slug":"T-GNN简介-时态GNN简介-动态GNN简介","date":"2024-02-23T08:12:45.000Z","updated":"2024-02-23T11:30:14.590Z","comments":true,"path":"2024/02/23/T-GNN简介-时态GNN简介-动态GNN简介/","link":"","permalink":"http://example.com/2024/02/23/T-GNN%E7%AE%80%E4%BB%8B-%E6%97%B6%E6%80%81GNN%E7%AE%80%E4%BB%8B-%E5%8A%A8%E6%80%81GNN%E7%AE%80%E4%BB%8B/","excerpt":"","text":"https://dl.acm.org/doi/10.14778/3583140.3583150这篇论文的背景部分介绍的，介绍得好好！不了解GNN的建议先看 GNN简介 这篇博客 时态图 T GNN原理 Temporal Message Passing 黄色的便签内容： tao和来的interaction的t有啥关系：tao最开始传进来是传的t，由于要拿temporal邻居的h，求邻居的h要递归下去 绿色的便签内容： 递归在这里发生：求这个要递归下去 figure 1： 关键是这里，展示为啥是递归： State Update 时间复杂度 和静态GNN的区别为啥静态GNN就没有递归这种说法？其实时态GNN也可以没有递归，但是这样的话，L层的GNN，对于某个temporal node (v,t)来说，要求其L阶邻居内所有顶点*所有t之前的时间戳（当然可能实际传播下去并不会是所有的时间戳）的temporal node都要从第一层开始计算，一直计算到第L层，这涉及到的node比静态GNN多很多（静态GNN：对于一个node，最多是其L阶邻居内所有顶点），所以采用递归的方式，实际上可以理解为一种lazy策略，要它的时候才启动计算的感觉不过，从这个过程中我们可以看到，如果每来一个event(interaction)，其涉及的两个temporal node (v,t)都要严格aggregate所有在t之前的L阶邻居的话，注意到来的event的时间戳是递增的，这样产生的计算对于同样的v来说一定是有冗余的","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"valgrind install 安装","slug":"valgrind-install-安装","date":"2024-02-23T05:09:57.000Z","updated":"2024-02-23T05:11:21.048Z","comments":true,"path":"2024/02/23/valgrind-install-安装/","link":"","permalink":"http://example.com/2024/02/23/valgrind-install-%E5%AE%89%E8%A3%85/","excerpt":"","text":"https://valgrind.org/docs/manual/dist.readme.html download tar.bz from https://valgrind.org/downloads/ 解压，进入目录 tar -jxvf xxx.tar.bz2 Run .&#x2F;configure, with some options if you wish. The only interestingone is the usual –prefix&#x3D;&#x2F;where&#x2F;you&#x2F;want&#x2F;it&#x2F;installed. Run “make”. Run “make install”, possibly as root if the destination permissionsrequire that. See if it works. Try “valgrind ls -l”. Either this works, or itbombs out with some complaint. In that case, please let us know(see http://valgrind.org/support/bug_reports.html).","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"pandas判断某列是否是整形","slug":"pandas判断某列是否是整形","date":"2024-02-23T04:24:31.000Z","updated":"2024-02-23T04:32:49.511Z","comments":true,"path":"2024/02/23/pandas判断某列是否是整形/","link":"","permalink":"http://example.com/2024/02/23/pandas%E5%88%A4%E6%96%AD%E6%9F%90%E5%88%97%E6%98%AF%E5%90%A6%E6%98%AF%E6%95%B4%E5%BD%A2/","excerpt":"","text":"import pandas as pd pd.api.types.is_string_dtype(df[&#39;A&#39;]) pd.api.types.is_numeric_dtype(df[&#39;A&#39;]) pd.api.types.is_integer_dtype(df[&#39;A&#39;])","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"pandas判断某列是否有空值 是否全是空值","slug":"pandas判断某列是否有空值-是否全是空值","date":"2024-02-23T04:21:36.000Z","updated":"2024-02-23T04:22:11.813Z","comments":true,"path":"2024/02/23/pandas判断某列是否有空值-是否全是空值/","link":"","permalink":"http://example.com/2024/02/23/pandas%E5%88%A4%E6%96%AD%E6%9F%90%E5%88%97%E6%98%AF%E5%90%A6%E6%9C%89%E7%A9%BA%E5%80%BC-%E6%98%AF%E5%90%A6%E5%85%A8%E6%98%AF%E7%A9%BA%E5%80%BC/","excerpt":"","text":"判断某列是否有NaN df[&#39;col&#39;].isnull().any() 判断某列是否全部为NaN df[&#39;col&#39;].isnull().all()","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"pandas统计每列独立值 unique value_counts","slug":"pandas统计每列独立值-unique-value-counts","date":"2024-02-23T04:01:44.000Z","updated":"2024-02-23T04:02:20.740Z","comments":true,"path":"2024/02/23/pandas统计每列独立值-unique-value-counts/","link":"","permalink":"http://example.com/2024/02/23/pandas%E7%BB%9F%E8%AE%A1%E6%AF%8F%E5%88%97%E7%8B%AC%E7%AB%8B%E5%80%BC-unique-value-counts/","excerpt":"","text":"https://blog.csdn.net/Orange_Spotty_Cat/article/details/94576683 a = list(df[&#39;vin&#39;].unique()) # 列出该列的唯一值 len(a) # 统计该列有多少个不一样的值 b = pd.DataFrame(df[&#39;vin&#39;].value_counts()) # 统计每个唯一值出现了多少次","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"pandas字符串列数值化 转换成离散的数值标签","slug":"pandas字符串列数值化-转换成离散的数值标签","date":"2024-02-23T03:51:42.000Z","updated":"2024-02-23T03:52:41.934Z","comments":true,"path":"2024/02/23/pandas字符串列数值化-转换成离散的数值标签/","link":"","permalink":"http://example.com/2024/02/23/pandas%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%88%97%E6%95%B0%E5%80%BC%E5%8C%96-%E8%BD%AC%E6%8D%A2%E6%88%90%E7%A6%BB%E6%95%A3%E7%9A%84%E6%95%B0%E5%80%BC%E6%A0%87%E7%AD%BE/","excerpt":"","text":"https://blog.csdn.net/qq_42902997/article/details/121667555 df = pd.DataFrame(&#123;&quot;性别&quot;:[&quot;男&quot;,&quot;女&quot;,&quot;女&quot;,&quot;女&quot;,&quot;男&quot;,&quot;男&quot;,&quot;男&quot;,&quot;男&quot;,&quot;男&quot;,&quot;女&quot;,&quot;女&quot;,&quot;男&quot;]&#125;) df[&quot;性别&quot;] = pd.Categorical(df[&quot;性别&quot;]).codes","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"pandas 根据列值筛选行 选取某些列 获取拷贝","slug":"pandas-根据列值筛选行-选取某些列-获取拷贝","date":"2024-02-23T03:42:45.000Z","updated":"2024-02-23T03:44:26.254Z","comments":true,"path":"2024/02/23/pandas-根据列值筛选行-选取某些列-获取拷贝/","link":"","permalink":"http://example.com/2024/02/23/pandas-%E6%A0%B9%E6%8D%AE%E5%88%97%E5%80%BC%E7%AD%9B%E9%80%89%E8%A1%8C-%E9%80%89%E5%8F%96%E6%9F%90%E4%BA%9B%E5%88%97-%E8%8E%B7%E5%8F%96%E6%8B%B7%E8%B4%9D/","excerpt":"","text":"mark_is_model_col_name_in_excel=&quot;is_model&quot; feature_cols=[&#39;duration_group&#39;, &#39;altitude_level&#39;, &#39;chronic_heart_failure&#39;] # 要选取的列 X = df.loc[df[mark_is_model_col_name_in_excel]==1, feature_cols] # 行：仅选取is_model列的值==1的行 # 列：feature_cols","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"git pull 有些文件没有更新","slug":"git-pull-有些文件没有更新","date":"2024-02-22T07:09:52.000Z","updated":"2024-02-22T07:11:51.639Z","comments":true,"path":"2024/02/22/git-pull-有些文件没有更新/","link":"","permalink":"http://example.com/2024/02/22/git-pull-%E6%9C%89%E4%BA%9B%E6%96%87%E4%BB%B6%E6%B2%A1%E6%9C%89%E6%9B%B4%E6%96%B0/","excerpt":"","text":"有时候git pull和本地修改冲突之后没有修改成功，但是又把本地的head设置为了新的commit，这个时候重新pull就不会发生文件更新，而是告诉你already up to date，解决的方法：先git reset 然后重新git pull","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"git查看某次commit改动的内容 改动的文件","slug":"git查看某次commit改动的内容-改动的文件","date":"2024-02-22T06:37:47.000Z","updated":"2024-02-22T06:46:35.916Z","comments":true,"path":"2024/02/22/git查看某次commit改动的内容-改动的文件/","link":"","permalink":"http://example.com/2024/02/22/git%E6%9F%A5%E7%9C%8B%E6%9F%90%E6%AC%A1commit%E6%94%B9%E5%8A%A8%E7%9A%84%E5%86%85%E5%AE%B9-%E6%94%B9%E5%8A%A8%E7%9A%84%E6%96%87%E4%BB%B6/","excerpt":"","text":"git log查看commit的历史 git show commit_id查看某次commit的修改内容（会每个改动的文件的改动diff都显示） git show –name-only commit_id修改了哪些文件 git show 显示最后一次的文件改变的具体内容git log -p 查看某个文件的修改历史git log -p -2查看最近2次的更新内容 git whatchanged 每次修改的文件列表git whatchanged –stat 每次修改的文件列表, 及文件修改的统计","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"pyG introduction by example","slug":"pyG-introduction-by-example","date":"2024-02-20T07:19:11.000Z","updated":"2024-02-20T07:27:04.452Z","comments":true,"path":"2024/02/20/pyG-introduction-by-example/","link":"","permalink":"http://example.com/2024/02/20/pyG-introduction-by-example/","excerpt":"","text":"https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html Data Handling of GraphsA graph is used to model pairwise relations (edges) between objects (nodes). A single graph in PyG is described by an instance of torch_geometric.data.Data, which holds the following attributes by default: data.x: Node feature matrix with shape [num_nodes, num_node_features] data.edge_index: Graph connectivity in COO format with shape [2, num_edges] and type torch.long data.edge_attr: Edge feature matrix with shape [num_edges, num_edge_features] data.y: Target to train against (may have arbitrary shape), e.g., node-level targets of shape [num_nodes, *] or graph-level targets of shape [1, *] data.pos: Node position matrix with shape [num_nodes, num_dimensions] None of these attributes are required. In fact, the Data object is not even restricted to these attributes. We can, e.g., extend it by data.face to save the connectivity of triangles from a 3D mesh in a tensor with shape [3, num_faces] and type torch.long. We show a simple example of an unweighted and undirected graph with three nodes and four edges. Each node contains exactly one feature: import torch from torch_geometric.data import Data # 图拓扑 edge_index = torch.tensor([[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long) # 边0-&gt;1,1-&gt;0,1-&gt;2,2-&gt;1 # 顶点特征 x = torch.tensor([[-1], [0], [1]], dtype=torch.float) data = Data(x=x, edge_index=edge_index) &gt;&gt;&gt; Data(edge_index=[2, 4], x=[3, 1]) Besides holding a number of node-level, edge-level or graph-level attributes, Data provides a number of useful utility functions, e.g.: print(data.keys()) &gt;&gt;&gt; [&#39;x&#39;, &#39;edge_index&#39;] print(data[&#39;x&#39;]) &gt;&gt;&gt; tensor([[-1.0], [0.0], [1.0]]) for key, item in data: print(f&#39;&#123;key&#125; found in data&#39;) &gt;&gt;&gt; x found in data &gt;&gt;&gt; edge_index found in data &#39;edge_attr&#39; in data &gt;&gt;&gt; False data.num_nodes &gt;&gt;&gt; 3 data.num_edges &gt;&gt;&gt; 4 data.num_node_features &gt;&gt;&gt; 1 data.has_isolated_nodes() &gt;&gt;&gt; False data.has_self_loops() &gt;&gt;&gt; False data.is_directed() &gt;&gt;&gt; False # Transfer data object to GPU. device = torch.device(&#39;cuda&#39;) data = data.to(device) You can find a complete list of all methods at torch_geometric.data.Data. Common Benchmark DatasetsPyG contains a large number of common benchmark datasets , e.g., all Planetoid datasets (Cora, Citeseer, Pubmed), all graph classification datasets from http://graphkernels.cs.tu-dortmund.de and their cleaned versions, the QM7 and QM9 dataset, and a handful of 3D mesh&#x2F;point cloud datasets like FAUST, ModelNet10&#x2F;40 and ShapeNet. Initializing a dataset is straightforward. An initialization of a dataset will automatically download its raw files and process them to the previously described Data format. E.g., to load the ENZYMES dataset (consisting of 600 graphs within 6 classes), type: from torch_geometric.datasets import TUDataset dataset = TUDataset(root=&#39;/tmp/ENZYMES&#39;, name=&#39;ENZYMES&#39;) &gt;&gt;&gt; ENZYMES(600) len(dataset) &gt;&gt;&gt; 600 dataset.num_classes &gt;&gt;&gt; 6 dataset.num_node_features &gt;&gt;&gt; 3 We now have access to all 600 graphs in the dataset: data = dataset[0] &gt;&gt;&gt; Data(edge_index=[2, 168], x=[37, 3], y=[1]) data.is_undirected() &gt;&gt;&gt; True We can see that the first graph in the dataset contains 37 nodes, each one having 3 features. There are 168&#x2F;2 &#x3D; 84 undirected edges and the graph is assigned to exactly one class. In addition, the data object is holding exactly one graph-level target. We can even use slices, long or bool tensors to split the dataset. E.g., to create a 90&#x2F;10 train&#x2F;test split, type: train_dataset = dataset[:540] &gt;&gt;&gt; ENZYMES(540) test_dataset = dataset[540:] &gt;&gt;&gt; ENZYMES(60) Let’s try another one! Let’s download Cora, the standard benchmark dataset for semi-supervised graph node classification: from torch_geometric.datasets import Planetoid dataset = Planetoid(root=&#39;/tmp/Cora&#39;, name=&#39;Cora&#39;) &gt;&gt;&gt; Cora() len(dataset) &gt;&gt;&gt; 1 dataset.num_classes &gt;&gt;&gt; 7 dataset.num_node_features &gt;&gt;&gt; 1433 Here, the dataset contains only a single, undirected citation graph: data = dataset[0] &gt;&gt;&gt; Data(edge_index=[2, 10556], test_mask=[2708], train_mask=[2708], val_mask=[2708], x=[2708, 1433], y=[2708]) data.is_undirected() &gt;&gt;&gt; True data.train_mask.sum().item() &gt;&gt;&gt; 140 data.val_mask.sum().item() &gt;&gt;&gt; 500 data.test_mask.sum().item() &gt;&gt;&gt; 1000 This time, the Data objects holds a label for each node, and additional node-level attributes: train_mask, val_mask and test_mask, where train_mask denotes against which nodes to train (140 nodes), val_mask denotes which nodes to use for validation, e.g., to perform early stopping (500 nodes), test_mask denotes against which nodes to test (1000 nodes). Learning Methods on GraphsAfter learning about data handling, datasets, loader and transforms in PyG, it’s time to implement our first graph neural network! We will use a simple GCN layer and replicate the experiments on the Cora citation dataset. For a high-level explanation on GCN, have a look at its blog post. We first need to load the Cora dataset: from torch_geometric.datasets import Planetoid dataset = Planetoid(root=&#39;/tmp/Cora&#39;, name=&#39;Cora&#39;) &gt;&gt;&gt; Cora() Note that we do not need to use transforms or a dataloader. Now let’s implement a two-layer GCN: import torch import torch.nn.functional as F from torch_geometric.nn import GCNConv class GCN(torch.nn.Module): def __init__(self): super().__init__() self.conv1 = GCNConv(dataset.num_node_features, 16) self.conv2 = GCNConv(16, dataset.num_classes) def forward(self, data): x, edge_index = data.x, data.edge_index x = self.conv1(x, edge_index) x = F.relu(x) x = F.dropout(x, training=self.training) x = self.conv2(x, edge_index) return F.log_softmax(x, dim=1) The constructor defines two GCNConv layers which get called in the forward pass of our network. Note that the non-linearity (意思是比如relu这样的函数) is not integrated in the conv calls and hence needs to be applied afterwards (something which is consistent across all operators in PyG). Here, we chose to use ReLU as our intermediate non-linearity and finally output a softmax distribution over the number of classes. Let’s train this model on the training nodes for 200 epochs: device = torch.device(&#39;cuda&#39; if torch.cuda.is_available() else &#39;cpu&#39;) model = GCN().to(device) data = dataset[0].to(device) optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4) model.train() for epoch in range(200): optimizer.zero_grad() out = model(data) loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask]) loss.backward() optimizer.step() Finally, we can evaluate our model on the test nodes: model.eval() pred = model(data).argmax(dim=1) correct = (pred[data.test_mask] == data.y[data.test_mask]).sum() acc = int(correct) / int(data.test_mask.sum()) print(f&#39;Accuracy: &#123;acc:.4f&#125;&#39;) &gt;&gt;&gt; Accuracy: 0.8150 This is all it takes to implement your first graph neural network. The easiest way to learn more about Graph Neural Networks is to study the examples in the examples/ directory and to browse torch_geometric.nn. Happy hacking!","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"torch Sparse COO tensors; COO format; coordinate format","slug":"torch-Sparse-COO-tensors-COO-format-coordinate-format","date":"2024-02-20T06:55:19.000Z","updated":"2024-02-20T07:00:05.873Z","comments":true,"path":"2024/02/20/torch-Sparse-COO-tensors-COO-format-coordinate-format/","link":"","permalink":"http://example.com/2024/02/20/torch-Sparse-COO-tensors-COO-format-coordinate-format/","excerpt":"","text":"https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs PyTorch implements the so-called Coordinate format, or COO format, as one of the storage formats for implementing sparse tensors. In COO format, the specified elements are stored as tuples of element indices and the corresponding values. In particular, the indices of specified elements are collected in indices tensor of size (ndim, nse) and with element type torch.int64, the corresponding values are collected in values tensor of size (nse,) and with an arbitrary integer or floating point number element type, where ndim is the dimensionality of the tensor and nse is the number of specified elements. 举例： Suppose we want to define a sparse tensor with the entry 3 at location (0, 2), entry 4 at location (1, 0), and entry 5 at location (1, 2). Unspecified elements are assumed to have the same value, fill value, which is zero by default. We would then write: &gt;&gt;&gt; i = [[0, 1, 1], [2, 0, 2]] &gt;&gt;&gt; v = [3, 4, 5] &gt;&gt;&gt; s = torch.sparse_coo_tensor(i, v, (2, 3)) &gt;&gt;&gt; s tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([3, 4, 5]), size=(2, 3), nnz=3, layout=torch.sparse_coo) &gt;&gt;&gt; s.to_dense() tensor([[0, 0, 3], [4, 0, 5]]) Suppose we want to create a (2 + 1)-dimensional tensor with the entry [3, 4] at location (0, 2), entry [5, 6] at location (1, 0), and entry [7, 8] at location (1, 2). We would write &gt;&gt;&gt; i = [[0, 1, 1], [2, 0, 2]] &gt;&gt;&gt; v = [[3, 4], [5, 6], [7, 8]] &gt;&gt;&gt; s = torch.sparse_coo_tensor(i, v, (2, 3, 2)) &gt;&gt;&gt; s tensor(indices=tensor([[0, 1, 1], [2, 0, 2]]), values=tensor([[3, 4], [5, 6], [7, 8]]), size=(2, 3, 2), nnz=3, layout=torch.sparse_coo) &gt;&gt;&gt; s.to_dense() tensor([[[0, 0], [0, 0], [3, 4]], [[5, 6], [0, 0], [7, 8]]])","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"softmax function","slug":"softmax-function","date":"2024-02-19T12:48:35.000Z","updated":"2024-02-19T12:52:02.526Z","comments":true,"path":"2024/02/19/softmax-function/","link":"","permalink":"http://example.com/2024/02/19/softmax-function/","excerpt":"","text":"hardmax是最大值， 对于一个集合z1,z2,…zC，我们想求最大值 hardmax是最大值， softmax要soft一些，不是仅保留最大值，而是给所有都赋一个概率，这个概率分布满足值越大对应的概率越大 softmax函数如下：","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"windowsterminal 快捷键","slug":"windowsterminal-快捷键","date":"2024-02-19T06:30:47.000Z","updated":"2024-02-19T06:32:54.133Z","comments":true,"path":"2024/02/19/windowsterminal-快捷键/","link":"","permalink":"http://example.com/2024/02/19/windowsterminal-%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"快捷键设置和查看：设置-操作 关闭当前窗格 ctrl+shift+w新建窗格 ctrl+shift+t下一个窗格 ctrl+tab(上一个窗格 ctrl+shift+tab)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"GNN introduction GNN简介","slug":"GNN-introduction-GNN简介","date":"2024-02-18T13:59:51.000Z","updated":"2024-02-23T11:33:36.407Z","comments":true,"path":"2024/02/18/GNN-introduction-GNN简介/","link":"","permalink":"http://example.com/2024/02/18/GNN-introduction-GNN%E7%AE%80%E4%BB%8B/","excerpt":"","text":"写得好好！循序渐进！图例简直了超级形象呀！ 向全世界安利这个博客作为GNN的入门博客！ 不过这是2021年的了，一些比较新的技术和方向没有包含 A Gentle Introduction to Graph Neural NetworksGraphs have up to four types of information that we will potentially want to use to make predictions: nodes, edges, global-context and connectivity Graph representwe need to represent: nodes, edges, global-context and connectivity representing a graph’s connectivity is more complicated.Perhaps the most obvious choice would be to use an adjacency matrix, since this is easily tensorisable.However, this representation has a few drawbacks.From the example dataset table, we see the number of nodes in a graph can be on the order of millions, and the number of edges per node can be highly variable. Often, this leads to very sparse adjacency matrices, which are space-inefficient.Another problem is that there are many adjacency matrices that can encode the same connectivity, and there is no guarantee that these different matrices would produce the same result in a deep neural network (that is to say, they are not permutation invariant). permutation invariant: If we permute the nodes in some way, the resulting representations of the nodes as computed by our algorithms should also be permuted in the same way. nodes: node embeddings (information&#x2F;attributes&#x2F;representation of nodes, node vectors) edges: edge embeddings adjacency lists: These describe the connectivity of edge ek between nodes ni and nj as a tuple (i,j) in the k-th entry of an adjacency list. global: global embeddings On one side we have a small graph and on the other the information of the graph in a tensor representation. It should be noted that the figure uses scalar values per node&#x2F;edge&#x2F;global, but most practical tensor representations have vectors per graph attribute. Instead of a node tensor of size [nnodes] we will be dealing with node tensors of size [nnodes,nodedim]. Same for the other graph attributes. Now that the graph’s description is in a matrix format that is permutation invariant, What’s a GNNA GNN is an optimizable transformation on all attributes of the graph (nodes, edges, global-context) that preserves graph symmetries (permutation invariances). The simplest GNNWith the numerical representation of graphs that we’ve constructed above (with vectors instead of scalars), we are now ready to build a GNN. We will start with the simplest GNN architecture, one where we learn new embeddings for all graph attributes (nodes, edges, global), but where we do NOT yet use the connectivity of the graph. This GNN uses a separate multilayer perceptron (MLP) (or your favorite differentiable model) on **each component **(V,E,U，共三个component) of a graph; we call this a GNN layer. For each node vector, we apply the MLP and get back a learned node-vector. We do the same for each edge, learning a per-edge embedding, and also for the global-context vector, learning a single embedding for the entire graph. 每个node vector、每个edge vector以及global vector都要过一个MLP是合理的：回忆普通神经网络，对于每个输入的vector，都是这个vector要过一个MLP 这个最简单的GNN，其实即非常直接地对图数据应用普通神经网络，比如想对node vector做预测，于是对node vector训练数据过神经网络做训练；这样存在的问题是，（以node vector为例）node vector并不是相互独立的，而是有边相连（这和普通神经网络假设输入样本彼此独立不一样），后面的message passing GNN layer就是考虑了**拓扑上的相关**，在训练的时候不是每个node vector独立过神经网络，而是在过网络之前先和其拓扑邻居的vector聚合一下，由此来利用拓扑关联信息 a GNN layer: You could also call it a GNN block. Because it contains multiple operations&#x2F;layers (like a ResNet block). A single layer of a simple GNN. A graph is the input, and each component (V,E,U) gets updated by a MLP (f in this figure) to produce a new graph. Each function subscript indicates a separate function for a different graph attribute at the n-th layer of a GNN model. As is common with neural networks modules or layers, we can stack these GNN layers together. Because a GNN does not update the connectivity of the input graph, we can describe the output graph of a GNN with the same adjacency list and the same number of feature vectors as the input graph. But, the output graph has updated embeddings, since the GNN has updated each of the node, edge and global-context representations. GNN Predictions by Pooling InformationWe have built a simple GNN, but how do we make predictions in any of the tasks we described above? We will consider the case of binary classification. If the task is to make binary predictions on nodes, and the graph already contains node information, the approach is straightforward — for each node embedding, apply a linear classifier. However, it is not always so simple. For instance, you might have information in the graph stored in edges, but no information in nodes, but still need to make predictions on nodes. e.g., We could imagine a social network, where we wish to anonymize user data (nodes) by not using them, and only using relational data (edges). We need a way to collect information from edges and give them to nodes (将edge embeddings转化为node embeddings) for prediction. We can do this by pooling. Pooling proceeds in two steps: For each item to be pooled (比如顶点的所有邻边), gather each of their embeddings and concatenate them into a matrix. The gathered embeddings are then aggregated, usually via a sum operation. We represent the pooling operation by the letter ρ, and denote that we are gathering information from edges to nodes as ρEn→Vn. Hover over a node to visualize which edges are gathered and aggregated to produce an embedding for that target node. So If we only have edge-level features, and are trying to predict binary node information, we can use pooling to route (or pass) information to where it needs to go. The model looks like this. If we only have node-level features, and are trying to predict binary edge-level information, the model looks like this. e.g., Nodes can be recognized as image entities, and we are trying to predict if the entities share a relationship (binary edges). If we only have node-level features, and need to predict a binary global property, we need to gather all available node information together and aggregate them. This is similar to Global Average Pooling layers in CNNs. The same can be done for edges. e.g., This is a common scenario for predicting molecular properties. For example, we have atomic information, connectivity and we would like to know the toxicity of a molecule (toxic&#x2F;not toxic), or if it has a particular odor (rose&#x2F;not rose). In our examples, the classification model c can easily be replaced with any differentiable model, or adapted to multi-class classification using a generalized linear model. An end-to-end prediction task with a GNN model. Now we’ve demonstrated that we can build a simple GNN model, and make binary predictions by routing information between different parts of the graph. This pooling technique will serve as a building block for constructing more sophisticated GNN models. If we have new graph attributes, we just have to define how to pass information from one attribute to another. Note that in this simplest GNN formulation, we’re not using the connectivity of the graph at all inside the GNN layer. Each node is processed independently, as is each edge, as well as the global context (都是每个vector单独过一个MLP). We only use connectivity when pooling information for prediction. Passing messages between parts of the graphWe could make more sophisticated predictions by using pooling within the GNN layer, in order to make our learned embeddings aware of graph connectivity. We can do this using message passing[18], where neighboring nodes or edges exchange information and influence each other’s updated embeddings. Message passing works in three steps: For each node in the graph, gather all the neighboring node embeddings (or messages), which is the g function described above. Aggregate all messages via an aggregate function (like sum). All pooled messages are passed through an update function, usually a learned neural network. You could also 1) gather messages, 3) update them and 2) aggregate them and still have a permutation invariant operation.[20] Just as pooling can be applied to either nodes or edges, message passing can occur between either nodes or edges. These steps are key for leveraging the connectivity of graphs. We will build more elaborate variants of message passing in GNN layers that yield GNN models of increasing expressiveness and power. This sequence of operations, when applied once, is the simplest type of message-passing GNN layer. (相较于simpliest GNN layer，在对vector应用function f之前添加了message-passing&#x2F;“pooling”（gather-aggregate）的操作) This is reminiscent of standard convolution: in essence, message passing and convolution are operations to aggregate and process the information of an element’s neighbors in order to update the element’s value. In graphs, the element is a node, and in images, the element is a pixel. However, the number of neighboring nodes in a graph can be variable, unlike in an image where each pixel has a set number of neighboring elements. By stacking message passing GNN layers together, a node can eventually incorporate information from across the entire graph: after three layers, a node has information about the nodes three steps away from it. We can update our architecture diagram to include this new source of information for nodes: Schematic for a GCN architecture, which updates node representations of a graph by pooling neighboring nodes at a distance of one degree. Learning edge representationsOur dataset does not always contain all types of information (node, edge, and global context). When we want to make a prediction on nodes, but our dataset only has edge information, we showed above how to use pooling to route information from edges to nodes, but only at the final prediction step of the model. We can share information between nodes and edges within the GNN layer using message passing. However, the node and edge information stored in a graph are not necessarily the same size or shape, so it is not immediately clear how to combine them. One way is to learn a linear mapping from the space of edges to the space of nodes, and vice versa. Alternatively, one may concatenate them together before the update function. Architecture schematic for Message Passing layer. 在把embedding送到普通神经网络之前，增加下面的这个步骤，使得node&#x2F;edge vector可以用上图的拓扑信息（而不是仅用node&#x2F;edge vector这个vector本身的信息）：The first step (即ρVn→En) “prepares” a message composed of information from an edge and it’s connected nodes and then (即ρEn→Vn，对node vector跟新时，用的邻边的vector是来自上一步(ρVn→En)聚合得到的message) “passes” the message to the node. Which graph attributes we update and in which order we update them is one design decision when constructing GNNs. We could choose whether to update node embeddings before edge embeddings, or the other way around. This is an open area of research with a variety of solutions– for example we could update in a ‘weave’ fashion[21] where we have four updated representations that get combined into new node and edge representations: node to node (linear), edge to edge (linear), node to edge (edge layer), edge to node (node layer). Some of the different ways we might combine edge and node representation in a GNN layer. Adding global representationsThere is one flaw with the networks we have described so far: nodes that are far away from each other in the graph may never be able to efficiently transfer information to one another, even if we apply message passing several times. For one node, If we have k-layers, information will propagate at most k-steps away. This can be a problem for situations where the prediction task depends on nodes, or groups of nodes, that are far apart. One solution would be to have all nodes be able to pass information to each other (即任意两点之间有“边”相连，比如Node to node的fashion，则在一个GNN层中求一个node vector时，是先聚合当前node的vector和全图所有其他顶点的vector、然后送到神经网络中). Unfortunately for large graphs, this quickly becomes computationally expensive (although this approach, called ‘virtual edges’, has been used for small graphs such as molecules).[18] One solution to this problem is by using the global representation of a graph (U) which is sometimes called a master node [19][18] or context vector. This global context vector is connected to all other nodes and edges in the network, and can act as a bridge between them to pass information, building up a representation for the graph as a whole. This creates a richer and more complex representation of the graph than could have otherwise been learned. Schematic of a Graph Nets architecture leveraging global representations. U是global representation，它和所有点边都相连，所以既是点又是边：上图中，第一步Vn→En和Un→En，其实Un也是Vn的角色；第二步；第三步 In this view all graph attributes have learned representations, so we can leverage them during pooling by conditioning the information of our attribute of interest with respect to the rest. For example, for one node we can consider information from neighboring nodes, connected edges and the global information. To condition the new node embedding on all these possible sources of information, we can simply concatenate them. Additionally we may also map them to the same space via a linear map and add them or apply a feature-wise modulation layer[22] (feature-wise的意思是，apply的这个layer，对node info、edge info和global info apply的layer不一样，对于node information有一个layer，对于edge information有另一个layer，对于global infor还有一个) , which can be considered a type of featurize-wise attention mechanism. Schematic for conditioning the information of one node based on three other embeddings (adjacent nodes, adjacent edges, global). This step corresponds to the node operations in the Graph Nets Layer. GNN playgroundWe’ve described a wide range of GNN components here, but how do they actually differ in practice? This GNN playground allows you to see how these different components and architectures contribute to a GNN’s ability to learn a real task. Our playground shows a graph-level prediction task with small molecular graphs. We use the the Leffingwell Odor Dataset[23][24], which is composed of molecules with associated odor percepts (labels). Predicting the relation of a molecular structure (graph) to its smell is a 100 year-old problem straddling chemistry, physics, neuroscience, and machine learning. To simplify the problem, we consider only a single binary label per molecule, classifying if a molecular graph smells “pungent” or not, as labeled by a professional perfumer. We say a molecule has a “pungent” scent if it has a strong, striking smell. For example, garlic and mustard, which might contain the molecule allyl alcohol have this quality. The molecule piperitone, often used for peppermint-flavored candy, is also described as having a pungent smell. We represent each molecule as a graph, where atoms are nodes containing a one-hot encoding for its atomic identity (哪种原子) (Carbon, Nitrogen, Oxygen, Fluorine) and bonds are edges containing a one-hot encoding its bond type (single, double, triple or aromatic). Our general modeling template for this problem will be built up using sequential GNN layers, followed by a linear model with a sigmoid activation for classification. The design space for our GNN has many levers that can customize the model: The number of GNN layers, also called the depth. The dimensionality of each attribute when updated. The update function is a 1-layer MLP with a relu activation function and a layer norm for normalization of activations. The aggregation function used in pooling: max, mean or sum. The graph attributes that get updated, or styles of message passing: nodes, edges and global representation. We control these via boolean toggles (on or off). A baseline model would be a graph-independent GNN (all message-passing off) which aggregates all data at the end into a single global attribute. Toggling on all message-passing functions yields a GraphNets architecture. To better understand how a GNN is learning a task-optimized representation of a graph, we also look at the penultimate layer activations of the GNN. These ‘graph embeddings’ are the outputs of the GNN model right before prediction. Since we are using a generalized linear model for prediction, a linear mapping is enough to allow us to see how we are learning representations around the decision boundary. Since these are high dimensional vectors, we reduce them to 2D via principal component analysis (PCA). A perfect model would visibility separate labeled data, but since we are reducing dimensionality and also have imperfect models, this boundary might be harder to see. https://distill.pub/2021/gnn-intro/#gnn-playground Play around with different model architectures to build your intuition. For example, see if you can edit the molecule on the left to make the model prediction increase. Do the same edits have the same effects for different model architectures? Some empirical GNN design lessonsWhen exploring the architecture choices above, you might have found some models have better performance than others. Are there some clear GNN design choices that will give us better performance? For example, do deeper GNN models perform better than shallower ones? or is there a clear choice between aggregation functions? The answers are going to depend on the data, [25][26], and even different ways of featurizing and constructing graphs can give different answers. With the following interactive figure, we explore the space of GNN architectures and the performance of this task across a few major design choices: Style of message passing, the dimensionality of embeddings, number of layers, and aggregation operation type. the number of trainable variablesEach point in the scatter plot represents a model: the x axis is the number of trainable variables, and the y axis is the performance. Hover over a point to see the GNN architecture parameters. The first thing to notice is that, surprisingly, a higher number of parameters does correlate with higher performance. GNNs are a very parameter-efficient model type: for even a small number of parameters (3k) we can already find models with high performance. the dimensionality of embeddingsNext, we can look at the distributions of performance aggregated based on the dimensionality of the learned representations for different graph attributes. Aggregate performance of models across varying node, edge, and global dimensions. We can notice that models with higher dimensionality tend to have better mean and lower bound performance but the same trend is not found for the maximum. Some of the top-performing models can be found for smaller dimensions. Since higher dimensionality is going to also involve a higher number of parameters, these observations go in hand with the previous figure. the number of GNN layersNext we can see the breakdown of performance based on the number of GNN layers. Chart of number of layers vs model performance, and scatterplot of model performance vs number of parameters. Each point is colored by the number of layers. Hover over a point to see the GNN architecture parameters. The box plot shows a similar trend, while the mean performance tends to increase with the number of layers, the best performing models do not have three or four layers, but two. Furthermore, the lower bound for performance decreases with four layers. This effect has been observed before, GNN with a higher number of layers will broadcast information at a higher distance and can risk having their node representations ‘diluted’ from many successive iterations [27]. aggregation operation typeDoes our dataset have a preferred aggregation operation? Our following figure breaks down performance in terms of aggregation type. Chart of aggregation type vs model performance, and scatterplot of model performance vs number of parameters. Each point is colored by aggregation type. Hover over a point to see the GNN architecture parameters. Overall it appears that sum has a very slight improvement on the mean performance, but max or mean can give equally good models. This is useful to contextualize when looking at the discriminatory&#x2F;expressive capabilities of aggregation operations . The previous explorations have given mixed messages. We can find mean trends where more complexity gives better performance but we can find clear counterexamples where models with fewer parameters, number of layers, or dimensionality perform better. One trend that is much clearer is about the number of attributes that are passing information to each other (下面展示的是这个). the style of message passingHere we break down performance based on the style of message passing. On both extremes, we consider models that do not communicate between graph entities (“none”) and models that have messaging passed between nodes, edges, and globals. Chart of message passing vs model performance, and scatterplot of model performance vs number of parameters. Each point is colored by message passing. Hover over a point to see the GNN architecture parameters Overall we see that the more graph attributes are communicating, the better the performance of the average model. Our task is centered on global representations, so explicitly learning this attribute also tends to improve performance. Our node representations also seem to be more useful than edge representations, which makes sense since more information is loaded in these attributes. There are many directions you could go from here to get better performance. We wish two highlight general directions, one related to more sophisticated graph algorithms and another towards the graph itself. Up until now, our GNN is based on a neighborhood-based pooling operation. There are some graph concepts that are harder to express in this way, for example a linear graph path (a connected chain of nodes). Designing new mechanisms in which graph information (全图拓扑信息) can be extracted, executed and propagated in a GNN is one current research area [28], [29], [30], [31]. One of the frontiers of GNN research is not making new models and architectures, but “how to construct graphs”, to be more precise, imbuing graphs with additional structure or relations that can be leveraged. As we loosely saw, the more graph attributes are communicating the more we tend to have better models. In this particular case, we could consider making molecular graphs more feature rich, by adding additional spatial relationships between nodes, adding edges that are not bonds, or explicit learnable relationships between subgraphs. Into the WeedsNext, we have a few sections on a myriad of graph-related topics that are relevant for GNNs. Other types of graphs (multigraphs, hypergraphs, hypernodes, hierarchical graphs)While we only described graphs with vectorized information for each attribute, graph structures are more flexible and can accommodate other types of information. Fortunately, the message passing framework is flexible enough that often adapting GNNs to more complex graph structures is about defining how information is passed and updated by new graph attributes. For example, we can consider multi-edge graphs or multigraphs[32], where a pair of nodes can share multiple types of edges, this happens when we want to model the interactions between nodes differently based on their type. For example with a social network, we can specify edge types based on the type of relationships (acquaintance, friend, family). A GNN can be adapted by having different types of message passing steps for each edge type. We can also consider nested graphs, where for example a node represents a graph, also called a hypernode graph.[33] Nested graphs are useful for representing hierarchical information. For example, we can consider a network of molecules, where a node represents a molecule and an edge is shared between two molecules if we have a way (reaction) of transforming one to the other [34][35]. In this case, we can learn on a nested graph by having a GNN that learns representations at the molecule level and another at the reaction network level, and alternate between them during training (这个的意思是，比如在reaction network level的GNN中学到的node embedding，是molecule level的GNN中的global embedding). Sampling Graphs and Batching in GNNsA common practice for training neural networks is to update network parameters with gradients calculated on randomized constant size (batch size) subsets of the training data (mini-batches). This practice presents a challenge for graphs due to the variability in the number of nodes and edges adjacent to each other, meaning that we cannot have a constant batch size. The main idea for batching with graphs is to create subgraphs that preserve essential properties of the larger graph. This graph sampling operation is highly dependent on context and involves sub-selecting nodes and edges from a graph (sub-selecting的意思就是从全图的顶点集合和边集合中取子集). These operations might make sense in some contexts (citation networks) and in others, these might be too strong of an operation (molecules, where a subgraph simply represents a new, smaller molecule). How to sample a graph is an open research question.[39] If we care about preserving structure at a neighborhood level, one way would be to randomly sample a uniform number of nodes, our node-set. Then add neighboring nodes of distance k adjacent to the node-set, including their edges.[40] Each neighborhood can be considered an individual graph and a GNN can be trained on batches of these subgraphs. The loss can be masked to only consider the node-set since all neighboring nodes would have incomplete neighborhoods. A more efficient strategy might be to first randomly sample a single node, expand its neighborhood to distance k, and then pick the other node within the expanded set. These operations can be terminated once a certain amount of nodes, edges, or subgraphs are constructed. If the context allows, we can build constant size neighborhoods by picking an initial node-set and then sub-sampling a constant number of nodes (e.g randomly, or via a random walk or Metropolis algorithm[41]). Four different ways of sampling the same graph. Choice of sampling strategy depends highly on context since they will generate different distributions of graph statistics (# nodes, #edges, etc.). For highly connected graphs, edges can be also subsampled. Sampling a graph is particularly relevant when a graph is large enough that it cannot be fit in memory. Inspiring new architectures and training strategies such as Cluster-GCN [42] and GraphSaint [43]. We expect graph datasets to continue growing in size in the future. Inductive biasesWhen building a model to solve a problem on a specific kind of data, we want to specialize our models to leverage the characteristics of that data. When this is done successfully, we often see better predictive performance, lower training time, fewer parameters and better generalization. When labeling on images, for example, we want to take advantage of the fact that a dog is still a dog whether it is in the top-left or bottom-right corner of an image. Thus, most image models use convolutions, which are translation invariant. For text, the order of the tokens is highly important, so recurrent neural networks process data sequentially. Further, the presence of one token (e.g. the word ‘not’) can affect the meaning of the rest of a sentence, and so we need components that can ‘attend’ to other parts of the text, which transformer models like BERT and GPT-3 can do. These are some examples of inductive biases, where we are identifying symmetries or regularities in the data and adding modelling components that take advantage of these properties. In the case of graphs, we care about how each graph component (edge, node, global) is related to each other so we seek models that have a relational inductive bias.[19] A model should preserve explicit relationships between entities (adjacency matrix) and preserve graph symmetries (permutation invariance). We expect problems where the interaction between entities is important will benefit from a graph structure. Concretely, this means designing transformation on sets: the order of operation on nodes or edges should not matter and the operation should work on a variable number of inputs (这句话没有看懂). Comparing aggregation operationsPooling information from neighboring nodes and edges is a critical step in any reasonably powerful GNN architecture. Because each node has a variable number of neighbors, and because we want a differentiable method of aggregating this information, we want to use a smooth aggregation operation that is invariant to node ordering and the number of nodes provided. Selecting and designing optimal aggregation operations is an open research topic.[44] A desirable property of an aggregation operation is that similar inputs provide similar aggregated outputs (这个的意思是，对一个这样的函数，输入1和输入2类似的话，输出1和输出2也要类似), and vice-versa. Some very simple candidate permutation-invariant operations are sum, mean, and max. Summary statistics like variance also work. All of these take a variable number of inputs, and provide an output that is the same, no matter the input ordering. There is no operation that is uniformly the best choice. The mean operation can be useful when nodes have a highly-variable number of neighbors or you need a normalized view of the features of a local neighborhood. The max operation can be useful when you want to highlight single salient features in local neighborhoods. Sum provides a balance between these two, by providing a snapshot of the local distribution of features, but because it is not normalized, can also highlight outliers. In practice, sum is commonly used. Designing aggregation operations is an open research problem that intersects with machine learning on sets.[45] New approaches such as Principal Neighborhood aggregation[27] take into account several aggregation operations by concatenating them and adding a scaling function that depends on the degree of connectivity of the entity to aggregate. Meanwhile, domain specific aggregation operations can also be designed. One example lies with the “Tetrahedral Chirality” aggregation operators [46]. GCN as subgraph function approximatorsAnother way to see GCN (and MPNN) of k-layers with a 1-degree neighbor (一阶邻居) lookup (意思是，message passing时pooling的范围，对顶点来说是其一阶邻居) is as a neural network (下图中的gsubgraphs) that operates on learned embeddings of subgraphs of size k[47][44]: (放到前面讲解的GNN框架中，下图中的gsubgraphs对应着下游的graph-level task的预测阶段(这个阶段拿已经学习到的embeddings去做预测)) When focusing on one node, after k-layers, the updated node representation has a limited viewpoint of all neighbors up to k-distance, essentially a subgraph representation. Same is true for edge representations. So a GCN is collecting all possible subgraphs of size k and learning vector representations from the vantage point of one node or edge. The number of possible subgraphs can grow combinatorially, so enumerating these subgraphs from the beginning vs building them dynamically as in a GCN, might be prohibitive. Edges and the Graph DualOne thing to note is that edge predictions and node predictions, while seemingly different, often reduce to the same problem: an edge prediction task on a graph G can be phrased as a node-level prediction on G’s dual. To obtain G’s dual, we can convert nodes to edges (and edges to nodes). A graph and its dual contain the same information, just expressed in a different way. Sometimes this property makes solving problems easier in one representation than another, like frequencies in Fourier space. In short, to solve an edge classification problem on G, we can think about doing graph convolutions on G’s dual (which is the same as learning edge representations on G) (这句没看懂), this idea was developed with Dual-Primal Graph Convolutional Networks.[48] Graph convolutions as matrix multiplications, and matrix multiplications as walks on a graphWe’ve talked a lot about graph convolutions and message passing, and of course, this raises the question of how do we implement these operations in practice? For this section, we explore some of the properties of matrix multiplication, message passing, and its connection to traversing a graph. 个人感觉graph convolutions可以理解成是message passing， 回忆图像领域的卷积神经网络，是先对图像进行卷积计算，为每个pixel做卷积（即聚合它周围的pixel）得到每个pixel的向量表示，然后把这个送到神经网络中去， graph convolution也是类似的，在送到神经网络中之前，增加一步，是利用图的结构信息，通过message passing来“扩充”当前vector（比如node vector或edge vector或global vector等） The first point we want to illustrate is that the matrix multiplication of an adjacent matrix A of size nnodes×nnodes with a node feature matrix X of size nnodes×nodedim implements an simple message passing with a summation aggregation (对于顶点特征的每一维，累加顶点的一阶邻居的vector的这一维). Let the matrix be B&#x3D;AX, we can observe that any entry Bij can be expressed as &lt;Arowi, Xcolumnj&gt;&#x3D;Ai,1 X1,j+Ai,2 X2,j+…+Ai,n Xn,j&#x3D;∑Ai,k Xk,j. Because Ai,k are binary entries only when a edge exists between nodei and nodek, the inner product is essentially “gathering” all node features values of dimension j that share an edge with nodei. It should be noted that this message passing is not updating the representation of the node features, just pooling neighboring node features. But this can be easily adapted by passing X through your favorite differentiable transformation (e.g. MLP) before or after the matrix multiply. From this view, we can appreciate the benefit of using adjacency lists. Due to the expected sparsity of A we don’t have to sum all values where Ai,j is zero. As long as we have an operation to gather values based on an index, we should be able to just retrieve positive entries. Additionally, this matrix multiply-free approach frees us from using summation as an aggregation operation. We can imagine that applying this operation multiple times allows us to propagate information at greater distances. In this sense, matrix multiplication is a form of traversing over a graph. This relationship is also apparent when we look at powers A^k of the adjacency matrix. If we consider the matrix A^2, the term A^2ij counts all walks of length 2 from nodei to nodej and can be expressed as the inner product &lt;Arowi,Acolumnj&gt;&#x3D;Ai,1 A1,j+Ai,2 A2,j+…+Ai,n An,j . The intuition is that the first term Ai,1 A1,j is only positive under two conditions, there is edge that connects nodei to node1 and another edge that connects node1 to nodej. In other words, both edges form a path of length 2 that goes from nodei to nodej passing by node1. Due to the summation, we are counting over all possible intermediate nodes. This intuition carries over when we consider A^3&#x3D;A*A^2.. and so on to A^k. There are deeper connections on how we can view matrices as graphs to explore [49][50][51]. Graph Attention NetworksAnother way of communicating information between graph attributes is via attention.[52] For example, when we consider the sum-aggregation of a node and its 1-degree neighboring nodes (一阶邻居) we could also consider using a weighted sum. 这里我感觉， 像是aggregation function设计领域的 The challenge then is to associate weights in a permutation invariant fashion. One approach is to consider a scalar scoring function that assigns weights based on pairs of nodes (f(nodei,nodej)). In this case, the scoring function can be interpreted as a function that measures how relevant a neighboring node is in relation to the center node. Weights can be normalized, for example with a softmax function to focus most of the weight on a neighbor most relevant for a node in relation to a task. This concept is the basis of Graph Attention Networks (GAT) [53] and Set Transformers[54]. Permutation invariance is preserved, because scoring works on pairs of nodes. A common scoring function is the inner product and nodes are often transformed before scoring into query and key vectors via a linear map to increase the expressivity of the scoring mechanism. Additionally for interpretability, the scoring weights can be used as a measure of the importance of an edge in relation to a task. Schematic of attention over one node with respect to it’s adjacent nodes. For each edge an interaction score is computed, normalized and used to weight node embeddings. 这里没有看很懂： Additionally, transformers can be viewed as GNNs with an attention mechanism [55]. Under this view, the transformer models several elements (i.g. character tokens) as nodes in a fully connected graph and the attention mechanism is assigning edge embeddings to each node-pair which are used to compute attention weights. The difference lies in the assumed pattern of connectivity between entities, a GNN is assuming a sparse pattern and the Transformer is modelling all connections. 我理解的GNN过程k层的GNN：对于一个顶点v，v以及其k阶邻居（及以内的邻居），初始化每人一个embedding，然后第一层：这些顶点进行消息传递（message-aggregate），然后每个顶点都update得到新的embedding第二层：消息传递，update…","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"chrome暗黑模式 网页暗黑模式 page dark mode 可自定义调节","slug":"chrome暗黑模式-网页暗黑模式-page-dark-mode-可自定义调节","date":"2024-02-18T13:12:23.000Z","updated":"2024-02-18T13:30:38.438Z","comments":true,"path":"2024/02/18/chrome暗黑模式-网页暗黑模式-page-dark-mode-可自定义调节/","link":"","permalink":"http://example.com/2024/02/18/chrome%E6%9A%97%E9%BB%91%E6%A8%A1%E5%BC%8F-%E7%BD%91%E9%A1%B5%E6%9A%97%E9%BB%91%E6%A8%A1%E5%BC%8F-page-dark-mode-%E5%8F%AF%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B0%83%E8%8A%82/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/162015675 chrome:&#x2F;&#x2F;flags&#x2F;#enable-force-dark然后选择enable","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"node2vec","slug":"node2vec","date":"2024-02-18T09:45:49.000Z","updated":"2024-02-18T10:12:43.329Z","comments":true,"path":"2024/02/18/node2vec/","link":"","permalink":"http://example.com/2024/02/18/node2vec/","excerpt":"","text":"对deepwalk的改进：替换deepwalk中的neighborhood sampling strategy，即从随机游走(randomwalk)改成node2vecWalk deepwalk见博客 node2vecWalk 下面介绍Πvx怎么计算 dtx为啥取值只可能是0,1,2：因为t和v相邻，v和x相邻，只有三种情况： t和x相同：dtx&#x3D;0 t和x不相邻：dtx&#x3D;2 t和x相邻：dtx&#x3D;1 node2vec伪代码 in any random walk, there is an implicit bias due to the choice of the start node u. Since we learn representations for all nodes, we offset this bias by simulating r random walks of fixed length l starting from every node.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"deepwalk","slug":"deepwalk","date":"2024-02-18T09:05:53.000Z","updated":"2024-02-18T09:53:19.539Z","comments":true,"path":"2024/02/18/deepwalk/","link":"","permalink":"http://example.com/2024/02/18/deepwalk/","excerpt":"","text":"图嵌入&#x2F;图表示学习Graph Embedding将图中的节点以低维稠密向量的形式进行表达，要求在原始图中相似(不同的方法对相似的定义不同)的节点其在低维表达空间也接近。得到的表达向量可以用来进行下游任务，如节点分类，链接预测，可视化或重构原始图等。 deepwalk原理https://zhuanlan.zhihu.com/p/56380812 在NLP任务中，word2vec是一种常用的word embedding方法，word2vec通过语料库中的句子序列来描述词与词的共现关系，进而学习到词语的向量表示。 DeepWalk的思想类似word2vec，使用图中节点与节点的共现关系来学习节点的向量表示。那么关键的问题就是如何来描述节点与节点的共现关系，DeepWalk给出的方法是使用随机游走(RandomWalk)的方式在图中进行节点采样。 RandomWalk是一种可重复访问已访问节点的DFS算法。给定当前访问起始节点，从其邻居中随机采样节点作为下一个访问节点，重复此过程，直到访问序列长度满足预设条件。 获取足够数量的节点访问序列后（这是得到的训练数据），使用skip-gram model 进行向量学习。 deepwalk伪代码https://arxiv.org/abs/1403.6652 SkipGram is a language model that maximizes the cooccurrence probability among the words that appear within a window, w, in a sentence. Lines 3-9 in Algorithm 1 shows the core of our approach. The outer loop specifies the number of times, γ, which we should start random walks at each vertex. We think of each iteration as making a ‘pass’ over the data and sample one walk per node during this pass. At the start of each pass we generate a random ordering to traverse the vertices. This is not strictly required, but is well-known to speed up the convergence of stochastic gradient descent. node2vec中解释了为啥每轮都要从所有顶点出发做随机游走：in any random walk, there is an implicit bias due to the choice of the start node u. Since we learn representations for all nodes, we offset this bias by simulating r random walks of fixed length l starting from every node. In the inner loop, we iterate over all the vertices of the graph. For each vertex vi we generate a random walk |Wvi | &#x3D; t, and then use it to update our representations (Line 7). Algorithm 2 iterates over all possible collocations in random walk that appear within the window w (lines 1-2). For each, we map each vertex vj to its current representation vector Φ(vj ) ∈ R d. Given the representation of vj , we would like to maximize the probability of its neighbors in the walk (line 3; 传进来的Wvi是从vi出发随机走t步经过的点的序列，认为在点vj前后宽度w内的点都是离vj很近的点（和vj结构上共现的概率预期要大）). 优化其中Algorithm 2 的 line 3的概率计算：","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"GNN训练框架入门 美团图神经网络框架Tulong","slug":"GNN训练框架入门-美团图神经网络框架Tulong","date":"2024-02-18T07:41:18.000Z","updated":"2024-02-18T08:42:13.637Z","comments":true,"path":"2024/02/18/GNN训练框架入门-美团图神经网络框架Tulong/","link":"","permalink":"http://example.com/2024/02/18/GNN%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E5%85%A5%E9%97%A8-%E7%BE%8E%E5%9B%A2%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A1%86%E6%9E%B6Tulong/","excerpt":"","text":"美团图神经网络框架Tulong，图计算库MTGraph 图神经网络训练框架的实践和探索1. 前言深度学习技术将图像、文本、语音等多种多样的数据转化为稠密的向量表示，提供了表示数据的另一种方式。 由于图数据特有的稀疏性（图的所有节点对之间只有少量边相连），直接使用通用的深度学习框架（例如TensorFlow和PyTorch）训练往往性能不佳。 针对图神经网络的深度学习框架应运而出：PyG (PyTorch Geometric)[6]和DGL (Deep Graph Library)[7]等开源框架大幅提升了图神经网络的训练速度，并且降低了资源消耗[17][18]，拥有活跃的社区支持。 1.1 一个“好用”的图神经网络框架至少具备以下特点。 （1）完善支持当前流行的图神经网络模型。 （2）以合理的代价支持大规模图上的模型训练。 希望单机即可在合理的时间内训练百亿边规模的模型 （3）与业务系统无缝对接。 图神经网络的完整落地流程至少包括：基于业务数据构图、离线训练和评测模型、线上推理、业务指标观测等步骤。合适的工具能提升对接业务数据的效率，然而现有的图神经网络框架大多聚焦在模型的离线训练和评测，缺乏此类工具。 （4）研发人员易于上手，同时提供充足的可扩展性。 通过简单地配置即能完成多数任务。在此基础上，对于一些特殊的建模需求，也能提供适当的支持。 1.2 美团的解决方案图神经网络框架Tulong以及配套的图学习平台 对当前流行的图神经网络模型进行了细粒度的剖析，归纳总结出了一系列子操作，实现了一套通用的模型框架。简单修改配置即可实现许多现有的图神经网络模型。 高度可配置化的训练和评测，从参数初始化到学习率，从模型结构到损失函数类型… 2. 系统概览 （1）图以及深度学习引擎 我们把图神经网络的底层算子分为三类：图结构查询、稀疏张量计算和稠密张量计算。 我们开发了图计算库MTGraph提供图数据的存储和查询功能，深度优化了内存占用和子图采样速度。 MTGraph兼容PyTorch和DGL，用户可以在MTGraph的基础上直接编写基于DGL的模型代码。 （2）Tulong框架 Tulong框架首先封装实现了训练图神经网络所需的基本组件，包括图和特征数据的预处理流程、子图采样器、通用的GNN模型框架，以及包括训练和评测在内的基础任务。 基于上述组件，Tulong框架提供丰富的预定义模型和训练&#x2F;推理流程，用户通过修改配置文件即可在业务数据上训练和评测GNN模型。 3. 模型框架我们从工程实现的角度，归纳总结了当前主流图神经网络模型的基本范式，实现一套通用框架，以期涵盖多种GNN模型。 3.1 同质图同质图(Homogeneous Graph)可以定义为节点集合和边集合：**G&#x3D;(V,E)**，一条边(u,v)∈E表示节点u与节点v相连。节点和边上往往还附加有特征，我们记x(u,v)为边(u,v)的特征。 前向计算过程的计算范式： 上述计算范式仍然分为生成消息、聚合消息、更新当前节点三个步骤，具体包括： 层次维度的聚合函数ρL(⋅)：用于聚合同一节点在模型不同层次的表示。例如，多数GNN模型中，层次维度的聚合函数为上一层的节点表示；而在JKNet[10]中，层次维度的聚合函数可以设定为LSTM[11]。 消息函数ϕ(⋅)：结合起始节点和目标节点，以及边的特征，生成用于消息传递的消息向量。 节点维度的聚合函数ρN(⋅)：汇集了来自邻居节点N(v)的所有消息向量。值得注意的是，N(v)也可以有不同的实现。例如，在GCN中为所有邻居节点，而在GraphSage[9]中为邻居节点的子集。 更新函数ψ(⋅)：用于聚合节点自身在上一层和当前层的表示。 不难看出，上述计算范式可以覆盖当前大多数GNN模型。在工程实践中，我们将上述函数进一步分拆细化，预先提供了多种高效的实现。通过配置选项即可实现不同的组合搭配，从而实现多数主流的GNN模型。 3.2 异质图相比于同质图，异质图(Heterogeneous Graph)扩充了节点类型和边类型。 比如，学术引用网络[13]中包含论文、作者、机构等类型的节点，节点直接通过“论文引用其他论文”、“作者撰写论文”、“作者属于机构”等类型的边相连，如下图2所示： 图2 同质图与异质图的比较 我们把异质图视为多个二分图的叠加，每一个二分图对应于一种边类型。上述的学术引用网络可以表示成“论文-引用-论文”、“作者-撰写-论文”、“作者-属于-机构”，共计三个二分图，同质图的GNN模型框架稍加修改即可在二分图上应用。 在此基础上，一个节点在不同的二分图中会产生不同的表示。我们进一步提出边类型维度的聚合函数ρR(⋅)，用于聚合节点在不同二分图中的表示（如下图3所示）。框架中同样提供边类型维度聚合函数的多种实现，可以通过配置选项调用。例如，要实现RGCN，可以在二分图上应用GCN，然后在边类型维度上取平均。 图3 异质图模型框架 3.3 动态图动态图(Dynamic Graph)是指随时间变化的图。与之相对的，上述的同质图和异质图可以称为静态图。动态图上的GNN模型旨在生成给定时间下的节点表示H(t)。根据时间粒度的粗细，动态图可分为离散时间动态图和连续时间动态图。 在离散时间动态图中，时间被划分为多个时间片（例如以天&#x2F;小时划分），每个时间片对应一个静态的图。离散时间动态图的GNN模型通常在每个时间片上单独应用GNN模型，然后聚合节点在不同时间的表征[14]。我们把聚合过程抽象为离散时间维度的聚合函数ρT(⋅)，同样提供预定义的实现。 此外，Tulong框架还提供离散时间动态图数据的加载和管理机制，仅在内存中保留必须的时间片，降低硬件资源的消耗。 图4 离散时间动态图GNN模型框架 在连续时间动态图中，每条边附有时间戳，表示交互事件发生的时刻。相比于静态图，连续时间动态图中的消息函数ϕ(⋅,t,et)还依赖于给定样本的时间戳以及边的时间戳。此外，邻居节点N(v,t)必须与时间有关，例如邻居节点中不能出现t时刻之后才出现的节点。 针对此问题，我们开发了多种连续时间动态图上的邻居节点采样器，可以在指定的时间范围内，高效地采样邻居节点。 图5 连续时间动态图GNN模型框架 以上分析了同质图、异质图和动态图的计算范式，我们从中抽取出通用的函数（算子），包括消息函数、聚合函数、更新函数、邻居节点函数，并给出多种预定义的实现。框架用户通过配置选项即可拼装组合算子，从而实现需要的GNN模型。 4. 训练流程框架训练GNN模型通常包括加载数据、定义GNN模型、训练和评测、导出模型等流程。 框架被分为两层：基础组件和流程组件。 基础组件聚焦于单一的功能，例如图数据组件只维护内存中的图数据结构，不提供图上的采样或张量计算功能；图上的采样功能通过图采样器来提供。 流程组件通过组装基础组件提供较为完整的数据预处理、训练和评测流程，例如训练流程组合了图数据、图采样器、GNN模型等组件，提供完整的训练功能。 图6 训练流程框架 更上一层，我们提供多种流程配置模板和GNN模型模板。模板对外暴露若干超参，例如训练数据路径、模型类型、学习率等参数，结合用户指定的超参后就可以完整定义一次训练任务。换言之，基于模板和参数即可完整复现一次GNN模型实验。框架将会解析这些配置，并生成可执行的应用。 举例来说，用户可以选择GraphSage模型的配置模板，以及链接预测任务的训练模板，指定模型层数和维度，以及训练评测数据路径，即可开始训练基于GraphSage的链接预测模型。 5. 性能优化高效训练数十亿乃至百亿边规模的GNN模型 5.1 图数据结构优化我们设计实现了更为紧凑的图数据结构，提升了单机可承载的图规模。 我们借助图压缩技术降低内存占用。不同于常规的图压缩问题，GNN的场景下需要支持随机查询操作。例如，查询给定节点的邻居节点；判断给定的两个节点在图中是否相连。 我们对此提出的解决方案包括两部分： 图数据预处理和压缩：首先分析图的统计特征，以轻量级的方式对节点进行聚类和重新编号，以期让编号接近的节点在领域结构上也更为相似。随后调整边的顺序，对边数据进行分块和编码，产生“节点-分块索引-邻接边”层次的图数据文件（如下图7所示）。最后，如果数据包含节点特征或边特征，还需要将特征与压缩后的图对齐。 图7 压缩后的图数据结构 图的随机查询：查询操作分为两步：首先定位所需的边数据块，然后在内存中解压数据块，读取所查询的数据。例如在查询节点u和v是否相连时，首先根据两个节点的编号计算边数据块的地址，解压数据块后获得少量候选邻接边（通常不多于16条），然后查找是否包含边(u,v)。 5.2 子图采样优化子图采样是GNN模型训练的性能瓶颈之一。 我们分别针对静态图和动态图，设计实现了多种高效的邻居节点采样算法。主要的优化手段包括： 随机数发生器：相比于通信加密等应用，图上的采样对于随机数发生器的“随机性”并没有苛刻的要求。我们适当放松了对随机性的要求，设计实现了更快速的随机数发生器，可以直接应用在有放回和无放回的采样操作中。 概率量化：有权重的采样中，在可接受的精度损失下，将浮点数表示的概率值量化为更为紧凑的整型。不仅降低了采样器的内存消耗，也可以将部分浮点数操作转化为整型操作。 时间戳索引：动态图的子图采样操作要求限定边的时间范围。采样器首先对边上的时间戳构建索引，采样时先根据索引确定可采样边的范围，然后再执行实际的采样操作。 6. 图学习平台 数据集管理：从业务数据构造图是模型开发的第一步，图学习平台提供基于Spark的构图功能，可以将Hive中存储的业务数据转化为Tulong自定义的图数据格式。业务数据经常以事件日志的方式存储，如何从中抽象出图，有大量的选择。例如，在推荐场景中，业务日志包含用户对商家的点击和下单记录，除了把”用户-点击-商家”的事件刻画为图以外，还可以考虑刻画短时间内共同点击商家的关系。除此之外，还可以引入额外的数据，比如商家的地理位置、商家在售的菜品等。究竟使用何种构图方案，需要经过实验才能确定。对此，图学习平台提供了图形化的构图工具（如下图10所示），帮助用户梳理构图方案；同时还提供图数据集的版本管理，方便比较不同构图方案的效果。 实验管理：确定图数据之后，建模方案和训练策略是影响最终效果的关键。例如，应该用何种GNN模型？损失函数如何选取？模型超参和训练超参如何确定？这些问题也需要经过大量实验才能回答。基于Tulong框架，建模方案和训练策略可以通过一组配置来控制。图学习平台提供配置的可视化编辑器和版本管理功能，方便比较不同的方案的优劣。 流程管理：有了图数据集和建模&#x2F;训练方案后，还需要让整个流程自动化。这是模型上线的必要条件，同时也有利于团队成员复现彼此的方案。图学习平台针对常见的“构图、训练、评测、导出”流程提供了自动化的调度，在适当的时候可以复用前一阶段的结果，以提升效率。例如，如果数据集的定义没有变化，可以跳过Spark构图阶段直接使用已有的图数据。此外，针对模型上线的需求，平台提供构图和建模方案整合和定时调度等功能。 9. 参考文献 [1] Cai, Hongyun, Vincent W. Zheng, and Kevin Chen-Chuan Chang. “A comprehensive survey of graph embedding: Problems, techniques, and applications.” IEEE Transactions on Knowledge and Data Engineering 30, no. 9 (2018): 1616-1637. [2] Perozzi, Bryan, Rami Al-Rfou, and Steven Skiena. “Deepwalk: Online learning of social representations.” In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 701-710. 2014. [3] Grover, Aditya, and Jure Leskovec. “Node2vec: Scalable feature learning for networks.” In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 855-864. 2016. [4] Kipf, Thomas N., and Max Welling. “Semi-supervised classification with graph convolutional networks.” International Conference on Learning Representations (2017). [5] Wu, Zonghan, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S. Yu Philip. “A comprehensive survey on graph neural networks.” IEEE transactions on neural networks and learning systems 32, no. 1 (2020): 4-24. [6] https://github.com/pyg-team/pytorch_geometric [7] https://www.dgl.ai/ [8] Chen, Jie, Tengfei Ma, and Cao Xiao. “FastGCN: Fast Learning with Graph Convolutional Networks via Importance Sampling.” In International Conference on Learning Representations (2018). [9] Hamilton, Will, Zhitao Ying, and Jure Leskovec. “Inductive representation learning on large graphs.” Advances in neural information processing systems 30 (2017). [10] Xu, Keyulu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. “Representation learning on graphs with jumping knowledge networks.” In International Conference on Machine Learning, pp. 5453-5462. PMLR, 2018. [11] Hochreiter, Sepp, and Jürgen Schmidhuber. “Long short-term memory.” Neural computation 9, no. 8 (1997): 1735-1780. [12] https://github.com/snap-stanford/GraphGym [13] https://ogb.stanford.edu/ [14] Sankar, Aravind, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. “Dysat: Deep neural representation learning on dynamic graphs via self-attention networks.” In Proceedings of the 13th International Conference on Web Search and Data Mining, pp. 519-527. 2020. [15] Xu, Da, Chuanwei Ruan, Evren Korpeoglu, Sushant Kumar, and Kannan Achan. “Inductive representation learning on temporal graphs.” International Conference on Learning Representations (2020). [16] https://github.com/dmlc/dgl/tree/master/dglgo [17] Wang, Minjie, Da Zheng, Zihao Ye, Quan Gan, Mufei Li, Xiang Song, Jinjing Zhou et al. “Deep graph library: A graph-centric, highly-performant package for graph neural networks.” arXiv preprint arXiv:1909.01315 (2019). [18] Fey, M. and Lenssen, J. E. “Fast graph representation learning with PyTorch Geometric.” In ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019. [19] Schlichtkrull, Michael, Thomas N. Kipf, Peter Bloem, Rianne van den Berg, Ivan Titov, and Max Welling. “Modeling relational data with graph convolutional networks.” In European semantic web conference, pp. 593-607. Springer, Cham, 2018.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"windowsterminal wt 设置为默认命令行","slug":"windowsterminal-wt-设置为默认命令行","date":"2024-02-18T04:29:29.000Z","updated":"2024-02-18T04:34:46.594Z","comments":true,"path":"2024/02/18/windowsterminal-wt-设置为默认命令行/","link":"","permalink":"http://example.com/2024/02/18/windowsterminal-wt-%E8%AE%BE%E7%BD%AE%E4%B8%BA%E9%BB%98%E8%AE%A4%E5%91%BD%E4%BB%A4%E8%A1%8C/","excerpt":"","text":"win+s 搜索终端，进入wt ctrl+,进入设置 设置默认配置文件用cmd：设置-启动-默认配置文件 设置为默认的终端：设置-启动-默认终端应用程序 设置主题：wt是以配置文件为单元设置默认值的，以设置cmd的默认主题为例，设置-（左边栏”配置文件”列表）命令提示符然后在右边进行设置，设置主题的话就点击外观","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"管理wsl LxRunOffline 查看wsl所在目录 移动wsl到非c盘","slug":"管理wsl-LxRunOffline-查看wsl所在目录-移动wsl到非c盘","date":"2024-02-18T04:26:23.000Z","updated":"2024-02-18T04:26:38.551Z","comments":true,"path":"2024/02/18/管理wsl-LxRunOffline-查看wsl所在目录-移动wsl到非c盘/","link":"","permalink":"http://example.com/2024/02/18/%E7%AE%A1%E7%90%86wsl-LxRunOffline-%E6%9F%A5%E7%9C%8Bwsl%E6%89%80%E5%9C%A8%E7%9B%AE%E5%BD%95-%E7%A7%BB%E5%8A%A8wsl%E5%88%B0%E9%9D%9Ec%E7%9B%98/","excerpt":"","text":"LxRunOffline 在cmd中直接运行 LxRunOffline.exe 将输出help信息 查看WSL所在目录 查看子系统所在目录 LxRunOffline.exe get-dir -n Ubuntu-18.04 移动到非C盘 参考https://learnku.com/articles/46234https://blog.csdn.net/yihuajack/article/details/119915303 停止运行中要迁移的系统 wsl --shutdown 新建目标目录并授权 icacls D:\\wsl\\installed /grant &quot;cnguu:(OI)(CI)(F)&quot; 目标目录：D:\\wsl\\installed用户名：cnguu此步骤失败了似乎没事 迁移系统 .\\LxRunOffline move -n Ubuntu-18.04 -d D:\\wsl\\installed\\Ubuntu-18.04","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"ssh连接WSL ssh连接WSL中的docker","slug":"ssh连接WSL-ssh连接WSL中的docker","date":"2024-02-18T04:23:54.000Z","updated":"2024-02-18T04:24:16.260Z","comments":true,"path":"2024/02/18/ssh连接WSL-ssh连接WSL中的docker/","link":"","permalink":"http://example.com/2024/02/18/ssh%E8%BF%9E%E6%8E%A5WSL-ssh%E8%BF%9E%E6%8E%A5WSL%E4%B8%AD%E7%9A%84docker/","excerpt":"","text":"ssh连接WSL 参考https://cloud.tencent.com/developer/article/1538305 sudo vim /etc/ssh/sshd_config，把PasswordAuthentication no改成PasswordAuthentication yes 重启ssh服务sudo service ssh restart ifconfig查看ip（inet即ip地址，不为127.0.0.1的那个网卡的inet即所求），然后ssh &lt;usrname&gt;@&lt;ip&gt;即可连接 ssh连接WSL中的docker假设在wsl中可以以如下配置连接tigergraph docker Host tigerg HostName localhost User tigergraph Port 14022 则在pc上对~/.ssh/config新增如下配置（实际上是把wsl作为跳板机） # my dell pc windows wsl Host wsl # 参考&quot;ssh连接WSL&quot;中的配置 HostName 172.17.165.64 User yuanzhiqiu # tigergraph docker on my dell wsl Host tigerg HostName localhost User tigergraph Port 14022 ProxyCommand ssh -W %h:%p wsl # 看这里，通过跳板机 然后即可在本机上ssh tigerg连接上wsl上的docker注意连接之前，wsl上要先启动docker服务和对应容器（sudo service docker start, docker start tigergraph） 免密登录配置好本机-&gt;wsl，本机-&gt;wsl上的docker容器，即可ssh tigerg免密：将本机的公匙传入wsl和wsl上的docker容器中的~/.ssh/authorized_keys wsl -l -v 或者 下载工具LxRunOffline（一个非常强大的管理子系统的工具），下载并解压后，在解压目录中打开 PowerShell 查看已安装的子系统 LxRunOffline.exe list","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"新wsl安装开发环境 linux生产环境","slug":"新wsl安装开发环境-linux生产环境","date":"2024-02-18T04:16:05.000Z","updated":"2024-02-18T07:46:20.862Z","comments":true,"path":"2024/02/18/新wsl安装开发环境-linux生产环境/","link":"","permalink":"http://example.com/2024/02/18/%E6%96%B0wsl%E5%AE%89%E8%A3%85%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83-linux%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83/","excerpt":"","text":"如果默认是用root登录，则设定下默认用户搜我的博客 默认用户 如果登录上去发现命令行无色（是&#x2F;bin&#x2F;sh）或者想改默认命令行程序搜我的博客 设定默认shell 换源搜我的博客 ubuntu换源 文件传输：WSL中访问本机文件/mnt目录下的目录即对应本机的各个盘 vscode打开WSL中的目录本机的vscode安装WSL插件，然后ctrl+shift+p打开控制面板输入connect to wsl c++sudo apt-get install build-essential gdb cmake linux performance toolsudo apt-get install sysstat bcc-tools bpftrace linux-tools-common linux-tools-$(uname -r) iproute2 msr-tools git clone https://github.com/brendangregg/msr-cloud-tools git clone https://github.com/brendangregg/bpf-perf-tools-book","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"linux新建用户 设定默认shell 给sudo","slug":"linux新建用户-设定默认shell-给sudo","date":"2024-02-18T04:11:48.000Z","updated":"2024-02-18T04:12:26.602Z","comments":true,"path":"2024/02/18/linux新建用户-设定默认shell-给sudo/","link":"","permalink":"http://example.com/2024/02/18/linux%E6%96%B0%E5%BB%BA%E7%94%A8%E6%88%B7-%E8%AE%BE%E5%AE%9A%E9%BB%98%E8%AE%A4shell-%E7%BB%99sudo/","excerpt":"","text":"创建用户创建一个拥有主目录（-m）和默认shell（-s）是/usr/bin/zsh的用户 useradd -m -s /usr/bin/zsh username useradd -m -s &#x2F;bin&#x2F;bash yuanzhiqiu 然后你将为该用户添加一个密码： passwd username sudo需要的话，给sudo：修改/etc/sudoers文件：在行root ALL=(ALL:ALL) ALL下添加一行 yuanzhiqiu ALL=(ALL:ALL) ALL 编辑该文件的方法： visudo 或用vim：编辑好之后:w !sudo tee %，ok退出之后文件是被修改了的 Using vim to force edit a file when you opened without permissions","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"wox插件推荐 除了自带的插件外的插件","slug":"wox插件推荐-除了自带的插件外的插件","date":"2024-02-18T02:48:35.000Z","updated":"2024-02-18T02:50:48.012Z","comments":true,"path":"2024/02/18/wox插件推荐-除了自带的插件外的插件/","link":"","permalink":"http://example.com/2024/02/18/wox%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90-%E9%99%A4%E4%BA%86%E8%87%AA%E5%B8%A6%E7%9A%84%E6%8F%92%E4%BB%B6%E5%A4%96%E7%9A%84%E6%8F%92%E4%BB%B6/","excerpt":"","text":"插件管理在alt+space出来的框中键入：插件安装：wpm install &lt;plugin_name&gt; 插件卸载：wpm uninstall &lt;plugin_name&gt; 插件管理（enable，插件设置，查看文档等）settings然后plugin选项卡 插件列表Timer设置倒计时，时间到了会通过wox的提示来提醒 http://www.wox.one/plugin/243","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win注册表编辑","slug":"win注册表编辑","date":"2024-02-18T02:02:36.000Z","updated":"2024-02-18T02:04:31.291Z","comments":true,"path":"2024/02/18/win注册表编辑/","link":"","permalink":"http://example.com/2024/02/18/win%E6%B3%A8%E5%86%8C%E8%A1%A8%E7%BC%96%E8%BE%91/","excerpt":"","text":"方法一： win+R，输入regedit，进入注册表编辑GUI界面 顶部路径那里，可以直接输入路径，或者输入前缀，会自动提示和切换到路径 方法二：新建文件xxx.reg，按需添加内容，双击运行该文件","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"linux硬件配置信息 硬件环境 cpu信息 内存信息 缓存信息 磁盘信息","slug":"linux硬件配置信息-硬件环境-cpu信息-内存信息-缓存信息-磁盘信息","date":"2024-02-17T13:18:40.000Z","updated":"2024-02-17T13:30:25.658Z","comments":true,"path":"2024/02/17/linux硬件配置信息-硬件环境-cpu信息-内存信息-缓存信息-磁盘信息/","link":"","permalink":"http://example.com/2024/02/17/linux%E7%A1%AC%E4%BB%B6%E9%85%8D%E7%BD%AE%E4%BF%A1%E6%81%AF-%E7%A1%AC%E4%BB%B6%E7%8E%AF%E5%A2%83-cpu%E4%BF%A1%E6%81%AF-%E5%86%85%E5%AD%98%E4%BF%A1%E6%81%AF-%E7%BC%93%E5%AD%98%E4%BF%A1%E6%81%AF-%E7%A3%81%E7%9B%98%E4%BF%A1%E6%81%AF/","excerpt":"","text":"cpulscpu cpu型号cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 8 Intel(R) Xeon(R) CPU E5410 @ 2.33GHz(8个逻辑CPU, 以及CPU型号) 逻辑核数目cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l 物理核数目cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l 内存free -m cat /proc/meminfo 磁盘df -h 关注/目录的大小 缓存仅需知道缓存大小 lscpu 缓存行大小 cat /sys/devices/system/cpu/cpu0/cache/ getconf -a | grep CACHE linux内核uname -a cat /proc/version linux系统版本cat /etc/redhat-release lsb_release -a cat /etc/issue 机器型号（机器硬件型号）dmidecode | grep &quot;Product Name&quot; dmidecode","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"cachegrind cache profile 缓存profile","slug":"cachegrind-cache-profile-缓存profile","date":"2024-02-17T12:50:44.000Z","updated":"2024-02-17T14:01:35.542Z","comments":true,"path":"2024/02/17/cachegrind-cache-profile-缓存profile/","link":"","permalink":"http://example.com/2024/02/17/cachegrind-cache-profile-%E7%BC%93%E5%AD%98profile/","excerpt":"","text":"https://wwwcdf.pd.infn.it/valgrind/cg_main.html 4 Cachegrind: a cache-miss profilervalgrind --tool=cachegrind Detailed technical documentation on how Cachegrind works is available here. If you want to know how to use it, you only need to read this page. 4.1 [read here!] Cache profilingCachegrind is a tool for doing cache simulations and annotating your source line-by-line with the number of cache misses. In particular, it records: L1 instruction cache reads (references) and misses; L1 data cache reads and read misses, writes and write misses; L2 unified cache reads and read misses, writes and writes misses. On a modern x86 machine, an L1 miss will typically cost around 10 cycles, and an L2 miss can cost as much as 200 cycles. Detailed cache profiling can be very useful for improving the performance of your program. Also, since one instruction cache read is performed per instruction executed, you can find out how many instructions are executed per line, which can be useful for traditional profiling and test coverage. 4.2 Overviewcompile with debugging info (the -g flag). turn optimisation on, since you should profile your program as it will be normally run. then Run your program with valgrind --tool=cachegrind in front of the normal command line invocation. When the program finishes, Cachegrind will print summary cache statistics. It also collects line-by-line information in a file cachegrind.out.pid , where pid is the program’s process id. Generate a function-by-function summary, and possibly annotate source files, using the supplied cg_annotate program. Source files to annotate can be specified manually, or manually on the command line, or “interesting” source files can be annotated automatically with the --auto=yes option. You can annotate C&#x2F;C++ files or assembly language files equally easily. The steps are described in detail in the following sections. 4.3 Cache simulation specificsa split L1 cache and a unified L2 cache. split：data cache和instruction cache分开 Write-allocate: when a write miss occurs, the block written to is brought into the D1 cache. Most modern caches have this property. Bit-selection hash function: the line(s) in the cache to which a memory block maps is chosen by the middle bits M–(M+N-1) of the byte address, where: line size &#x3D; 2^M bytes (cache size &#x2F; line size) &#x3D; 2^N bytes Inclusive L2 cache: the L2 cache replicates all the entries of the L1 cache. This is standard on Pentium chips, but AMD Athlons use an exclusive L2 cache that only holds blocks evicted from L1. Ditto AMD Durons and most modern VIAs. The cache configuration simulated (cache size, associativity and line size) is determined automagically using the CPUID instruction. If you have an old machine that (a) doesn’t support the CPUID instruction, or (b) supports it in an early incarnation that doesn’t give any cache information, then Cachegrind will fall back to using a default configuration (that of a model 3&#x2F;4 Athlon). Cachegrind will tell you if this happens. You can manually specify one, two or all three levels (I1&#x2F;D1&#x2F;L2) of the cache from the command line using the --I1, --D1 and --L2 options. Other noteworthy behaviour: References that straddle(跨坐) two cache lines are treated as follows: If both blocks hit –&gt; counted as one hit If one block hits, the other misses –&gt; counted as one miss If both blocks miss –&gt; counted as one miss (not two) Instructions that modify a memory location (eg. inc and dec ) are counted as doing just a read, ie. a single data reference. This may seem strange, but since the write can never cause a miss (the read guarantees the block is in the cache) it’s not very interesting. Thus it measures not the number of times the data cache is accessed, but the number of times a data cache miss could occur (这句话啥意思？). If you are interested in simulating a cache with different properties, it is not particularly hard to write your own cache simulator, or to modify the existing ones in vg_cachesim_I1.c, vg_cachesim_D1.c, vg_cachesim_L2.c and vg_cachesim_gen.c. We’d be interested to hear from anyone who does. 4.4 Profiling programsTo gather cache profiling information about the program ls -l, invoke Cachegrind like this: valgrind --tool=cachegrind ls -l The program will execute (slowly). Upon completion, summary statistics that look like this will be printed: ==31751== I refs: 27,742,716 ==31751== I1 misses: 276 ==31751== L2 misses: 275 ==31751== I1 miss rate: 0.0% ==31751== L2i miss rate: 0.0% ==31751== ==31751== D refs: 15,430,290 (10,955,517 rd + 4,474,773 wr) ==31751== D1 misses: 41,185 ( 21,905 rd + 19,280 wr) ==31751== L2 misses: 23,085 ( 3,987 rd + 19,098 wr) ==31751== D1 miss rate: 0.2% ( 0.1% + 0.4%) ==31751== L2d miss rate: 0.1% ( 0.0% + 0.4%) ==31751== ==31751== L2 misses: 23,360 ( 4,262 rd + 19,098 wr) ==31751== L2 miss rate: 0.0% ( 0.0% + 0.4%) Cache accesses for instruction fetches are summarised first, giving the number of fetches made (this is the number of instructions executed, which can be useful to know in its own right), the number of I1 misses (L1 instruction missies), and the number of L2 instruction misses. Cache accesses for data follow. The information is similar to that of the instruction fetches, except that the values are also shown split between reads and writes (note each row’s rd and wr values add up to the row’s total). Combined instruction and data figures for the L2 cache follow that. 4.5 【read here】Output fileAs well as printing summary information, Cachegrind also writes line-by-line cache profiling information to a file named cachegrind.out.*pid*. This file is human-readable, but is best interpreted by the accompanying program cg_annotate, described in the next section. Things to note about the cachegrind.out.*pid* file: It is written every time Cachegrind is run, and will overwrite any existing cachegrind.out.*pid* in the current directory (but that won’t happen very often because it takes some time for process ids to be recycled). It can be huge: ls -l generates a file of about 350KB. Browsing a few files and web pages with a Konqueror built with full debugging information generates a file of around 15 MB. Note that older versions of Cachegrind used a log file named cachegrind.out (i.e. no *.pid* suffix). The suffix serves two purposes. Firstly, it means you don’t have to rename old log files that you don’t want to overwrite. Secondly, and more importantly, it allows correct profiling with the --trace-children=yes option of programs that spawn child processes. 4.6 Cachegrind optionsCache-simulation specific options are: --I1=&lt;size&gt;,&lt;associativity&gt;,&lt;line_size&gt; --D1=&lt;size&gt;,&lt;associativity&gt;,&lt;line_size&gt; --L2=&lt;size&gt;,&lt;associativity&gt;,&lt;line_size&gt; [default: uses CPUID for automagic cache configuration] Manually specifies the I1&#x2F;D1&#x2F;L2 cache configuration, where size and line_size are measured in bytes. The three items must be comma-separated, but with no spaces, eg: valgrind --tool=cachegrind --I1=65535,2,64 You can specify one, two or three of the I1&#x2F;D1&#x2F;L2 caches. Any level not manually specified will be simulated using the configuration found in the normal way (via the CPUID instruction, or failing that, via defaults). 4.7 Annotating C&#x2F;C++ programsBefore using cg_annotate, it is worth widening your window to be at least 120-characters wide if possible, as the output lines can be quite long. To get a function-by-function summary, run cg_annotate --*pid* in a directory containing a cachegrind.out.*pid* file. The --*pid* is required so that cg_annotate knows which log file to use when several are present. The output looks like this: -------------------------------------------------------------------------------- I1 cache: 65536 B, 64 B, 2-way associative D1 cache: 65536 B, 64 B, 2-way associative L2 cache: 262144 B, 64 B, 8-way associative Command: concord vg_to_ucode.c Events recorded: Ir I1mr I2mr Dr D1mr D2mr Dw D1mw D2mw Events shown: Ir I1mr I2mr Dr D1mr D2mr Dw D1mw D2mw Event sort order: Ir I1mr I2mr Dr D1mr D2mr Dw D1mw D2mw Threshold: 99% Chosen for annotation: Auto-annotation: on -------------------------------------------------------------------------------- Ir I1mr I2mr Dr D1mr D2mr Dw D1mw D2mw -------------------------------------------------------------------------------- 27,742,716 276 275 10,955,517 21,905 3,987 4,474,773 19,280 19,098 PROGRAM TOTALS -------------------------------------------------------------------------------- Ir I1mr I2mr Dr D1mr D2mr Dw D1mw D2mw file:function -------------------------------------------------------------------------------- 8,821,482 5 5 2,242,702 1,621 73 1,794,230 0 0 getc.c:_IO_getc 5,222,023 4 4 2,276,334 16 12 875,959 1 1 concord.c:get_word 2,649,248 2 2 1,344,810 7,326 1,385 . . . vg_main.c:strcmp 2,521,927 2 2 591,215 0 0 179,398 0 0 concord.c:hash 2,242,740 2 2 1,046,612 568 22 448,548 0 0 ctype.c:tolower 1,496,937 4 4 630,874 9,000 1,400 279,388 0 0 concord.c:insert 897,991 51 51 897,831 95 30 62 1 1 ???:??? 598,068 1 1 299,034 0 0 149,517 0 0 ../sysdeps/generic/lockfile.c:__flockfile 598,068 0 0 299,034 0 0 149,517 0 0 ../sysdeps/generic/lockfile.c:__funlockfile 598,024 4 4 213,580 35 16 149,506 0 0 vg_clientmalloc.c:malloc 446,587 1 1 215,973 2,167 430 129,948 14,057 13,957 concord.c:add_existing 341,760 2 2 128,160 0 0 128,160 0 0 vg_clientmalloc.c:vg_trap_here_WRAPPER 320,782 4 4 150,711 276 0 56,027 53 53 concord.c:init_hash_table 298,998 1 1 106,785 0 0 64,071 1 1 concord.c:create 149,518 0 0 149,516 0 0 1 0 0 ???:tolower@@GLIBC_2.0 149,518 0 0 149,516 0 0 1 0 0 ???:fgetc@@GLIBC_2.0 95,983 4 4 38,031 0 0 34,409 3,152 3,150 concord.c:new_word_node 85,440 0 0 42,720 0 0 21,360 0 0 vg_clientmalloc.c:vg_bogus_epilogue First up is a summary of the annotation options: I1 cache, D1 cache, L2 cache: cache configuration. So you know the configuration with which these results were obtained. Command: the command line invocation of the program under examination. Events recorded: event abbreviations are: Ir : I cache reads (ie. instructions executed) I1mr: I1 cache read misses I2mr: L2 cache instruction read misses Dr : D cache reads (ie. memory reads) D1mr: D1 cache read misses D2mr: L2 cache data read misses Dw : D cache writes (ie. memory writes) D1mw: D1 cache write misses D2mw: L2 cache data write misses Note that D1 total accesses is given by D1mr + D1mw, and that L2 total accesses is given by I2mr + D2mr + D2mw. Events shown: the events shown (a subset of events gathered). This can be adjusted with the --show option. Event sort order: the sort order in which functions are shown. For example, in this case the functions are sorted from highest Ir counts to lowest. If two functions have identical Ir counts, they will then be sorted by I1mr counts, and so on. This order can be adjusted with the --sort option. Note that this dictates the order the functions appear. It is not the order in which the columns appear; that is dictated by the “events shown” line (and can be changed with the --show option). Threshold: cg_annotate by default omits functions that cause very low numbers of misses to avoid drowning you in information. In this case, cg_annotate shows summaries the functions that account for 99% of the Ir counts; Ir is chosen as the threshold event since it is the primary sort event. The threshold can be adjusted with the --threshold option. Chosen for annotation: names of files specified manually for annotation; in this case none. Auto-annotation: whether auto-annotation was requested via the --auto=yes option. In this case no. Then follows summary statistics for the whole program. These are similar to the summary provided when running valgrind --tool=cachegrind. Then follows function-by-function statistics. Each function is identified by a file_name:function_name pair. If a column contains only a dot it means the function never performs that event (eg. the third row shows that strcmp() contains no instructions that write to memory). The name ??? is used if the the file name and&#x2F;or function name could not be determined from debugging information. If most of the entries have the form ???:??? the program probably wasn’t compiled with -g. If any code was invalidated (either due to self-modifying code or unloading of shared objects) its counts are aggregated into a single cost centre written as (discarded):(discarded). It is worth noting that functions will come from three types of source files: From the profiled program (concord.c in this example). From libraries (eg. getc.c) From Valgrind’s implementation of some libc functions (eg. vg_clientmalloc.c:malloc). These are recognisable because the filename begins with vg_, and is probably one of vg_main.c, vg_clientmalloc.c or vg_mylibc.c. There are two ways to annotate source files – by choosing them manually, or with the --auto=yes option. To do it manually, just specify the filenames as arguments to cg_annotate. For example, the output from running cg_annotate concord.c for our example produces the same output as above followed by an annotated version of concord.c, a section of which looks like: -------------------------------------------------------------------------------- -- User-annotated source: concord.c -------------------------------------------------------------------------------- Ir I1mr I2mr Dr D1mr D2mr Dw D1mw D2mw [snip] . . . . . . . . . void init_hash_table(char *file_name, Word_Node *table[]) 3 1 1 . . . 1 0 0 &#123; . . . . . . . . . FILE *file_ptr; . . . . . . . . . Word_Info *data; 1 0 0 . . . 1 1 1 int line = 1, i; . . . . . . . . . 5 0 0 . . . 3 0 0 data = (Word_Info *) create(sizeof(Word_Info)); . . . . . . . . . 4,991 0 0 1,995 0 0 998 0 0 for (i = 0; i &lt; TABLE_SIZE; i++) 3,988 1 1 1,994 0 0 997 53 52 table[i] = NULL; . . . . . . . . . . . . . . . . . . /* Open file, check it. */ 6 0 0 1 0 0 4 0 0 file_ptr = fopen(file_name, &quot;r&quot;); 2 0 0 1 0 0 . . . if (!(file_ptr)) &#123; . . . . . . . . . fprintf(stderr, &quot;Couldn&#39;t open &#39;%s&#39;.\\n&quot;, file_name); 1 1 1 . . . . . . exit(EXIT_FAILURE); . . . . . . . . . &#125; . . . . . . . . . 165,062 1 1 73,360 0 0 91,700 0 0 while ((line = get_word(data, line, file_ptr)) != EOF) 146,712 0 0 73,356 0 0 73,356 0 0 insert(data-&gt;;word, data-&gt;line, table); . . . . . . . . . 4 0 0 1 0 0 2 0 0 free(data); 4 0 0 1 0 0 2 0 0 fclose(file_ptr); 3 0 0 2 0 0 . . . &#125; (Although column widths are automatically minimised, a wide terminal is clearly useful.) Each source file is clearly marked (User-annotated source) as having been chosen manually for annotation. If the file was found in one of the directories specified with the -I&#x2F;--include option, the directory and file are both given. Each line is annotated with its event counts. Events not applicable for a line are represented by a &#96;.’; this is useful for distinguishing between an event which cannot happen, and one which can but did not. Sometimes only a small section of a source file is executed. To minimise uninteresting output, Valgrind only shows annotated lines and lines within a small distance of annotated lines. Gaps are marked with the line numbers so you know which part of a file the shown code comes from, eg: (figures and code for line 704) -- line 704 ---------------------------------------- -- line 878 ---------------------------------------- (figures and code for line 878) The amount of context to show around annotated lines is controlled by the --context option. To get automatic annotation, run cg_annotate --auto=yes. cg_annotate will automatically annotate every source file it can find that is mentioned in the function-by-function summary. Therefore, the files chosen for auto-annotation are affected by the --sort and --threshold options. Each source file is clearly marked (Auto-annotated source) as being chosen automatically. Any files that could not be found are mentioned at the end of the output, eg: -------------------------------------------------------------------------------- The following files chosen for auto-annotation could not be found: -------------------------------------------------------------------------------- getc.c ctype.c ../sysdeps/generic/lockfile.c This is quite common for library files, since libraries are usually compiled with debugging information, but the source files are often not present on a system. If a file is chosen for annotation both manually and automatically, it is marked as User-annotated source. Use the -I/--include option to tell Valgrind where to look for source files if the filenames found from the debugging information aren’t specific enough. Beware that cg_annotate can take some time to digest large cachegrind.out.*pid* files, e.g. 30 seconds or more. Also beware that auto-annotation can produce a lot of output if your program is large! 4.8 Annotating assembler programsValgrind can annotate assembler programs too, or annotate the assembler generated for your C program. Sometimes this is useful for understanding what is really happening when an interesting line of C code is translated into multiple instructions. To do this, you just need to assemble your .s files with assembler-level debug information. gcc doesn’t do this, but you can use the GNU assembler with the --gstabs option to generate object files with this information, eg: as --gstabs foo.s You can then profile and annotate source files in the same way as for C&#x2F;C++ programs. 4.9 cg_annotate options --*pid* Indicates which cachegrind.out.*pid* file to read. Not actually an option – it is required. -h, --help -v, --version Help and version, as usual. --sort=A,B,C [default: order in cachegrind.out.pid ] Specifies the events upon which the sorting of the function-by-function entries will be based. Useful if you want to concentrate on eg. I cache misses (--sort=I1mr,I2mr), or D cache misses (--sort=D1mr,D2mr), or L2 misses (--sort=D2mr,I2mr). --show=A,B,C [default: all, using order in cachegrind.out.pid ] Specifies which events to show (and the column order). Default is to use all present in the cachegrind.out.*pid* file (and use the order in the file). --threshold=X [default: 99%] Sets the threshold for the function-by-function summary. Functions are shown that account for more than X% of the primary sort event. If auto-annotating, also affects which files are annotated. Note: thresholds can be set for more than one of the events by appending any events for the --sort option with a colon and a number (no spaces, though). E.g. if you want to see the functions that cover 99% of L2 read misses and 99% of L2 write misses, use this option: --sort=D2mr:99,D2mw:99 --auto=no [default] --auto=yes When enabled, automatically annotates every file that is mentioned in the function-by-function summary that can be found. Also gives a list of those that couldn’t be found. --context=N [default: 8] Print N lines of context before and after each annotated line. Avoids printing large sections of source files that were not executed. Use a large number (eg. 10,000) to show all source lines. -I=&lt;dir&gt;, --include=&lt;dir&gt; [default: empty string] Adds a directory to the list in which to search for files. Multiple -I&#x2F;–include options can be given to add multiple directories. 4.10 WarningsThere are a couple of situations in which cg_annotate issues warnings. If a source file is more recent than the cachegrind.out.pid file. This is because the information in cachegrind.out.pid is only recorded with line numbers, so if the line numbers change at all in the source (eg. lines added, deleted, swapped), any annotations will be incorrect. If information is recorded about line numbers past the end of a file. This can be caused by the above problem, ie. shortening the source file while using an old cachegrind.out.*pid* file. If this happens, the figures for the bogus lines are printed anyway (clearly marked as bogus) in case they are important. 4.11 Things to watch out forSome odd things that can occur during annotation: If annotating at the assembler level, you might see something like this: 1 0 0 . . . . . . leal -12(%ebp),%eax 1 0 0 . . . 1 0 0 movl %eax,84(%ebx) 2 0 0 0 0 0 1 0 0 movl $1,-20(%ebp) . . . . . . . . . .align 4,0x90 1 0 0 . . . . . . movl $.LnrB,%eax 1 0 0 . . . 1 0 0 movl %eax,-16(%ebp) How can the third instruction be executed twice when the others are executed only once? As it turns out, it isn’t. Here’s a dump of the executable, using objdump -d : 8048f25: 8d 45 f4 lea 0xfffffff4(%ebp),%eax 8048f28: 89 43 54 mov %eax,0x54(%ebx) 8048f2b: c7 45 ec 01 00 00 00 movl $0x1,0xffffffec(%ebp) 8048f32: 89 f6 mov %esi,%esi 8048f34: b8 08 8b 07 08 mov $0x8078b08,%eax 8048f39: 89 45 f0 mov %eax,0xfffffff0(%ebp) Notice the extra mov %esi,%esi instruction. Where did this come from? The GNU assembler inserted it to serve as the two bytes of padding needed to align the movl $.LnrB,%eax instruction on a four-byte boundary, but pretended it didn’t exist when adding debug information. Thus when Valgrind reads the debug info it thinks that the movl $0x1,0xffffffec(%ebp) instruction covers the address range 0x8048f2b–0x804833 by itself, and attributes the counts for the mov %esi,%esi to it. Inlined functions can cause strange results in the function-by-function summary. If a function inline_me() is defined in foo.h and inlined in the functions f1() , f2() and f3() in bar.c , there will not be a foo.h:inline_me() function entry. Instead, there will be separate function entries for each inlining site, ie. foo.h:f1() , foo.h:f2() and foo.h:f3() . To find the total counts for foo.h:inline_me() , add up the counts from each entry. The reason for this is that although the debug info output by gcc indicates the switch from bar.c to foo.h, it doesn’t indicate the name of the function in foo.h, so Valgrind keeps using the old one. Sometimes, the same filename might be represented with a relative name and with an absolute name in different parts of the debug info, eg: /home/user/proj/proj.h and ../proj.h . In this case, if you use auto-annotation, the file will be annotated twice with the counts split between the two. Files with more than 65,535 lines cause difficulties for the stabs debug info reader. This is because the line number in the struct nlist defined in a.out.h under Linux is only a 16-bit value. Valgrind can handle some files with more than 65,535 lines correctly by making some guesses to identify line number overflows. But some cases are beyond it, in which case you’ll get a warning message explaining that annotations for the file might be incorrect. If you compile some files with -g and some without, some events that take place in a file without debug info could be attributed to the last line of a file with debug info (whichever one gets placed before the non-debug-info file in the executable). This list looks long, but these cases should be fairly rare. Note: stabs is not an easy format to read. If you come across bizarre annotations that look like might be caused by a bug in the stabs reader, please let us know. 4.12 AccuracyValgrind’s cache profiling has a number of shortcomings: It doesn’t account for kernel activity – the effect of system calls on the cache contents is ignored. It doesn’t account for other process activity (although this is probably desirable when considering a single program). It doesn’t account for virtual-to-physical address mappings; hence the entire simulation is not a true representation of what’s happening in the cache. It doesn’t account for cache misses not visible at the instruction level, eg. those arising from TLB misses, or speculative execution. Valgrind’s custom threads implementation will schedule threads differently to the standard one. This could warp the results for threaded programs. The instructions bts , btr and btc will incorrectly be counted as doing a data read if both the arguments are registers, eg: btsl %eax, %edx This should only happen rarely. FPU instructions with data sizes of 28 and 108 bytes (e.g. fsave) are treated as though they only access 16 bytes. These instructions seem to be rare so hopefully this won’t affect accuracy much. Another thing worth nothing is that results are very sensitive. Changing the size of the valgrind.so file, the size of the program being profiled, or even the length of its name can perturb the results. Variations will be small, but don’t expect perfectly repeatable results if your program changes at all. While these factors mean you shouldn’t trust the results to be super-accurate, hopefully they should be close enough to be useful. 4.13 Todo Program start-up&#x2F;shut-down calls a lot of functions that aren’t interesting and just complicate the output. Would be nice to exclude these somehow.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win11右键菜单管理 右键菜单快捷键管理","slug":"win11右键菜单管理-右键菜单快捷键管理","date":"2024-02-17T11:09:51.000Z","updated":"2024-02-18T02:23:19.242Z","comments":true,"path":"2024/02/17/win11右键菜单管理-右键菜单快捷键管理/","link":"","permalink":"http://example.com/2024/02/17/win11%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95%E7%AE%A1%E7%90%86-%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95%E5%BF%AB%E6%8D%B7%E9%94%AE%E7%AE%A1%E7%90%86/","excerpt":"","text":"https://blog.csdn.net/qq_42951560/article/details/123507617https://zhuanlan.zhihu.com/p/638686816 步骤： 通过ContextMenuManager管理右键菜单，或找到右键菜单某项目（比如”在terminal中打开”）所在的注册表项目 win10的话有确定的注册表路径，win11不太行，得借助工具，这个工具无需安装，github高星，可信任 想修改或添加快捷键：如想新增快捷键F：修改值，在原先的名字后面新增(&amp;F) 修改注册表后点击 ContextMenuManager 顶部的刷新，在修改某些条目之后 ContextMenuManager 可能会提示要重启资源管理器，点击提示处的刷新图标 上述步骤不行的：win11修改”在terminal中打开”的快捷键：思路：在注册表中添加项目 https://blog.csdn.net/qq_42659660/article/details/123465415 ， 新建文件xxx.reg，内容如下，然后双击该文件（这会修改注册表） 格式说明：@&#x3D;是设定项的值，;开头是注释 Windows Registry Editor Version 5.00 [HKEY_CLASSES_ROOT\\directory\\background\\shell\\cmdhere] @=&quot;在此打开终端(&amp;T)&quot; ; 设定条目文本（在此打开终端(T)）和快捷键（T） &quot;Icon&quot;=&quot;C:\\\\Windows\\\\System32\\\\cmd.exe&quot; ; 设定图标 [HKEY_CLASSES_ROOT\\directory\\background\\shell\\cmdhere\\command] @=&quot;cmd.exe /s /k pushd \\&quot;%V\\&quot;&quot; ; 设定条目对应的命令（在当前目录打开cmd.exe） 可能会出现条目文本乱码的情况，可以在 ContextMenuManager 中修改文本 在 ContextMenuManager 中把原来的在终端中打开给关闭（当然留着也没问题啦） win11修改”新建-文本文件”的快捷键：还没有找到解决方案，找到的都是给添加新建文本文档项目的，但是没有给这个项目添加快捷键的","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win11修改任务栏高度","slug":"win11修改任务栏高度","date":"2024-02-17T07:57:22.000Z","updated":"2024-02-17T07:57:34.114Z","comments":true,"path":"2024/02/17/win11修改任务栏高度/","link":"","permalink":"http://example.com/2024/02/17/win11%E4%BF%AE%E6%94%B9%E4%BB%BB%E5%8A%A1%E6%A0%8F%E9%AB%98%E5%BA%A6/","excerpt":"","text":"https://blog.csdn.net/winkexin/article/details/131619069","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win摆脱鼠标工具 wox 基础使用","slug":"win摆脱鼠标工具-wox-基础使用","date":"2024-02-17T07:50:04.000Z","updated":"2024-02-18T02:49:24.385Z","comments":true,"path":"2024/02/17/win摆脱鼠标工具-wox-基础使用/","link":"","permalink":"http://example.com/2024/02/17/win%E6%91%86%E8%84%B1%E9%BC%A0%E6%A0%87%E5%B7%A5%E5%85%B7-wox-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/","excerpt":"","text":"http://doc.wox.one/en/basic/超级好用，相见恨晚","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win 重启资源管理器 explorer","slug":"win-重启资源管理器-explorer","date":"2024-02-17T07:48:42.000Z","updated":"2024-02-17T07:50:58.017Z","comments":true,"path":"2024/02/17/win-重启资源管理器-explorer/","link":"","permalink":"http://example.com/2024/02/17/win-%E9%87%8D%E5%90%AF%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8-explorer/","excerpt":"","text":"重启资源管理器 taskkill /f /im explorer.exe &amp; start explorer.exe","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win where 查看程序所在路径 查看命令所在路径","slug":"win-where-查看程序所在路径-查看命令所在路径","date":"2024-02-17T07:23:00.000Z","updated":"2024-02-17T07:23:20.120Z","comments":true,"path":"2024/02/17/win-where-查看程序所在路径-查看命令所在路径/","link":"","permalink":"http://example.com/2024/02/17/win-where-%E6%9F%A5%E7%9C%8B%E7%A8%8B%E5%BA%8F%E6%89%80%E5%9C%A8%E8%B7%AF%E5%BE%84-%E6%9F%A5%E7%9C%8B%E5%91%BD%E4%BB%A4%E6%89%80%E5%9C%A8%E8%B7%AF%E5%BE%84/","excerpt":"","text":"where gcc","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win11资源管理器右键菜单恢复成win10版本","slug":"win11资源管理器右键菜单恢复成win10版本","date":"2024-02-17T02:52:04.000Z","updated":"2024-02-17T02:52:46.193Z","comments":true,"path":"2024/02/17/win11资源管理器右键菜单恢复成win10版本/","link":"","permalink":"http://example.com/2024/02/17/win11%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8%E5%8F%B3%E9%94%AE%E8%8F%9C%E5%8D%95%E6%81%A2%E5%A4%8D%E6%88%90win10%E7%89%88%E6%9C%AC/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/626355083 inspiron 15 3511 用了修改注册表的方法 恢复的方法：删除掉注册表中HKEY_CURRENT_USER\\SOFTWARE\\CLASSES\\CLSID\\&#123;86ca1aa0-34aa-4e8b-a509-50c905bae2a2&#125;下的项InprocServer32，然后重启资源管理器taskkill /f /im explorer.exe &amp; start explorer.exe","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"vscode leetcode插件登录","slug":"vscode-leetcode插件登录","date":"2024-02-17T02:39:49.000Z","updated":"2024-02-17T02:45:53.171Z","comments":true,"path":"2024/02/17/vscode-leetcode插件登录/","link":"","permalink":"http://example.com/2024/02/17/vscode-leetcode%E6%8F%92%E4%BB%B6%E7%99%BB%E5%BD%95/","excerpt":"","text":"目前leetcode插件似乎仅支持leetcode.cn的endpoint，不支持leetcode.com的步骤： 安装leetcode插件 switch endpoint: 将endpoint切换为cn 可以在插件设置中修改，也可以点击左侧栏的leetcode插件图标然后点击侧边栏顶部的地球图标 sign in: 如果同时网页上也登录了，那无法使用账号密码登录，不过可以使用cookie登录","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win GNU MSYS2 非MSVC环境安装Rust","slug":"win-GNU-MSYS2-非MSVC环境安装Rust","date":"2024-02-17T02:05:40.000Z","updated":"2024-02-17T02:05:56.424Z","comments":true,"path":"2024/02/17/win-GNU-MSYS2-非MSVC环境安装Rust/","link":"","permalink":"http://example.com/2024/02/17/win-GNU-MSYS2-%E9%9D%9EMSVC%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85Rust/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/613466378","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"判断笔记本是否是新机","slug":"判断笔记本是否是新机","date":"2024-02-17T01:41:38.000Z","updated":"2024-02-17T01:41:50.539Z","comments":true,"path":"2024/02/17/判断笔记本是否是新机/","link":"","permalink":"http://example.com/2024/02/17/%E5%88%A4%E6%96%AD%E7%AC%94%E8%AE%B0%E6%9C%AC%E6%98%AF%E5%90%A6%E6%98%AF%E6%96%B0%E6%9C%BA/","excerpt":"","text":"https://mp.weixin.qq.com/s/r8UtWtotGtnyPGiMnc996A","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"笔记本查看电池健康","slug":"笔记本查看电池健康","date":"2024-02-07T07:06:32.000Z","updated":"2024-02-07T07:12:42.000Z","comments":true,"path":"2024/02/07/笔记本查看电池健康/","link":"","permalink":"http://example.com/2024/02/07/%E7%AC%94%E8%AE%B0%E6%9C%AC%E6%9F%A5%E7%9C%8B%E7%94%B5%E6%B1%A0%E5%81%A5%E5%BA%B7/","excerpt":"","text":"https://blog.csdn.net/weixin_43960383/article/details/118395867 打开cmd，生成电池健康报告 powercfg/batteryreport 含义电池型号 Installed batteries当前电池健康 Installed batteriesDESIGN CAPACITYFULL CHARGE CAPACITYbattery health &#x3D; FULL CHARGE CAPACITY &#x2F; DESIGN CAPACITY 电池容量历史 Battery capacity history","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"多线程程序性能上不去 没有线性加速 cpu没有跑满 原因排查","slug":"多线程程序性能上不去-没有线性加速-cpu没有跑满-原因排查","date":"2024-02-07T02:26:37.000Z","updated":"2024-02-07T04:07:48.000Z","comments":true,"path":"2024/02/07/多线程程序性能上不去-没有线性加速-cpu没有跑满-原因排查/","link":"","permalink":"http://example.com/2024/02/07/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD%E4%B8%8A%E4%B8%8D%E5%8E%BB-%E6%B2%A1%E6%9C%89%E7%BA%BF%E6%80%A7%E5%8A%A0%E9%80%9F-cpu%E6%B2%A1%E6%9C%89%E8%B7%91%E6%BB%A1-%E5%8E%9F%E5%9B%A0%E6%8E%92%E6%9F%A5/","excerpt":"","text":"现象：在n个物理核的机器上跑线程数为c（小于n）的多线程程序，其对串行版本的加速比达不到c （持续完善ing，目前只有“全内存，计算intensive”类程序的经验） 原因排查： 看cpu占用是否达到线性加速： top或htop：看是否达到串行时的cpu占用率*c（top中程序的cpu占用是把每个线程的cpu占用累加起来的） htop可以更加直观地看到每个逻辑核的占用情况 达不到的可能原因： 环境：系统有其他进程在跑（实际经验表明，不同时候在同一台机器上跑性能差距可能相差达到3倍） IO等待 达到了， 但是加速比明显没有c（比如30线程，加速比是10），可能原因： 程序逻辑是否存在忙等 看程序逻辑层面的时间占用：perf火焰图，看哪些处理时间占比大 程序逻辑层面的线程竞争，如加锁和解锁 如果加锁和解锁的时间占到50%，那加速比应该最多只有c&#x2F;2 IO竞争 和串行版本的IO时间占比对比 说明：若不同线程等待的IO资源是相互独立的（即没有相互等待，相互等待比如要写同一个资源），则IO等待不是多线程程序无法线性加速的原因（此时IO等待对运行时间的贡献和没有竞争的计算类似了）（多说一句，对于线程数多于物理核数的情况，会出现这样的图景：某个核上的线程进入等待IO时，这个核上可以切换成另一个线程来执行） 看系统底层执行的情况： 看上下文切换：vmstat，vmstat 1 10每个1秒统计一次，总共统计10次；关注cs列 上下文切换发生在：线程切换，系统调用等 看缓存竞争","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"linux命令行没有颜色 tab自动补全无效 新云服务器指定命令行为bash","slug":"linux命令行没有颜色-tab自动补全无效-新云服务器指定命令行为bash","date":"2024-02-07T02:23:57.000Z","updated":"2024-02-07T02:25:52.000Z","comments":true,"path":"2024/02/07/linux命令行没有颜色-tab自动补全无效-新云服务器指定命令行为bash/","link":"","permalink":"http://example.com/2024/02/07/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%B2%A1%E6%9C%89%E9%A2%9C%E8%89%B2-tab%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8%E6%97%A0%E6%95%88-%E6%96%B0%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%8C%87%E5%AE%9A%E5%91%BD%E4%BB%A4%E8%A1%8C%E4%B8%BAbash/","excerpt":"","text":"https://blog.csdn.net/Frederick_Bala/article/details/107410923（首先系统要有bin/bash，然后） 查看使用的shell echo $SHELL如果不是/bin/bash，查看 ls -l /bin/sh，如果该软链接的不是/bin/bash，执行 ln -sf /bin/bash /bin/sh","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"leetcode 完全二叉树的节点个数","slug":"leetcode-完全二叉树的节点个数","date":"2024-02-03T06:25:07.000Z","updated":"2024-02-03T07:22:30.000Z","comments":true,"path":"2024/02/03/leetcode-完全二叉树的节点个数/","link":"","permalink":"http://example.com/2024/02/03/leetcode-%E5%AE%8C%E5%85%A8%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E8%8A%82%E7%82%B9%E4%B8%AA%E6%95%B0/","excerpt":"","text":"完全二叉树的节点个数Q给你一棵 完全二叉树 的根节点 root ，求出该树的节点个数。 完全二叉树 的定义如下：在完全二叉树中，除了最底层节点可能没填满外，其余每层节点数都达到最大值，并且最下面一层的节点都集中在该层最左边的若干位置。若最底层为第 h 层，则该层包含 1~ 2h 个节点。 示例 1： 输入：root = [1,2,3,4,5,6] 输出：6 示例 2： 输入：root = [] 输出：0 示例 3： 输入：root = [1] 输出：1 提示： 树中节点的数目范围是[0, 5 * 104] 0 &lt;= Node.val &lt;= 5 * 104 题目数据保证输入的树是 完全二叉树 进阶：遍历树来统计节点是一种时间复杂度为 O(n) 的简单解决方案。你可以设计一个更快的算法吗？ A最简单的就是直接遍历整棵树（BFS或DFS）累计节点个数 不过我们可以利用完全二叉树的结构性质 利用完全二叉树性质时，取根所处深度为0而不是1会让分析简单一些 1. 计算空结点数目，右深树最坏为O(n)，即最底下一层只有一个节点，实际上只会经过包含所有空结点的最小的树（以及从根节点按右边走到这棵树的根） class Solution &#123; int h; public: // return done: done means that, we have found the last empty node, there&#39;s no more empty node // accumulate empty_node_count bool count_empty_node_for_level_just_above_leaf(TreeNode *root, int depth, int &amp;empty_node_cnt) &#123; if (depth + 1 == h) &#123; if (root-&gt;left) &#123; if (root-&gt;right == nullptr) empty_node_cnt++; return true; &#125; empty_node_cnt += 2; return false; &#125; else &#123; if (count_empty_node_for_level_just_above_leaf(root-&gt;right, depth + 1, empty_node_cnt)) return true; return count_empty_node_for_level_just_above_leaf(root-&gt;left, depth + 1, empty_node_cnt); &#125; &#125; int countNodes(TreeNode *root) &#123; if (root == nullptr) return 0; // calculate h h = -1; TreeNode *p = root; while (p) &#123; p = p-&gt;left; ++h; &#125; // calculate node if (h == 0) return 1; int empty_node_count = 0; count_empty_node_for_level_just_above_leaf(root, 0, empty_node_count); return (1 &lt;&lt; (h + 1)) - empty_node_count - 1; // last level: (1 &lt;&lt; h) - empty_node_count // above levels: (1 &lt;&lt; h) - 1 &#125; &#125;; 2. 二分查找，完全二叉树的节点若从1开始编号，编号的二进制表示代表了从根到该节点的路径第i层的节点的编号二进制有i+1位，最高位是1，其余位从高到低表示从根走到该节点的路径：0则向左，1则向右 O(logn*logn)，对宽度为2^h的范围进行二分查找，判断次数是log(2^h)&#x3D;h&#x3D;logn（一定会判断这么多次，因为要到l和r相遇才结束），每次判断都是按比特指示从根走到最下层，复杂度是logn，因此logn*logn class Solution &#123; public: // num: `h`th bit is 1; other bits: from high bit to low bit, the path from root to node bool node_exist(TreeNode *root, int num, int h) &#123; int msk = 1 &lt;&lt; (h - 1); for (int i = 0; i &lt; h; ++i) &#123; if (msk &amp; num) &#123; // go right if (root-&gt;right) root = root-&gt;right; else return false; &#125; else &#123; // go left if (root-&gt;left) root = root-&gt;left; else return false; &#125; msk &gt;&gt;= 1; &#125; return true; &#125; int countNodes(TreeNode *root) &#123; if (root == nullptr) return 0; // get height int h = -1; TreeNode *p = root; while (p) &#123; ++h; p = p-&gt;left; &#125; if (h == 0) return 1; // binary search for node_count: whether node_count is mid? // number the node from 1 (start from root, then level by level, each level from left to right) // then node&#39;s id represents path from root, also id somewhat represents count of nodes // [l, r) // &quot;l is inclusive, r is exclusive&quot; is from the following process. see comments below // #nodes above level h: (1 &lt;&lt; h) - 1 int l = 1 &lt;&lt; h; // lower bound of node_count: level h only contain one node int r = 1 &lt;&lt; (h + 1); // upper bound of node_count: level h is full: 1 &lt;&lt; h int mid; while (l + 1 &lt; r) &#123; mid = (l + r) / 2; if (node_exist(root, mid, h)) // #nodes &gt;= mid l = mid; // l is inclusive else // #nodes &lt; mid r = mid; // r is exclusive &#125; return l; &#125; &#125;; // @lc code=end 3. 比较左右两边的depth复杂度不太行，不过有这个思路 好的地方可能在，比如在某节点，左子树没有空节点，那么对左子树的调用就会一层结束 class Solution &#123; public: int countNodes(TreeNode *root) &#123; if (root == nullptr) return 0; TreeNode *p; // left height int lh = -1; p = root; while (p) &#123; ++lh; p = p-&gt;left; &#125; // right height int rh = -1; p = root; while (p) &#123; ++rh; p = p-&gt;right; &#125; if (lh == rh) // all level is full // 2^0 + ... + 2^lh: from binary representation point of view, this sum = (1 &lt;&lt; (lh + 1)) - 1 return (1 &lt;&lt; (lh + 1)) - 1; return 1 + countNodes(root-&gt;left) + countNodes(root-&gt;right); &#125; &#125;; // @lc code=end 最坏为O(nlogn)，即最底下一层只有一个节点，需要求logn层的左右两边depth（logn次，因为树高是logn）， 对第i层求depth的复杂度：第i层每个节点都求左右两边的depth，第i层有节点2^i个，求depth的复杂度是logn-i（树的深度-当前层的深度），所以是2^i*(logn-i)， 然后对i从0到logn求和，得到nlogn","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/tags/leetcode/"},{"name":"leetcode-easy","slug":"leetcode-easy","permalink":"http://example.com/tags/leetcode-easy/"},{"name":"leetcode-brain-teaser","slug":"leetcode-brain-teaser","permalink":"http://example.com/tags/leetcode-brain-teaser/"},{"name":"leetcode-binary-tree","slug":"leetcode-binary-tree","permalink":"http://example.com/tags/leetcode-binary-tree/"}],"author":"zhiqiuyuan"},{"title":"linux 监控多线程程序 监控多核心 查看每个核心的使用情况","slug":"linux-监控多线程程序-监控多核心-查看每个核心的使用情况","date":"2024-02-03T02:44:02.000Z","updated":"2024-02-05T23:49:33.000Z","comments":true,"path":"2024/02/03/linux-监控多线程程序-监控多核心-查看每个核心的使用情况/","link":"","permalink":"http://example.com/2024/02/03/linux-%E7%9B%91%E6%8E%A7%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%A8%8B%E5%BA%8F-%E7%9B%91%E6%8E%A7%E5%A4%9A%E6%A0%B8%E5%BF%83-%E6%9F%A5%E7%9C%8B%E6%AF%8F%E4%B8%AA%E6%A0%B8%E5%BF%83%E7%9A%84%E4%BD%BF%E7%94%A8%E6%83%85%E5%86%B5/","excerpt":"","text":"https://juejin.cn/s/linux%E6%9F%A5%E7%9C%8Bcpu%E6%AF%8F%E4%B8%AA%E6%A0%B8%E4%BD%BF%E7%94%A8%E7%8E%87 htop真的相见恨晚！！ htop上面显示每个虚拟核心，内存，下面显示每个进程教程 https://cloud.tencent.com/developer/article/1115041https://htop.dev/screenshots.htmlIt is similar to top, but allows you to scroll vertically and horizontally, so you can see all the processes running on the system, along with their full command lines, as well as viewing them as a process tree, selecting multiple processes and acting on them all at once.Configuring I&#x2F;O scheduling priority (press “i”)Configuring CPU affinity (press “a”) top -H显示每个进程，以及每个进程的每个线程的情况-H :Threads-mode operation Instructs top to display individual threads. Without this command-line option a summation of all threads in each process is shown. Later this can be changed with the &#96;H’ interactive command. sar -P ALL 1该命令将以每秒钟一个数据点的方式显示每个CPU核心的使用情况。","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"线程绑定到核心 绑核 c/c++","slug":"线程绑定到核心-绑核-c-c","date":"2024-02-03T02:22:16.000Z","updated":"2024-02-05T15:15:39.000Z","comments":true,"path":"2024/02/03/线程绑定到核心-绑核-c-c/","link":"","permalink":"http://example.com/2024/02/03/%E7%BA%BF%E7%A8%8B%E7%BB%91%E5%AE%9A%E5%88%B0%E6%A0%B8%E5%BF%83-%E7%BB%91%E6%A0%B8-c-c/","excerpt":"","text":"https://blog.csdn.net/zfjBIT/article/details/105846212 c++11的std::thread可以通过native_handle()来获取底层的pthread_t，然后照样使用pthread_t的函数pthread_setaffinity_np来绑核 #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;thread&gt; #include &lt;pthread.h&gt; #include &lt;mutex&gt; int main(int argc, const char **argv) &#123; constexpr unsigned num_threads = 4; std::mutex iomutex; std::vector&lt;std::thread&gt; threads(num_threads); for (unsigned i = 0; i &lt; num_threads; ++i) &#123; threads[i] = std::thread([&amp;iomutex, i] &#123;std::this_thread::sleep_for(std::chrono::milliseconds(20)); // endless loop while (1) &#123; &#123; std::lock_guard&lt;std::mutex&gt; iolock(iomutex); std::cout&lt;&lt; &quot;Thread #&quot; &lt;&lt; i &lt;&lt; &quot;:on CPU &quot; &lt;&lt;sched_getcpu() &lt;&lt; &quot;\\n&quot;; &#125; // Simulate work std::this_thread::sleep_for(std::chrono::milliseconds(900)); &#125; &#125;); // 这里 cpu_set_t cpuset; CPU_ZERO(&amp;cpuset); // clean cpuset CPU_SET(i, &amp;cpuset); // only contain cpu i int rc = pthread_setaffinity_np(threads[i].native_handle(), sizeof(cpu_set_t), &amp;cpuset); // bind threads[i] to cpu i if (rc != 0) &#123; std::cerr &lt;&lt; &quot;Error calling pthread_setaffinity_np: &quot; &lt;&lt; rc &lt;&lt; &quot;\\n&quot;; &#125; &#125; for (auto &amp;t : threads) t.join(); return 0; &#125; cmake_minimum_required(VERSION 3.0.0) project(bind_cpu_test) set(CMAKE_CXX_FLAGS &quot;-std=c++11&quot;) set(CMAKE_CXX_FLAGS_RELEASE &quot;-O3 -Wall -g&quot;) add_executable(main main.cpp ) target_link_libraries(main pthread) # 注意这里链接pthread库","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"leetcode 同构字符串","slug":"leetcode-同构字符串","date":"2024-02-03T01:52:09.000Z","updated":"2024-02-03T01:57:32.000Z","comments":true,"path":"2024/02/03/leetcode-同构字符串/","link":"","permalink":"http://example.com/2024/02/03/leetcode-%E5%90%8C%E6%9E%84%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"同构字符串Q给定两个字符串 s 和 t ，判断它们是否是同构的。 如果 s 中的字符可以按某种映射关系替换得到 t ，那么这两个字符串是同构的。 每个出现的字符都应当映射到另一个字符，同时不改变字符的顺序。不同字符不能映射到同一个字符上，相同字符只能映射到同一个字符上，字符可以映射到自己本身。 示例 1: 输入：s = &quot;egg&quot;, t = &quot;add&quot; 输出：true 示例 2： 输入：s = &quot;foo&quot;, t = &quot;bar&quot; 输出：false 示例 3： 输入：s = &quot;paper&quot;, t = &quot;title&quot; 输出：true 提示： 1 &lt;= s.length &lt;= 5 * 104 t.length == s.length s 和 t 由任意有效的 ASCII 字符组成 A 一一映射，从s到t，从t到s，只一边满射不可以 字符到字符的映射 -&gt; 两边字符到位置的映射 不用哈希表，因为可能的键的范围是非负char bool isIsomorphic(string s, string t) &#123; if (s.size() != t.size()) return false; // char to pos // char only contain 128 nonnegative values (which represents all ASCII char) size_t smap[128] = &#123;0&#125;; size_t tmap[128] = &#123;0&#125;; char sc, tc; for (size_t i = 0, sz = s.size(); i &lt; sz; ++i) &#123; sc = s[i]; tc = t[i]; if (smap[sc] != tmap[tc]) return false; // smap[sc] == tmap[tc]: // 1. both 0: sc and tc haven&#39;t been mapped to any pos // 2. both non zero: sc and tc have been mapped to the same pos smap[sc] = i + 1; // pos: i+1 for 0 represents haven&#39;t been mapped to any pos tmap[tc] = i + 1; &#125; return true; &#125;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/tags/leetcode/"},{"name":"leetcode-easy","slug":"leetcode-easy","permalink":"http://example.com/tags/leetcode-easy/"},{"name":"leetcode-string","slug":"leetcode-string","permalink":"http://example.com/tags/leetcode-string/"}],"author":"zhiqiuyuan"},{"title":"GMT time epochs human read time","slug":"GMT-time-epochs-human-read-time","date":"2024-01-25T06:03:39.000Z","updated":"2024-01-25T06:09:25.000Z","comments":true,"path":"2024/01/25/GMT-time-epochs-human-read-time/","link":"","permalink":"http://example.com/2024/01/25/GMT-time-epochs-human-read-time/","excerpt":"","text":"human-readable date: 人类可读的时间 epoch&#x2F;timestamp: 从某个固定的时间点开始的timestamp,单位有微秒的,也有毫秒的 The Unix epoch (or Unix time or POSIX time or Unix timestamp) is the number of seconds that have elapsed since January 1, 1970 (midnight UTC&#x2F;GMT), not counting leap seconds (in ISO 8601: 1970-01-01T00:00:00Z) 在线转换工具,各种编程语言下不同时间的相互转化https://www.epochconverter.com/ 比如C语言https://www.epochconverter.com/programming/cpython import calendar, time calendar.timegm(time.strptime(&#39;2000-01-01 12:34:00&#39;, &#39;%Y-%m-%d %H:%M:%S&#39;)) # unit: secs","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"leetcode 快乐数","slug":"leetcode-快乐数","date":"2024-01-19T10:26:18.000Z","updated":"2024-02-03T02:10:58.000Z","comments":true,"path":"2024/01/19/leetcode-快乐数/","link":"","permalink":"http://example.com/2024/01/19/leetcode-%E5%BF%AB%E4%B9%90%E6%95%B0/","excerpt":"","text":"https://leetcode.cn/problems/happy-number/description/ Q编写一个算法来判断一个数 n 是不是快乐数。 「快乐数」 定义为： 对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和。 然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到 1。 如果这个过程 结果为 1，那么这个数就是快乐数。 如果 n 是 快乐数 就返回 true ；不是，则返回 false 。 示例 1： 输入：n = 19 输出：true 解释： 12 + 92 = 82 82 + 22 = 68 62 + 82 = 100 12 + 02 + 02 = 1 示例 2： 输入：n = 2 输出：false 提示： 1 &lt;= n &lt;= 231 - 1 A分析什么情况出现无限循环：出现重复数字的时候（从n开始，不断求当前数字的各位平方和，得到一个数列，这个数列中出现一个数字在之前出现过的话，从这个数字开始会重复之前的序列） 有没有情况是，不会出现重复数字，但是这个序列没法到达1呢？不可能： 考虑当前数组，其是d位数，其各位平方和最大是9^2*d&#x3D;81d， 对于题目的输入，初始n最大是10位数，下一步最大是81d&#x3D;810，3位数， 3位数的各位平方和最大不超过243（81*3），2位数…162（81*2），1位数…81，因此这个序列接下来一直是不超过3位数的情况 也就是说，这个序列是：n，然后都是不超过3位数的数，而不超过3位数的数，不可能一直不重复到无限，所以到无限的情况是有重复出现 检测是否有环(floyd环路检测)：快慢指针。从同一个位置出发，快指针一次走2步（走一步：求出该序列的下一个数字），慢指针一次走1步，如果有环，慢指针和快指针一定会相遇 class Solution &#123; public: int one_step(int n) &#123; int sum = 0; while(n &gt; 0) &#123; int r = n%10; sum += r*r; n /= 10; &#125; return sum; &#125; bool isHappy(int n) &#123; int slow = n, fast = n; do &#123; slow = one_step(slow); fast = one_step(one_step(fast)); if(fast == 1) return 1; &#125; while(slow != fast); return 0; &#125; &#125;;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/tags/leetcode/"},{"name":"leetcode-easy","slug":"leetcode-easy","permalink":"http://example.com/tags/leetcode-easy/"},{"name":"leetcode-brain-teaser","slug":"leetcode-brain-teaser","permalink":"http://example.com/tags/leetcode-brain-teaser/"}],"author":"zhiqiuyuan"},{"title":"leetcode 位1的个数","slug":"leetcode-位1的个数","date":"2024-01-19T10:12:49.000Z","updated":"2024-01-19T10:44:29.000Z","comments":true,"path":"2024/01/19/leetcode-位1的个数/","link":"","permalink":"http://example.com/2024/01/19/leetcode-%E4%BD%8D1%E7%9A%84%E4%B8%AA%E6%95%B0/","excerpt":"","text":"https://leetcode.cn/problems/number-of-1-bits/description/ Q编写一个函数，输入是一个无符号整数（以二进制串的形式），返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为汉明重量）。 A移位，检查每一位是不是1 class Solution &#123; public: int hammingWeight(uint32_t n) &#123; int cnt = 0; for (int i = 0; i &lt; 32; ++i) &#123; if (n &amp; 1u) ++cnt; n &gt;&gt;= 1; &#125; return cnt; &#125; &#125;; 不断将最低位的1设置为0： n &amp;= (n - 1);将n的最低位1设置成0，其他不变 n-1将n的最低位1（之前的位都是0）之前的位变成1，将n的最低位1变成0 class Solution &#123; public: int hammingWeight(uint32_t n) &#123; int cnt = 0; while (n) &#123; ++cnt; n &amp;= (n - 1); // 将最低位的1设置为0 &#125; return cnt; &#125; &#125;;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/tags/leetcode/"},{"name":"leetcode-easy","slug":"leetcode-easy","permalink":"http://example.com/tags/leetcode-easy/"},{"name":"leetcode-bit-trick","slug":"leetcode-bit-trick","permalink":"http://example.com/tags/leetcode-bit-trick/"}],"author":"zhiqiuyuan"},{"title":"leetcode 众数","slug":"leetcode-众数","date":"2024-01-18T11:10:45.000Z","updated":"2024-01-19T10:05:56.000Z","comments":true,"path":"2024/01/18/leetcode-众数/","link":"","permalink":"http://example.com/2024/01/18/leetcode-%E4%BC%97%E6%95%B0/","excerpt":"","text":"Qhttps://leetcode.cn/problems/majority-element/description/ 给定一个大小为 n 的数组 nums ，返回其中的多数元素。多数元素是指在数组中出现次数 大于 ⌊ n/2 ⌋ 的元素。 你可以假设数组是非空的，并且给定的数组总是存在多数元素。 示例 1： 输入：nums = [3,2,3] 输出：3 示例 2： 输入：nums = [2,2,1,1,1,2,2] 输出：2 提示： n == nums.length 1 &lt;= n &lt;= 5 * 104 -109 &lt;= nums[i] &lt;= 109 进阶：尝试设计时间复杂度为 O(n)、空间复杂度为 O(1) 的算法解决此问题。 AHash Table Count the number of appearances for each distinct number in nums, once we see a number appear more than n / 2 times, it is the majority element. class Solution &#123; public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; unordered_map&lt;int, int&gt; counter; for (int num : nums) &#123; if (++counter[num] &gt; nums.size() / 2) &#123; return num; &#125; &#125; return 0; &#125; &#125;; Sorting Since the majority element appears more than n / 2 times, the n / 2-th element in the sorted nums must be the majority element. In this case, a partial sort by nth_element is enough. class Solution &#123; public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; nth_element(nums.begin(), nums.begin() + nums.size() / 2, nums.end()); return nums[nums.size() / 2]; &#125; &#125;; Randomization Pick an element randomly and check whether it is the majority one. class Solution &#123; public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; int n=nums.size(); int gate=n/2; while(true)&#123; int pos=(((double)rand())/RAND_MAX)*n; int num=nums[pos]; if(count(nums.begin(),nums.end(),num)&gt;gate) return num; &#125; return 0; &#125; &#125;; Divide and Conquer Recursively find the majority in the two halves of nums and combine the results. The base case is that the majority element of a single-element array is just that element. nlg(n) class Solution &#123; public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; return majority(nums, 0, nums.size() - 1); &#125; private: int majority(vector&lt;int&gt;&amp; nums, int l, int r) &#123; if (l == r) &#123; return nums[l]; &#125; int m = l + (r - l) / 2, lm = majority(nums, l, m), rm = majority(nums, m + 1, r); if (lm == rm) &#123; return lm; &#125; return count(nums.begin() + l, nums.begin() + r + 1, lm) &gt; count(nums.begin() + l, nums.begin() + r + 1, rm) ? lm : rm; &#125; &#125;; Moore Voting Algorithm 众数最终一定会打败其他可能是众数的数字 class Solution &#123; public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; int counter = 0, majority; for (int num : nums) &#123; if (!counter) &#123; // check counter before update counter: 如果counter等于0，说明之前的所有可能的众数都打平了，可以重新开始一个 majority = num; &#125; counter += num == majority ? 1 : -1; &#125; return majority; &#125; &#125;; Bit Manipulation The bits in the majority are just the majority bits of all numbers. 众数的某bit如果是0，则所有数的这一位的bit为0的数目会&gt;一半，从而bit为1的数目会小于一半 class Solution &#123; public: int majorityElement(vector&lt;int&gt;&amp; nums) &#123; int majority = 0; for (unsigned int i = 0, mask = 1; i &lt; 32; i++, mask &lt;&lt;= 1) &#123; // 使用无符号类型作为mask，因为有符号类型移位宽度位的时候是未定义的 int bits = 0; for (int num : nums) &#123; if (num &amp; mask) &#123; bits++; &#125; &#125; if (bits &gt; nums.size() / 2) &#123; majority |= mask; &#125; &#125; return majority; &#125; &#125;;","categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/categories/leetcode/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/tags/leetcode/"},{"name":"leetcode-easy","slug":"leetcode-easy","permalink":"http://example.com/tags/leetcode-easy/"}],"author":"zhiqiuyuan"},{"title":"lmdb接口学习","slug":"lmdb接口学习","date":"2024-01-03T12:01:10.000Z","updated":"2024-01-19T08:48:04.000Z","comments":true,"path":"2024/01/03/lmdb接口学习/","link":"","permalink":"http://example.com/2024/01/03/lmdb%E6%8E%A5%E5%8F%A3%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"简介： http://www.lmdb.tech/doc/ Quick Start： http://www.lmdb.tech/doc/starting.html 全部接口介绍： http://www.lmdb.tech/doc/group__mdb.html The entire database is exposed in a memory map, and all data fetches return data directly from the mapped memory, so no malloc’s or memcpy’s occur during data fetches. The memory map can be used as a read-only or read-write map. It is read-only by default as this provides total immunity to corruption. Using read-write mode offers much higher write performance, but adds the possibility for stray application writes thru pointers to silently corrupt the database. Of course if your application code is known to be bug-free (…) then this is not an issue. Quick StartGetting StartedEverything starts with an environment, created by mdb_env_create(). Once created, this environment must also be opened with mdb_env_open(). mdb_env_open() gets passed a name which is interpreted as a directory path. Note that this directory must exist already, it is not created for you. Within that directory, a lock file and a storage file will be generated. If you don’t want to use a directory, you can pass the MDB_NOSUBDIR option, in which case the path you provided is used directly as the data file, and another file with a “-lock” suffix added will be used for the lock file. Once the environment is open, a transaction can be created within it using mdb_txn_begin(). Transactions may be read-write or read-only, and read-write transactions may be nested. A transaction must only be used by one thread at a time. Transactions are always required, even for read-only access. The transaction provides a consistent view of the data. Once a transaction has been created, a database can be opened within it using mdb_dbi_open(). If only one database will ever be used in the environment, a NULL can be passed as the database name. For named databases, the MDB_CREATE flag must be used to create the database if it doesn’t already exist. Also, mdb_env_set_maxdbs() must be called after mdb_env_create() and before mdb_env_open() to set the maximum number of named databases you want to support. mdb_env_set_mapsize Note: a single transaction can open multiple databases. Generally databases should only be opened once, by the first transaction in the process. After the first transaction completes, the database handles can freely be used by all subsequent transactions. Within a transaction, mdb_get() and mdb_put() can store single key&#x2F;value pairs if that is all you need to do (but see Cursors below if you want to do more). A key&#x2F;value pair is expressed as two MDB_val structures. This struct has two fields, mv_size and mv_data. The data is a void pointer to an array of mv_size bytes. Because LMDB is very efficient (and usually zero-copy), the data returned in an MDB_val structure may be memory-mapped straight from disk. In other words look but do not touch (or free() for that matter). Once a transaction is closed, the values can no longer be used, so make a copy if you need to keep them after that. CursorTo do more powerful things, we must use a cursor. Within the transaction, a cursor can be created with mdb_cursor_open(). With this cursor we can store&#x2F;retrieve&#x2F;delete (multiple) values using mdb_cursor_get(), mdb_cursor_put(), and mdb_cursor_del(). mdb_cursor_get() positions itself depending on the cursor operation requested, and for some operations, on the supplied key. For example, to list all key&#x2F;value pairs in a database, use operation MDB_FIRST for the first call to mdb_cursor_get(), and MDB_NEXT on subsequent calls, until the end is hit. To retrieve all keys starting from a specified key value, use MDB_SET. For more cursor operations, see the LMDB API docs. When using mdb_cursor_put(), either the function will position the cursor for you based on the key, or you can use operation MDB_CURRENT to use the current position of the cursor. Note that key must then match the current position’s key. Summarizing the OpeningSo we have a cursor in a transaction which opened a database in an environment which is opened from a filesystem after it was separately created. Or, we create an environment, open it from a filesystem, create a transaction within it, open a database within that transaction, and create a cursor within all of the above. Got it? Threads and ProcessesLMDB uses POSIX locks on files, and these locks have issues if one process opens a file multiple times. Because of this, do not mdb_env_open() a file multiple times from a single process. Instead, share the LMDB environment that has opened the file across all threads. Otherwise, if a single process opens the same environment multiple times, closing it once will remove all the locks held on it, and the other instances will be vulnerable to corruption from other processes. Also note that a transaction is tied to one thread by default using Thread Local Storage. If you want to pass read-only transactions across threads, you can use the MDB_NOTLS option on the environment. Transactions, Rollbacks, etc.To actually get anything done, a transaction must be committed using mdb_txn_commit(). Alternatively, all of a transaction’s operations can be discarded using mdb_txn_abort(). In a read-only transaction, any cursors will not automatically be freed. In a read-write transaction, all cursors will be freed and must not be used again. For read-only transactions, obviously there is nothing to commit to storage. The transaction still must eventually be aborted to close any database handle(s) opened in it, or committed to keep the database handles around for reuse in new transactions. In addition, as long as a transaction is open, a consistent view of the database is kept alive, which requires storage. A read-only transaction that no longer requires this consistent view should be terminated (committed or aborted) when the view is no longer needed (but see below for an optimization). There can be multiple simultaneously active read-only transactions but only one that can write. Once a single read-write transaction is opened, all further attempts to begin one will block until the first one is committed or aborted. This has no effect on read-only transactions, however, and they may continue to be opened at any time. Duplicate Keysmdb_get() and mdb_put() respectively have no and only some support for multiple key&#x2F;value pairs with identical keys. If there are multiple values for a key, mdb_get() will only return the first value. When multiple values for one key are required, pass the MDB_DUPSORT flag to mdb_dbi_open(). In an MDB_DUPSORT database, by default mdb_put() will not replace the value for a key if the key existed already. Instead it will add the new value to the key. In addition, mdb_del() will pay attention to the value field too, allowing for specific values of a key to be deleted. Finally, additional cursor operations become available for traversing through and retrieving duplicate values. Some OptimizationIf you frequently begin and abort read-only transactions, as an optimization, it is possible to only reset and renew a transaction. mdb_txn_reset() releases any old copies of data kept around for a read-only transaction. To reuse this reset transaction, call mdb_txn_renew() on it. Any cursors in this transaction must also be renewed using mdb_cursor_renew(). Note that mdb_txn_reset() is similar to mdb_txn_abort() and will close any databases you opened within the transaction. To permanently free a transaction, reset or not, use mdb_txn_abort(). Cleaning UpFor read-only transactions, any cursors created within it must be closed using mdb_cursor_close(). It is very rarely necessary to close a database handle, and in general they should just be left open. The Full APIThe full LMDB API documentation lists further details, like how to: size a database (the default limits are intentionally small) drop and clean a database detect and report errors optimize (bulk) loading speed (temporarily) reduce robustness to gain even more speed gather statistics about the database define custom sort orders Full APIlmdb很简单 Functions Functions char * mdb_version (int *major, int *minor, int *patch) Return the LMDB library version information. char * mdb_strerror (int err) Return a string describing a given error code. env Functions int mdb_env_create (MDB_env **env) Create an LMDB environment handle. int mdb_env_open (MDB_env *env, const char *path, unsigned int flags, mdb_mode_t mode) Open an environment handle. flags： MDB_FIXEDMAP use a fixed address for the mmap region. This flag must be specified when creating the environment, and is stored persistently in the environment. If successful, the memory map will always reside at the same virtual address and pointers used to reference data items in the database will be constant across multiple invocations. This option may not always work, depending on how the operating system has allocated memory to shared libraries and other uses. The feature is highly experimental. MDB_NOSUBDIR MDB_RDONLY Open the environment in read-only mode. No write operations will be allowed. LMDB will still modify the lock file - except on read-only filesystems, where LMDB does not use locks. MDB_WRITEMAP Use a writeable memory map unless MDB_RDONLY is set. This is faster and uses fewer mallocs, but loses protection from application bugs like wild pointer writes and other bad updates into the database. Incompatible with nested transactions. Do not mix processes with and without MDB_WRITEMAP on the same environment. This can defeat durability (mdb_env_sync etc). MDB_NOMETASYNC Flush system buffers to disk only once per transaction, omit the metadata flush. Defer that until the system flushes files to disk, or next non-MDB_RDONLY commit or mdb_env_sync(). This optimization maintains database integrity, but a system crash may undo the last committed transaction. I.e. it preserves the ACI (atomicity, consistency, isolation) but not D (durability) database property. This flag may be changed at any time using mdb_env_set_flags(). MDB_NOSYNC Don’t flush system buffers to disk when committing a transaction. This optimization means a system crash can corrupt the database or lose the last transactions if buffers are not yet flushed to disk. The risk is governed by how often the system flushes dirty buffers to disk and how often mdb_env_sync() is called. However, if the filesystem preserves write order and the MDB_WRITEMAP flag is not used, transactions exhibit ACI (atomicity, consistency, isolation) properties and only lose D (durability). I.e. database integrity is maintained, but a system crash may undo the final transactions. Note that (MDB_NOSYNC | MDB_WRITEMAP) leaves the system with no hint for when to write transactions to disk, unless mdb_env_sync() is called. (MDB_MAPASYNC | MDB_WRITEMAP) may be preferable. This flag may be changed at any time using mdb_env_set_flags(). MDB_MAPASYNC When using MDB_WRITEMAP, use asynchronous flushes to disk. As with MDB_NOSYNC, a system crash can then corrupt the database or lose the last transactions. Calling mdb_env_sync() ensures on-disk database integrity until next commit. This flag may be changed at any time using mdb_env_set_flags(). MDB_NOTLS Don’t use Thread-Local Storage. Tie reader locktable slots to MDB_txn objects instead of to threads. I.e. mdb_txn_reset() keeps the slot reseved for the MDB_txn object. A thread may use parallel read-only transactions. A read-only transaction may span threads if the user synchronizes its use. Applications that multiplex many user threads over individual OS threads need this option. Such an application must also serialize the write transactions in an OS thread, since LMDB’s write locking is unaware of the user threads. MDB_NOLOCK Don’t do any locking. If concurrent access is anticipated, the caller must manage all concurrency itself. For proper operation the caller must enforce single-writer semantics, and must ensure that no readers are using old transactions while a writer is active. The simplest approach is to use an exclusive lock so that no readers may be active at all when a writer begins. MDB_NORDAHEAD Turn off readahead. Most operating systems perform readahead on read requests by default. This option turns it off if the OS supports it. Turning it off may help random read performance when the DB is larger than RAM and system RAM is full. The option is not implemented on Windows. MDB_NOMEMINIT Don’t initialize malloc’d memory before writing to unused spaces in the data file. By default, memory for pages written to the data file is obtained using malloc. While these pages may be reused in subsequent transactions, freshly malloc’d pages will be initialized to zeroes before use. This avoids persisting leftover data from other code (that used the heap and subsequently freed the memory) into the data file. Note that many other system libraries may allocate and free memory from the heap for arbitrary uses. E.g., stdio may use the heap for file I&#x2F;O buffers. This initialization step has a modest performance cost so some applications may want to disable it using this flag. This option can be a problem for applications which handle sensitive data like passwords, and it makes memory checkers like Valgrind noisy. This flag is not needed with MDB_WRITEMAP, which writes directly to the mmap instead of using malloc for pages. The initialization is also skipped if MDB_RESERVE is used; the caller is expected to overwrite all of the memory that was reserved in that case. This flag may be changed at any time using mdb_env_set_flags(). int mdb_env_copy (MDB_env *env, const char *path) Copy an LMDB environment to the specified path. int mdb_env_copyfd (MDB_env *env, mdb_filehandle_t fd) Copy an LMDB environment to the specified file descriptor. int mdb_env_copy2 (MDB_env *env, const char *path, unsigned int flags) Copy an LMDB environment to the specified path, with options. int mdb_env_copyfd2 (MDB_env *env, mdb_filehandle_t fd, unsigned int flags) Copy an LMDB environment to the specified file descriptor, with options. int mdb_env_stat (MDB_env *env, MDB_stat *stat) Return statistics about the LMDB environment. int mdb_env_info (MDB_env *env, MDB_envinfo *stat) Return information about the LMDB environment. int mdb_env_sync (MDB_env *env, int force) Flush the data buffers to disk. void mdb_env_close (MDB_env *env) Close the environment and release the memory map. int mdb_env_set_flags (MDB_env *env, unsigned int flags, int onoff) Set environment flags. or to unset these flags int mdb_env_get_flags (MDB_env *env, unsigned int *flags) Get environment flags. int mdb_env_get_path (MDB_env *env, const char **path) Return the path that was used in mdb_env_open(). int mdb_env_get_fd (MDB_env *env, mdb_filehandle_t *fd) Return the filedescriptor for the given environment. int mdb_env_set_mapsize (MDB_env *env, size_t size) Set the size of the memory map to use for this environment. The default is 10485760 bytes int mdb_env_set_maxreaders (MDB_env *env, unsigned int readers) Set the maximum number of threads&#x2F;reader slots for the environment. int mdb_env_get_maxreaders (MDB_env *env, unsigned int *readers) Get the maximum number of threads&#x2F;reader slots for the environment. int mdb_env_set_maxdbs (MDB_env *env, MDB_dbi dbs) Set the maximum number of named databases for the environment. int mdb_env_get_maxkeysize (MDB_env *env) Get the maximum size of keys and MDB_DUPSORT data we can write. int mdb_env_set_userctx (MDB_env *env, void *ctx) Set application information associated with the MDB_env. void * mdb_env_get_userctx (MDB_env *env) Get the application information associated with the MDB_env. int mdb_env_set_assert (MDB_env *env, MDB_assert_func *func) txn Functions int mdb_txn_begin (MDB_env *env, MDB_txn *parent, unsigned int flags, MDB_txn **txn) Create a transaction for use with the environment. flags：MDB_RDONLY This transaction will not perform any write operations. MDB_env * mdb_txn_env (MDB_txn *txn) Returns the transaction’s MDB_env. size_t mdb_txn_id (MDB_txn *txn) Return the transaction’s ID. int mdb_txn_commit (MDB_txn *txn) Commit all the operations of a transaction into the database. void mdb_txn_abort (MDB_txn *txn) Abandon all the operations of the transaction instead of saving them. void mdb_txn_reset (MDB_txn *txn) Reset a read-only transaction. int mdb_txn_renew (MDB_txn *txn) Renew a read-only transaction. dbi Functions int mdb_dbi_open (MDB_txn *txn, const char *name, unsigned int flags, MDB_dbi *dbi) Open a database in the environment. int mdb_stat (MDB_txn *txn, MDB_dbi dbi, MDB_stat *stat) Retrieve statistics for a database. int mdb_dbi_flags (MDB_txn *txn, MDB_dbi dbi, unsigned int *flags) Retrieve the DB flags for a database handle. void mdb_dbi_close (MDB_env *env, MDB_dbi dbi) Close a database handle. Normally unnecessary. Use with care: int mdb_drop (MDB_txn *txn, MDB_dbi dbi, int del) Empty or delete+close a database. int mdb_set_compare (MDB_txn *txn, MDB_dbi dbi, MDB_cmp_func *cmp) Set a custom key comparison function for a database. int mdb_set_dupsort (MDB_txn *txn, MDB_dbi dbi, MDB_cmp_func *cmp) Set a custom data comparison function for a MDB_DUPSORT database. int mdb_set_relfunc (MDB_txn *txn, MDB_dbi dbi, MDB_rel_func *rel) Set a relocation function for a MDB_FIXEDMAP database. int mdb_set_relctx (MDB_txn *txn, MDB_dbi dbi, void *ctx) Set a context pointer for a MDB_FIXEDMAP database’s relocation function. read&#x2F;write on dbi Functions int mdb_get (MDB_txn *txn, MDB_dbi dbi, MDB_val *key, MDB_val *data) Get items from a database. int mdb_put (MDB_txn *txn, MDB_dbi dbi, MDB_val *key, MDB_val *data, unsigned int flags) Store items into a database. int mdb_del (MDB_txn *txn, MDB_dbi dbi, MDB_val *key, MDB_val *data) Delete items from a database. int mdb_cursor_open (MDB_txn *txn, MDB_dbi dbi, MDB_cursor **cursor) Create a cursor handle. void mdb_cursor_close (MDB_cursor *cursor) Close a cursor handle. int mdb_cursor_renew (MDB_txn *txn, MDB_cursor *cursor) Renew a cursor handle. MDB_txn * mdb_cursor_txn (MDB_cursor *cursor) Return the cursor’s transaction handle. MDB_dbi mdb_cursor_dbi (MDB_cursor *cursor) Return the cursor’s database handle. int mdb_cursor_get (MDB_cursor *cursor, MDB_val *key, MDB_val *data, MDB_cursor_op op) Retrieve by cursor. int mdb_cursor_put (MDB_cursor *cursor, MDB_val *key, MDB_val *data, unsigned int flags) Store by cursor. int mdb_cursor_del (MDB_cursor *cursor, unsigned int flags) Delete current key&#x2F;data pair. int mdb_cursor_count (MDB_cursor *cursor, size_t *countp) Return count of duplicates for current key. int mdb_cmp (MDB_txn *txn, MDB_dbi dbi, const MDB_val *a, const MDB_val *b) Compare two data items according to a particular database. int mdb_dcmp (MDB_txn *txn, MDB_dbi dbi, const MDB_val *a, const MDB_val *b) Compare two data items according to a particular database. others Functions int mdb_reader_list (MDB_env *env, MDB_msg_func *func, void *ctx) Dump the entries in the reader lock table. int mdb_reader_check (MDB_env *env, int *dead) Check for stale entries in the reader lock table. Modules（一些硬编码的值，比如flags） Modules Version Macros Environment Flags Database Flags Write Flags Copy Flags Return Codes Data Structures Data Structures struct MDB_val Generic structure used for passing keys and data in and out of the database. More… struct MDB_stat Statistics for a database in the environment. More… struct MDB_envinfo Information about the environment. More… Macros Macros #define mdb_open(txn, name, flags, dbi) mdb_dbi_open(txn,name,flags,dbi) #define mdb_close(env, dbi) mdb_dbi_close(env,dbi) Typedefs Typedefs typedef unsigned int MDB_dbi A handle for an individual database in the DB environment. typedef int( MDB_cmp_func )(const MDB_val *a, const MDB_val *b) A callback function used to compare two keys in a database. typedef void( MDB_rel_func )(MDB_val *item, void *oldptr, void *newptr, void *relctx) A callback function used to relocate a position-dependent data item in a fixed-address database. typedef void MDB_assert_func (MDB_env *env, const char *msg) A callback function for most LMDB assert() failures, called before printing the message and aborting. typedef int( MDB_msg_func )(const char *msg, void *ctx) A callback function used to print a message from the library. Enumerations Enumerations enum MDB_cursor_op { MDB_FIRST, MDB_FIRST_DUP, MDB_GET_BOTH, MDB_GET_BOTH_RANGE, MDB_GET_CURRENT, MDB_GET_MULTIPLE, MDB_LAST, MDB_LAST_DUP, MDB_NEXT, MDB_NEXT_DUP, MDB_NEXT_MULTIPLE, MDB_NEXT_NODUP, MDB_PREV, MDB_PREV_DUP, MDB_PREV_NODUP, MDB_SET, MDB_SET_KEY, MDB_SET_RANGE } Cursor Get operations. More… Caveatshaven’t read yet benchmark","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"ssh远程关闭服务器 init 0","slug":"ssh远程关闭服务器-init-0","date":"2023-12-26T03:05:35.000Z","updated":"2023-12-26T03:06:31.000Z","comments":true,"path":"2023/12/26/ssh远程关闭服务器-init-0/","link":"","permalink":"http://example.com/2023/12/26/ssh%E8%BF%9C%E7%A8%8B%E5%85%B3%E9%97%AD%E6%9C%8D%E5%8A%A1%E5%99%A8-init-0/","excerpt":"","text":"目前是ssh登录到远程服务器的状态，想关闭远程服务器： sudo init 0","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win10桌面刷新快捷键","slug":"win10桌面刷新快捷键","date":"2023-12-26T02:34:17.000Z","updated":"2023-12-26T02:34:24.000Z","comments":true,"path":"2023/12/26/win10桌面刷新快捷键/","link":"","permalink":"http://example.com/2023/12/26/win10%E6%A1%8C%E9%9D%A2%E5%88%B7%E6%96%B0%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"F5","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win10黑屏只有鼠标的解决方案","slug":"win10黑屏只有鼠标的解决方案","date":"2023-12-26T02:23:22.000Z","updated":"2023-12-26T02:25:20.000Z","comments":true,"path":"2023/12/26/win10黑屏只有鼠标的解决方案/","link":"","permalink":"http://example.com/2023/12/26/win10%E9%BB%91%E5%B1%8F%E5%8F%AA%E6%9C%89%E9%BC%A0%E6%A0%87%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"","text":"https://knowledge.ipason.com/ipKnowledge/knowledgedetail.html/104#:~:text=%E9%BB%91%E5%B1%8F%E7%9A%84%E6%97%B6%E5%80%99%E5%8F%AA%E6%9C%89%E9%BC%A0%E6%A0%87,%E5%8F%AF%E4%BB%A5%E8%A7%A3%E5%86%B3%E9%BB%91%E5%B1%8F%E5%8F%AA%E6%9C%89%E9%BC%A0%E6%A0%87 进入这种状态的一个原因之一是explorer.exe或者Windows资源管理器进程出现一些情况，所以一个方法是关掉这个进程重新跑它：1、首先在键盘上按下【Ctrl+Alt+DEL】调出操作界面，打开【任务管理器】。2、在【启动任务管理器】界面找到【进程】。3、（如果有的话）然后找到运行的【explorer.exe】，win10 这里叫【Windows资源管理器】。接着我们鼠标右键点【explorer.exe或Windows资源管理器】，右击选择【结束进程】。4、依次点【文件】–【运行新任务】。5、直接在其中输入【explorer.exe】，点确定，按键盘F5再次刷新桌面，就好了。","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"regular file 是啥","slug":"regular-file-是啥","date":"2023-12-24T06:18:03.000Z","updated":"2024-01-18T08:42:04.000Z","comments":true,"path":"2023/12/24/regular-file-是啥/","link":"","permalink":"http://example.com/2023/12/24/regular-file-%E6%98%AF%E5%95%A5/","excerpt":"","text":"https://www.computerhope.com/jargon/r/regular-file.htm In the Linux kernel, file types are declared in the header file sys&#x2F;stat.h. The type name, symbolic name, and bitmask for each Linux file type are listed below. Type name Symbolic name Bitmask Socket S_IFSOCK 0140000 Symbolic link S_IFLNK 0120000 Regular file S_IFREG 0100000 Block special file S_IFBLK 0060000 Directory S_IFDIR 0040000 Character device S_IFCHR 0020000 FIFO (first in, first out) S_IFIFO 0010000 Most files used directly by a human user are regular files. For example, executable files, text files, and image files are regular files. list regular file find -type f check is regular file test -f file returns an exit status of 0 if file is a regular file. It returns 1 if file is of another type or does not exist.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"编译运行使用rocksdb的项目","slug":"编译运行使用rocksdb的项目","date":"2023-12-24T02:34:37.000Z","updated":"2024-01-18T08:47:13.000Z","comments":true,"path":"2023/12/24/编译运行使用rocksdb的项目/","link":"","permalink":"http://example.com/2023/12/24/%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E4%BD%BF%E7%94%A8rocksdb%E7%9A%84%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"流程： 编译rocksdb静态库(.a)或动态库(.so) 写编译控制文件，给你的target链接rocksdb库，以及rocksdb库依赖的其他库 编译生成rocksdb库编译生成rocksdb动态库： tar -zxvf rocksdb-v8.0.0-main.tar.gz # rocksdb-v8.0.0-main.tar.gz是github上rocksdb源码 cd rocksdb-v8.0.0 make shared_lib DISABLE_WARNING_AS_ERROR=true # 在当前目录下生成librocksdb.so* 编译生成rocksdb静态库：上述把shared_lib改成static_lib，在当前目录下生成librocksdb.a g++手动编译，没有解决指定要链接rocksdb库，所以加上参数-lrocksdb（以及让ld详细输出-Wl,--verbose），且加上-L/home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0指明编译链接阶段可以搜索库的路径 但是仍然报一样的错 ld能找到rocksdb库，librocksdb.so和librocksdb.a都找到了 attempt to open /home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/librocksdb.so succeeded 这就很玄学 CMake解决用cmake，写完target_link_libraries(rocksdb_lmdb /home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/librocksdb.a)之后就直接解决了上面的链接阶段没有链接到rocksdb库的问题 https://github.com/TuGraph-family/gdbms-microbenchmark/tree/master/kv_test 编译rocksdb_lmdb.cpp： cmake_minimum_required(VERSION 3.15) project(rksdb_lmdb) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++17 -I/home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/include -pthread&quot;) # -Wl,--verbose: argument to ld # -pthread: Define additional macros required for using the POSIX threads library. add_executable(rocksdb_lmdb rocksdb_lmdb.cpp) target_link_libraries(rocksdb_lmdb lmdb /home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/librocksdb.a z dl gflags stdc++fs) # z dl: needed for rocksdb # gflags stdc++fs: needed in rocksdb_lmdb.cpp","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"将目录下全部文本文件的\\n\\r替换为\\n win记事本的换行符\\n\\r换成\\n","slug":"将目录下全部文本文件的-n-r替换为-n-win记事本的换行符-n-r换成-n","date":"2023-12-24T02:34:15.000Z","updated":"2023-12-24T06:17:45.000Z","comments":true,"path":"2023/12/24/将目录下全部文本文件的-n-r替换为-n-win记事本的换行符-n-r换成-n/","link":"","permalink":"http://example.com/2023/12/24/%E5%B0%86%E7%9B%AE%E5%BD%95%E4%B8%8B%E5%85%A8%E9%83%A8%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%9A%84-n-r%E6%9B%BF%E6%8D%A2%E4%B8%BA-n-win%E8%AE%B0%E4%BA%8B%E6%9C%AC%E7%9A%84%E6%8D%A2%E8%A1%8C%E7%AC%A6-n-r%E6%8D%A2%E6%88%90-n/","excerpt":"","text":"win换行符\\r替换为没有： 单个文件： sed -i &#39;s/\\r//g&#39; filename 其中-i: sed处理过的输出是直接输出到屏幕上的,要保存可以将输出重定向,或者使用-i直接在文件中替换替换动作s: sed ‘s&#x2F;原字符串&#x2F;替换字符串&#x2F;‘g: g替换每一个匹配的关键字,否则只替换每行的第一个 某目录下的全部regular file: find ./ -type f | xargs sed -i &#39;s/\\r//g&#39;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"有线网络修复","slug":"有线网络修复","date":"2023-12-23T09:22:37.000Z","updated":"2023-12-23T09:49:58.000Z","comments":true,"path":"2023/12/23/有线网络修复/","link":"","permalink":"http://example.com/2023/12/23/%E6%9C%89%E7%BA%BF%E7%BD%91%E7%BB%9C%E4%BF%AE%E5%A4%8D/","excerpt":"","text":"https://support.microsoft.com/zh-cn/windows/%E4%BF%AE%E5%A4%8D-windows-%E4%B8%AD%E7%9A%84%E4%BB%A5%E5%A4%AA%E7%BD%91%E8%BF%9E%E6%8E%A5%E9%97%AE%E9%A2%98-2311254e-cab8-42d6-90f3-cb0b9f63645f#WindowsVersion=Windows_10https://zhuanlan.zhihu.com/p/355042893 管理员模式进入cmd，然后 １、修复网络配置及winsock协议。 输入命令 netsh winsock reset ２、重置IP 设置，恢复到默认自动获取IP 和DNS 服务器地址。 输入命令 netsh int ip reset ３、解除代理设置。 输入命令 netsh winhttp reset proxy ４、重置防火墙设置。 输入命令 netsh advfirewall reset 重启 管理员模式进入cmd，然后 ５、ipconfig &#x2F;release命令，按回车键，进行释放电脑的ip地址，这时候会断一会儿网，会自动重新获取ip地址 ６、输入ipconfig &#x2F;renew命令，按回车键，可以进行重新获取ip地址 ７、输入ipconfig &#x2F;flushdns命令，按回车键，可以进行刷新DNS缓存","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win10安装wifi驱动","slug":"win10安装wifi驱动","date":"2023-12-23T09:14:10.000Z","updated":"2023-12-23T09:40:13.000Z","comments":true,"path":"2023/12/23/win10安装wifi驱动/","link":"","permalink":"http://example.com/2023/12/23/win10%E5%AE%89%E8%A3%85wifi%E9%A9%B1%E5%8A%A8/","excerpt":"","text":"前提是有无线网卡这个硬件，检查是否有： 设备管理器-网络适配器，看有没有名字包含wireless的没有的话没有网卡噢 有些win10电脑没有安装wifi驱动，连不了无线网，网络相关的设置里面有没有无线驱动相关的部分： 网络设置中，没有wifi这项 更改适配器选项，没有wireless的 安装方法https://www.intel.cn/content/www/cn/zh/support/articles/000005600/wireless/legacy-intel-wireless-products.html","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"程序性能指标 ops qps tps","slug":"程序性能指标-ops-qps-tps","date":"2023-12-23T08:25:14.000Z","updated":"2023-12-23T08:27:46.000Z","comments":true,"path":"2023/12/23/程序性能指标-ops-qps-tps/","link":"","permalink":"http://example.com/2023/12/23/%E7%A8%8B%E5%BA%8F%E6%80%A7%E8%83%BD%E6%8C%87%E6%A0%87-ops-qps-tps/","excerpt":"","text":"tps：Transactions Per Second，一般在事务系统之中，主要是增删改操作 qps：Queries Per Second ops：Operates Per Second 一种测它们的方法，比如ops，是测出每个operates平均需要的时间，然后用1秒除以这个时间，得到1秒内可以进行的operates次数","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"linux下库和头文件的路径搜索顺序","slug":"linux下库和头文件的路径搜索顺序","date":"2023-12-23T02:45:51.000Z","updated":"2023-12-23T08:35:47.000Z","comments":true,"path":"2023/12/23/linux下库和头文件的路径搜索顺序/","link":"","permalink":"http://example.com/2023/12/23/linux%E4%B8%8B%E5%BA%93%E5%92%8C%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9A%84%E8%B7%AF%E5%BE%84%E6%90%9C%E7%B4%A2%E9%A1%BA%E5%BA%8F/","excerpt":"","text":"https://www.cnblogs.com/ishen/p/11993957.html 库文件介绍包含静态库文件(.a)和动态库文件(.so)。 静态库就是在链接的时候加入到执行代码中，成为了代码的一部分，所以生成的可执行文件就比较大，以后和静态库没瓜葛了，自己随便用了；动态库是指运行的时候会链接到库文件，如果没找到就运行。 overview 1.目标文件、静态库、动态库文件的生成目标文件xxx.o的生成，使用 -c 选项，指定只生成而不链接 gcc -c xxx.c -o xxx.o 静态库的生成，需先生成目标文件，使用**ar rcs**命令对其做转换 gcc -c xx1.c -o xx1.o gcc -c xx2.c -o xx2.o ar rsc libxxx.a xx1.o xx2.o 动态库的生成，使用**-shared要求生成动态库，通常还加上-fpic**要求生成的代码地址无关，就是要动态库内部的使用相对偏移寻址，防止安全攻击 gcc xxx.c -fPIC -shared -o libxxx.so 2. 头文件的查找顺序 先搜索当前目录 然后搜索**-I**指定的目录 gcc xxx.c -o xxx -lopenssl // 链接openssl.so 环境变量**CPLUS_INCLUDE_PATH（c使用的是C_INCLUDE_PATH**） 最后搜索gcc&#x2F;g++的内定目录&#x2F;usr&#x2F;include&#x2F;usr&#x2F;local&#x2F;include&#x2F;usr&#x2F;lib&#x2F;gcc&#x2F;x86_64-redhat-linux&#x2F;4.1.1&#x2F;include -v -H可以打印查找使用的头文件和过程 3.库的查找顺序运行时动态库的查找顺序:1.环境变量**LD_LIBRARY_PATH**（注意不是LIBRARY_PATH） 2.&#x2F;etc&#x2F;ld.so.conf下所包含的路径 其中，关于ld.so.conf中，参见此文: Linux的动态链接库绝大多数都在`/lib`和`/usr/lib`下，操作系统也会默认去这两个路径下搜索动态链接库。另外，`/etc/ld.so.conf`文件里可以配置路径，`/etc/ld.so.conf`文件会告诉操作系统去哪些路径下搜索动态链接库。这些位置的动态链接库很多，如果链接器每次都去这些路径遍历一遍，非常耗时，Linux提供了`ldconfig`工具，这个工具会对这些路径的动态链接库按照SONAME规则创建软连接，同时也会生成一个缓存Cache到`/etc/ld.so.cache`文件里，链接器根据缓存可以更快地查找到各个`.so`文件。每次在`/lib`和`/usr/lib`这些路径下安装了新的库，或者更改了`/etc/ld.so.conf`文件，都需要调用`ldconfig`命令来做一次更新，重新生成软连接和Cache。但是`/etc/ld.so.conf`文件和`ldconfig`命令最好使用root账户操作。非root用户可以在某个路径下安装库文件，并将这个路径添加到`/etc/ld.so.conf`文件下，再由root用户调用一下`ldconfig`。 编译链接时，库查找顺序:1.-L或 -Wl, rpath指定的路径 2.查找环境变量**LIBRARY_PATH**下的路径（注意不是LD_LIBRARY_PATH） 3.查找 &#x2F;etc&#x2F;ld.so.conf 下包含的路径 4 &#x2F;lib 和 &#x2F;usr&#x2F;lib 其中，-L和-Wl, rpath都能够显示的指定库所在的目录，但它们存在区别，参见此文: -L指定的库路径，在动态链接的时候，库的路径信息不会被存到到目标文件中，运行时目标文件只能通过LD_LIBRARY_PATH以及ld.so.conf提供的路径查找， 如果使用-Wl, rpath则库的路径会存到目标文件中，运行时目标文件会先去这个路径查找，找不到了，再去LD_LIBRARY_PATH和ld.so.conf中找 查看动态库的路径.so文件的 ldconfig -p 4. 链接静态库和动态库的优先级直接使用**-l查找路径的时候，gcc&#x2F;g++默认优先链接动态库，找不到动态库后，才去找静态**库 gcc xxx.c -o xxx -lopenssl // 链接openssl.so 要明确指明链接静态库就需要使用或者 -static 进行显示指定全都使用静态库 gcc xxx.c -o xxx -static -lopenssl // 链接libopenssl.a 也可以使用 -Wl,-Bstatic， 这个选项使用后，后续的-l都是去找静态库，但可以通过Wl,-Bdynamic 再指定后面的都是动态库 //连接 libxx1.a libxx2.a libxx3.so gcc xxx.c -o xxx -WL,-Bstatic -lxx1 -lxx2 -WL,-Bdynamic -lxx3 修改环境变量export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:XXXX 相较于g++原始编译，推荐CMake上面的路径搜索顺序、动态库静态库顺序、给编译器的flags还是适用的。 指明要链接库gflags： add_executable(main main.cpp) target_link_libraries(main gflags) 可以用绝对路径指明库文件 add_executable(main main.cpp) target_link_libraries(main /home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/librocksdb.a) 举例： 代码是https://github.com/TuGraph-family/gdbms-microbenchmark/tree/master/kv_test中的`rocksdb_lmdb.cpp` cmake_minimum_required(VERSION 3.15) project(rksdb_lmdb) set(CMAKE_CXX_STANDARD 17) set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++17 -I/home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/include -pthread&quot;) # for debug: -Wl,--verbose: argument to ld # -Idir: Add the directory dir to the list of directories to be searched for header files during preprocessing. # -pthread: Define additional macros required for using the POSIX threads library. add_executable(rocksdb_lmdb rocksdb_lmdb.cpp) target_link_libraries(rocksdb_lmdb lmdb /home/yuanzhiqiu/project/gpstore/tools/rocksdb-v8.0.0/librocksdb.a z dl gflags stdc++fs) # z dl: needed for rocksdb # gflags stdc++fs: needed in rocksdb_lmdb.cpp","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"英语缩写和连词用法例句","slug":"英语缩写和连词用法例句","date":"2023-12-13T10:57:29.000Z","updated":"2023-12-14T08:18:23.000Z","comments":true,"path":"2023/12/13/英语缩写和连词用法例句/","link":"","permalink":"http://example.com/2023/12/13/%E8%8B%B1%E8%AF%AD%E7%BC%A9%E5%86%99%E5%92%8C%E8%BF%9E%E8%AF%8D%E7%94%A8%E6%B3%95%E4%BE%8B%E5%8F%A5/","excerpt":"","text":"举例子e.g.There are many ways to cook an egg (e.g., boiled, scrambled, fried), but I have always preferred it poached.Many of the people present disagreed with the result of the assembly, e.g., faculty’s professors and deans. etc.Allow the children to eat only healthy food—vegetables, fruits, etc.The children should bring paper, pencils, scissors, etc.I love you to pieces, distraction, etc.Who are respondents (registered voters, likely voters, state residents, etc.) 去除情况excludingShe invited everyone to the party, excluding her noisy neighbors.The museum offers free admission to children, excluding infants.Excluding the latecomers, everyone was present at the meeting.I bought all the ingredients for the recipe, excluding the mushrooms.The discount applies to all items, excluding sale items and gift cards.The survey results were analyzed, excluding responses from participants under the age of 18.All passengers are allowed one carry-on bag, excluding personal items such as laptops or purses.The offer is valid for all customers, excluding those who have previously used a promotional code.You can choose any color for the room, excluding shades of red due to the client’s preference. 进一步解释that isThat is, you won’t be directly helping out with the groundwork, but with the theoretical part.You will be a community manager, that is, you will manage our social media posting.We had all decided we were going to make a surprise for her, a party, that is. in thatThe new smartphone is superior to its predecessor in that it has a faster processor and a larger display.She couldn’t attend the party, in that she had a prior commitment.He is a talented musician, in that he can play multiple instruments. i.e.I am a vegan, i.e., I do not eat any animal-based products.I do not like eating raw fish, i.e., sushi.She likes poetry about love, i.e., poems that explore matters of the heart : colonThere are three types of muscle in the body: cardiac, smooth, and skeletal.We have two options here: stay and fight, or run like the wind.There is one big reason we don’t talk about Bruno: His premonitions frightened the family.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python画图","slug":"python画图","date":"2023-12-13T05:55:10.000Z","updated":"2023-12-25T09:52:36.000Z","comments":true,"path":"2023/12/13/python画图/","link":"","permalink":"http://example.com/2023/12/13/python%E7%94%BB%E5%9B%BE/","excerpt":"","text":"import matplotlib.pyplot as plt import numpy as np 并列的柱状图labels = [&#39;G1&#39;, &#39;G2&#39;, &#39;G3&#39;, &#39;G4&#39;, &#39;G5&#39;] men_means = [20, 34, 30, 35, 27] women_means = [25, 32, 34, 20, 25] x = np.arange(len(labels)) # x locations width = 0.35 # the width of the bars fig, ax = plt.subplots() rects1 = ax.bar(x - width/2, men_means, width, label=&#39;Men&#39;) rects2 = ax.bar(x + width/2, women_means, width, label=&#39;Women&#39;) ax.set_ylabel(&#39;Scores&#39;) ax.set_title(&#39;Scores by group and gender&#39;) ax.set_xticks(x) ax.set_xticklabels(labels) ax.legend() def autolabel(rects): &quot;&quot;&quot;Attach a text label above each bar in *rects*, displaying its height.&quot;&quot;&quot; for rect in rects: height = rect.get_height() ax.annotate(&#39;&#123;&#125;&#39;.format(height), xy=(rect.get_x() + rect.get_width() / 2, height), xytext=(0, 3), # 3 points vertical offset textcoords=&quot;offset points&quot;, ha=&#39;center&#39;, va=&#39;bottom&#39;) autolabel(rects1) autolabel(rects2) fig.tight_layout() # plt.show() plt.savefig(&#39;output.jpg&#39;) 双Y轴曲线图https://www.cnblogs.com/atanisi/p/8530693.html x = np.arange(0., np.e, 0.01) y1 = np.exp(-x) y2 = np.log(x) fig = plt.figure() ax1 = fig.add_subplot() l1=ax1.plot(x, y1, label=&#39;l1&#39;) # line ax1.set_ylabel(&#39;Y values for exp(-x)&#39;) ax2 = ax1.twinx() # share x axis # 之后的公共操作，可以只在ax1上进行 l2=ax2.plot(x, y2, &#39;r&#39;, label=&#39;l1&#39;) # line # ax2.set_xlim([0, np.e]) ax2.set_ylabel(&#39;Y values for ln(x)&#39;) # 公共操作，在ax1上进行 ax1.set_title(&quot;Double Y axis&quot;) ax1.set_xlabel(&#39;Same X for both exp(-x) and ln(x)&#39;) # 公共图例 ls=l1+l2 labs = [l.get_label() for l in ls] ax1.legend(lns, labs, loc=0) plt.show() 小功能设置坐标轴显示范围ax2.set_xlim([0, np.e])","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"linux查看系统日志","slug":"linux查看系统日志","date":"2023-12-08T13:55:29.000Z","updated":"2023-12-08T13:55:44.000Z","comments":true,"path":"2023/12/08/linux查看系统日志/","link":"","permalink":"http://example.com/2023/12/08/linux%E6%9F%A5%E7%9C%8B%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97/","excerpt":"","text":"dmesg","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"docker request returned Method Not Allowed for API route and version win10","slug":"docker-request-returned-Method-Not-Allowed-for-API-route-and-version-win10","date":"2023-11-24T00:46:45.000Z","updated":"2023-11-24T00:47:16.000Z","comments":true,"path":"2023/11/24/docker-request-returned-Method-Not-Allowed-for-API-route-and-version-win10/","link":"","permalink":"http://example.com/2023/11/24/docker-request-returned-Method-Not-Allowed-for-API-route-and-version-win10/","excerpt":"","text":"问题： &gt;docker ps request returned Method Not Allowed for API route and version http://%2F%2F.%2Fpipe%2Fdocker_engine/v1.24/containers/json, check if the server supports the requested API version 解决方法：关掉docker desktop，以管理员身份运行","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"docker desktop win10 解决一直在starting或者settings一直在转圈","slug":"docker-desktop-win10-解决一直在starting或者settings一直在转圈","date":"2023-11-23T03:02:22.000Z","updated":"2023-11-23T03:03:39.000Z","comments":true,"path":"2023/11/23/docker-desktop-win10-解决一直在starting或者settings一直在转圈/","link":"","permalink":"http://example.com/2023/11/23/docker-desktop-win10-%E8%A7%A3%E5%86%B3%E4%B8%80%E7%9B%B4%E5%9C%A8starting%E6%88%96%E8%80%85settings%E4%B8%80%E7%9B%B4%E5%9C%A8%E8%BD%AC%E5%9C%88/","excerpt":"","text":"可能是wsl2需要更新，先关掉所有docker程序（任务管理器，结束所有docker的任务），然后 wsl --update 结束之后重新点docker desktop就好了","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win cmd 美化","slug":"win-cmd-美化","date":"2023-11-17T01:03:11.000Z","updated":"2023-11-22T09:00:30.000Z","comments":true,"path":"2023/11/17/win-cmd-美化/","link":"","permalink":"http://example.com/2023/11/17/win-cmd-%E7%BE%8E%E5%8C%96/","excerpt":"","text":"在Micorsoft store安装windows terminal 设置windows terminal为默认终端（比如这样就可以通过win+x,c来启动了）：打开windows terminal，打开设置，设置默认终端应用程序为windows终端 配色方案：https://windowsterminalthemes.dev/windows terminal的设置中选择打开json，然后把下面的加到主题那里，就可以新增主题选项了一种好看的配色 &#123; &quot;name&quot;: &quot;Ayu Mirage&quot;, &quot;black&quot;: &quot;#191e2a&quot;, &quot;red&quot;: &quot;#ed8274&quot;, &quot;green&quot;: &quot;#a6cc70&quot;, &quot;yellow&quot;: &quot;#fad07b&quot;, &quot;blue&quot;: &quot;#6dcbfa&quot;, &quot;purple&quot;: &quot;#cfbafa&quot;, &quot;cyan&quot;: &quot;#90e1c6&quot;, &quot;white&quot;: &quot;#c7c7c7&quot;, &quot;brightBlack&quot;: &quot;#686868&quot;, &quot;brightRed&quot;: &quot;#f28779&quot;, &quot;brightGreen&quot;: &quot;#bae67e&quot;, &quot;brightYellow&quot;: &quot;#ffd580&quot;, &quot;brightBlue&quot;: &quot;#73d0ff&quot;, &quot;brightPurple&quot;: &quot;#d4bfff&quot;, &quot;brightCyan&quot;: &quot;#95e6cb&quot;, &quot;brightWhite&quot;: &quot;#ffffff&quot;, &quot;background&quot;: &quot;#1f2430&quot;, &quot;foreground&quot;: &quot;#cbccc6&quot;, &quot;selectionBackground&quot;: &quot;#33415e&quot;, &quot;cursorColor&quot;: &quot;#ffcc66&quot; &#125; 太好看了我哭哭 相见恨晚 设置默认字体大小：修改json文件： &quot;profiles&quot;: &#123; &quot;defaults&quot;: &#123; &quot;colorScheme&quot;: &quot;Ayu Mirage&quot;, &quot;font&quot;: &#123; &quot;size&quot;: 12 &#125; &#125;, &quot;list&quot;: [ // ... ] &#125;,","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"命令行安装R","slug":"命令行安装R","date":"2023-10-29T10:38:37.000Z","updated":"2023-10-29T10:49:17.000Z","comments":true,"path":"2023/10/29/命令行安装R/","link":"","permalink":"http://example.com/2023/10/29/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%AE%89%E8%A3%85R/","excerpt":"","text":"命令行安装no root access:or say, install from source $ wget http://cran.rstudio.com/src/base/R-3/R-3.1.1.tar.gz $ tar xvf R-3.1.1.tar.gz $ cd R-3.1.1 $ ./configure --prefix=/home/Kryo/R-3.1.1 $ make -j 可能没有装bzip2，得install from sourcehttps://stackoverflow.com/questions/15910219/how-to-manually-pass-source-of-bzip2-install-for-python-install或者是在path但是却说找不到https://stackoverflow.com/questions/60499505/bzip2-in-path-but-not-found-while-installing-r 命令行运行https://stackoverflow.com/questions/18306362/run-r-script-from-command-line","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"perf火焰图“","slug":"perf火焰图“","date":"2023-10-28T06:32:01.000Z","updated":"2024-02-25T03:07:11.376Z","comments":true,"path":"2023/10/28/perf火焰图“/","link":"","permalink":"http://example.com/2023/10/28/perf%E7%81%AB%E7%84%B0%E5%9B%BE%E2%80%9C/","excerpt":"","text":"火焰图介绍https://www.ruanyifeng.com/blog/2017/09/flame-graph.html 火焰图生成教程https://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html 下载根据perf输出得到火焰图的可执行文件./stackcollapse-perf.pl&amp;./flamegraph.plgit clone https://github.com/brendangregg/FlameGraph # or download it from github cd FlameGraph perf你的程序，会将数据放到./perf.data中sudo perf record -F 2999 -a --call-graph dwarf yourRunningCmd # The perf record command samples at 2999 Hertz (-F 2999) across all CPUs (-a), capturing stack traces so that a call graph (-g) of function ancestry can be generated later. # The samples are saved in a perf.data file, which are read by perf script. # --call-graph dwarf: When &quot;dwarf&quot; recording is used, perf also records (user) stack dump # when sampled. Default size of the stack dump is 8192 (bytes). # User can change the size by passing the size after comma like # &quot;--call-graph dwarf,4096&quot;. # 或者，更快一点的： sudo perf record -F 2999 -a --call-graph fp yourRunningCmd # --call-graph fp: faster then --call-graph dwarf 根据./perf.data生成火焰图sudo perf script | ./stackcollapse-perf.pl &gt; out.perf-folded ./flamegraph.pl out.perf-folded &gt; perf.svg modfun上火焰图装在&#x2F;home&#x2F;shared&#x2F;FlameGraph&#x2F;生成火焰图 sudo perf script | /home/shared/FlameGraph/stackcollapse-perf.pl &gt; out.perf-folded /home/shared/FlameGraph/flamegraph.pl out.perf-folded &gt; perf.svg 火焰图分析点击块，会expand 支持统计关键字（可正则搜索）出现的百分比，且根据选择的根块自动换算百分比点击根块，然后ctrl+f搜索要统计的关键字，然后火焰图上就会用粉紫色高亮匹配到的块，并在右下角显示总共的百分比且关键词支持正则搜索，比如搜Database::|getobjIDlistBysubIDpreID|getsubIDlistByobjIDpreID自动换算是指，比如调用栈是main-&gt;fun1-&gt;fun2，统计某关键字的百分比时，点击main块得到的结果和点击fun1块得到的结果不一样","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python内存和时间占用监测 资源占用监测","slug":"python内存和时间占用监测-资源占用监测","date":"2023-10-18T05:37:59.000Z","updated":"2023-10-18T05:40:26.000Z","comments":true,"path":"2023/10/18/python内存和时间占用监测-资源占用监测/","link":"","permalink":"http://example.com/2023/10/18/python%E5%86%85%E5%AD%98%E5%92%8C%E6%97%B6%E9%97%B4%E5%8D%A0%E7%94%A8%E7%9B%91%E6%B5%8B-%E8%B5%84%E6%BA%90%E5%8D%A0%E7%94%A8%E7%9B%91%E6%B5%8B/","excerpt":"","text":"我们可以使用sys模块的getsizeof函数来检查存储同样的元素的元组和列表各自占用了多少内存空间 f = [x ** 2 for x in range(1, 1000)] print(sys.getsizeof(f)) # 查看对象占用内存的字节数 我们可以在ipython中使用魔法指令%timeit来分析创建同样内容的元组和列表所花费的时间 &gt;ipython Python 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)] Type &#39;copyright&#39;, &#39;credits&#39; or &#39;license&#39; for more information IPython 8.4.0 -- An enhanced Interactive Python. Type &#39;?&#39; for help. In [1]: %timeit [1,2,3] 41.2 ns ± 0.428 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each) In [2]: %timeit (1,2,3) 7.3 ns ± 0.0727 ns per loop (mean ± std. dev. of 7 runs, 100,000,000 loops each)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"chrome查看网页cookie","slug":"chrome查看网页cookie","date":"2023-10-18T01:17:46.000Z","updated":"2024-02-17T02:37:25.372Z","comments":true,"path":"2023/10/18/chrome查看网页cookie/","link":"","permalink":"http://example.com/2023/10/18/chrome%E6%9F%A5%E7%9C%8B%E7%BD%91%E9%A1%B5cookie/","excerpt":"","text":"F12-network-Doc-你要查看的网页的Name条目（在network界面有）（如果没有数据，刷新一下界面）-Headers可以看到有cookie等信息左键三次可以选中cookie信息","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"transformer模型介绍","slug":"transformer模型介绍","date":"2023-10-13T01:49:29.000Z","updated":"2023-10-13T02:05:24.000Z","comments":true,"path":"2023/10/13/transformer模型介绍/","link":"","permalink":"http://example.com/2023/10/13/transformer%E6%A8%A1%E5%9E%8B%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"Large-scale pre-trained models (PTMs), such as Transformer models, have promoted the deep learning (DL) development on various complicated tasks, including natural language processing, e.g., BERT [9], GPT [6], T5 [41], computer vision, e.g., ViT [10], Swin [25], advertising recommendation, e.g., M6 [24], and so on.These models are also known as foundation models since they are trained on hundreds of gigabytes of data and can be adapted, e.g., task-specific fine-tuning, to a wide range of downstream tasks FlexMoE: Scaling Large-scale Sparse Pre-trained Model Training via Dynamic Device Placement https://zhuanlan.zhihu.com/p/338817680","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"virtualbox解决桥接网卡无法上网的问题","slug":"virtualbox解决桥接网卡无法上网的问题","date":"2023-10-12T10:12:25.000Z","updated":"2023-10-12T10:20:20.000Z","comments":true,"path":"2023/10/12/virtualbox解决桥接网卡无法上网的问题/","link":"","permalink":"http://example.com/2023/10/12/virtualbox%E8%A7%A3%E5%86%B3%E6%A1%A5%E6%8E%A5%E7%BD%91%E5%8D%A1%E6%97%A0%E6%B3%95%E4%B8%8A%E7%BD%91%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"https://blog.csdn.net/a469517790/article/details/80747383 在PC中，为虚拟机上网的网卡（可能和桥接的网卡不一样），设置成与实际上PC上网的网卡共享：实际上PC上网的网卡：如果PC是有线网，则有实际网卡，如果是无线网，则是无线网卡虚拟机上网的网卡：PC中点击左下角网络图标-网络和internet设置-更改适配器选项，可以看到一个连接叫VirtualBox Host-Only Ethernet Adapter右键这个适配器-属性-共享，勾选，然后在下拉框中选择你PC上网的网卡（如何判断PC上网的网卡：看状态，应该是已启用的状态）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"makefile中设置环境变量","slug":"makefile中设置环境变量","date":"2023-10-11T08:20:19.000Z","updated":"2023-10-11T08:22:25.000Z","comments":true,"path":"2023/10/11/makefile中设置环境变量/","link":"","permalink":"http://example.com/2023/10/11/makefile%E4%B8%AD%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"直接像命令行中一样设置会有问题，应这样设置：https://segmentfault.com/a/1190000008535305 全局设置： export FLASK_ENV=dev export FLASK_DEBUG=1 dev: @echo $(FLASK_ENV) @echo $(FLASK_DEBUG) 运行make dev时则返回： $ make devdev1 在不同target下设置不同环境变量： dev:export FLASK_ENV=dev dev:export FLASK_DEBUG=1 dev: @echo $(FLASK_ENV) @echo $(FLASK_DEBUG) prod:export FLASK_ENV=prod prod:export FLASK_DEBUG=0 prod: @echo $(FLASK_ENV) @echo $(FLASK_DEBUG) $ make devdev1$ make prodprod0","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"hadoop入门 example","slug":"hadoop入门-example","date":"2023-10-11T02:07:47.000Z","updated":"2023-10-11T11:07:30.000Z","comments":true,"path":"2023/10/11/hadoop入门-example/","link":"","permalink":"http://example.com/2023/10/11/hadoop%E5%85%A5%E9%97%A8-example/","excerpt":"","text":"最简单的wordcount程序https://hadoop.apache.org/docs/stable/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html 加上in-mapper-combine：https://jinwooooo.github.io/jinwooooo-blog/hadoop-in-mapper-combiner/ hadoop坑：Text不能代替String作为map的key：Text作为key，判断是是地址值因此不管是用set的方式还是每次new，都无法实现用string作key的语义 Map&lt;Text, Integer&gt; count = new HashMap&lt;Text, Integer&gt;(); private Text word = new Text(); // local aggregate public void map(Object key, Text value, Context context ) throws IOException, InterruptedException &#123; StringTokenizer itr = new StringTokenizer(value.toString()); while (itr.hasMoreTokens()) &#123; word.set(itr.nextToken()); if(count.containsKey(word)) &#123; // 所有的都会走这个分支，因为word的地址不变 count.put(word, (int) count.get(word) + 1); &#125; else &#123; count.put(word, 1); &#125; &#125; &#125; 这才可以： Map&lt;String, Integer&gt; count = new HashMap&lt;String, Integer&gt;(); // local aggregate public void map(Object key, Text value, Context context ) throws IOException, InterruptedException &#123; StringTokenizer itr = new StringTokenizer(value.toString()); while (itr.hasMoreTokens()) &#123; String wd = itr.nextToken(); if(count.containsKey(wd)) &#123; count.put(wd, (int) count.get(wd) + 1); &#125; else &#123; count.put(wd, 1); &#125; &#125; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"光标移动不用方向键 vscode shell等","slug":"光标移动不用方向键-vscode-shell等","date":"2023-10-11T01:42:58.000Z","updated":"2023-10-11T01:49:27.000Z","comments":true,"path":"2023/10/11/光标移动不用方向键-vscode-shell等/","link":"","permalink":"http://example.com/2023/10/11/%E5%85%89%E6%A0%87%E7%A7%BB%E5%8A%A8%E4%B8%8D%E7%94%A8%E6%96%B9%E5%90%91%E9%94%AE-vscode-shell%E7%AD%89/","excerpt":"","text":"vscodehttps://blog.csdn.net/m0_65450343/article/details/124704989ctrl+K, ctrl+S 进入快捷键设置alt+i 上alt+k 下alt+j 左alt+l 右alt+u 行首alt+o 行末 // Place your key bindings in this file to override the defaultsauto[] [ &#123; &quot;key&quot;: &quot;alt+i&quot;, &quot;command&quot;: &quot;cursorUp&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;up&quot;, &quot;command&quot;: &quot;cursorUp&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+i&quot;, &quot;command&quot;: &quot;selectPrevSuggestion&quot;, &quot;when&quot;: &quot;suggestWidgetMultipleSuggestions &amp;&amp; suggestWidgetVisible &amp;&amp; textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;up&quot;, &quot;command&quot;: &quot;selectPrevSuggestion&quot;, &quot;when&quot;: &quot;suggestWidgetMultipleSuggestions &amp;&amp; suggestWidgetVisible &amp;&amp; textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+k&quot;, &quot;command&quot;: &quot;cursorDown&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;down&quot;, &quot;command&quot;: &quot;cursorDown&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+k&quot;, &quot;command&quot;: &quot;selectNextSuggestion&quot;, &quot;when&quot;: &quot;suggestWidgetMultipleSuggestions &amp;&amp; suggestWidgetVisible &amp;&amp; textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;down&quot;, &quot;command&quot;: &quot;-selectNextSuggestion&quot;, &quot;when&quot;: &quot;suggestWidgetMultipleSuggestions &amp;&amp; suggestWidgetVisible &amp;&amp; textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+l&quot;, &quot;command&quot;: &quot;cursorRight&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;right&quot;, &quot;command&quot;: &quot;cursorRight&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+j&quot;, &quot;command&quot;: &quot;cursorLeft&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;left&quot;, &quot;command&quot;: &quot;cursorLeft&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+o&quot;, &quot;command&quot;: &quot;cursorEnd&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;end&quot;, &quot;command&quot;: &quot;cursorEnd&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;alt+u&quot;, &quot;command&quot;: &quot;cursorHome&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125;, &#123; &quot;key&quot;: &quot;home&quot;, &quot;command&quot;: &quot;cursorHome&quot;, &quot;when&quot;: &quot;textInputFocus&quot; &#125; ] shellhttps://blog.csdn.net/Mmm654/article/details/100990346Ctrl+n相当于方向向下的方向键，Ctrl+p相当于方向向上的方向键。Ctrl+a：光标回到命令行首。 （a：ahead）Ctrl+e：光标回到命令行尾。 （e：end）Ctrl+b：光标向行首移动一个字符。 （b：backwards）Ctrl+f：光标向行尾移动一个字符。 （f：forwards）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python pip安装网络问题","slug":"python-pip安装网络问题","date":"2023-10-10T11:38:49.000Z","updated":"2023-10-10T11:43:07.000Z","comments":true,"path":"2023/10/10/python-pip安装网络问题/","link":"","permalink":"http://example.com/2023/10/10/python-pip%E5%AE%89%E8%A3%85%E7%BD%91%E7%BB%9C%E9%97%AE%E9%A2%98/","excerpt":"","text":"https://blog.csdn.net/qq_22476313/article/details/120342538 python.exe -m pip install scikit-learn -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com 解决方式：在 pip install xxx 后面加上镜像路径(xxxx为要安装的包) # 阿里云 pip install xxxx -i http://mirrors.aliyun.com/pypi/simple/ --trust-host mirrors.aliyun.com # or 中国科技大学 pip install xxxx -i https://pypi.mirrors.ustc.edu.cn/simple/ --trust-host pypi.mirrors.ustc.edu.cn # or 豆瓣 pip install xxxx -i http://pypi.douban.com/simple/ --trust-host pypi.douban.com # or 清华大学 pip install xxxx -i https://pypi.tuna.tsinghua.edu.cn/simple/ --trust-host pypi.tuna.tsinghua.edu.cn","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"ubuntu打不开termial解决 图形界面和ctrl+alt+T快捷键都打不开","slug":"ubuntu打不开termial解决-图形界面和ctrl-alt-T快捷键都打不开","date":"2023-10-08T01:42:32.000Z","updated":"2023-10-11T02:18:43.000Z","comments":true,"path":"2023/10/08/ubuntu打不开termial解决-图形界面和ctrl-alt-T快捷键都打不开/","link":"","permalink":"http://example.com/2023/10/08/ubuntu%E6%89%93%E4%B8%8D%E5%BC%80termial%E8%A7%A3%E5%86%B3-%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E5%92%8Cctrl-alt-T%E5%BF%AB%E6%8D%B7%E9%94%AE%E9%83%BD%E6%89%93%E4%B8%8D%E5%BC%80/","excerpt":"","text":"解决流程https://www.jianshu.com/p/6c21a1683ac5ctrl+alt+F1进入命令行界面，解决gnome-terminal的报错，然后ctrl+alt+F7返回图形界面，即解决问题 [可选步骤]export DISPLAY&#x3D;:0https://askubuntu.com/questions/871092/failed-to-connect-to-mir-failed-to-connect-to-server-socket-no-such-file-or-di不过这一步只是为了在命令行界面gnome-terminal”报正确的错”，并不是导致ubuntu打不开terminal的原因此步骤解决下述报错 $ gnome-terminal Failed to connect to Mir: Failed to connect to server socket: No such file or directory Unable to init server: Could not connect: Connection refused Error: cannot open display: 改locale（原来是LANG&#x3D;”en_US”，改成LANG&#x3D;”en_US.UTF-8”）（改文件然后重启） vi /etc/default/locale https://askubuntu.com/questions/608330/problem-with-gnome-terminal-on-gnome-3-12-2是这步解决了ubuntu打不开terminal的问题此步骤解决下述报错 $ gnome-terminal Error constructing proxy for org.gnome.Terminal: /org/gnome/Terminal/Factory0: Error calling StartServiceByName for org.gnome.Terminal: GDBus.Error:org.freedesktop.DBus.Error.Spawn.ChildExited: Process /usr/lib/gnome-terminal/gnome-terminal-server exited with status 8","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"awk提取文件某一列存到数组中 awk输出存到数组 awk存到数组","slug":"awk提取文件某一列存到数组中-awk输出存到数组-awk存到数组","date":"2023-08-08T06:38:52.000Z","updated":"2023-08-08T06:52:20.000Z","comments":true,"path":"2023/08/08/awk提取文件某一列存到数组中-awk输出存到数组-awk存到数组/","link":"","permalink":"http://example.com/2023/08/08/awk%E6%8F%90%E5%8F%96%E6%96%87%E4%BB%B6%E6%9F%90%E4%B8%80%E5%88%97%E5%AD%98%E5%88%B0%E6%95%B0%E7%BB%84%E4%B8%AD-awk%E8%BE%93%E5%87%BA%E5%AD%98%E5%88%B0%E6%95%B0%E7%BB%84-awk%E5%AD%98%E5%88%B0%E6%95%B0%E7%BB%84/","excerpt":"","text":"# 将tmp文件中倒数第二列提取到一个数组evl中 # 这样不行: evl=`awk &#39;&#123;print $(NF-1)&#125;&#39; tmp` 这样是把空格分割的字符串赋值给evl（且还不严格是空格分割的，用IFS方法拆分无效） # 得加一个括号，这样转成数组 evl=(`awk &#39;&#123;print $(NF-1)&#125;&#39; tmp`) echo -e &quot;$&#123;evl[0]&#125;\\t$&#123;evl[1]&#125;&quot;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"正则表达式","slug":"正则表达式","date":"2023-08-05T07:15:40.000Z","updated":"2023-08-05T07:18:51.000Z","comments":true,"path":"2023/08/05/正则表达式/","link":"","permalink":"http://example.com/2023/08/05/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","excerpt":"","text":"一些语法x 匹配字符 x. 除换行符外的任何字符[xyz] 字符类别；匹配x、y、z[abj-oZ] 具有范围的字符类；匹配 a， b， j到o中的任何字母或 Z[^A-Z] 否定字符类，即该类中的字符以外的任何字符 [^A-Z\\n] 除大写字母或换行符外的任何字符 r* 零个或多个r，其中r是任何正则表达式（如何确定r：*前的子表达式）r+ 一个或多个 rr？ 零或一个rr{2,5} 从两到五​​个r{2,} 两个或多个r{4} 恰好4个上面这些默认是最长匹配，加一个?则是最短匹配*? 重复任意次，但尽可能少重复+? 重复1次或更多次，但尽可能少重复?? 重复0次或1次，但尽可能少重复{n,m}? 重复n到m次，但尽可能少重复{n,}? 重复n次以上，但尽可能少重复 {name} 扩展name定义，把别处定义的name拿过来用 \\X 普通字符(不是特殊字符，比如不是*,&quot;等)不转义，就是表示\\x。否则，为字符X 举例：”[xyz]&quot;foo” 表示[xyz]&quot;foo，外面的””表示是一个字符串，里面的&quot;表示是一个转义字符，匹配&quot;\\0 一个NUL字符（ASCII代码0）\\123 八进制值123的字符\\x2a 十六进制值为2a的字符 (r) 匹配r；定义子表达式；括号用于改变优先级；且可以和\\1等配合进行捕获 rs 正则表达式r后跟正则表达式s，称为串联r|s r或sr&#x2F;s 一个r，但前提是其后跟一个s。确定此规则是否为最长匹配项时， 将包含用s匹配的文本，但在执行操作之前，该文本将返回到输入。因此， 该操作只会看到与r匹配的文本。这种模式称为尾随上下文。 （flex不能正确 匹配某些r&#x2F;s组合。有关危险的尾随上下文，请参见限制。） ^r 一个r，但仅在一行的开头（即刚开始扫描时，或在扫描换行符之后）。r$ 一个r，但只能在一行的末尾（即，在换行符之前）。等同于r&#x2F;\\n。 请注意，flex的”换行符”概念与C编译器用来将flex解释为\\n的情况完全相同。 特别是，在某些DOS系统上，您必须自己过滤掉输入中的\\r， 或显式地将” r &#x2F;\\r\\ n”用作” r $”。 r 一个r，但仅在起始条件s中（请参阅”起始条件”以了解起始条件）。&lt;s1，s2，s3&gt; r 同上，但在任何启动条件s1，s2或s3中。&lt;*&gt; r 任何开始条件下的r，甚至是排他条件。&lt;&lt; EOF &gt;&gt; 文件结束。&lt;s1,s2&gt;&lt;&gt; 在开始条件s1或s2中的文件结束 匹配任意字符串注意这样不行：[.\\n]* 这样会匹配.或\\n而不是任意字符要这样写：(.|\\n)* python正则表达式获取第一个匹配项的位置和值 import re pattern = r&quot;\\d+&quot; string = &quot;The price is 20 dollars and 50 cents.&quot; match = re.search(pattern, string) if match: print(&quot;匹配项的位置:&quot;, match.start()) # 匹配项的起始位置 print(&quot;匹配项的结束位置:&quot;, match.end()) # 匹配项的结束位置 print(&quot;匹配项的值:&quot;, match.group()) # 匹配项的值 获取所有匹配项的位置和值 import re pattern = r&quot;\\w+&quot; string = &quot;Python is a popular programming language.&quot; matches = re.finditer(pattern, string) for match in matches: print(&quot;匹配项的位置:&quot;, match.start()) # 匹配项的起始位置 print(&quot;匹配项的结束位置:&quot;, match.end()) # 匹配项的结束位置 print(&quot;匹配项的值:&quot;, match.group()) # 匹配项的值","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"bash分割字符串","slug":"bash分割字符串","date":"2023-08-05T03:25:24.000Z","updated":"2023-08-08T07:04:06.000Z","comments":true,"path":"2023/08/05/bash分割字符串/","link":"","permalink":"http://example.com/2023/08/05/bash%E5%88%86%E5%89%B2%E5%AD%97%E7%AC%A6%E4%B8%B2/","excerpt":"","text":"方法一 tr替代字符串然后()转数组string=&quot;hello,shell,split,test&quot; array=(`echo $string | tr &#39;,&#39; &#39; &#39;` ) # tr &#39;,&#39; &#39; &#39;将string中,替换成空格，然后()转成数组 for var in $&#123;array[@]&#125; do echo $var done 方法二 IFSf=interactive-complex-14.rq ori_IFS=$IFS # for later recovering IFS=&#39;.&#39; # setting . as delimiter read -a arr1 &lt;&lt;&lt;&quot;$f&quot; # reading f as an array as tokens separated by IFS str=$&#123;arr1[0]&#125; echo $str # interactive-complex-14 IFS=&#39;-&#39; # setting - as delimiter read -a arr2 &lt;&lt;&lt;&quot;$str&quot; # reading str as an array as tokens separated by IFS echo $&#123;arr2[-1]&#125; # 14 IFS=$ori_IFS # recover $IFS是一个特殊的内部变量，“内部字段分隔符”，它确定Bash如何识别边界。空格是$IFS的默认值。 分配定界符后，可以通过两个选项读取字符串：-r和-a。即，read -ra ARR &lt;&lt;&lt; “$str”。选项-r用于定义反斜杠()，它是字符而不是转义字符。-a选项用于定义将单词(用$IFS分隔)分配给从零开始的数组顺序索引。","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"ubuntu换源","slug":"ubuntu换源","date":"2023-07-26T06:18:37.000Z","updated":"2024-02-18T07:31:46.730Z","comments":true,"path":"2023/07/26/ubuntu换源/","link":"","permalink":"http://example.com/2023/07/26/ubuntu%E6%8D%A2%E6%BA%90/","excerpt":"","text":"https://blog.csdn.net/xiangxianghehe/article/details/122856771 https://midoq.github.io/2022/05/30/Ubuntu20-04%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85%E9%95%9C%E5%83%8F%E6%BA%90/ 总结步骤：- 编辑/etc/apt/sources.list，在文件最前面添加条目(操作前请做好相应备份)sudo apt-get update sudo apt-get upgrade","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"导入安装的wsl设置默认登录用户","slug":"导入安装的wsl设置默认登录用户","date":"2023-07-26T02:42:23.000Z","updated":"2024-02-18T04:09:52.748Z","comments":true,"path":"2023/07/26/导入安装的wsl设置默认登录用户/","link":"","permalink":"http://example.com/2023/07/26/%E5%AF%BC%E5%85%A5%E5%AE%89%E8%A3%85%E7%9A%84wsl%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E7%99%BB%E5%BD%95%E7%94%A8%E6%88%B7/","excerpt":"","text":"https://learn.microsoft.com/zh-cn/windows/wsl/basic-commands#set-wsl-version-to-1-or-2 先确认该分发的wsl版本是2查看版本 wsl -l -v 如果不是2的话设置版本 wsl --set-version &lt;distribution name&gt; &lt;versionNumber&gt; 若要指定运行 Linux 发行版的 WSL 版本（1 或 2），请将 &lt;distribution name&gt; 替换为发行版的名称（即wsl -l -v输出的NAME列），并将 &lt;versionNumber&gt; 替换为 1 或 2。 确定该分发上有那个用户没有的话新建：进入wsl，创建一个拥有主目录（-m）和默认shell（-s）是/usr/bin/zsh的用户 useradd -m -s /usr/bin/zsh username useradd -m -s &#x2F;bin&#x2F;bash yuanzhiqiu 然后你将为该用户添加一个密码： passwd username 需要的话，给sudo：修改/etc/sudoers文件：在行root ALL=(ALL:ALL) ALL下添加一行 yuanzhiqiu ALL=(ALL:ALL) ALL 编辑该文件的方法： visudo 或用vim：编辑好之后:w !sudo tee %，ok退出之后文件是被修改了的 Using vim to force edit a file when you opened without permissions 然后在该分发上修改https://blog.csdn.net/qq_37085158/article/details/131041223 进入 wsl ，编辑 /etc/wsl.conf 配置文件，添加如下内容： [user] default = yuanzhiqiu 保存配置并退出，关闭 wsl 之后重新进入，便会发现默认用户已经修改了： wsl --shutdown wsl","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win10设置应用程序启动快捷键","slug":"win10设置应用程序启动快捷键","date":"2023-07-26T02:11:21.000Z","updated":"2023-07-26T02:11:32.000Z","comments":true,"path":"2023/07/26/win10设置应用程序启动快捷键/","link":"","permalink":"http://example.com/2023/07/26/win10%E8%AE%BE%E7%BD%AE%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"https://blog.csdn.net/qq_43546203/article/details/122490415#:~:text=windows10%20%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E5%BF%AB%E6%8D%B7%E9%94%AE%E8%AE%BE%E7%BD%AE%E4%B8%8E%E5%8F%96%E6%B6%88%201%20%E5%8F%B3%E9%94%AE%E7%82%B9%E5%87%BB%E5%9C%A8%E8%8F%9C%E5%8D%95%E6%A0%8F%E4%B8%AD%E9%80%89%E6%8B%A9%E3%80%90%E5%B1%9E%E6%80%A7%E3%80%91%EF%BC%8C%E9%9A%8F%E5%90%8E%E5%9C%A8%E3%80%90%E5%BF%AB%E6%8D%B7%E6%96%B9%E5%BC%8F%E3%80%91%E6%A0%8F%E4%B8%AD%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E9%BB%98%E8%AE%A4%E7%9A%84%E6%98%AF%E3%80%90%E6%97%A0%E3%80%91%EF%BC%9B%202,%E8%BF%99%E9%87%8C%E5%8F%AA%E9%9C%80%E6%8C%89%E4%BD%8F%E9%BC%A0%E6%A0%87%E4%B8%8A%E7%9A%84%E5%BF%AB%E6%8D%B7%E7%BB%84%E5%90%88%E9%94%AE%E5%8D%B3%E5%8F%AF%E8%87%AA%E5%8A%A8%E7%9A%84%E8%BE%93%E5%85%A5%E7%9A%84%E3%80%82%20%E6%AF%94%E5%A6%82%E8%BE%93%E5%85%A5%EF%BC%9A%E3%80%90Ctrl%E3%80%91%2B%E3%80%90Alt%E3%80%91%2B%E3%80%90Q%E3%80%91%EF%BC%9B%203%20%E7%82%B9%E5%87%BB%E2%80%9C%E5%BA%94%E7%94%A8%E2%80%9D%E3%80%81%E2%80%9C%E7%A1%AE%E5%AE%9A%E2%80%9D%E4%BF%9D%E5%AD%98%E8%AE%BE%E7%BD%AE%EF%BC%8C%E6%8C%89%E4%B8%8B%E8%BF%99%E4%B8%AA%E5%BF%AB%E6%8D%B7%E9%94%AE%E7%BB%84%E5%90%88%E5%B0%B1%E5%8F%AF%E4%BB%A5%E5%BF%AB%E9%80%9F%E7%9A%84%E6%89%93%E5%BC%80%E4%B8%8A%E8%BF%B0%E8%AE%BE%E7%BD%AE%E7%9A%84%E8%BD%AF%E4%BB%B6%E5%92%8C%E7%A8%8B%E5%BA%8F%E4%BA%86%E3%80%82%204%20%E5%A6%82%E9%9C%80%E5%85%B3%E9%97%AD%EF%BC%8C%E4%B9%9F%E6%98%AF%E5%90%8C%E7%90%86%E3%80%82","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"c++头文件相互包含","slug":"c-头文件相互包含","date":"2023-07-25T01:14:58.000Z","updated":"2023-07-25T01:24:26.000Z","comments":true,"path":"2023/07/25/c-头文件相互包含/","link":"","permalink":"http://example.com/2023/07/25/c-%E5%A4%B4%E6%96%87%E4%BB%B6%E7%9B%B8%E4%BA%92%E5%8C%85%E5%90%AB/","excerpt":"","text":"类相互引用的情况，如果编译不通过的话，参考下面的原则（如果通过的话就没啥管的bushi）： 在本文件中， 需要引用某类的成员（数据成员或函数成员，静态或不是静态），才需包含头文件 若只需要使用某类的指针或引用，可以不包含头文件，有一个前置申明即可 举例：A中用到B的成员，B中有A*B.h // 仅用到A的指针，不需要包含头文件 class A; // 但是需要前置申明 class B &#123; public: A* data; int Int; &#125;; A.h #include &quot;B.h&quot; // 由于用到B的成员，需要包含头文件 class A &#123; public: int func(B* bp)&#123; return bp-&gt;Int; // 这里用到B的成员 &#125; &#125;;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"vscode老版本gdb命令行查看vector内容","slug":"vscode老版本gdb命令行查看vector内容","date":"2023-07-23T13:28:32.000Z","updated":"2023-07-23T13:29:20.000Z","comments":true,"path":"2023/07/23/vscode老版本gdb命令行查看vector内容/","link":"","permalink":"http://example.com/2023/07/23/vscode%E8%80%81%E7%89%88%E6%9C%ACgdb%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9F%A5%E7%9C%8Bvector%E5%86%85%E5%AE%B9/","excerpt":"","text":"在DEBUG_CONSOLE中或者watch*(your_vector._M_impl._M_start)@(your_vector.size())","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"20","slug":"daily-2023-7-20","date":"2023-07-20T01:18:58.000Z","updated":"2023-07-20T02:58:34.000Z","comments":true,"path":"2023/07/20/daily-2023-7-20/","link":"","permalink":"http://example.com/2023/07/20/daily-2023-7-20/","excerpt":"","text":"今日目标：完成ptnpred 上午 1 read ptn -&gt; bgp code ptn -&gt; bgp 2 code ptn -&gt; bgp 3 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"设置vscode命令行启动路径为当前文件所在目录","slug":"设置vscode命令行启动路径为当前文件所在目录","date":"2023-07-15T00:02:13.000Z","updated":"2024-02-24T02:08:28.546Z","comments":true,"path":"2023/07/15/设置vscode命令行启动路径为当前文件所在目录/","link":"","permalink":"http://example.com/2023/07/15/%E8%AE%BE%E7%BD%AEvscode%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%90%AF%E5%8A%A8%E8%B7%AF%E5%BE%84%E4%B8%BA%E5%BD%93%E5%89%8D%E6%96%87%E4%BB%B6%E6%89%80%E5%9C%A8%E7%9B%AE%E5%BD%95/","excerpt":"","text":"ctrl+,进入设置 ，然后terminal &gt; integrated: cwd （可以直接搜terminal cwd，vscode会定位那个配置项的位置）${fileDirname}","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"15","slug":"daily-2023-7-15","date":"2023-07-15T00:01:14.000Z","updated":"2023-07-15T00:01:42.000Z","comments":true,"path":"2023/07/15/daily-2023-7-15/","link":"","permalink":"http://example.com/2023/07/15/daily-2023-7-15/","excerpt":"","text":"今日目标：任务分配完成；开始做ppt或者开始思考研究问题 上午下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"自定义安装wsl","slug":"自定义安装wsl","date":"2023-07-14T03:33:15.000Z","updated":"2024-02-18T03:38:09.467Z","comments":true,"path":"2023/07/14/自定义安装wsl/","link":"","permalink":"http://example.com/2023/07/14/%E8%87%AA%E5%AE%9A%E4%B9%89%E5%AE%89%E8%A3%85wsl/","excerpt":"","text":"step 1https://lukebest.github.io/posts/bb32在这里下载分发版：https://learn.microsoft.com/en-us/windows/wsl/install-manual#downloading-distributions 注意，在该博客的安装命令（LxRunOffline i）之前，还要执行下述步骤： 安装内核更新包 （这步似乎执行了没用）设置wsl默认版本为2：在cmd中执行wsl --set-default-version 2 LxRunOffline i -n ubuntu2204 -d D:\\dev\\wsl\\Ubuntu2204-221101-install -f D:\\dev\\wsl\\Ubuntu2204-221101\\Ubuntu_2204.1.7.0_x64\\install.tar.gz step 2: 切换成版本2查看版本 wsl -l -v 如果不是2的话设置版本 wsl --set-version &lt;distribution_name&gt; &lt;versionNumber&gt; 若要指定运行 Linux 发行版的 WSL 版本（1 或 2），请将 &lt;distribution_name&gt; 替换为发行版的名称（即wsl -l -v输出的NAME列），并将 &lt;versionNumber&gt; 替换为 1 或 2。 成功的话输出如下： 正在进行转换，这可能需要几分钟时间... 有关与 WSL 2 的主要区别的信息，请访问 https://aka.ms/wsl2 转换完成。 切换版本2失败解决请启用虚拟机平台 Windows 功能并确保在 BIOS 中启用虚拟化https://ohana.moe/archives/wsl-1/该博客中如何进入windows功能：win+s搜索windows功能，启用或关闭windows功能为所求 WSL 2 需要更新其内核组件正在进行转换，这可能需要几分钟时间... 有关与 WSL 2 的主要区别的信息，请访问 https://aka.ms/wsl2 WSL 2 需要更新其内核组件。有关信息，请访问 https://aka.ms/wsl2kernel 如果输出如下，说明上面在安装命令之前你忘记装内核更新包了，要去执行下这个步骤 安装内核更新包，然后重新来切换版本2，如果还是不行，可以卸载重装卸载： LxRunOffline ui -n &lt;distribution_name&gt; step 3: 启动在cmd中键入wsl即可进入完整命令： wsl -d &lt;distribution_name&gt; -u &lt;user_name&gt;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"windows安装mingw","slug":"windows安装mingw","date":"2023-07-14T02:19:46.000Z","updated":"2023-07-14T02:21:48.000Z","comments":true,"path":"2023/07/14/windows安装mingw/","link":"","permalink":"http://example.com/2023/07/14/windows%E5%AE%89%E8%A3%85mingw/","excerpt":"","text":"https://stackoverflow.com/questions/46455927/mingw-w64-installer-the-file-has-been-downloaded-incorrectly 下载https://sourceforge.net/projects/mingw-w64/files/mingw-w64/，然后解压，然后把bin目录添加环境变量 关于选型：Version: 指的是 gcc 的版本，如果没有特殊的需求，一般选择最高的版本号即可。最高版本是8.1.0 ，选中它即可Architechture:电脑系统是 64位的，选择 x86_64；如果是 32位 系统，则选择 i686Threads:如果是 Windows ，选择 win32 ，如果是 Linux、Unix、Mac OS 等其他操作系统要选择 posixException：seh 是新发明的，而 sjlj 则是古老的。seh 性能比较好，但不支持 32位。 sjlj 稳定性好，支持 32位。建议64位操作系统选择seh","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"chrome快捷键","slug":"chrome快捷键","date":"2023-07-14T01:45:48.000Z","updated":"2023-07-14T01:45:59.000Z","comments":true,"path":"2023/07/14/chrome快捷键/","link":"","permalink":"http://example.com/2023/07/14/chrome%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"Ctrl+Tab 或 Ctrl+PgDown 切换到下一个标签页。 Ctrl+Shift+Tab 或 Ctrl+PgUp 切换到上一个标签页。 Ctrl+W 或 Ctrl+F4 关闭当前标签页或弹出窗口。 Ctrl+T 打开新标签页。","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"win10快捷键","slug":"win10快捷键","date":"2023-07-14T01:45:10.000Z","updated":"2023-07-14T01:45:21.000Z","comments":true,"path":"2023/07/14/win10快捷键/","link":"","permalink":"http://example.com/2023/07/14/win10%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"win+D 切换到桌面win+S 底部工具栏的搜索 win+R 运行win+X 黑色栏","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"windows vscode 环境变量和系统不同步","slug":"windows-vscode-环境变量和系统不同步","date":"2023-07-14T01:41:18.000Z","updated":"2023-07-14T01:44:37.000Z","comments":true,"path":"2023/07/14/windows-vscode-环境变量和系统不同步/","link":"","permalink":"http://example.com/2023/07/14/windows-vscode-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E5%92%8C%E7%B3%BB%E7%BB%9F%E4%B8%8D%E5%90%8C%E6%AD%A5/","excerpt":"","text":"https://github.com/microsoft/vscode/issues/144339 在全局settings.json中添加 &quot;terminal.integrated.env.windows&quot;: &#123; &quot;PATH&quot;: &quot;$&#123;env:PATH&#125;;&quot; &#125;, C:\\Users\\username\\AppData\\Roaming\\Code\\User\\settings.json然后重启vscode","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-7-14","date":"2023-07-14T01:39:29.000Z","updated":"2023-07-15T00:03:24.000Z","comments":true,"path":"2023/07/14/daily-2023-7-14/","link":"","permalink":"http://example.com/2023/07/14/daily-2023-7-14/","excerpt":"","text":"今日目标：任务分配完成；相关工作ppt 上午 1 环境 任务理解 2 环境 读文档 下午 1 read code 2 read code 3，4 设计实现，补充外围代码 探索测试方法：gconsole输入cypher查询 晚上 1 装wsl 读list compre和pattern pred的文档 2 读ptn pred文档 outline&amp;commit","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"13","slug":"daily-2023-7-13","date":"2023-07-13T00:18:31.000Z","updated":"2023-07-13T12:33:27.000Z","comments":true,"path":"2023/07/13/daily-2023-7-13/","link":"","permalink":"http://example.com/2023/07/13/daily-2023-7-13/","excerpt":"","text":"今日目标：相关工作和已经提出的idea部分的ppt思考idea有点成型（然后加到ppt中） 上午 1 讲座信息 适应中 复习调研的相关工作 思考最强劲对手的idea是不是没有路径过长的问题了 2 思考最强劲对手的idea是不是没有路径过长的问题了 设计ppt呈现逻辑台式开发环境 下午讲座 晚上台式开发环境","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"9","slug":"daily-2023-7-9","date":"2023-07-09T01:24:54.000Z","updated":"2023-07-09T07:26:17.000Z","comments":true,"path":"2023/07/09/daily-2023-7-9/","link":"","permalink":"http://example.com/2023/07/09/daily-2023-7-9/","excerpt":"","text":"今日目标：disjoint path调研收尾msbfs简单调研（可能不是很相关了）有idea突破 上午 1 disjoint path: 本机connected paper msbfs: msbfs connected paper 2 msbfs: msbfs connected paper msbfs: BCC connected paper 3 读1991GB和证明 下午 1 读1991GB和证明逛街麦！ 晚上 思考1991的GB扩展到多点对 思考p1区域索引（站在1974(找p1-拆分p1-找p2)的肩膀上，思考搜索视图）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"8","slug":"daily-2023-7-8","date":"2023-07-08T02:05:34.000Z","updated":"2023-07-09T01:25:36.000Z","comments":true,"path":"2023/07/08/daily-2023-7-8/","link":"","permalink":"http://example.com/2023/07/08/daily-2023-7-8/","excerpt":"","text":"今日目标：msbfs&amp;BCC connected paper（目标：找share的最新研究现状和counterpart）独立路径调研结束思考idea有突破 上午 1 disjoint path: 检查本机的论文集锦问题 disjoint path: read 1991 2,3 disjoint path: read 1991 这篇好牛好牛，爱了 下午 1 read st numbering 2 search st numbering read st numbering parallel 3 read st numbering parallel disjoint path: cited 1991 晚上 1 disjoint path: cited 1991 2 disjoint path: cited 1991 3 disjoint path: cited 1991 disjoint path: read 1995 disjoint path: read lec22","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"7","slug":"daily-2023-7-7","date":"2023-07-07T06:07:30.000Z","updated":"2023-07-08T02:05:25.000Z","comments":true,"path":"2023/07/07/daily-2023-7-7/","link":"","permalink":"http://example.com/2023/07/07/daily-2023-7-7/","excerpt":"","text":"今日目标：完成独立路径相关工作search，开始share的search（目标：找到重要的counterpart，但是又没有我们的好）disjoint path现状： 电脑上的文章检查：读可能非常相关的 电脑上的文章检查：检查问题定义，搜寻可能是counter part的 谷歌学术2023 disjoint path：检查完page4，要检查page5; independent trees; independent path 上午百讲讲座 - 1974 connected paper(说不定会有follow它们的多点对问题) 下午 1 电脑上的文章检查：读可能非常相关的 2 电脑上的文章检查：读可能非常相关的 3 电脑上的文章检查：读可能非常相关的 4 电脑上的文章检查：读可能非常相关的 思考p1区域索引（站在1974的肩膀上，思考搜索视图；确定局部拆分是别人已经提出来了的） 晚上骑车+找臭臭狗吃饭+骑车","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"6","slug":"daily-2023-7-6","date":"2023-07-05T23:50:38.000Z","updated":"2023-07-07T06:09:04.000Z","comments":true,"path":"2023/07/06/daily-2023-7-6/","link":"","permalink":"http://example.com/2023/07/06/daily-2023-7-6/","excerpt":"","text":"今日目标： 上午 1,2,3 check on ppt 4 发现了新的更相关的工作，检查它们 下午 1 发现了新的更相关的工作，检查它们 完了，我提出的idea咋全部都被人提出过了，救命，救命 2 idea发现了一样的counterpart(1971 1974)，重新思考idea的空间 3 cited 1971 4 1974 connected paper(说不定会有follow它们的多点对问题) 晚上去找臭臭狗吃东西了bushi","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"5","slug":"daily-2023-7-5","date":"2023-07-04T23:46:06.000Z","updated":"2023-07-05T23:50:27.000Z","comments":true,"path":"2023/07/05/daily-2023-7-5/","link":"","permalink":"http://example.com/2023/07/05/daily-2023-7-5/","excerpt":"","text":"今日目标：类似的现状： BCC 上午 1 read BCC 2 read BCC 3 read BCC 4 read BCC 5 key of BCC, and ins 下午 1 read 1994 2 check 3,4 check 晚上 1,2,3 check rethink BCC 4 check","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"minor 拓扑子式","slug":"minor-拓扑子式","date":"2023-07-04T03:17:38.000Z","updated":"2023-07-04T03:29:14.000Z","comments":true,"path":"2023/07/04/minor-拓扑子式/","link":"","permalink":"http://example.com/2023/07/04/minor-%E6%8B%93%E6%89%91%E5%AD%90%E5%BC%8F/","excerpt":"","text":"https://en.wikipedia.org/wiki/Graph_minor minor typeTopological minors https://zhuanlan.zhihu.com/p/351950187 A graph H is called a topological minor of a graph G if a subdivision of H is isomorphic to a subgraph of G 另一种：https://www.graphclasses.org/classes/gc_309.html G is a minor of H if G can be obtained from H be a series of vertex deletions, edge deletions and&#x2F;or edge contractions (replacing two adjacent vertices u,v by a vertex that is adjacent to all neighbours of u or v). Minor-closed graph familiesMany families of graphs have the property that every minor of a graph in F is also in F; such a class is said to be minor-closed. https://en.wikipedia.org/wiki/Robertson%E2%80%93Seymour_theorem example: the planar graphs are closed under taking minors: contracting an edge in a planar graph, or removing edges or vertices from the graph, cannot destroy its planarity the collection of all planar graphs and, more generally, all graphs that can be embedded in a fixed surface Topological-Minor-Free Graph ClassesA graph G is K4*-minor-free if* K4 isn’t a minor of G.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"4","slug":"daily-2023-7-4","date":"2023-07-03T23:39:36.000Z","updated":"2023-07-04T23:45:56.000Z","comments":true,"path":"2023/07/04/daily-2023-7-4/","link":"","permalink":"http://example.com/2023/07/04/daily-2023-7-4/","excerpt":"","text":"今日目标：idea已有材料嚼完并思考启发出来的问题（今日穿插）google scholar disjoint path 20224：嚼完ppt上已经有的相关工作（问题定义和idea） 目标：嚼清除目前disjoint path和share的研究现状 上午 1 reivew &amp; chew solution cross output 2 solution cross output reivew &amp; chew 3 reivew &amp; chew 调研最新相关工作(谷歌学术2023 disjoint path) 4，5 调研最新相关工作(谷歌学术2023 disjoint path) 下午讲座&amp;录取通知书&amp;吃东西 晚上 1 谷歌学术2023 disjoint path 2 谷歌学术2023 disjoint path 3 谷歌学术2023 disjoint path 4 之前搜集的disjoint path工作检查和分类","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"3","slug":"daily-2023-7-3","date":"2023-07-03T01:46:53.000Z","updated":"2023-07-03T23:39:26.000Z","comments":true,"path":"2023/07/03/daily-2023-7-3/","link":"","permalink":"http://example.com/2023/07/03/daily-2023-7-3/","excerpt":"","text":"今日目标：yuxu老师word内容完成（部分阅读）yuxu老师的工作标题浏览，知道他做了啥工作我的idea消化 上午 1 hellogithub 办实习 2 hellogithub paper read 3 paper read 4 paper read 下午 1 paper read 2 paper read yuxu list scan 3 paper read 4 yuxu list abstract scan paper read dinner read my idea slides think my problem and idea 晚上 1,2,3 think: cut 4 think: BRtree applied to p1g? 5 review p1g idea in posts 完成了哈哈哈哈今日新的风景：新工位；工位上嚼idea，思考idea；工位上看论文这是好的且新的学术开始！get对自己新的理解：思考idea不能持续太长时间，最多一个block就至少切换一个block的其他任务~","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"29","slug":"daily-2023-6-29","date":"2023-06-28T23:48:37.000Z","updated":"2023-06-28T23:49:28.000Z","comments":true,"path":"2023/06/29/daily-2023-6-29/","link":"","permalink":"http://example.com/2023/06/29/daily-2023-6-29/","excerpt":"","text":"毕业到现在属于是快乐的毕业+爹妈来接+在家看小说摆烂四天今日目标：上午sklearn新方法有眉目，可能没有跑完 上午下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"sklearn metrics scorings 性能度量","slug":"sklearn-metrics-scorings-性能度量","date":"2023-06-28T23:47:46.000Z","updated":"2023-06-28T23:48:18.000Z","comments":true,"path":"2023/06/29/sklearn-metrics-scorings-性能度量/","link":"","permalink":"http://example.com/2023/06/29/sklearn-metrics-scorings-%E6%80%A7%E8%83%BD%E5%BA%A6%E9%87%8F/","excerpt":"","text":"https://scikit-learn.org/stable/modules/model_evaluation.html#","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-6-14","date":"2023-06-14T00:41:12.000Z","updated":"2023-06-14T01:15:30.000Z","comments":true,"path":"2023/06/14/daily-2023-6-14/","link":"","permalink":"http://example.com/2023/06/14/daily-2023-6-14/","excerpt":"","text":"今日目标：做完2dp的ppt7.1之前，论文上通过阅读钉钉文件来进行弥补学习；code通过刷Leetcode来弥补 上午 1 ccg: run and output 500 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"keras神经网络","slug":"keras神经网络","date":"2023-05-30T02:46:24.000Z","updated":"2023-05-30T03:08:41.000Z","comments":true,"path":"2023/05/30/keras神经网络/","link":"","permalink":"http://example.com/2023/05/30/keras%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","excerpt":"","text":"可以使用的度量：https://keras.io/api/metrics/优化器（比如梯度下降）：https://keras.io/api/optimizers/激活函数：https://keras.io/api/layers/activations/ 神经网络介绍和结构调整(训练你的神经网络)https://towardsdatascience.com/designing-your-neural-networks-a5e4617027ed","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"不平衡分类问题","slug":"不平衡分类问题","date":"2023-05-30T02:03:22.000Z","updated":"2023-06-01T09:16:06.000Z","comments":true,"path":"2023/05/30/不平衡分类问题/","link":"","permalink":"http://example.com/2023/05/30/%E4%B8%8D%E5%B9%B3%E8%A1%A1%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98/","excerpt":"","text":"https://scikit-learn.org/dev/modules/cross_validation.html#cross-validation-iterators-with-stratification-based-on-class-labels Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in StratifiedKFold and StratifiedShuffleSplit to ensure that relative class frequencies is approximately preserved in each train and validation fold.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"MPI自定义类型","slug":"MPI自定义类型","date":"2023-05-28T04:14:42.000Z","updated":"2023-05-28T11:15:50.000Z","comments":true,"path":"2023/05/28/MPI自定义类型/","link":"","permalink":"http://example.com/2023/05/28/MPI%E8%87%AA%E5%AE%9A%E4%B9%89%E7%B1%BB%E5%9E%8B/","excerpt":"","text":"https://enccs.github.io/intermediate-mpi/derived-datatypes-pt2/# MPI已经定义的类型https://rookiehpc.org/mpi/docs/mpi_datatype/index.htmlList of named predefined dataypes:MPI_SIGNED_CHAR &#x2F; MPI_UNSIGNED_CHARMPI_SHORT &#x2F; MPI_UNSIGNED_SHORTMPI_INT &#x2F; MPI_UNSIGNEDMPI_LONG &#x2F; MPI_UNSIGNED_LONGMPI_LONG_LONG_INT (a.k.a MPI_LONG_LONG) &#x2F; MPI_UNSIGNED_LONG_LONGMPI_CHARMPI_WCHARMPI_FLOATMPI_DOUBLEMPI_LONG_DOUBLEMPI_INT8_T &#x2F; MPI_UINT8_TMPI_INT16_T &#x2F; MPI_UINT16_TMPI_INT32_T &#x2F; MPI_UINT32_TMPI_INT64_T &#x2F; MPI_UINT64_TMPI_C_BOOLMPI_C_COMPLEXMPI_C_FLOAT_COMPLEXMPI_C_DOUBLE_COMPLEXMPI_C_LONG_DOUBLE_COMPLEXMPI_AINTMPI_COUNTMPI_OFFSETMPI_BYTEMPI_PACKED List of datatypes for reduction functions MPI_MINLOC and MPI_MAXLOC:MPI_SHORT_INTMPI_LONG_INTMPI_FLOAT_INTMPI_DOUBLE_INTMPI_LONG_DOUBLE_INTMPI_2INT 自定义结构体类型举例struct Pair &#123; int first; char second; &#125;; // build up the typemap for Pair // the type signature for Pair MPI_Datatype typesig[2] = &#123;MPI_INT, MPI_CHAR&#125;; // how many of each type in a &quot;block&quot; of Pair int block_lengths[2] = &#123;1, 1&#125;; // displacements of data members in Pair MPI_Aint displacements[2],base_address; // why not use pointer arithmetic directly? We cannot use pointer arithmetic to compute displacements. Always keep in mind that your program might be deployed on heterogeneous architectures: you have to program for correctness and portability. MPI_Get_address(&amp;my_pair.first, base_address); displacements[0] = 0; MPI_Get_address(&amp;my_pair.second, &amp;displacements[1]); // ! note, can NOT use - displacements[1] = MPI_Aint_diff(displacements[1], base_address); // create and commit the new type MPI_Datatype mpi_pair; MPI_Type_create_struct(2, block_lengths, displacements, typesig, &amp;mpi_pair); MPI_Type_commit(&amp;mpi_pair); // clean up after use MPI_Type_free(&amp;mpi_pair); 包括通信的举例https://github.com/ENCCS/intermediate-mpi/blob/main/content/code/day-1/07_pokemon-type-create-struct/solution/pokemon-type-create-struct.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;mpi.h&gt; #define STRLEN 25 struct Pokemon &#123; // name of pokemon attacking char name[STRLEN]; // life points double life_points; // damage done by the attack int damage; // strength multiplier double multiplier; &#125;; int main(int argc, char *argv[]) &#123; int rank; int size; struct Pokemon charizard; MPI_Init(&amp;argc, &amp;argv); MPI_Comm comm = MPI_COMM_WORLD; MPI_Comm_size(comm, &amp;size); MPI_Comm_rank(comm, &amp;rank); MPI_Datatype typesig[4] = &#123;MPI_CHAR, MPI_DOUBLE, MPI_INT, MPI_DOUBLE&#125;; int block_lengths[4] = &#123;STRLEN, 1, 1, 1&#125;; MPI_Aint base_address, displacements[4]; MPI_Get_address(&amp;charizard.name, &amp;displacements[0]); base_address = displacements[0]; displacements[0] = displacements[0] - base_address; MPI_Get_address(&amp;charizard.life_points, &amp;displacements[1]); displacements[1] = displacements[1] - base_address; MPI_Get_address(&amp;charizard.damage, &amp;displacements[2]); displacements[2] = displacements[2] - base_address; MPI_Get_address(&amp;charizard.multiplier, &amp;displacements[3]); displacements[3] = displacements[3] - base_address; MPI_Datatype mpi_pokemon; MPI_Type_create_struct(4, block_lengths, displacements, typesig, &amp;mpi_pokemon); MPI_Type_commit(&amp;mpi_pokemon); if (rank == 0) &#123; sprintf(charizard.name, &quot;Charizard&quot;); charizard.life_points = 180.0; charizard.damage = 60; charizard.multiplier = 0.89; MPI_Bcast(&amp;charizard, 1, mpi_pokemon, 0, comm); &#125; else &#123; // matching broadcast on all other processes. MPI_Bcast(&amp;charizard, 1, mpi_pokemon, 0, comm); // did we get it right? printf(&quot;rank %d:\\n&quot;, rank); printf(&quot; pokemon = %s\\n&quot;, charizard.name); printf(&quot; life_points = %2.2f\\n&quot;, charizard.life_points); printf(&quot; damage = %d\\n&quot;, charizard.damage); printf(&quot; multiplier = %2.2f\\n&quot;, charizard.multiplier); &#125; MPI_Type_free(&amp;mpi_pokemon); MPI_Finalize(); return EXIT_SUCCESS; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"U盘读不了问题解决","slug":"U盘读不了问题解决","date":"2023-05-27T03:22:39.000Z","updated":"2023-05-27T03:22:55.000Z","comments":true,"path":"2023/05/27/U盘读不了问题解决/","link":"","permalink":"http://example.com/2023/05/27/U%E7%9B%98%E8%AF%BB%E4%B8%8D%E4%BA%86%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","excerpt":"","text":"https://www.disktool.cn/content-center/usb-detected-but-not-accessible-666.htmlhttps://zhuanlan.zhihu.com/p/386056939","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"27","slug":"daily-2023-5-27","date":"2023-05-27T01:37:03.000Z","updated":"2023-05-27T07:10:13.000Z","comments":true,"path":"2023/05/27/daily-2023-5-27/","link":"","permalink":"http://example.com/2023/05/27/daily-2023-5-27/","excerpt":"","text":"今日目标：hw搞定，包括报告，最好可以搞一点ccg 上午 1,2,3 hw mem 4 hw test &amp; report 下午 1 hw test &amp; report 2 dfs 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"26","slug":"daily-2023-5-26","date":"2023-05-26T01:19:42.000Z","updated":"2023-05-26T08:36:28.000Z","comments":true,"path":"2023/05/26/daily-2023-5-26/","link":"","permalink":"http://example.com/2023/05/26/daily-2023-5-26/","excerpt":"","text":"今日目标：hw的除了开始写报告，其他不确定因素都解决；调研graph embeding，大概知道用这个分批是啥意思 上午 1 hw output 2 hw output 3 hw output 下午 1,2,3 hw 检查code看风险代码在什么地方 4 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"sklearn调参","slug":"sklearn调参","date":"2023-05-25T08:07:56.000Z","updated":"2023-05-25T11:37:48.000Z","comments":true,"path":"2023/05/25/sklearn调参/","link":"","permalink":"http://example.com/2023/05/25/sklearn%E8%B0%83%E5%8F%82/","excerpt":"","text":"举例：https://www.kaggle.com/code/funxexcel/p2-logistic-regression-hyperparameter-tuning 先看这篇中的3.2.1 Exhaustive Grid Search https://scikit-learn.org/dev/modules/grid_search.html# 然后看这篇 https://scikit-learn.org/dev/auto_examples/model_selection/plot_multi_metric_evaluation.html# 然后回去看第一篇","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"k折交叉验证 训练集 验证集 测试集","slug":"k折交叉验证-训练集-验证集-测试集","date":"2023-05-25T04:36:06.000Z","updated":"2023-05-25T10:48:33.000Z","comments":true,"path":"2023/05/25/k折交叉验证-训练集-验证集-测试集/","link":"","permalink":"http://example.com/2023/05/25/k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81-%E8%AE%AD%E7%BB%83%E9%9B%86-%E9%AA%8C%E8%AF%81%E9%9B%86-%E6%B5%8B%E8%AF%95%E9%9B%86/","excerpt":"","text":"https://scikit-learn.org/dev/modules/cross_validation.html#cross-validation这个官方文档写得太好了 概念Here is a flowchart of typical cross validation workflow in model training. k折交叉验证解释： cross_val_score 和cross_validatehttps://scikit-learn.org/dev/modules/cross_validation.html#computing-cross-validated-metrics 可以传给scoring的度量： https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"机器学习缺失值处理","slug":"机器学习缺失值处理","date":"2023-05-25T01:19:42.000Z","updated":"2023-05-25T01:19:56.000Z","comments":true,"path":"2023/05/25/机器学习缺失值处理/","link":"","permalink":"http://example.com/2023/05/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%BC%BA%E5%A4%B1%E5%80%BC%E5%A4%84%E7%90%86/","excerpt":"","text":"https://towardsdatascience.com/7-ways-to-handle-missing-values-in-machine-learning-1a6326adf79e","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"25","slug":"daily-2023-5-25","date":"2023-05-25T00:43:56.000Z","updated":"2023-05-25T12:20:35.000Z","comments":true,"path":"2023/05/25/daily-2023-5-25/","link":"","permalink":"http://example.com/2023/05/25/daily-2023-5-25/","excerpt":"","text":"今日目标：ccg 上午 1 learn ml 2 learn missing data handle run 2dp partition 3 exam data 4 data processing missing data handle method select 5 missing data handle 6(half) load data 下午一折-&gt;10折-&gt;10折调参 1 1 fold run 买票和琐事 2 classification_report输出含义 output auc 3 初步选定进一步调参的模型 learn how to tuning 4 learn how to tuning 选择性能度量 5 选择性能度量 晚上 1 pr-auc和f1多少算好模型 10折的计算pr-auc 2 调参学习 tune logit 3 tune logit tune decision_tree 4 tune svc","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"机器学习实战入门","slug":"机器学习实战入门","date":"2023-05-25T00:42:14.000Z","updated":"2023-06-29T00:03:10.000Z","comments":true,"path":"2023/05/25/机器学习实战入门/","link":"","permalink":"http://example.com/2023/05/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%E5%85%A5%E9%97%A8/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/59768106https://stackabuse.com/overview-of-classification-methods-in-python-with-scikit-learn/","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"Confusion Matrix, Accuracy, Precision, Recall, F1 Score","slug":"Confusion-Matrix-Accuracy-Precision-Recall-F1-Score","date":"2023-05-25T00:12:16.000Z","updated":"2023-05-25T00:27:54.000Z","comments":true,"path":"2023/05/25/Confusion-Matrix-Accuracy-Precision-Recall-F1-Score/","link":"","permalink":"http://example.com/2023/05/25/Confusion-Matrix-Accuracy-Precision-Recall-F1-Score/","excerpt":"","text":"https://medium.com/analytics-vidhya/confusion-matrix-accuracy-precision-recall-f1-score-ade299cf63cd https://www.scikit-yb.org/en/latest/api/classifier/classification_report.html A person who is actually pregnant (positive) and classified as pregnant (positive). This is called TRUE POSITIVE (*TP*). A person who is actually not pregnant (negative) and classified as not pregnant (negative). This is called TRUE NEGATIVE (*TN*). A person who is actually not pregnant (negative) and classified as pregnant (positive). This is called FALSE POSITIVE (*FP*). A person who is actually pregnant (positive) and classified as not pregnant (negative). This is called FALSE NEGATIVE (*FN*). accuracy precision所有报的positive中，真的是positive的占比 recall所有真的positive中，被报positive的占比 F1-scoreF1 score is the harmonic mean of precision and recall and is a better measure than accuracy.F1 Score becomes 1 only when precision and recall are both 1. F1 score becomes high only when both precision and recall are high. supportSupport is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing. Support doesn’t change between models but instead diagnoses the evaluation process. sklearn.metrics.classification_report举例from sklearn.neighbors import KNeighborsClassifier # load &amp; split dataset = load_iris() (trainX, testX, trainY, testY) = train_test_split( dataset.data, dataset.target, random_state=3, test_size=0.25 ) # train: fit model = KNeighborsClassifier(n_neighbors=1) model.fit(trainX, trainY) # predict &amp; evaluate predictions = model.predict(testX) print(classification_report(testY, predictions, target_names=dataset.target_names)) 输出： precision recall f1-score support setosa 1.00 1.00 1.00 15 versicolor 0.92 0.92 0.92 12 virginica 0.91 0.91 0.91 11 accuracy 0.95 38 macro avg 0.94 0.94 0.94 38 weighted avg 0.95 0.95 0.95 38 setosa、versicolor和virginica是这个数据集的三类","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"23","slug":"daily-2023-5-23","date":"2023-05-23T00:41:23.000Z","updated":"2023-05-23T13:29:56.000Z","comments":true,"path":"2023/05/23/daily-2023-5-23/","link":"","permalink":"http://example.com/2023/05/23/daily-2023-5-23/","excerpt":"","text":"今日目标：2dp debug done; hw code(report); ccg data run 上午 1 debug 2 debug 3 debug 4 debug 5 debug 下午 1 debug and redesign 2 code + debug 3 debug 4 debug done, hurray! 5 result and to ta 晚上画画去了…挣扎好一会+吃了东西终于决定去研楼搞搞不想干的事情x 1 hw run","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"22","slug":"daily-2023-5-22","date":"2023-05-22T00:15:00.000Z","updated":"2023-05-23T00:41:14.000Z","comments":true,"path":"2023/05/22/daily-2023-5-22/","link":"","permalink":"http://example.com/2023/05/22/daily-2023-5-22/","excerpt":"","text":"今日目标：idea code+test+opt; ccg 上午 1,2 debug 3,4 debug 下午 1 debug 2 debug 3 debug 4 debug 晚上debug done!","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"21","slug":"daily-2023-5-21","date":"2023-05-21T06:03:25.000Z","updated":"2023-05-21T12:06:30.000Z","comments":true,"path":"2023/05/21/daily-2023-5-21/","link":"","permalink":"http://example.com/2023/05/21/daily-2023-5-21/","excerpt":"","text":"今日目标：跑出idea的效果；ccg数据跑出来（毕竟是很小的数据量） 上午毕设答辩 下午 1 idea adjust p1p2 code framework 2 code framework 3,4 step debug idea 5 step debug idea 晚上 1 step debug idea 2 step debug idea 3 step debug idea operf and opt","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"20","slug":"daily-2023-5-20","date":"2023-05-20T05:31:11.000Z","updated":"2023-05-20T06:43:23.000Z","comments":true,"path":"2023/05/20/daily-2023-5-20/","link":"","permalink":"http://example.com/2023/05/20/daily-2023-5-20/","excerpt":"","text":"昨天和今天上午搞毕设材料的事情（像夏令营那会了xs）今日目标：实现完搜索版的idea看效果！ 上午下午 1 code framwork and p2 2 code rev_p1 code p2 3 code p2 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"18","slug":"daily-2023-5-18","date":"2023-05-18T01:01:48.000Z","updated":"2023-05-18T11:40:57.000Z","comments":true,"path":"2023/05/18/daily-2023-5-18/","link":"","permalink":"http://example.com/2023/05/18/daily-2023-5-18/","excerpt":"","text":"今日目标：分组效果做出来（寄，感觉似乎就是没有用呜呜）；idea实现好，最好run起来！([hw]验收输出的可能性，每种都写一个config：1. 输出所有pattern 2. 输出一些pattern举例 3. 仅计算) 上午 1 see new db result 这下寄了，除了twitter，其他都是分组方式没啥用 transform indonitia 找到了工具，进行中 2 transform&amp;run indonitia 分组方式：1lmsbfs修改： 度数和同组数的排序优先级修改 寄，也没什么耶[哭] 3 uniform的分组方式加一下随机打乱 寄，没用，还是这么快[哭] 这不就意味着分组还不如随机 麻 idea design and exam 下午 1 脚本检查各种分组方法的效果 看nmsbfs实现的分组方式到底啥样，有没有实现想要的分组方式 chao以前的实现果然垃圾，修正之后跑5次求平均吧 估计下如果跑5次要多久 寄，还是没啥用呜呜呜怎么办救命 2 idea设计 晚上 1 idea设计 艹 思考到牛逼点了！ 2 idea思考 3 idea实现（先用搜索替代索引实现下看看效果） 优化rev_p1","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"17","slug":"daily-2023-5-17","date":"2023-05-17T00:46:08.000Z","updated":"2023-05-18T01:01:29.000Z","comments":true,"path":"2023/05/17/daily-2023-5-17/","link":"","permalink":"http://example.com/2023/05/17/daily-2023-5-17/","excerpt":"","text":"今日目标：上午设计idea，下午准备组会论文汇报，晚上hw重run和文档 上午 1 baseline prec&#x2F;succ改local cache和msbfs一致，重测比较 这样才有可比性，否则太狡猾了bushi run and wait 2 review and design idea (on 1step2) 更公平的baseline 3 review and design idea (on 1step2) 128 see on arabic 划分好像有问题 可能是batchset实现的问题 4 review and design idea (on 1step2) 下午 1 [分组]考虑原生的uint64_t来代替自己实现的batchset?毕竟目前比特操作占时间比较多 benchmark一下 [wait]修改Baseline重新测试 [组会报告论文准备]reread paper and mark content 2 不，完全看不动Bushi，可能是因为比较熟悉了 边看边做 3 paper pre ppt 哈哈哈哈哈哈哈哈通知这周不开组会！那下周再做ppt[旺柴] 4 检查hw输出，看下输出函数中是否包含的不是复杂计算 看了下，输出阶段的计算是沿prec track，这个我理解是ok的 [分组]检查common.txt来看分组没啥区别的原因是不是因为划分占用时间过长（不过注意到，在twitter上有显著差异） 5 输出不计算分组时长的总计算时长，看是否有差异 不是分组时间太长的问题，可以看到相较于计算时间分组时间几乎可以忽略，这就是分组方式不行x 寄，咋办，只有twitter上有一个是27%，三个数据集结论还不一致 晚上 1 分组潜力检查 2,3,4 [分组]找其他数据集试一下 [idea]设计和实现idea(先论证和实现个最简单的)([毕设]抄ppt)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"图分析开发的坑","slug":"图分析开发的坑","date":"2023-05-16T10:35:00.000Z","updated":"2023-05-16T10:38:59.000Z","comments":true,"path":"2023/05/16/图分析开发的坑/","link":"","permalink":"http://example.com/2023/05/16/%E5%9B%BE%E5%88%86%E6%9E%90%E5%BC%80%E5%8F%91%E7%9A%84%E5%9D%91/","excerpt":"","text":"图加载图输入文件中： 顶点编号是否连续，是否从0开始 是否有自旋边 是否有重边 有时候用之前的图加载函数却没有检查数据图文件是否有这个函数假设的性质会导致天坑，现象告诉你似乎是图分析算法有问题，一步步追溯直到发现是基于某假设的图加载数据结构有问题，这个时候真的一口老血喷出来 大图debug方法超级大的图调试用gdb单步可能就不是很合适了，可以采用log的方式进行“单步”，不断定位问题","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"16","slug":"daily-2023-5-16","date":"2023-05-15T23:54:03.000Z","updated":"2023-05-16T14:10:30.000Z","comments":true,"path":"2023/05/16/daily-2023-5-16/","link":"","permalink":"http://example.com/2023/05/16/daily-2023-5-16/","excerpt":"","text":"今日目标：优化完基础实现并更新结果；设计idea(oh 这个没有进行x) 上午 1 debug direct impl: msbfs_1step2 run and operf 2 检查1step2中Map记录路径的占比超级高的原因，更新实现 3 检查1step2中Map记录路径的占比超级高的原因，更新实现 4 检查1step2中Map记录路径的占比超级高的原因，更新实现 design new 1step2 5 design &amp; code new 1step2 6 debug new 1step2 7 debug new 1step2 run 3msbfs on large graph 100vp天哪今天真棒！好的文学艺术作品给人力量！ 下午 1,2 msbfs_merge在reverse p1时似乎有死循环现象，解决bug 现象：在twitter上没问题，但是在另外俩数据集上，merge和1step2都会卡在rev p1 3 debug 4,5,6,7 debug 哈哈哈哈哈哈哈哈哈破案啦！ 晚上 1 one load multiple run run 500vp partition 2 baseline follow operf guide 3 debug baseline run multiple on 3 graph","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"15","slug":"daily-2023-5-15","date":"2023-05-15T09:34:35.000Z","updated":"2023-05-15T14:00:58.000Z","comments":true,"path":"2023/05/15/daily-2023-5-15/","link":"","permalink":"http://example.com/2023/05/15/daily-2023-5-15/","excerpt":"","text":"今日目标： 上午下午 1 debug direct impl: msbfs 晚上 1 run msbfs 看下是不是比之前的Neighbors实现快 code direct impl: msbfs_merge 2 code and test and run direct impl: msbfs_merge operf msbfs_merge see bottle neck 3 code direct impl: msbfs_1step2 4 code direct impl: msbfs_1step2 5 debug direct impl: msbfs_1step2 6 debug direct impl: msbfs_1step2 baseline opt","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-5-14","date":"2023-05-14T05:11:26.000Z","updated":"2023-05-14T10:41:49.000Z","comments":true,"path":"2023/05/14/daily-2023-5-14/","link":"","permalink":"http://example.com/2023/05/14/daily-2023-5-14/","excerpt":"","text":"今日目标：到可以直接实现idea的程度，最好把idea也设计好 上午下午 1 code direct impl: msbfs 2,3,4 debug direct impl: msbfs 晚上 1 debug direct impl: msbfs run看下是不是比之前的Neighbors实现快 code direct impl: msbfs_merge code direct impl: msbfs_1step2 1step2需要参考之前idea中的1step2实现进行修改，因为现在的“为非CSR邻居记录前驱”占用的时间比merge高很多，然而事实上应该是类似的才对，而且Neighbors占用时间太多了 可能可以先实现direct impl再来优化1step2噢，因为1step2的修改涉及到替换部分Neighbors操作，这个省的返工了 baseline opt","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"13","slug":"daily-2023-5-13","date":"2023-05-13T01:04:15.000Z","updated":"2023-05-14T05:11:05.000Z","comments":true,"path":"2023/05/13/daily-2023-5-13/","link":"","permalink":"http://example.com/2023/05/13/daily-2023-5-13/","excerpt":"","text":"今日目标：尽量完成直接实现，然后今天主要任务当然是出去玩了！ 上午 1 code direct impl 2 code direct impl 3 code direct impl出去玩啦！ 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"12","slug":"daily-2023-5-12","date":"2023-05-12T00:51:47.000Z","updated":"2023-05-13T01:04:31.000Z","comments":true,"path":"2023/05/12/daily-2023-5-12/","link":"","permalink":"http://example.com/2023/05/12/daily-2023-5-12/","excerpt":"","text":"今日目标：优化原始实现(msbfs series &amp; baseline)然后operf看瓶颈；（有时间的话，设计和实现新的直接实现） 上午 1 code prec&amp;succ 复用 debug 2 debug see effect of share 3 operf下看看情况 code检查培养方案对不对 4 code prec&amp;succ opt for msbfs 下午 1 run新的msbfs prec&amp;succ on wiki merge的prec&amp;succ design&amp;code 2 code merge prec&amp;succ opt 3 code merge prec&amp;succ opt 4 debug above (msbfs_merge, msbfs_1step2) 5 debug above (msbfs_merge, msbfs_1step2) run and operf 根据operf的结果，只有3%左右的时间是记录反向边和inner edge的前驱的，这是不是意味着idea“传送”没啥用？ idea传送可能可以优化的part在下面用注释标注了 76 3.8618 main MsbfsMerge::OneBatch&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::path(bool) 227 31.7927 main MsbfsMerge::OneBatch&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::init_static_data(unsigned int, unsigned long) 82 11.4846 main BuiltinUIntWrapper&lt;unsigned long&gt;::operator|=(BuiltinUIntWrapper&lt;unsigned long&gt; const&amp;) 记录prec,succ（这是在正常CSR邻居中的前驱） 76 10.6443 main MsbfsMerge::OneBatch&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::path(bool) [self] 76 10.6443 main MsbfsMerge::OneBatch&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::path(bool) // 可能可以减少搜索层数（因为传送了则是一下走了几层；但是这个依赖于p1和p2有抵消交集的点对的占比） // 比特操作相应得可能减少 50 7.0028 main BuiltinUIntWrapper&lt;unsigned long&gt;::operator&amp;(BuiltinUIntWrapper&lt;unsigned long&gt; const&amp;) const 39 5.4622 main Neighbors&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::Neighbors(Graph&amp;, unsigned int, BuiltinUIntWrapper&lt;unsigned long&gt; const&amp;, unsigned int, bool, unsigned int*, GraphUpdate&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt; const*) // 获取邻居操作可能更快 33 4.6218 main BuiltinUIntWrapper&lt;unsigned long&gt;::andnot(BuiltinUIntWrapper&lt;unsigned long&gt; const&amp;) 23 3.2213 main OneBatchMerge&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::adjust_p1p2() // 抵消p1p2可能更快 22 3.0812 main BuiltinUIntWrapper&lt;unsigned long&gt;::zero_all() 21 2.9412 main BuiltinUIntWrapper&lt;unsigned long&gt;::is_all_zero(unsigned int) const 17 2.3810 main MsbfsMerge::OneBatch&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::reverse_path1() // 但是反向p1可能会更慢 17 2.3810 main Neighbors&lt;BuiltinUIntWrapper&lt;unsigned long&gt; &gt;::next(BuiltinUIntWrapper&lt;unsigned long&gt;&amp;, bool, unsigned int&amp;&amp;, Graph&amp;&amp;) 13 1.8207 main std::unordered_map&lt;unsigned int, std::unordered_map&lt;unsigned int, BuiltinUIntWrapper&lt;unsigned long&gt;, std::hash&lt;unsigned int&gt;, std::equal_to&lt;unsigned int&gt;, std::allocator&lt;std::pair&lt;unsigned int const, BuiltinUIntWrapper&lt;unsigned long&gt; &gt; &gt; &gt;, std::hash&lt;unsigned int&gt;, std::equal_to&lt;unsigned int&gt;, std::allocator&lt;std::pair&lt;unsigned int const, std::unordered_map&lt;unsigned int, BuiltinUIntWrapper&lt;unsigned long&gt;, std::hash&lt;unsigned int&gt;, std::equal_to&lt;unsigned int&gt;, std::allocator&lt;std::pair&lt;unsigned int const, BuiltinUIntWrapper&lt;unsigned long&gt; &gt; &gt; &gt; &gt; &gt; &gt;::operator[](unsigned int const&amp;) 记录add_prec,add_succ（这是不在正常CSR邻居中的前驱） // 记录不在正常CSR邻居中的前驱可能会更快，但也可能更慢，因为可能记录了不必要的非正常CSR前驱 8 1.1204 main std::unordered_map&lt;unsigned int, BuiltinUIntWrapper&lt;unsigned long&gt;, std::hash&lt;unsigned int&gt;, std::equal_to&lt;unsigned int&gt;, std::allocator&lt;std::pair&lt;unsigned int const, BuiltinUIntWrapper&lt;unsigned long&gt; &gt; &gt; &gt;::operator[](unsigned int const&amp;) 晚上 1 design&amp;code direct impl 2 code direct impl 一些完全静不下心来想吃东西的小豹x 决定撤退先吃东西和跑步再看情况x","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"11","slug":"daily-2023-5-11","date":"2023-05-11T00:23:52.000Z","updated":"2023-05-12T11:52:37.000Z","comments":true,"path":"2023/05/11/daily-2023-5-11/","link":"","permalink":"http://example.com/2023/05/11/daily-2023-5-11/","excerpt":"","text":"今日目标：思考完成idea并想清楚这个idea是不是有效果（而不是寄希望于实验看效果，复杂度降下来了的就是有效果，没有降下来就是没啥效果）；更新基础实现和baseline实现（是个大工程）；（有时间的话，优化分组的实现，重新run各种分组100点对；还有时间的话，实现idea） 上午 1 思考idea是不是有效果 2 更新直接实现和根据operf更新msbfs实现 operf 3 kinds of msbfs read code 3 github ssh error operf 3 kinds of msbfs and ana 4 operf 3 kinds of msbfs and ana redesign prec&amp;succ + 复用, reoperf（现在由于这俩太dominate，neighbors的开销都可以忽略不计） 下午 1 code comm复用 2 code comm复用 3 code comm复用 4 debug comm复用 time measure 晚上 1 code prec&amp;succ 复用 2,3 code prec&amp;succ 复用 尚未通过编译 md橘子洲烟花！ operf下看看情况 code prec&amp;succ opt design direct impl","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"10","slug":"daily-2023-5-10","date":"2023-05-10T01:55:00.000Z","updated":"2023-05-18T11:16:20.000Z","comments":true,"path":"2023/05/10/daily-2023-5-10/","link":"","permalink":"http://example.com/2023/05/10/daily-2023-5-10/","excerpt":"","text":"注意昨天有遗留任务：检索来的四篇论文检查是否是做Batch disjoint path的 今日目标：选定论文并看完（明天准备ppt）；baseline和Msbfs优化完成，做出效果；（有时间：思考统一p2搜索） 上午 1，2 读论文选论文 3 hw meeting 下午 1 就不按常规来思考呢？ 2 决定论文就讲suurrble了 继续思考，有进展！ 3 read surrble impl 继续思考！ 4 继续思考！ 5 继续思考！ 晚上 1 继续思考 2 继续思考 ideasurrble中很重要的一点为啥处理subtree之间的non-tree-edge不会增加复杂度是因为，subtree只会划分得越来越小，划分是在上一轮划分的结果下继续划分下去，且一条non-tree-edge只会最多被处理一次，这两点都是基于T上每个顶点最多被扩展一次 输入：点对集合，每个点对一条p1，图H输出：每对点对一条p2原始方法：每对点对都反向p1，把这个更新增量标记，从s和t双向bfs找p2所有点对p1的并集图p1g，有几个弱连通分量(通过依次从所有s出发在p1g上按无向图搜索)，每个分量p1g_comp中的点对分成一组，这个组中的点对只需要考虑p1g_comp(其他的p1都不是这个组中点对的，这个组中的点对搜p2时，都不需要反向其他p1)直接的实现： p1g_comp记录：每条边u-&gt;v都记录了两条(除非()bitset&#x3D;&#x3D;0)：u-&gt;v(bitset), v-&gt;u(bitset)，这两条边都称作p1-edge msbfs扩展当前点：v,iset： 考虑&amp;seen[nbr]之前的，需要考虑哪些nbr： v出发的不在p1g_comp中的边(non-p1-edge) v出发的在p1g_comp中的边(p1-edge)，&amp;iset 希望：不区分点对，面向统一的图H’，搜索模式修改 msbfs扩展当前点：v,iset：考虑&amp;seen[nbr]之前的，需要考虑哪些nbr： 直接的实现： v出发的non-p1-edge v出发的p1-edge，&amp;iset不为0 idea的核心：走p1-edge的时候一下沿p1-edge走很远：只要进入p1g_comp就直接传送出去 suurble中是通过subtree之间的跨边直接得到的这个，而没有显式地进行搜索看能被传送到哪里 idea的好处（为什么这么做）： - 增大搜p2时的共享程度：搜p2的共享程度没搜p1时大，一个原因是反向p1导致某个instance从iset中拆出来单独走自己的 - 复用p1，直接完成抵消 - 直接实现中，每次batch到p1g_comp上的顶点时，都要沿着其中部分做”nbr-msk”的访问，这些是不是可以一起先处理了弄成一个索引 - 可以不用split vertex了！split vertex本来就只是用来确保vertex disjoint的，这样单独处理了p1p2交叠部分的话，搜p2时也不需要split vertex了 - 只需要对p1g做split vertex来得到索引，其他地方都不需要split vertex了 一个索引start_reach_index: 很直观的内容：输入和输出都是：没有split vertex的顶点 闭包允许搜p2在非p1部分不用split vertex 一个CSR：从p1g_comp上每个顶点u，以全batch(这个p1g_comp中所有p1对应的点对)出发，在p1g_comp上可以到达哪些{v,iset} 注意，这个信息，在在p1g_comp中某些顶点被visited之后会发生变化，对于某instance从某顶点出发，现在可能有些原先可以到达的顶点现在到达不了，但是移除掉某些顶点（某些顶点被visited之后），从某顶点u出发可以到达的{v,iset}是没移除前的子集，且不能到达的那些{v,iset}是被移除掉的顶点可以到达的那些，因此之前在visit那些顶点时就会把这些顶点的seen设置，从而此时从u出发用原始信息+msk seen的话是正确的 空间：|p1g_comp所有顶点|^2*batchset |p1g_comp所有顶点|在实验中大概是64对点对*路径长度10&#x3D;640 上述中，u到{v,iset}的前驱 空间：p1g_comp的拓扑CSR*batchset使用： 搜索：扩展{u,iset}，若u在p1g_comp中则根据索引传送，为传送到达的nbr不仅记录prec，还记录u 构造路径：p1p2抵消的地方只可能发生在传送段构造方法：p1g_comp上全顶点all batch的msbfs，注意all batch就变成了计算的数据，而遍历过程用msbfs也有其一套bitset(每个bit表示一个出发点) 从p1g_comp上出发？ 是否有树的祖先关系可以用于加速之类的？ 存档msbfs扩展当前点：v,iset：考虑&amp;seen[nbr]之前的，需要考虑哪些nbr： idea： v出发的non-p1-edge(对于iset中任意instance都有这部分需要扩展) 移除v之后把p1g_comp分成的多个弱连通分量之间的non-p1-edge 要求non-p1-edge的起点：iset沿p1g_comp可以走到 不是跨边、只有一个端点在p1g_comp上的non-p1-edge是否要考虑呢？所有两端点不在同一个弱连通分量中的non-p1-edge(包括两个端点都在p1g_comp上的跨边，和只有一个端点在p1g_comp上的) 一个索引p1g_comp_terminal_index(一个p1g_comp对应一个)：对于每个有non-p1-edge的顶点，如果batch到达这个顶点，batch会被传送到哪些(顶点,iset) - suurble中是通过subtree之间的跨边直接得到的这个，而没有显式地进行搜索看能被传送到哪里如何构造p1g_comp_terminal_index：从p1g_comp中每个顶点以全1bitset出发在p1g_comp上做bfs，得到从其中每个顶点出发，可以到达的所有首个不在p1g_comp中的(顶点terminal,iset) iset表示只有这些iset可以到达terminal 这样的索引还是要用batch和所有entry做&amp;操作耶 一个索引p1_nbrs_index：每条p1存一个CSR：此CSR可以得到从p1上某一点v开始直到s的其上游所有顶点有哪些不属于p1的邻居 在重构路径的时候，如果走到这个CSR中的点，则v会被用到用来重构路径，且重构路径时就完成抵消p1: s-&gt;v0-&gt;v1-&gt;v2-&gt;tmsbfs扩展当前点：v,iset： - 若v在p1g_comp上，且(设v在p1_has_v_iset这些instance的p1上)若p1_has_v_iset&amp;iset不为空，则p1_has_v_iset&amp;iset中的每个instance都根据索引p1_nbrs_index进行传送(instance传送到v的所有p1上游，~instance传送给v的在p1上的下游邻居)，iset的其他部分正常扩展non-p1-edge - 否则正常扩展limit: 这个索引可能效果十分有限，因为这个只是压缩了沿反向p1的边进行的搜索，但是在实际数据集上可以观察到，p1反向边被用上的数目很少，几百的数量级，所以这个效果很有限","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"9","slug":"daily-2023-5-9","date":"2023-05-09T00:46:54.000Z","updated":"2023-05-10T01:56:16.000Z","comments":true,"path":"2023/05/09/daily-2023-5-9/","link":"","permalink":"http://example.com/2023/05/09/daily-2023-5-9/","excerpt":"","text":"五一发疯结束+思考了下前路，开始学术之路！今日目标：suurrble read again; hw ppt(分布式算法；数据图规模说明；取消输出的时间；响应时间) 上午 1 modify flow graph svn check paper diff help bro read new paper 2 read new paper merge and check ccg data 3 read suurrble 4 DP meeting hw ppt 下午 1 read suurrble and think 2 read suurrble and think预期：所有点对搜p2时面对的是同一个图（仍然是搜p1时的图H），改变搜索模式（不再是单纯扩展当前顶点的未访问邻居；这个搜索模式一定和所有点对的p1结构有关），达到每对点对是面对p1反向的图H搜最短路径的目的 如果用suurrble来解决每对点对 所有p1并集而成的一个有向图p1gtree-edge, non-tree-edge -&gt; p1-edge, non-p1-edge像suurrble一样，不再是单纯扩展当前顶点的未访问邻居，而是可能考虑沿着反向的p1走到的更多的邻居 对于当前顶点v，面对的图是从出发点到v沿p1g的路径反向了的 这个算法，当输入点对情况是one2all时，就退化为suurrble（点对情况是one2all时，由于p1都是最短路，因此p1g是T） 注意到p1g中一定包含了所有点对的点 3 operf msbfs vins_merge 4 think 检查是否有人做过上述问题 5 检查是否有人做过上述问题 晚上 1 检查是否有人做过上述问题 找disjoint path新的有影响力的工作 2 检查是否有人做过上述问题 找disjoint path新的有影响力的工作 3 检查是否有人做过上述问题 找disjoint path新的有影响力的工作","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python处理excel pandas","slug":"python处理excel-pandas","date":"2023-05-07T04:18:28.000Z","updated":"2024-02-23T03:45:34.187Z","comments":true,"path":"2023/05/07/python处理excel-pandas/","link":"","permalink":"http://example.com/2023/05/07/python%E5%A4%84%E7%90%86excel-pandas/","excerpt":"","text":"https://geek-docs.com/pandas/pandas-read-write/pandas-to-read-and-write-excel.html read_excel可以把excel读成dataframesto_excel把dataframes写成excel 读excelimport pandas as pd df = pd.read_excel(&quot;copy.xls&quot;, 1) 1是指定第二个sheet，默认是读取第一个sheet会自动识别列的内容类型，比如是int还是str，不过也可以通过传参dtype=&#123;&#39;col_name&#39;:str&#125;来指定哪些列读取的数据的类型 写excel写多个sheet frame = pd.DataFrame( np.random.random((4, 4)), index=[&quot;exp1&quot;, &quot;exp2&quot;, &quot;exp3&quot;, &quot;exp4&quot;], columns=[&quot;jan2015&quot;, &quot;Fab2015&quot;, &quot;Mar2015&quot;, &quot;Apr2005&quot;], ) with pd.ExcelWriter(&quot;test.xlsx&quot;) as ew: frame.to_excel(ew, sheet_name=&quot;1&quot;) frame.to_excel(ew, sheet_name=&quot;2&quot;) 写入一个sheet frame.to_excel(&quot;test.xlsx&quot;, sheet_name=&quot;1&quot;) 操作df获取列名 df.columns 获取拷贝获取行 df[1:2] # 行1 df[1:3] # 行1和行2 获取某行某列 df[1:2][&#39;年龄&#39;] # 行1的年龄列 获取引用https://blog.csdn.net/qq_18351157/article/details/104838924某行某列 df.at[1,&#39;年龄&#39;] # 行1的年龄列 合并dfhttps://blog.csdn.net/qq_41853758/article/details/83280104推荐使用merge和concat：支持内外连接左右连接","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"python模拟网页操作","slug":"python模拟网页操作","date":"2023-05-03T00:19:51.000Z","updated":"2023-05-04T01:45:11.000Z","comments":true,"path":"2023/05/03/python模拟网页操作/","link":"","permalink":"http://example.com/2023/05/03/python%E6%A8%A1%E6%8B%9F%E7%BD%91%E9%A1%B5%E6%93%8D%E4%BD%9C/","excerpt":"","text":"Pre-requisites: Python installed and Selenium installed as package along with the web driver (.exe file) Browser Automation Using Selenium 举例from selenium import webdriver import time import re opt = webdriver.ChromeOptions() #创建浏览器 driver = webdriver.Chrome(options=opt) #创建浏览器对象 driver.get(&#39;https://www.baidu.com/&#39;) #打开网页 # driver.maximize_window() #最大化窗口 time.sleep(2) #加载等待 driver.find_element_by_id(&#39;kw&#39;).send_keys(&#39;天气&#39;) driver.find_element_by_xpath(&quot;//span[@class=&#39;bg s_btn_wr&#39;]/input&quot;).click() 更新： You need to import Selenium WebDriver using this code: from selenium.webdriver.common.by import By Next use this API: Old API New API find_element_by_id(‘id’) find_element(By.ID, ‘id’) find_element_by_name(‘name’) find_element(By.NAME, ‘name’) find_element_by_xpath(‘xpath’) find_element(By.XPATH, ‘xpath’) and so on. Source: Fixing Selenium AttributeError: ‘WebDriver’ object has no attribute ‘find_element_by_xpath’ non blocking wait （加载出某些元素之后就进行操作，而不是等到整个网页加载完）visibility_of_element_locatedhttps://www.geeksforgeeks.org/non-blocking-wait-in-selenium-using-python/ When we want to do web automation, we require to wait for some javascript elements to load before we perform some action. The possible solution to this is to wait until a element appears and not wait for more than that. Let’s say you want to login on GeeksForGeeks through web automation and fill the login credentials as soon as username and password elements are visible on the web page and not wait until the whole page is loaded. Step1:You configure the webdriver as follows: from selenium import webdriver options = webdriver.ChromeOptions() options.add_argument(&quot;--start-maximized&quot;) options.add_argument(&quot;disable-infobars&quot;) chrome = webdriver.Chrome(the_path_of_webdriver_which_is_an_exe, chrome_options = options, service_args =[&#39;--ignore-ssl-errors = true&#39;]) login_uri = &#39;https://auth.geeksforgeeks.org/&#39; username = &#39;something&#39; password = &#39;anything&#39; username_xpath = &#39;//*[@id =&quot;luser&quot;]&#39; password_xpath = &#39;//*[@id =&quot;password&quot;]&#39; sign_in_xpath = &#39;//*[@id =&quot;Login&quot;]/button&#39; chrome.get(login_uri) Here I’ve used chrome web driver which would start maximized (full window) with no infobars i.e it won’t say that chrome is being controlled by automation code and load the sign page of GFG without any hassle. Do Note that in order to find the xpath of these elements you need to get into the developer mode and inspect these elements. Step 2: from selenium.webdriver.support import expected_conditions as EC from selenium.webdriver.support.wait import WebDriverWait # return True if element is visible within 30 seconds, otherwise False def is_visible(locator, timeout = 30): try: WebDriverWait(chrome, timeout).until(EC.visibility_of_element_located((By.XPATH, locator))) return True except TimeoutException: return False The above function is_visible is facilitator of the non blocking call we intend to discuss here.Explanation:\\1) locator – the xpath of the element\\2) timeout – until when to wait for the element to appear (because we don’t want to wait forever)\\3) chrome – the webdriver object we initialized earlier\\4) It utilizes the inbuild utility of ui to make the web driver wait until the element is visible (identified by xpath)\\5) if it does appear within the timeout it returns True else False Step 3:This is how we utilize the function: if not is_visible(username_xpath): raise RuntimeError(&quot;Something went wrong with the username field :(&quot;) username_field = chrome.find_element_by_xpath(username_xpath) username_field.send_keys(username) if not is_visible(password_xpath): raise RuntimeError(&quot;Something went wrong with the password field :(&quot;) password_field = chrome.find_element_by_xpath(password_xpath) password_field.send_keys(password) if not is_visible(sign_in_xpath): raise RuntimeError(&quot;Something went wrong with the sign in field :(&quot;) sign_in_btn = chrome.find_element_by_xpath(sign_in_xpath) sign_in_btn.click() Here we call the is_visible function and pass the xpath of username, password and sign_in button respectively and wait for the element to appear within timeout (here 30s). If not visible then we raise an RuntimeError with appropriate message.If it appears anytime earlier than 30s it proceeds and find the element by xpath (as now it is visible on the webpage so this call wouldn’t throw exception error. We then send the data and click on sign in and you can enjoy learning on GFG without any blocking call","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"28","slug":"daily-2023-4-28","date":"2023-04-28T00:50:55.000Z","updated":"2023-04-28T01:48:13.000Z","comments":true,"path":"2023/04/28/daily-2023-4-28/","link":"","permalink":"http://example.com/2023/04/28/daily-2023-4-28/","excerpt":"","text":"今日目标：读完rfc，可能的话写一下hw 上午 1 read rfc 2 read rfc 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"27","slug":"daily-2023-4-27","date":"2023-04-27T01:47:09.000Z","updated":"2023-04-28T00:50:44.000Z","comments":true,"path":"2023/04/27/daily-2023-4-27/","link":"","permalink":"http://example.com/2023/04/27/daily-2023-4-27/","excerpt":"","text":"昨晚看到自己的idea被别人提出来了很emo就回去摆烂了bushi今天冷静下来，显然要彻底弄懂别人的想法然后检查自己的想法是否还有空间今日目标：rfc check and exam; suurbale again, maybe inspiration; other paper cited by jsac 上午 1 read rfc 下午晚上下午和晚上出去玩了hhh一些逃避行为","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"26","slug":"daily-2023-4-26","date":"2023-04-26T00:35:33.000Z","updated":"2023-04-26T11:33:27.000Z","comments":true,"path":"2023/04/26/daily-2023-4-26/","link":"","permalink":"http://example.com/2023/04/26/daily-2023-4-26/","excerpt":"","text":"今日目标：看完相关论文和再次阅读jsac希望可以让自己进入“持续调研2-dp问题”的状态中 上午 1 read paper 2 read paper 3 read paper 下午 1 reread suurbale 2 reread suurbale 更懂一点了！明天可以考虑再读一遍hhh 3 reread suurbale 天哪，发现这个实现idea的程度居然是我可以想出来的！我对tree和dfs是真的熟；当然要认识到的一点是，1984这篇让人拍案的地方在转换问题+合并dijkstra（也是这里要读好几遍） 4 reread suurbale done! read suurbale in jsac wow! I really understand! at least the path construction phase of suurbale! 晚上 1 read nfc 2 read nfc","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"25","slug":"daily-2023-4-25","date":"2023-04-25T00:03:11.000Z","updated":"2023-04-25T12:50:20.000Z","comments":true,"path":"2023/04/25/daily-2023-4-25/","link":"","permalink":"http://example.com/2023/04/25/daily-2023-4-25/","excerpt":"","text":"今日目标： 上午 1 设计和code输出 test idea 2 设计和code输出 下午毕设代码检测 1 read paper 晚上希望晚上可以看一大半组会要讲的论文！（你发现你真的熟悉2dp这个领域！为什么不再清楚一点！到“老师问你我们是不是第一个做批量2dp问题”的时候很有底气地给答案）或许有时间评估下hw新的prec粒度是否值得实验？优先看完论文和做ppt 1 read paper 2 read paper 3 read paper噢天哪！第一次理论论文看得这么不劝退这么不艰难！ 4 read paper","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"非root修改/etc/hosts","slug":"非root修改-etc-hosts","date":"2023-04-24T12:25:33.000Z","updated":"2023-04-24T13:05:08.000Z","comments":true,"path":"2023/04/24/非root修改-etc-hosts/","link":"","permalink":"http://example.com/2023/04/24/%E9%9D%9Eroot%E4%BF%AE%E6%94%B9-etc-hosts/","excerpt":"","text":"注意：这个alias只对由gethostby()系统调用（和另一个忘了叫啥的系统调用）实现的功能起替换，但是对于从host名字到ip地址的转换还是没办法所以还是和修改&#x2F;etc&#x2F;hosts不一样 实际上并不是修改&#x2F;etc&#x2F;hosts，而是取得和修改&#x2F;etc&#x2F;hosts类似的效果： https://unix.stackexchange.com/questions/6887/can-i-create-override-dns-similar-to-writing-in-etc-hosts-without-root-access use the HOSTALIASES environment variable: $ echo “foo www.google.com&quot; &gt;&gt; &#x2F;.hosts$ HOSTALIASES&#x3D;&#x2F;.hosts wget fooSee hostname(7). In the example the HOSTALIASES environment variable only affects the wget process. Of course, you can export HOSTALIASES to have it take effect for all subprocesses of the current shell:add following to ~/.bashrc: (you may create ~&#x2F;.hosts through first cp &#x2F;etc&#x2F;hosts then modify as you need) export HOSTALIASES=~/.hosts","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"跳板机","slug":"跳板机","date":"2023-04-24T11:34:22.000Z","updated":"2023-04-24T11:55:35.000Z","comments":true,"path":"2023/04/24/跳板机/","link":"","permalink":"http://example.com/2023/04/24/%E8%B7%B3%E6%9D%BF%E6%9C%BA/","excerpt":"","text":"you-&gt;jump-&gt;dest 1. Passwordless SSH LoginPasswordless SSH Login between machines: you-&gt;jump, jump-&gt;dest detail gen key:ssh-keygen on you and jump pass key:first,~/.ssh/config on you: Host jump HostName ip_addr1 User username ~/.ssh/config on jump: Host dest HostName ip_addr2 User username then,on you: ssh-copy-id jumpon jump: ssh-copy-id dest3. checkon you: ssh jumpon jump: ssh dest 2. ProxyCommand~/.ssh/config on you: Host jump HostName ip_addr1 User username Host dest HostName ip_addr2 User username ProxyCommand ssh -W %h:%p jump 3. Passwordless SSH Loginnow you can pass key on you to dest (ssh-copy-id dest) 4. done!on you: ssh dest 仍然不能免密的原因copy-ssh-id问题解决 scp传送文件you&lt;-&gt;destscp some_file_path dest:file_pathscp dest:some_file_path file_path","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"copy-ssh-id问题解决","slug":"copy-ssh-id问题解决","date":"2023-04-24T11:17:43.000Z","updated":"2023-04-24T11:20:46.000Z","comments":true,"path":"2023/04/24/copy-ssh-id问题解决/","link":"","permalink":"http://example.com/2023/04/24/copy-ssh-id%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/","excerpt":"","text":"https://www.linuxquestions.org/questions/linux-networking-3/after-ssh-copy-id-still-need-to-provide-password-911888/ After ssh-copy-id , still need to provide password Check whether your public key on the local machine (typically something like ~&#x2F;.ssh&#x2F;id_rsa.pub) has actually been appended onto the authorized list on the remote machine (in ~&#x2F;.ssh&#x2F;authorized_keys). These are viewable as text files. Check the permissions on the &#x2F;.ssh directory (usually readable only by the owner: 0700/drwx------,可以通过命令chmod 700来正确设置), the permissions on the private key of the local machine (typically ~&#x2F;.ssh&#x2F;id_rsa, must be restricted to owner only: -rw------- chmod 600), and the permissions on the authorized list on the remote machine (&#x2F;.ssh&#x2F;authorized_keys, must not be group writable: 正确的比如-rw-------). Have a look at the settings on the sshd daemon on the remote machine if it is viewable (&#x2F;etc&#x2F;ssh&#x2F;sshd_config). Check flags like ‘PubkeyAuthentication’. Is the ssh login giving any information, or does it just ask for the password immediately? You can use the verbose flag ‘-v’ to see what is happening in more detail.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"24","slug":"daily-2023-4-24","date":"2023-04-24T00:13:17.000Z","updated":"2023-04-24T13:01:04.000Z","comments":true,"path":"2023/04/24/daily-2023-4-24/","link":"","permalink":"http://example.com/2023/04/24/daily-2023-4-24/","excerpt":"","text":"今日目标：搞完杂碎（妈的毕设）；学习和设计图划分分布式；有时间的话，读论文 上午 1 读资讯 读motif code的”main.cpp”，写中文注释怎么用，这些也对应了代码测试项目，然后都跑一下，如果可以跑就添加到word上 2 改写cmake搞定编译 搜集用法 3（天啊为什么我还在搞毕设的垃圾测试！这个block必须完成！） 写word，准备两个数据集 run一下 接了一个新的简单的锅，妈的今天杂碎这么多 感觉要学会调整自己的心态：diss杂碎，1秒钟之内没有搞完就觉得浪费时间很讨厌 应该修正为：杂碎很简单，没啥脑力活，这是不得不做的事情，咱可以在提升效率上来为有意思的事情腾时间，同时可以通过寻找和试用新工具来化解杂碎没啥意思的性质 4 毕设run 下午（一些摆烂到现在） 1 gstore twitter query 晚上 1 update k hop count and shortest path count three node mod try ssh问题 2 解决其他的ssh问题和写博客 3，4 试了一下config配置的名字不可以取代&#x2F;etc&#x2F;hosts的，如果找不到其他非root写&#x2F;etc&#x2F;hosts的方法，则三节点就没办法了 噢找到了方法！ 哦不，似乎没有用","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpirun","slug":"mpirun","date":"2023-04-23T05:50:08.000Z","updated":"2023-04-23T06:49:53.000Z","comments":true,"path":"2023/04/23/mpirun/","link":"","permalink":"http://example.com/2023/04/23/mpirun/","excerpt":"","text":"man mpirun术语DEFINITION OF ‘SLOT’A slot is an allocation unit for a process. The number of slots on a node indicate how many processes can potentially execute on that node. By default, Open MPI will allow one process per slot. Slots are not hardware resources DEFINITION OF ‘PROCESSOR ELEMENT’By default, Open MPI defines that a “processing element” is a processor core. mpirun发生了什么 % mpirun [ -np X ] [ –hostfile ] This will run X copies of in your current run-time environment (if running under a supported resource manager, Open MPI’s mpirun will usually automatically use the corresponding resource manager process starter, as opposed to, for example, rsh or ssh, which require the use of a hostfile, or will default to running all X copies on the localhost), scheduling (by default) in a round-robin fashion by CPU slot. mpirun will send the name of the directory where it was invoked on the local node to each of the remote nodes, and attempt to change to that directory. Pass these run-time arguments to every new process. These must always be the last arguments to mpirun. Note that as of the start of the v1.8 release, mpirun will launch a daemon onto each host in the allocation (比如使用–host指定的所有节点) at the very beginning of execution, regardless of whether or not application processes will eventually be mapped to execute there. map和bindOpen MPI employs a three-phase procedure for assigning process locations and ranks: mapping Assigns a default location to each process ranking Assigns an MPI_COMM_WORLD rank value to each process binding Constrains each process to run on specific processors Note: the location assigned to the process（即mapping） is independent of where it will be bound - the assignment is used solely as input to the binding algorithm. process bindPlease note that mpirun automatically binds processes as of the start of the v1.8 series. Three binding patterns are used in the absence of any further directives: Bind to core: when the number of processes is &lt;&#x3D; 2 Bind to socket: when the number of processes is &gt; 2 Bind to none: when oversubscribed If your application uses threads, then you probably want to ensure that you are either not bound at all (by specifying –bind-to none), or bound to multiple cores using an appropriate binding level or specific number of processing elements per application process. （即每个process多线程的时候，要么指定**--bind-to none**，这样会not bound (or bound to all available processors；要么指定每个process分配多少处理器核心，比如--map-by node:PE=n是每个节点一个process、每个process bind to n个处理器核心） 相关option运行指定： –bind-to Bind processes to the specified object, defaults to core. Supported options include slot, hwthread, core, l1cache, l2cache, l3cache, socket, numa, board, cpu-list, and none. –map-by Map process to the specified object, defaults to socket. Supported options include slot, hwthread, core, L1cache, L2cache, L3cache, socket, numa, board, node, sequential, distance, and ppr. Any object can include modifiers by adding a : and any combination of PE&#x3D;n (bind n processing elements to each proc), SPAN (load balance the processes across the allocation), OVER‐ SUBSCRIBE (allow more processes on a node than processing elements), and NOOVERSUBSCRIBE. This includes PPR, where the pattern would be terminated by another colon to separate it from the modifiers. &gt; 比如 –map-by node:PE&#x3D;n &gt; load balance the processes across the available nodes, and bind each process to 32 processing elements. –use-hwthread-cpus ​ then **processing element** is not physical core, but hardware thread 帮助监控： -report-bindings, –report-bindings Report any bindings for launched processes. option运行指定 The program executable. This is identified as the first non-recognized argument to mpirun. The following options specify the number of processes to launch. Note that none of the options imply a particular binding policy -c, -n, –n, -np &lt;#&gt; Run this many copies of the program on the given nodes 还有很多其他参数，需要的时候man mpirun stdI&#x2F;O控制 -output-filename, –output-filename Redirect the stdout, stderr, and stddiag of all processes to a process-unique version of the specified filename. Any directories in the filename will automatically be created. Each output file will consist of filename.id, where the id will be the processes’ rank in MPI_COMM_WORLD, left-filled with zero’s for correct ordering in listings. A relative path value will be converted to an absolute path based on the cwd where mpirun is executed. Note that this will not work on environments where the file system on compute nodes differs from that where mpirun is executed. -tag-output, –tag-output Tag each line of output to stdout, stderr, and stddiag with [jobid, MCW_rank] indi‐ cating the process jobid and MPI_COMM_WORLD rank of the process that generated the output, and the channel which generated it. -timestamp-output, –timestamp-output Timestamp each line of output to stdout, stderr, and stddiag. -stdin, –stdin The MPI_COMM_WORLD rank of the process that is to receive stdin. The default is to forward stdin to MPI_COMM_WORLD rank 0, but this option can be used to forward stdin to any process. It is also acceptable to specify none, indicating that no processes are to receive stdin. 帮助监控 -display-map, –display-map Display a table showing the mapped location of each process prior to launch. -display-allocation, –display-allocationDisplay the detected resource allocation. -report-pid, –report-pid Print out mpirun’s PID during startup. The channel must be either a ‘-‘ to indicate that the pid is to be output to stdout, a ‘+’ to indicate that the pid is to be output to stderr, or a filename to which the pid is to be written. -show-progress, –show-progress Output a brief periodic report on launch progress 调试 -debug, –debug Invoke the user-level debugger indicated by the orte_base_user_debugger MCA parameter. -debugger, –debugger Sequence of debuggers to search for when –debug is used (i.e. a synonym for orte_base_user_debugger MCA parameter). 比如 mpirun -debug -debugger gdb ./myprogram -debugger gdb指明可以使用的调试器 bind process见上方[bind process节](# 相关option) mca -mca, –mca Send arguments to various MCA modules. See the “MCA” section, below.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"Scalasca 并行程序profile工具","slug":"Scalasca-并行程序profile工具","date":"2023-04-23T01:02:00.000Z","updated":"2023-04-23T05:52:42.000Z","comments":true,"path":"2023/04/23/Scalasca-并行程序profile工具/","link":"","permalink":"http://example.com/2023/04/23/Scalasca-%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8Fprofile%E5%B7%A5%E5%85%B7/","excerpt":"","text":"官网get started：https://apps.fz-juelich.de/scalasca/releases/scalasca/2.3/docs/manual/start.html 还有工具 Performance Analysis Tools，简称PAT Distributed Debugging Tool，简称DDT","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"TAU 并行程序profile工具","slug":"TAU-并行程序profile工具","date":"2023-04-23T01:01:33.000Z","updated":"2023-04-23T01:02:16.000Z","comments":true,"path":"2023/04/23/TAU-并行程序profile工具/","link":"","permalink":"http://example.com/2023/04/23/TAU-%E5%B9%B6%E8%A1%8C%E7%A8%8B%E5%BA%8Fprofile%E5%B7%A5%E5%85%B7/","excerpt":"","text":"官网：http://www.cs.uoregon.edu/research/tau/home.php","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"23","slug":"daily-2023-4-23","date":"2023-04-22T22:45:06.000Z","updated":"2023-04-23T07:05:50.000Z","comments":true,"path":"2023/04/23/daily-2023-4-23/","link":"","permalink":"http://example.com/2023/04/23/daily-2023-4-23/","excerpt":"","text":"今日目标：希望把mod集群搭建起来，在上面跑7500，找分布式比单机版慢的原因；twitter抄到word；有时间的话运行毕设代码填表格（呜呜希望下午可以出去吃点东西划掉，不管怎么样下午都出去吃东西因为这样才可以确保下周可以继续连轴转） 早上 1 装同一版本openMPI twitter抄到word 解决集群问题！ 上午 1,2,3 run 7500 on mod cluster 装高版本gcc 果然分布式要更慢，三倍时间，每个节点都是单节点的三倍时间，所以接下来的步骤是使用性能分析工具揭示原因 搜分布式profile工具和MPI提供的工具 下午 1 学习man mpirun,发现原因可能是每个进程只一个核的原因 2,3,4 验证是否上述原因和解决 哈哈哈哈哈哈哈哈哈哈哈哈哈真的是原因！妈的！出去玩！ 晚上mod搭集群遇到的问题在都装了4.1.5版本openmpi之后## mod90上helloworld可以跑集群，但是bcast报错：&#96;&#96;&#96;bash[yuanzhiqiu@server90 code]$ mpirun -np 2 –host server90,server91 .&#x2F;compare_bcast 1000 10WARNING: Open MPI accepted a TCP connection from what appears to be aanother Open MPI process but cannot find a corresponding processentry for that peer. This attempted connection will be ignored; your MPI job may or may notcontinue properly. Local host: server90 PID: 50670[server90:50665] 1 more process has sent help message help-mpi-btl-tcp.txt &#x2F; server accept cannot find guid[server90:50665] Set MCA parameter “orte_base_help_aggregate” to 0 to see all help &#x2F; error messages## mod91上 helloworld可以跑集群，但是bcast报错：bash[yuanzhiqiu@server91 code]$ mpirun -np 2 –host server90,server91 .&#x2F;compare_bcast 1000 10WARNING: Open MPI accepted a TCP connection from what appears to be aanother Open MPI process but cannot find a corresponding processentry for that peer. This attempted connection will be ignored; your MPI job may or may notcontinue properly. Local host: server91 PID: 11323[server91:11318] 1 more process has sent help message help-mpi-btl-tcp.txt &#x2F; server accept cannot find guid[server91:11318] Set MCA parameter “orte_base_help_aggregate” to 0 to see all help &#x2F; error messages ## 解决 搜索发现这个报错的原因和解决：https://www.mail-archive.com/users@lists.open-mpi.org/msg34182.html ```txt That typically occurs when some nodes have multiple interfaces, and several nodes have a similar IP on a private/unused interface. I suggest you explicitly restrict the interface Open MPI should be using. For example, you can mpirun --mca btl_tcp_if_include eth0 ... 先ifconfig看网卡，然后 [yuanzhiqiu@server90 code]$ mpirun -np 2 --host server90,server91 --mca btl_tcp_if_include em1 ./compare_bcast 1000 10 Data size = 4000, Trials = 10 Avg my_bcast time = 0.000161 Avg MPI_Bcast time = 0.000158 [yuanzhiqiu@server91 code]$ mpirun -np 2 --host server90,server91 --mca btl_tcp_if_include em1 ./compare_bcast 1000 10 Data size = 4000, Trials = 10 Avg my_bcast time = 0.000159 Avg MPI_Bcast time = 0.000158","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"22","slug":"daily-2023-4-22","date":"2023-04-22T00:43:34.000Z","updated":"2023-04-22T14:29:12.000Z","comments":true,"path":"2023/04/22/daily-2023-4-22/","link":"","permalink":"http://example.com/2023/04/22/daily-2023-4-22/","excerpt":"","text":"周末目标：分布式简单版（没有图划分）完成开发并且在你的可用资源上测试中图；毕设代码测试（或者重写啥的）今日目标：分布式简单版code+debug+run small test 上午 1 twitter query and hw single node result 设计简单分布式 学习每个节点一个全图的简单mpi分布式 2 mpi test 简单例程ok，但是collecttive call不可以 用教程例子测试下 3 解决通信不行 下午 1 解决通信 解决啦哈哈哈哈所以说报错信息+分析真的yyds test time measure 2 test time measure 3 code simple distribute 4 code simple distribute debug multiple run time logic gen data 晚上 1 单机模拟多机： debug multiple run（目前时间很奇怪） （checkanswer和single run目前kan起来没有问题） 新服务器账号 2 多机： check checkanswer（看是不是每个节点一个check_ans文件然后检查fail） check single run（看&gt;文件输出是不是一个节点一个（不是，主节点输出）；看时间对不对；看内存统计是不是一个节点一个） 3 check multiple run（同上） hnu上两个100跑一下单机（平均20次），看多机有没有加快 没有呜呜 mod生成数据 这里解决一些error 4 mod搭建集群测试 有个没有装mpi给装一下 不理解为什么叶子数目更少了却慢很多呢？通信明明是在时间已经拿到之后的 有可能是100x分成两个节点只有各50leaf，这样32线程？ 试一下7500的 是计时方法有问题吗？ mod搭集群遇到的问题：mod90和mod91之间可以ssh免密登录，且都关闭防火墙了下面是测试&#x2F;home&#x2F;yuanzhiqiu&#x2F;tutorials&#x2F;mpi-broadcast-and-collective-communication&#x2F;code程序的报错各自单机跑bcast可以 mod90上mod90是我刚安装的openmpi另外mod90上有时候单机跑bcast程序也会卡住 跑helloworld和跑bcast[yuanzhiqiu@server90 code]$ mpirun -np 2 --host server90,server91 ./compare_bcast 1000 10 orted: Error: unknown option &quot;--tree-spawn&quot; Type &#39;orted --help&#39; for usage. Usage: orted [OPTION]... -d|--debug Debug the OpenRTE --daemonize Daemonize the orted into the background --debug-daemons Enable debugging of OpenRTE daemons --debug-daemons-file Enable debugging of OpenRTE daemons, storing output in files -h|--help This help message --hnp Direct the orted to act as the HNP --hnp-uri &lt;arg0&gt; URI for the HNP -nodes|--nodes &lt;arg0&gt; Regular expression defining nodes in system -output-filename|--output-filename &lt;arg0&gt; Redirect output from application processes into filename.rank --parent-uri &lt;arg0&gt; URI for the parent if tree launch is enabled. -report-bindings|--report-bindings Whether to report process bindings to stderr --report-uri &lt;arg0&gt; Report this process&#39; uri on indicated pipe -s|--spin Have the orted spin until we can connect a debugger to it --set-sid Direct the orted to separate from the current session --singleton-died-pipe &lt;arg0&gt; Watch on indicated pipe for singleton termination --test-suicide &lt;arg0&gt; Suicide instead of clean abort after delay --tmpdir &lt;arg0&gt; Set the root for the session directory tree -xterm|--xterm &lt;arg0&gt; Create a new xterm window and display output from the specified ranks there For additional mpirun arguments, run &#39;mpirun --help &lt;category&gt;&#39; The following categories exist: general (Defaults to this option), debug, output, input, mapping, ranking, binding, devel (arguments useful to OMPI Developers), compatibility (arguments supported for backwards compatibility), launch (arguments to modify launch options), and dvm (Distributed Virtual Machine arguments). -------------------------------------------------------------------------- ORTE was unable to reliably start one or more daemons. This usually is caused by: * not finding the required libraries and/or binaries on one or more nodes. Please check your PATH and LD_LIBRARY_PATH settings, or configure OMPI with --enable-orterun-prefix-by-default * lack of authority to execute on one or more specified nodes. Please verify your allocation and authorities. * the inability to write startup files into /tmp (--tmpdir/orte_tmpdir_base). Please check with your sys admin to determine the correct location to use. * compilation of the orted with dynamic libraries when static are required (e.g., on Cray). Please check your configure cmd line and consider using one of the contrib/platform definitions for your system type. * an inability to create a connection back to mpirun due to a lack of common network interfaces and/or no route found between them. Please check network connectivity (including firewalls and network routing requirements). -------------------------------------------------------------------------- mod91上跑helloworld[yuanzhiqiu@server91 code]$ mpirun -np 2 --host server90,server91 ./mpi_hello_world [server91:20464] [[64313,0],0] tcp_peer_recv_connect_ack: received different version from [[64313,0],1]: 4.0.0 instead of 3.1.0 -------------------------------------------------------------------------- ORTE has lost communication with a remote daemon. HNP daemon : [[64313,0],0] on node server91 Remote daemon: [[64313,0],1] on node server90 This is usually due to either a failure of the TCP network connection to the node, or possibly an internal failure of the daemon itself. We cannot recover from this failure, and therefore will terminate the job. -------------------------------------------------------------------------- [yuanzhiqiu@server91 code]$ 跑bcast[yuanzhiqiu@server91 code]$ mpirun -np 2 --host server90,server91 ./compare_bcast 1000 10 [server91:20427] [[64258,0],0] tcp_peer_recv_connect_ack: received different version from [[64258,0],1]: 4.0.0 instead of 3.1.0 -------------------------------------------------------------------------- ORTE has lost communication with a remote daemon. HNP daemon : [[64258,0],0] on node server91 Remote daemon: [[64258,0],1] on node server90 This is usually due to either a failure of the TCP network connection to the node, or possibly an internal failure of the daemon itself. We cannot recover from this failure, and therefore will terminate the job. -------------------------------------------------------------------------- [yuanzhiqiu@server91 code]$ 分析看mod91的报错，应该是两台服务器openmpi的版本不一致另外还观察到，为啥版本是4.0.0而不是4.1.5? 现象：在s2上跑(s2,s4)集群：## 没有collective call的可以## 教程例子gather scatter可以## 教程例子bcast也会报错但是会结束运行，error(11)&#96;&#96;&#96;bash[yuanzhiqiu@s2 code]$ mpirun -np 2 .&#x2F;compare_bcast 1000 10Data size &#x3D; 4000, Trials &#x3D; 10Avg my_bcast time &#x3D; 0.000008Avg MPI_Bcast time &#x3D; 0.000005[yuanzhiqiu@s2 code]$ mpirun -np 2 –host s2,s4 .&#x2F;compare_bcast 1000 10WARNING: Open MPI failed to TCP connect to a peer MPI process. Thisshould not happen. Your Open MPI job may now hang or fail. Local host: s2 PID: 43343 Message: connect() to 115.157.197.31:1024 failed Error: Resource temporarily unavailable (11)Data size &#x3D; 4000, Trials &#x3D; 10Avg my_bcast time &#x3D; 0.010016Avg MPI_Bcast time &#x3D; 0.010018下面这些命令得到的输出和上面一样（找通信的网卡是通过`ifconfig`或者`netstat -nr`） 指明网卡bashmpirun -np 2 –host s2,s4 –mca btl_tcp_if_include 115.157.197.0&#x2F;24 .&#x2F;compare_bcast 1000 10mpirun -np 2 –host s2,s4 –mca btl_tcp_if_include em1 .&#x2F;compare_bcast 1000 10加通信方式bashmpirun -np 2 –host s2,s4 –mca btl tcp,vader,self .&#x2F;compare_bcast 1000 10## 我的例子会卡住，error(15)bash[yuanzhiqiu@s2 tool]$ mpirun -np 2 –host s2,s4 .&#x2F;mpi_test tWARNING: Open MPI failed to TCP connect to a peer MPI process. Thisshould not happen. Your Open MPI job may now hang or fail. Local host: s2 PID: 43860 Message: connect() to 115.157.197.31:1024 failed Error: Operation now in progress (115)卡在这里加参数的命令的也是上面一样的报错 ## 我的分析 看报错，message是&quot;connect() to 115.157.197.31:1024 failed&quot;，应该和网络有关系 ## 尝试解决 ### mpirun参数 见上述现象 ### 防火墙 分析：s2上可以跑(s2,s4)集群简单例程，s4上不可以，因此原因可能是s2没有关闭防火墙 可是s2和s4防火墙都是关闭的： ```bash [yuanzhiqiu@s4 ~]$ systemctl status firewalld ● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1) 注意到一个提示： This is usually caused by a firewall on the remote host. Please check that any firewall (e.g., iptables) has been disabled and try again. 所以不仅要关闭firewalld，还要关闭iptables?s4上： [yuanzhiqiu@s4 ~]$ service iptables status Redirecting to /bin/systemctl status iptables.service ● iptables.service - IPv4 firewall with iptables Loaded: loaded (/usr/lib/systemd/system/iptables.service; enabled; vendor preset: disabled) Active: active (exited) since Mon 2023-03-13 11:24:04 CST; 1 months 9 days ago Process: 1956 ExecStart=/usr/libexec/iptables/iptables.init start (code=exited, status=0/SUCCESS) Main PID: 1956 (code=exited, status=0/SUCCESS) CGroup: /system.slice/iptables.service 而s2上： [yuanzhiqiu@s2 ~]$ service iptables status Redirecting to /bin/systemctl status iptables.service Unit iptables.service could not be found. 所以s4上关一下看看 防火墙操作命令1:查看防火状态 systemctl status firewalld service iptables status 2:暂时关闭防火墙 systemctl stop firewalld service iptables stop 3:永久关闭防火墙 systemctl disable firewalld chkconfig iptables off 4:重启防火墙 systemctl enable firewalld service iptables restart 果然可以耶！现在可以在s4上跑集群，也可以跑bcast了！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"21","slug":"daily-2023-4-21","date":"2023-04-21T00:00:58.000Z","updated":"2023-04-21T13:48:08.000Z","comments":true,"path":"2023/04/21/daily-2023-4-21/","link":"","permalink":"http://example.com/2023/04/21/daily-2023-4-21/","excerpt":"","text":"今日目标：完成单机版debug测试性能；分布式chatgpt学习[旺柴]；twitter晚上下载下 上午 1 分布式BFS chatgpt学习 bfs检查得colorcc算法没有问题，也验证了一件事：50x中，50个leaf出发的bfs没有顶点交集 2 检查checkanswer有没有问题 不对，发现colorcc有问题 3 发现colorcc的问题可能是不是从bd出发 同时发现0.5的数据集中所有leaf在一个cc上，于是试一试单线程的（多线程也是单线程） 都在一个cc中（即有顶点交集）咋用多线程呢 其实所有Worker的static数据改成thread local就可以了~ 写local的 4 code and debug local 下午希望下午和晚上完成local copy开发，并且测试好性能优化local copy到两个7500数据集都达标完成twitter query 1 download twitter 解决了local copy bug，在7500上平均run 原来是粗心导致的nmd 2 看下下来的twitter是啥格式，开发load local share完全不scale up，operf下优化 定位问题是初始化每个线程per-vertex数组时间比较长，占了一半多 3 怎么解决这个问题？对于所有leaf都在一个cc中的情况： 其实我们可以用copy on write，每个线程中的副本，是只有其他线程写了的话才创建一个顶点的 设计下 这要加锁耶 休息 4 code copy on write 5 code copy on write 晚上先通过编译（考虑在graph中成员，constructor中先读文件） 1 code copy on write debug done see on 7500_0.5 twitter download unzip 2 艹哈哈哈哈哈哈哈哈哈居然达标啦哈哈哈哈哈哈哈哈哈哈哈哈哈 精益求精一点，operf一下[旺柴] operf优化之后，对两个7500的数据集最快的run 40次求平均，然后单机版算告一段落啦，设计general的多机版 3 operf改锁之后更慢了x 所以之前那样就得了x","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"20","slug":"daily-2023-4-20","date":"2023-04-20T00:58:31.000Z","updated":"2023-04-20T14:19:34.000Z","comments":true,"path":"2023/04/20/daily-2023-4-20/","link":"","permalink":"http://example.com/2023/04/20/daily-2023-4-20/","excerpt":"","text":"今日目标：debug完成twitter query；hw测单机版6跳7500（希望看看达标没有啦；希望还有时间可以开始优化单机版，如果尚未达标的话） 上午 1 整理hw code gpt毕设提纲hh 2 debug twitter bibfs twitter的log太大，找测试数据测试 3 发现原因，去重 bug解决 joint: 21497565(1,2) 23934110(1,4) grep -A 3 -E &#39;21497565|23934110&#39; nohup.out s边扩展第0层 n=21497565 scnt[n]==0 scnt[n]=1 sd[n]=1 n=23932899 -- n=23934110 scnt[n]==0 scnt[n]=1 sd[n]=1 n=23934184 -- t边扩展第1层 n=21497565 tcnt[n]==0 meet tcnt[n]=2 td[n]=2 vcnt是2，但是v是第1层的，不可能有两条路径到它，除非有重边 -- n=23934110 tcnt[n]==0 meet tcnt[n]=2 td[n]=2 vcnt是2，但是v是第1层的，不可能有两条路径到它，除非有重边 -- n=23934110 td[n] == vd + 1 tcnt[n]=4 n=23934111 -- 21497565(1,2) 23934110(1,4) 6 16,942,022us 4 下载数据集遇到的问题：Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443… failed: Connection timed out.Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.109.133|:443… failed: No route to host. 下午一个啥活动，我喜欢这个企业家！讲故事娓娓动听，鸡汤也很有道理 晚上目标：不优化的情况下把7500 6hop run起来看达标没有；twitter数据集下载和改load 1 - chatx - design dynamic type map - code load_vertices 2 - no, we don’t need to touch load_vertices - code dynamic type map - debug 6 hop 3 - debug 6 hop 4 - 问题出在多线程上 - 且两次run的错误结果不一样 - 且多的顶点都是microservice以上的顶点 - 怀疑是cc划分问题，run几次输出下cc - 单线程输出的cc也是每个cc只有一个leaf，所以问题出在cc划分算法上 - 但是这可能是对的。并查集单线程试一下 - 并查集结果是全部leaf都是一个cc中的，因此color算法有问题","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"19","slug":"daily-2023-4-19","date":"2023-04-19T01:39:33.000Z","updated":"2023-04-20T00:58:20.000Z","comments":true,"path":"2023/04/19/daily-2023-4-19/","link":"","permalink":"http://example.com/2023/04/19/daily-2023-4-19/","excerpt":"","text":"今日目标：twitter测试任务完成（可能的话优化单机版） 上午 1 做hw ppt 化工比赛AI力量设计logo hhh 有原创纠纷，谨慎例会 思考了下李老师twitter的算法（gpt help me hhh） 下午年级大会 1 整理毕设时间点 25000实际加载部分的点边数目 对齐要求和数据构造脚本 code bibfs 2 对齐数据生成问题 生成数据 晚上 code and debug bibfs and khop","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"18","slug":"daily-2023-4-18","date":"2023-04-18T01:33:12.000Z","updated":"2023-04-19T01:39:58.000Z","comments":true,"path":"2023/04/18/daily-2023-4-18/","link":"","permalink":"http://example.com/2023/04/18/daily-2023-4-18/","excerpt":"","text":"昨天搞定了单线程优化（虽然还是没有达标），并写完和调试了多线程，但是多线程比单线程慢今日目标：解决多线程比单线程慢的问题，尽量优化到达标（奇迹了） 上午 1 th&#x3D;1和tsk划分测试 tsk划分是原因！ th&#x3D;32测试多种tsk sz，因为毕竟还是比单线程快不了很多 2 operf 32th 2f ohno 没有什么可以改进的结论发现 把时间测量撤掉（反正看operf看的出来+多线程累加不准） code multiple run 3 debug multiple run 1000x: 一种最快的tsk sz测不同th 4(half) 对比下之前单线程和现在多线程的结果：只快了一点点 operf看看 推测原因可能和缓存竞争有关系，operf一下单线程的 对比1th_1f和原先的单线程的operf结果，看时间占比，找原因 发现占比没有很大区别，区别应该是来自于对static数据的访问 初始化static数据比原先普通数据成员要慢 在25000上跑th和f的组合，看看结果现在的现象是： # 之前的单线程： compute 167,501us init_bfs 595us bfs 2,323us collect_risky_spine 33,821us # 1th_1f： get_cc 31,085us solve 213,093us # 4th_2f: get_cc 13,606us solve 153,839us # 8th_2f: get_cc 9,283us solve 139,048us # 32th_2f: get_cc 7,600us solve 183,930us 1th_1f比之前的单线程慢一点，可能慢很多8th_2f比1th_1f加速较少 下午 1 看25000 gap有多大现象：solve: 1th-&gt;4th，加速两倍，4th达峰值color: 1th-&gt;20th，始终在加速1th-20th 1f-3f最快的组合：决定color用32th，solve用4th [4th 2f] compute 4,660,916us get_cc 597,641us solve 4,063,274us [8th 1f] compute 4,695,444us get_cc 459,420us solve 4,236,022us [8th 2f] compute 4,692,330us get_cc 480,149us solve 4,212,180us [12th 1f] compute 4,622,508us get_cc 439,691us solve 4,182,815us [20th 1f] compute 4,678,752us get_cc 394,137us solve 4,284,613us - 从case2tree中获得启示，重新思考算法中 2 从case2tree中获得启示，重新思考算法中 想出了优化版的算法！耶！赶紧写！ 这告诉我：从复杂度角度思考算法优化（我是从现在的算法和可以达标的算法，它们访问的边数到底分别有多少） code above 3 debug 4 debug 晚上目标：operf，尽量优化呀！因为复杂度其实大概只是case2tree的两倍，所以应该可以400拿下 1 operf opt 2 operf opt 3 operf opt 4 operf opt好棒！是谁从4000us优化到250us我不说[旺柴]","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"c++静态数据成员和普通数据成员访问快慢测评","slug":"c-静态数据成员和普通数据成员访问快慢测评","date":"2023-04-17T09:42:40.000Z","updated":"2023-04-17T09:55:40.000Z","comments":true,"path":"2023/04/17/c-静态数据成员和普通数据成员访问快慢测评/","link":"","permalink":"http://example.com/2023/04/17/c-%E9%9D%99%E6%80%81%E6%95%B0%E6%8D%AE%E6%88%90%E5%91%98%E5%92%8C%E6%99%AE%E9%80%9A%E6%95%B0%E6%8D%AE%E6%88%90%E5%91%98%E8%AE%BF%E9%97%AE%E5%BF%AB%E6%85%A2%E6%B5%8B%E8%AF%84/","excerpt":"","text":"比较类的静态数据成员和普通数据成员哪个访问得快一点 代码顺序访问#include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;vector&gt; #include &lt;chrono&gt; using namespace std; typedef chrono::microseconds UnitType; chrono::_V2::system_clock::time_point t_start, t_end; UnitType d; #define TIMING_START t_start = chrono::system_clock::now(); #define TIMING_END(str) \\ t_end = chrono::system_clock::now(); \\ d = chrono::duration_cast&lt;UnitType&gt;(t_end - t_start); \\ cout &lt;&lt; str &lt;&lt; d.count() &lt;&lt; &quot; us&quot; &lt;&lt; endl; class A &#123; public: vector&lt;int&gt; nbrs; A(size_t sz) : nbrs(sz) &#123;&#125; void seq_access(int round, ostream &amp;absorb_stdout) &#123; int total = 0; for (int i = 0; i &lt; round; ++i) for (size_t j = 0, jed = nbrs.size(); j &lt; jed; ++j) total += nbrs[j]; absorb_stdout &lt;&lt; total; &#125; &#125;; class B &#123; public: static vector&lt;int&gt; nbrs; void seq_access(int round, ostream &amp;absorb_stdout) &#123; int total = 0; for (int i = 0; i &lt; round; ++i) for (size_t j = 0, jed = nbrs.size(); j &lt; jed; ++j) total += nbrs[j]; absorb_stdout &lt;&lt; total; &#125; &#125;; vector&lt;int&gt; B::nbrs; void compare_static_data_member(ostream &amp;absorb_stdout) &#123; const size_t sz = 100000000; int repeat_times = 30; B::nbrs.resize(sz); B b; A a(sz); TIMING_START a.seq_access(repeat_times, absorb_stdout); TIMING_END(&quot;[normal data member]&quot;) TIMING_START b.seq_access(repeat_times, absorb_stdout); TIMING_END(&quot;[static data member]&quot;) &#125; int main() &#123; ofstream absorb_stdout(&quot;tmp.txt&quot;); compare_static_data_member(absorb_stdout); return 0; &#125; 随机访问上述seq_access改成： void rand_access(int round, ostream &amp;absorb_stdout) &#123; int total = 0; for (int i = 0; i &lt; round; ++i) for (size_t j = 0, jed = nbrs.size(), pos, max_pos = jed - 1; j &lt; jed; ++j) &#123; pos = double(rand()) / RAND_MAX * max_pos; total += nbrs[pos]; &#125; absorb_stdout &lt;&lt; total; &#125; 结果顺序访问重复30次顺序访问，nbrs元素个数100000000不开O3：静态更快 [normal data member]10166058 us [static data member]8635176 us 开O3：普通更快 [normal data member]831936 us [static data member]893034 us 随机访问100000000次随机访问nbrs不开O3：普通更快 [normal data member]5354315 us [static data member]5803599 us 开O3：静态略快 [normal data member]3785677 us [static data member]3708722 us","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"概率分布","slug":"概率分布","date":"2023-04-16T12:33:14.000Z","updated":"2023-06-02T00:59:43.000Z","comments":true,"path":"2023/04/16/概率分布/","link":"","permalink":"http://example.com/2023/04/16/%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/","excerpt":"","text":"常见离散型概率分布二项分布 泊松分布 超几何分布 常见连续型概率分布正态分布 指数分布","categories":[{"name":"概统","slug":"概统","permalink":"http://example.com/categories/%E6%A6%82%E7%BB%9F/"}],"tags":[{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"}],"author":"zhiqiuyuan"},{"title":"数学期望","slug":"数学期望","date":"2023-04-16T12:09:20.000Z","updated":"2023-04-16T12:13:24.000Z","comments":true,"path":"2023/04/16/数学期望/","link":"","permalink":"http://example.com/2023/04/16/%E6%95%B0%E5%AD%A6%E6%9C%9F%E6%9C%9B/","excerpt":"","text":"含义： 离散型 连续型 常见分布的数学期望指数分布","categories":[{"name":"概统","slug":"概统","permalink":"http://example.com/categories/%E6%A6%82%E7%BB%9F/"}],"tags":[{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"}],"author":"zhiqiuyuan"},{"title":"假设检验","slug":"假设检验","date":"2023-04-16T08:44:25.000Z","updated":"2023-04-16T12:40:15.000Z","comments":true,"path":"2023/04/16/假设检验/","link":"","permalink":"http://example.com/2023/04/16/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/","excerpt":"","text":"概念例子： 这个“去判定”的命题，即 概念：","categories":[{"name":"概统","slug":"概统","permalink":"http://example.com/categories/%E6%A6%82%E7%BB%9F/"}],"tags":[{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"}],"author":"zhiqiuyuan"},{"title":"西瓜书 2.4 比较检验","slug":"西瓜书-2-4-比较检验","date":"2023-04-16T08:11:57.000Z","updated":"2023-06-02T00:30:48.000Z","comments":true,"path":"2023/04/16/西瓜书-2-4-比较检验/","link":"","permalink":"http://example.com/2023/04/16/%E8%A5%BF%E7%93%9C%E4%B9%A6-2-4-%E6%AF%94%E8%BE%83%E6%A3%80%E9%AA%8C/","excerpt":"","text":"2.4.1 假设检验 对于这个假设即需要： “e&gt;e0”的总概率&lt;a “e&gt;e0”的总概率即","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"16","slug":"daily-2023-4-16","date":"2023-04-16T06:49:58.000Z","updated":"2023-04-16T08:18:10.000Z","comments":true,"path":"2023/04/16/daily-2023-4-16/","link":"","permalink":"http://example.com/2023/04/16/daily-2023-4-16/","excerpt":"","text":"周六动物园+周六上午周日上午文野今日目标： 上午下午 1 （任性一下，学西瓜书） 西瓜书2.3 完成PR 2 西瓜书2.3 完成代价敏感 3 西瓜书2.4 完成代价敏感 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"西瓜书 2.2 评估方法 2.3 性能度量","slug":"西瓜书-第2章","date":"2023-04-15T03:11:43.000Z","updated":"2023-04-16T08:12:37.000Z","comments":true,"path":"2023/04/15/西瓜书-第2章/","link":"","permalink":"http://example.com/2023/04/15/%E8%A5%BF%E7%93%9C%E4%B9%A6-%E7%AC%AC2%E7%AB%A0/","excerpt":"","text":"2.2对测试样本的假设 一个数据集得到训练集和测试集留出法 交叉验证 自助法有放回抽样m次，得到含m个样本的集合，作为训练集（这个训练集中有重复的样本，但是我们不去重） 调参 验证集验证集来自训练数据 即给定数据集D，其被划分为：训练数据，测试数据 其中训练数据进一步划分为：训练集，验证集 最终模型 2.3 性能度量（主要分类问题） 错误率 精度 混淆矩阵 查全率recall 查准率precision 查全：正例有多少被查出来了 查准：查出来的正例有多少是真正的正例 PR曲线 F1度量 b如何度量影响的，看加权调和平均式更明显 多个混淆矩阵 宏 微 ROC 这个“依次把每个样例划分为正例”其实不太准确，因为比如两个样例的预测输出相同的话，我们依次按样例的预测输出来作为阈值的话，这样一下会把两个样例划分到某一类中， ROC曲线绘制举例： 分类阈值变动一次，可能会新增多个真正例+假正例，这是因为可能有多个样例的预测输出是一样的 AUC 证明lrank是ROC曲线之上的面积： ROC曲线之上的面积：ROC曲线和y轴围成的面积 接下来我们解析下为啥这个式子就是ROC曲线和y轴围成的面积： 代价敏感错误率 代价曲线 代价敏感性能度量 代价曲线 为什么取下界之后，围成的自积即为在所有条件下学习器的期望总体代价？ 取下界实际含义是？ 不同的线段对应不同的分类结果，同一条线段上不同点对应某分类结果下不同的cost时的代价情况 取下界：相同正例概率代价的情况下（其对应多条线段上的多个点，这些点对应的分类结果（即式2.24和2.25中的p）和cost可能都不相同），归一化代价取最小值 期望总体代价： 各种cost分布下，这个学习器的平均总体代价 还是没懂，这里是对cost分布做了什么假设吗？","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"有向无环图 枚举st路径 st路径计数","slug":"有向无环图-枚举st路径-st路径计数","date":"2023-04-14T01:45:26.000Z","updated":"2023-04-14T01:59:19.000Z","comments":true,"path":"2023/04/14/有向无环图-枚举st路径-st路径计数/","link":"","permalink":"http://example.com/2023/04/14/%E6%9C%89%E5%90%91%E6%97%A0%E7%8E%AF%E5%9B%BE-%E6%9E%9A%E4%B8%BEst%E8%B7%AF%E5%BE%84-st%E8%B7%AF%E5%BE%84%E8%AE%A1%E6%95%B0/","excerpt":"","text":"https://www.geeksforgeeks.org/number-of-paths-from-source-to-destination-in-a-directed-acyclic-graph/ 拓扑排序+动态规划，好厉害 Let f(u) be the number of ways one can travel from node u to destination vertex. Hence, f(source) is required answer. As f(destination) &#x3D; 1 here so there is just one path from destination to itself. One can observe, f(u) depends on nothing other than the f values of all the nodes which are possible to travel from u. It makes sense because the number of different paths from u to the destination is the sum of all different paths from v1, v2, v3… v-n to destination vertex where v1 to v-n are all the vertices that have a direct path from vertex u. This approach, however, is too slow to be useful. Each function call branches out into further calls, and that branches into further calls, until each and every path is explored once. The problem with this approach is the calculation of f(u) again and again each time the function is called with argument u. Since this problem exhibits both overlapping subproblems and optimal substructure, dynamic programming is applicable here. In order to evaluate f(u) for each u just once, evaluate f(v) for all v that can be visited from u before evaluating f(u). This condition is satisfied by reverse topological sorted order of the nodes of the graph. #include &lt;bits/stdc++.h&gt; using namespace std; #define MAXN 1000005 // to make graph vector&lt;int&gt; v[MAXN]; // function to add edge in graph void add_edge(int a, int b, int fre[]) &#123; // there is path from a to b. v[a].push_back(b); fre[b]++; &#125; // function to make topological sorting vector&lt;int&gt; topological_sorting(int fre[], int n) &#123; queue&lt;int&gt; q; // insert all vertices which // don&#39;t have any parent. for (int i = 0; i &lt; n; i++) if (!fre[i]) q.push(i); vector&lt;int&gt; l; // using kahn&#39;s algorithm // for topological sorting while (!q.empty()) &#123; int u = q.front(); q.pop(); // insert front element of queue to vector l.push_back(u); // go through all it&#39;s childs for (int i = 0; i &lt; v[u].size(); i++) &#123; fre[v[u][i]]--; // whenever the frequency is zero then add // this vertex to queue. if (!fre[v[u][i]]) q.push(v[u][i]); &#125; &#125; return l; &#125; // Function that returns the number of paths int numberofPaths(int source, int destination, int n, int fre[]) &#123; // make topological sorting vector&lt;int&gt; s = topological_sorting(fre, n); // to store required answer. int dp[n] = &#123; 0 &#125;; // answer from destination // to destination is 1. dp[destination] = 1; // traverse in reverse order for (int i = s.size() - 1; i &gt;= 0; i--) &#123; for (int j = 0; j &lt; v[s[i]].size(); j++) &#123; dp[s[i]] += dp[v[s[i]][j]]; &#125; &#125; return dp; &#125; // Driver code int main() &#123; // here vertices are numbered from 0 to n-1. int n = 5; int source = 0, destination = 4; // to count number of vertex which don&#39;t // have any parents. int fre[n] = &#123; 0 &#125;; // to add all edges of graph add_edge(0, 1, fre); add_edge(0, 2, fre); add_edge(0, 3, fre); add_edge(0, 4, fre); add_edge(2, 3, fre); add_edge(3, 4, fre); // Function that returns the number of paths cout &lt;&lt; numberofPaths(source, destination, n, fre); &#125;","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-4-14","date":"2023-04-14T01:22:37.000Z","updated":"2023-04-14T01:23:53.000Z","comments":true,"path":"2023/04/14/daily-2023-4-14/","link":"","permalink":"http://example.com/2023/04/14/daily-2023-4-14/","excerpt":"","text":"还有两周时间，现在现状是非普适的单机算法在测试数据上已经达标需要开发：普适单机，非普适多机，普适多机今日目标：希望今天可以写完普适单机 上午 1 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"西瓜书 第1章","slug":"西瓜书-第1章","date":"2023-04-13T10:21:36.000Z","updated":"2023-04-15T03:33:11.000Z","comments":true,"path":"2023/04/13/西瓜书-第1章/","link":"","permalink":"http://example.com/2023/04/13/%E8%A5%BF%E7%93%9C%E4%B9%A6-%E7%AC%AC1%E7%AB%A0/","excerpt":"","text":"1.2数据集 1.3学得的模型也称假设 泛化能力 对样本空间和样本的假设 偏好 1.4模型在训练集之外的所有样本上的误差 NFL定理 但是事实上我们通常并不总是关心训练集外的“所有”样本，而是一部分","categories":[{"name":"ML","slug":"ML","permalink":"http://example.com/categories/ML/"}],"tags":[{"name":"ML","slug":"ML","permalink":"http://example.com/tags/ML/"}],"author":"zhiqiuyuan"},{"title":"13","slug":"daily-2023-4-13","date":"2023-04-13T01:24:39.000Z","updated":"2023-04-13T08:41:23.000Z","comments":true,"path":"2023/04/13/daily-2023-4-13/","link":"","permalink":"http://example.com/2023/04/13/daily-2023-4-13/","excerpt":"","text":"决定重新回归日报（之前开始日报是为了让自己不是全天一直摆烂，然后又暂停日报是因为自己已经进入不写日报也不摆烂的状态，现在重启是因为现在虽然进入这种状态但是有时候还是会忘记自己一天都干了啥）今日目标：生信paper*2；优化checkanswer（最好到合并indexfree） 上午 1 read nature paper 果然从零基础开始啃是艰难的 第一篇看了个摘要+框架，然后发现可能第二篇才是正餐 加油！相比起数据库，我显然对这个方向更感兴趣！（这是从别人分享给我资料后，我的兴趣程度观察到的） 2 记录hw case2语义和更新算法warning 日记关于换方向和兴趣 摘要 3 继续看论文 下午看论文一会设计优化general算法生信学习 晚上讲座","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"vector<unsigned>初始化对比","slug":"vector-unsigned-初始化对比","date":"2023-04-12T02:50:08.000Z","updated":"2023-04-12T03:25:01.000Z","comments":true,"path":"2023/04/12/vector-unsigned-初始化对比/","link":"","permalink":"http://example.com/2023/04/12/vector-unsigned-%E5%88%9D%E5%A7%8B%E5%8C%96%E5%AF%B9%E6%AF%94/","excerpt":"","text":"对比vector(sz)vector(sz,0)vector(sz,-1u)vector(sz)然后arr[i]&#x3D;i的时间 结果：performance是跑20次的平均 -O3编译：有initializer的两种差不多，另外两种差不多no initializer [ave performance] 1916320 us init to all 0 [ave performance] 1020553 us init to all -1 [ave performance] 838372 us init to pos [ave performance] 1748269 us 无O3：前三种差不多，最后一种时间大概是前三种的1.5倍no initializer [ave performance] 3929123 us init to all 0 [ave performance] 4024427 us init to all -1 [ave performance] 3152277 us init to pos [ave performance] 6734609 us 代码#include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;vector&gt; #include &lt;string.h&gt; #include &lt;chrono&gt; using namespace std; typedef chrono::microseconds UnitType; chrono::_V2::system_clock::time_point t_start, t_end; UnitType d; #define TIMING_START t_start = chrono::system_clock::now(); #define TIMING_END(str) \\ t_end = chrono::system_clock::now(); \\ d = chrono::duration_cast&lt;UnitType&gt;(t_end - t_start); \\ cout &lt;&lt; str &lt;&lt; d.count() &lt;&lt; &quot; us&quot; &lt;&lt; endl; void moving_average(double &amp;old_ave, double new_val, int &amp;cnt) &#123; ++cnt; double tmp1 = old_ave * ((double(cnt - 1)) / cnt); double tmp2 = new_val / cnt; old_ave = tmp1 + tmp2; &#125; #define BENCHMARK_INIT(str, ...) \\ cout &lt;&lt; str &lt;&lt; endl; \\ ave = 0; \\ cnt = 0; \\ for (int i = 0; i &lt; repeat_times; ++i) \\ &#123; \\ std::cout &lt;&lt; &quot;rnd &quot; &lt;&lt; i; \\ TIMING_START \\ __VA_ARGS__ \\ TIMING_END(&quot; &quot;) \\ absorb_stdout &lt;&lt; arr[rand() % sz] &lt;&lt; endl; \\ moving_average(ave, d.count(), cnt); \\ &#125; \\ cout &lt;&lt; &quot;[ave performance] &quot; &lt;&lt; (int64_t)ave &lt;&lt; &quot; us&quot; &lt;&lt; endl; #define INIT_TO_POS \\ vector&lt;unsigned&gt; arr(sz); \\ for (size_t i = 0; i &lt; sz; ++i) \\ arr[i] = i; void compare_init_all_zero_and_other(ostream &amp;absorb_stdout) &#123; size_t sz = 1000000000; // 10^9 int repeat_times = 20; double ave = 0; int cnt = 0; BENCHMARK_INIT(&quot;no initializer&quot;, vector&lt;unsigned&gt; arr(sz);) BENCHMARK_INIT(&quot;\\n\\ninit to all 0&quot;, vector&lt;unsigned&gt; arr(sz, 0);) BENCHMARK_INIT(&quot;\\n\\ninit to all -1&quot;, vector&lt;unsigned&gt; arr(sz, -1u);) BENCHMARK_INIT(&quot;\\n\\ninit to pos&quot;, INIT_TO_POS) &#125; int main() &#123; ofstream absorb_stdout(&quot;tmp.txt&quot;); compare_init_all_zero_and_other(absorb_stdout); return 0; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"vector<bool>不是一个好选择","slug":"vector-bool-不是一个好选择","date":"2023-04-10T07:05:25.000Z","updated":"2023-04-11T04:34:53.000Z","comments":true,"path":"2023/04/10/vector-bool-不是一个好选择/","link":"","permalink":"http://example.com/2023/04/10/vector-bool-%E4%B8%8D%E6%98%AF%E4%B8%80%E4%B8%AA%E5%A5%BD%E9%80%89%E6%8B%A9/","excerpt":"","text":"实现bool是一个字节但是vector实际上是用一个比特来表示一个bool 因此vector慢（实际测试中：访问vector x次，访问vector 2*x次，但是访问vector的时间却是访问vector的7倍） 虽然O3优化可以加速，但是开O3优化后可能出问题且for(auto&amp;v:vector)等对于vector元素的引用会出现问题 不如bitset（编译期知道长度，定长，一个比特表示一个bool）或bool*（变量长度，定长，一个字节表示一个数组）或vector 性能对比：vector, vector, bool*perfomance部分是20次的平均，初始化bool*数组用的是原始的for loop 结果：bool*最好无-O3编译bool*最快vector初始化比bool*快vector慢麻了 vector&lt;bool&gt; [alloc_and_init] 38624 us [ave performance] 33919797 us vector&lt;char&gt; [alloc_and_init] 327476 us [ave performance] 5525479 us bool* [alloc_and_init] 2190725 us [ave performance] 3875693 us -O3编译vector和bool*性能类似，vector初始化比bool*慢vector慢麻了 vector&lt;bool&gt; [alloc_and_init] 54526 us [ave performance] 1864292 us vector&lt;char&gt; [alloc_and_init] 406340 us [ave performance] 741159 us bool* [alloc_and_init] 149163 us [ave performance] 769090 us 代码编译 g++ -std=c++17 -O3 -g -Wall -rdynamic main.cpp -o main 代码 #include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;vector&gt; #include &lt;chrono&gt; using namespace std; typedef chrono::microseconds UnitType; chrono::_V2::system_clock::time_point t_start, t_end; UnitType d; #define TIMING_START t_start = chrono::system_clock::now(); #define TIMING_END(str) \\ t_end = chrono::system_clock::now(); \\ d = chrono::duration_cast&lt;UnitType&gt;(t_end - t_start); \\ cout &lt;&lt; str &lt;&lt; d.count() &lt;&lt; &quot; us&quot; &lt;&lt; endl; void moving_average(double &amp;old_ave, double new_val, int &amp;cnt) &#123; ++cnt; double tmp1 = old_ave * ((double(cnt - 1)) / cnt); double tmp2 = new_val / cnt; old_ave = tmp1 + tmp2; &#125; // vector&lt;bool&gt;, vector&lt;char&gt;, bool* template &lt;typename Arr&gt; void benchmark_bool_array(Arr arr, size_t sz, int repeat_times, ostream &amp;absorb_stdout) &#123; double ave = 0; int cnt = 0; for (int i = 0; i &lt; repeat_times; ++i) &#123; std::cout &lt;&lt; &quot;rnd &quot; &lt;&lt; i; TIMING_START for (size_t j = 0; j &lt; sz; ++j) &#123; if (j % 2) arr[j] = 1; else arr[j] = 0; &#125; bool or_total = 0; for (size_t j = 0; j &lt; sz; ++j) &#123; if (arr[j]) or_total = 1; &#125; TIMING_END(&quot; &quot;) absorb_stdout &lt;&lt; or_total; moving_average(ave, d.count(), cnt); &#125; cout &lt;&lt; &quot;[ave performance] &quot; &lt;&lt; (int64_t)ave &lt;&lt; &quot; us&quot; &lt;&lt; endl; &#125; void compare_bool_array(ostream &amp;absorb_stdout) &#123; size_t sz = 1000000000; // 10^9 int repeat_times = 20; cout &lt;&lt; &quot;vector&lt;bool&gt;&quot; &lt;&lt; endl; &#123; TIMING_START vector&lt;bool&gt; arr(sz, 0); TIMING_END(&quot;[alloc_and_init] &quot;) benchmark_bool_array&lt;vector&lt;bool&gt;&gt;(std::move(arr), sz, repeat_times, absorb_stdout); &#125; cout &lt;&lt; &quot;\\n\\nvector&lt;char&gt;&quot; &lt;&lt; endl; &#123; TIMING_START vector&lt;char&gt; arr(sz, 0); TIMING_END(&quot;[alloc_and_init] &quot;) benchmark_bool_array&lt;vector&lt;char&gt;&gt;(std::move(arr), sz, repeat_times, absorb_stdout); &#125; cout &lt;&lt; &quot;\\n\\nbool*&quot; &lt;&lt; endl; &#123; TIMING_START bool *arr = new bool[sz]; for (size_t j = 0; j &lt; sz; ++j) arr[j] = 0; TIMING_END(&quot;[alloc_and_init] &quot;) benchmark_bool_array&lt;bool *&gt;(arr, sz, repeat_times, absorb_stdout); delete[] arr; &#125; &#125; int main() &#123; ofstream absorb_stdout(&quot;tmp.txt&quot;); compare_bool_array(absorb_stdout); return 0; &#125; bool*初始化对比for loop和memset对比perfomance部分是20次的平均 结果：memset更好没有-O3差异显著 [alloc] 6 us for loop [ave performance] 1847234 us memset [ave performance] 114449 us -O3仍有差异 [alloc] 5 us for loop [ave performance] 114162 us memset [ave performance] 150901 us 代码工具函数等和上面的测评一样 void compare_bool_star_init() &#123; size_t sz = 1000000000; // 10^9 int repeat_times = 20; TIMING_START bool *arr = new bool[sz]; TIMING_END(&quot;[alloc] &quot;) cout &lt;&lt; &quot;for loop&quot; &lt;&lt; endl; double ave = 0; int cnt = 0; for (int i = 0; i &lt; repeat_times; ++i) &#123; std::cout &lt;&lt; &quot;rnd &quot; &lt;&lt; i; TIMING_START for (size_t j = 0; j &lt; sz; ++j) arr[j] = 0; TIMING_END(&quot; &quot;) moving_average(ave, d.count(), cnt); &#125; cout &lt;&lt; &quot;[ave performance] &quot; &lt;&lt; (int64_t)ave &lt;&lt; &quot; us&quot; &lt;&lt; endl; cout &lt;&lt; &quot;\\n\\nmemset&quot; &lt;&lt; endl; ave = 0; cnt = 0; for (int i = 0; i &lt; repeat_times; ++i) &#123; std::cout &lt;&lt; &quot;rnd &quot; &lt;&lt; i; TIMING_START memset(arr, 0, sizeof(bool) * sz); TIMING_END(&quot; &quot;) moving_average(ave, d.count(), cnt); &#125; cout &lt;&lt; &quot;[ave performance] &quot; &lt;&lt; (int64_t)ave &lt;&lt; &quot; us&quot; &lt;&lt; endl; delete[] arr; &#125; int main() &#123; compare_bool_star_init(); return 0; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"7","slug":"daily-2023-4-7","date":"2023-04-06T23:53:49.000Z","updated":"2023-04-06T23:56:24.000Z","comments":true,"path":"2023/04/07/daily-2023-4-7/","link":"","permalink":"http://example.com/2023/04/07/daily-2023-4-7/","excerpt":"","text":"今日目标：验证case2bctree的正确性；图加载限制仅加载某些边类型，然后operf+massif优化 上午下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"6","slug":"daily-2023-4-6","date":"2023-04-06T00:15:24.000Z","updated":"2023-04-06T00:16:23.000Z","comments":true,"path":"2023/04/06/daily-2023-4-6/","link":"","permalink":"http://example.com/2023/04/06/daily-2023-4-6/","excerpt":"","text":"昨天思考完成新的hw算法并开始开发到编码部分只剩下图加载今日目标：上午完成图加载开发和调试；下午在1000x上operf+massif优化 上午下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"4","slug":"daily-2023-4-4","date":"2023-04-04T07:19:31.000Z","updated":"2023-04-04T07:36:54.000Z","comments":true,"path":"2023/04/04/daily-2023-4-4/","link":"","permalink":"http://example.com/2023/04/04/daily-2023-4-4/","excerpt":"","text":"今日目标： 上午 hw例会 下午 1 gen case2 14 gen case1 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpi教程目录","slug":"mpi教程目录","date":"2023-04-03T02:40:55.000Z","updated":"2023-04-23T07:05:08.000Z","comments":true,"path":"2023/04/03/mpi教程目录/","link":"","permalink":"http://example.com/2023/04/03/mpi%E6%95%99%E7%A8%8B%E7%9B%AE%E5%BD%95/","excerpt":"","text":"主要参考：基础教程：https://mpitutorial.com/tutorials进阶教程：https://enccs.github.io/intermediate-mpi 基础教程安装运行： open mpi安装 run mpi program over a cluster 在集群上跑mpi程序 mpi overall 这篇必看，摘自man mpirun mpirun point-to-point： mpi block send and receive mpi dynamic receive (dynamic means buffer size) mpi Point-to-Point Communication example: random walk collective： MPI Broadcast and Collective Communication MPI Scatter, Gather, and Allgather collective call example: Performing Parallel Rank with MPI MPI Reduce and Allreduce hybrid MPI （MPI+多线程） MPI + openMP openMPI std::thread 杂项 mpi时间测量 MPI_Wtime 工具 openmpi提供的程序性能分析工具和调试工具","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"openMPI std::thread multithreaad","slug":"openMPI-std-thread-multithreaad","date":"2023-04-03T01:20:57.000Z","updated":"2023-04-23T06:56:36.000Z","comments":true,"path":"2023/04/03/openMPI-std-thread-multithreaad/","link":"","permalink":"http://example.com/2023/04/03/openMPI-std-thread-multithreaad/","excerpt":"","text":"来自chatgpt 这个是低阶版本的，高阶的是openMPI+openMP，见MPI + openMP openMPI和std::thread同时使用有什么要求当在MPI应用程序中使用std::thread时，只有主线程可以调用MPI接口。 在其他线程中调用MPI接口会导致未定义的行为，可能会导致程序崩溃或者产生不可预测的结果。因此，如果需要在其他线程中进行与MPI相关的操作，应该使用线程间通信机制将任务委托给主线程进行处理。 注意process bind（来自man mpirun和实验）Please note that mpirun automatically binds processes as of the start of the v1.8 series. Three binding patterns are used in the absence of any further directives: Bind to core: when the number of processes is &lt;&#x3D; 2 Bind to socket: when the number of processes is &gt; 2 Bind to none: when oversubscribed If your application uses threads, then you probably want to ensure that you are either not bound at all (by specifying –bind-to none), or bound to multiple cores using an appropriate binding level or specific number of processing elements per application process. （即每个process多线程的时候，要么指定--bind-to none，这样会not bound (or bound to all available processors；要么指定每个process分配多少处理器核心，比如--map-by node:PE=n是每个节点一个process、每个process bind to n个处理器核心） 相关option运行指定： –bind-to Bind processes to the specified object, defaults to core. Supported options include slot, hwthread, core, l1cache, l2cache, l3cache, socket, numa, board, cpu-list, and none. –map-by Map process to the specified object, defaults to socket. Supported options include slot, hwthread, core, L1cache, L2cache, L3cache, socket, numa, board, node, sequential, distance, and ppr. Any object can include modifiers by adding a : and any combination of PE&#x3D;n (bind n processing elements to each proc), SPAN (load balance the processes across the allocation), OVER‐ SUBSCRIBE (allow more processes on a node than processing elements), and NOOVERSUBSCRIBE. This includes PPR, where the pattern would be terminated by another colon to separate it from the modifiers. 比如 –map-by node:PE&#x3D;n load balance the processes across the available nodes, and bind each process to 32 processing elements. –use-hwthread-cpus ​ then processing element is not physical core, but hardware thread 帮助监控： -report-bindings, –report-bindingsReport any bindings for launched processes. 使用std::thread和openMPI以及读写锁的例子由于只在主线程中调用MPI接口，因此使用MPI_THREAD_FUNNELED层次 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;shared_mutex&gt; #include &lt;mpi.h&gt; std::shared_mutex rw_mutex; std::mutex cout_mutex; // 只是用于保护输出不interleaf的 void reader_func(int rank, int thread_id) &#123; std::shared_lock&lt;std::shared_mutex&gt; lock(rw_mutex); std::lock_guard&lt;std::mutex&gt; cout_lock(cout_mutex); std::cout &lt;&lt; &quot;Reader &quot; &lt;&lt; thread_id &lt;&lt; &quot; in process &quot; &lt;&lt; rank &lt;&lt; &quot; starts reading&quot; &lt;&lt; std::endl; // Reading... std::cout &lt;&lt; &quot;Reader &quot; &lt;&lt; thread_id &lt;&lt; &quot; in process &quot; &lt;&lt; rank &lt;&lt; &quot; finishes reading&quot; &lt;&lt; std::endl; &#125; void writer_func(int rank, int thread_id) &#123; std::unique_lock&lt;std::shared_mutex&gt; lock(rw_mutex); std::lock_guard&lt;std::mutex&gt; cout_lock(cout_mutex); std::cout &lt;&lt; &quot;Writer &quot; &lt;&lt; thread_id &lt;&lt; &quot; in process &quot; &lt;&lt; rank &lt;&lt; &quot; starts writing&quot; &lt;&lt; std::endl; // Writing... std::cout &lt;&lt; &quot;Writer &quot; &lt;&lt; thread_id &lt;&lt; &quot; in process &quot; &lt;&lt; rank &lt;&lt; &quot; finishes writing&quot; &lt;&lt; std::endl; &#125; int main(int argc, char **argv) &#123; int provided_level; MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_FUNNELED, &amp;provided_level); if (provided_level &lt; MPI_THREAD_FUNNELED) &#123; std::cerr &lt;&lt; &quot;MPI implementation does not support MPI_THREAD_FUNNELED.&quot; &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); &#125; int rank, size; MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); MPI_Comm_size(MPI_COMM_WORLD, &amp;size); // Create threads const int num_threads = 4; std::thread threads[num_threads]; for (int i = 0; i &lt; num_threads; i++) &#123; if (i % 2 == 0) &#123; threads[i] = std::thread(reader_func, rank, i); &#125; else &#123; threads[i] = std::thread(writer_func, rank, i); &#125; &#125; // Wait for threads to finish for (int i = 0; i &lt; num_threads; i++) &#123; threads[i].join(); &#125; MPI_Finalize(); return 0; &#125; 在这个例子中，每个进程启动4个线程（加上主线程的话是5个） 我们使用了一个std::shared_mutex变量rw_mutex，它用于实现读写锁。std::unique_lock和std::shared_lock用于在写入和读取时获取锁。在每个主线程中，我们创建了4个线程，其中2个是读者线程，另外2个是写者线程。 读者线程调用函数reader_func()，它获取了一个共享锁，然后打印一条消息，表示正在读取。写者线程调用函数writer_func()，它获取了一个独占锁，然后打印一条消息，表示正在写入。在实际的应用程序中，读者线程和写者线程将执行实际的读取和写入操作。 在输出消息时，我们使用了一个std::mutex变量cout_mutex，它用于在多个线程之间保护输出操作。这是必要的，因为std::cout不是线程安全的 编译运行编译： mpicxx -std=c++17 -g -Wall -pthread example.cpp -o example 运行：-n 3指明要3个进程 mpirun -n 3 ./example 输出：可以看到有三个进程 Reader 0 in process 1 starts reading Reader 0 in process 1 finishes reading Reader 2 in process 1 starts reading Reader 2 in process 1 finishes reading Writer 1 in process 1 starts writing Writer 1 in process 1 finishes writing Writer 3 in process 1 starts writing Writer 3 in process 1 finishes writing Reader 0 in process 2 starts reading Reader 0 in process 2 finishes reading Writer 1 in process 2 starts writing Writer 1 in process 2 finishes writing Reader 0 in process 0 starts reading Reader 0 in process 0 finishes reading Reader 2 in process 0 starts reading Reader 2 in process 0 finishes reading Reader 2 in process 2 starts reading Reader 2 in process 2 finishes reading Writer 3 in process 2 starts writing Writer 3 in process 2 finishes writing Writer 1 in process 0 starts writing Writer 1 in process 0 finishes writing Writer 3 in process 0 starts writing Writer 3 in process 0 finishes writing 这是一个不好的行为，我们最好不这么干 MPI库会保证这一点：MPI_THREAD_FUNNELED级别只有主线程可以调用MPI函数比如：这个例子中每个线程都会调用MPI_Barrier()函数，但是只有由主线程调用的这个MPI_Barrier()函数实际上会调用MPI库函数。MPI库会自动判断当前线程是否是主线程，如果不是，则会阻塞该线程，直到主线程完成相应的MPI库函数调用。 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mpi.h&gt; void worker_function(int thread_id, int rank) &#123; std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; thread_id &lt;&lt; &quot; running on rank &quot; &lt;&lt; rank &lt;&lt; std::endl; MPI_Barrier(MPI_COMM_WORLD); std::cout &lt;&lt; &quot;Thread &quot; &lt;&lt; thread_id &lt;&lt; &quot; finished on rank &quot; &lt;&lt; rank &lt;&lt; std::endl; &#125; int main(int argc, char **argv) &#123; int num_threads = 4; int provided_level; MPI_Init_thread(&amp;argc, &amp;argv, MPI_THREAD_FUNNELED, &amp;provided_level); if (provided_level &lt; MPI_THREAD_FUNNELED) &#123; std::cerr &lt;&lt; &quot;MPI implementation does not support MPI_THREAD_FUNNELED.&quot; &lt;&lt; std::endl; MPI_Abort(MPI_COMM_WORLD, 1); &#125; int rank, size; MPI_Comm_rank(MPI_COMM_WORLD, &amp;rank); MPI_Comm_size(MPI_COMM_WORLD, &amp;size); std::vector&lt;std::thread&gt; threads; for (int i = 0; i &lt; num_threads; i++) &#123; threads.emplace_back(worker_function, i, rank); &#125; for (int i = 0; i &lt; num_threads; i++) &#123; threads[i].join(); &#125; MPI_Finalize(); return 0; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"3","slug":"daily-2023-4-3","date":"2023-04-03T00:43:15.000Z","updated":"2023-04-04T01:38:28.000Z","comments":true,"path":"2023/04/03/daily-2023-4-3/","link":"","permalink":"http://example.com/2023/04/03/daily-2023-4-3/","excerpt":"","text":"今日目标：希望学完mpi multithread，并且设计好多机算法（呜，总是完成不了每日flag的话会影响心情的）艹问了gpt之后发现可以一起用std::thread的，那么不用学openmp了 上午下午 1 tsk size均分，测试各种数量线程的时间性能(希望了解为啥没有scale up的原因，以及tsksz是不是可能的原因) 晚上下午晚上摆烂了（因为突然通知明天hw开会，然后我和上次相比完全没有进展+目前啥都没达标+初次汇报ppt有点担心，然后就摆烂了呜呜呜）看完呼啸山庄（剧情up，描写up！虽然景物描写有些我没有看进去，但是对于人物的描写（语言，动作，神态，外貌）一点也没落下，寥寥数笔看见人物在眼前）开始看文豪野犬","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"MPI multi thread","slug":"MPI-multi-thread","date":"2023-04-02T11:19:02.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/02/MPI-multi-thread/","link":"","permalink":"http://example.com/2023/04/02/MPI-multi-thread/","excerpt":"","text":"教程：https://enccs.github.io/intermediate-mpi/mpi-and-threads-pt1/# 教程配套代码：https://github.com/ENCCS/intermediate-mpi/tree/master/content/code Comparing pure MPI（一个rank一个线程） vs hybrid MPI-threading（一个rank多个线程） solutions. MPI ranks are shown in red boxes. Total memory usage and message cost tends to be lower with hybrid, because threads can share the same memory. However, realizing those benefits can lead to further work to reduce contention and eliminate race conditions. MPI support for threadingSince version 2.0, MPI can be initialized in up to four different ways. The former approach using MPI_Init still works, but applications that wish to use threading should use MPI_Init_thread. int MPI_Init_thread(int *argc, char ***argv, int required, int *provided) The argc and argv may be NULL (and generally should be). required describes the level of threading support that is requested, and the value returned in *provided describes the level that the MPI runtime was able to provide. If this is not the level required, the program should inform the user and either use threading only at the level provided, or MPI_Finalize and e.g. exit(). The following threading levels are generally supported: MPI_THREAD_SINGLE - rank is not allowed to use threads, which is basically equivalent to calling MPI_Init. With MPI_THREAD_SINGLE, the rank may use MPI freely and will not use threads. MPI_THREAD_FUNNELED - rank can be multi-threaded but only the main thread may call MPI functions. Ideal for fork-join parallelism such as used in #pragma omp parallel, where all MPI calls are outside the OpenMP regions. MPI_THREAD_SERIALIZED - rank can be multi-threaded but only one thread at a time may call MPI functions. The rank must ensure that MPI is used in a thread-safe way. One approach is to ensure that MPI usage is mutually excluded by all the threads, eg. with a mutex. *With MPI_THREAD_SERIALIZED, the rank can use MPI from any thread so long as it ensures the threads synchronize such that no thread calls MPI while another thread is doing so MPI_THREAD_MULTIPLE - rank can be multi-threaded and any thread may call MPI functions. The MPI library ensures that this access is safe across threads. Note that this makes all MPI operations less efficient, even if only one thread makes MPI calls, so should be used only where necessary. With MPI_THREAD_MULTIPLE, the rank can use MPI from any thread. The MPI library ensures the necessary synchronization Querying the MPI runtimethreading levelWhen writing a library, sometimes MPI will be initialized outside your code. If you wish to use threading, you have to honor the requirements established at the time MPI was initialized (or give an error). This can be done with MPI_Query_thread. int MPI_Query_thread(int *provided) The value returned in *provided describes the level that the MPI runtime is providing. If this is not the level required, the library should inform the user and either use threading only at the level provided, or return an error to its caller. It is possible to influence the threading support available from some MPI implementations with environment variables, so it can be wise to use such a method even if your code is managing the call to MPI_Init_thread. main threadSimilarly, MPI regards the thread that called MPI_Init_thread as the main thread for the purpose of MPI_THREAD_FUNNELED. If your code needs to identify that thread (eg. to ensure that calls to your library happen from that thread, so you use MPI), then you need to call MPI_Is_thread_main. int MPI_Is_thread_main(int *flag) A boolean value is returned in *flag to indicate whether the thread that called MPI_Is_thread_main is the main thread, ie. the one that called MPI_Init_thread. code examplecode：https://github.com/ENCCS/intermediate-mpi/tree/master/content/code/day-4/00_threading-query Try to compile with: mpicc -g -Wall -fopenmp -std=c11 threading-query.c -o threading-query When you have the code compiling, try to run with: mpiexec -np 2 ./threading-query code examplecode: https://github.com/ENCCS/intermediate-mpi/tree/master/content/code/day-4/10_integrate-pi Try to compile with: mpicc -g -Wall -fopenmp -std=c11 pi-integration.c -o pi-integration try to run with: export OMP_NUM_THREADS=2 mpiexec -np 2 ./pi-integration 10000000","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"open mpi安装","slug":"open-mpi安装","date":"2023-04-02T08:14:15.000Z","updated":"2023-04-23T01:16:59.000Z","comments":true,"path":"2023/04/02/open-mpi安装/","link":"","permalink":"http://example.com/2023/04/02/open-mpi%E5%AE%89%E8%A3%85/","excerpt":"","text":"install on linuxhttps://sites.google.com/site/rangsiman1993/comp-env/program-install/install-openmpibrief: download and buildhttps://edu.itp.phys.ethz.ch/hs12/programming_techniques/openmpi.pdf The following instructions will help you installing OpenMPI on your machine. It takes about 5-10min. Create a temporary directory for compiling OpenMPI. You can do this in a terminal by typingmkdir $HOME&#x2F;built&#x2F;src Download openmpi-4.1.5.tar.bz2 from http://www.open-mpi.org Move the openmpi-4.1.5.tar.bz2 to the directory just created:mv $HOME&#x2F;Downloads&#x2F;openmpi-4.1.5.tar.bz2 $HOME&#x2F;built&#x2F;src&#x2F; Change to the directory and extract the package usingcd $HOME&#x2F;built&#x2F;srctar -jxf openmpi-4.1.5.tar.bz2如果是.tar.gz的话tar -zxvf openmpi-4.1.5.tar.gz Go into the source directorycd openmpi-4.1.5 Configure, compile and install by executing the following commands.&#x2F;configure –prefix&#x3D;$HOME&#x2F;local&#x2F;openmpi-4.1.5make all -j &amp;&amp; make installThis will install OpenMPI in your home directory in the $HOME&#x2F;local&#x2F;openmpi-4.1.5&#x2F; Remove the temporary directories:rm $HOME&#x2F;built&#x2F;src&#x2F;openmpi-4.1.5.tar.bz2rm -r $HOME&#x2F;built&#x2F;src&#x2F;openmpi-4.1.5 To use MPI you will have to adapt your PATH and LD_LIBRARY_PATH environment variable:echo “export PATH&#x3D;$PATH:$HOME&#x2F;local&#x2F;openmpi-4.1.5&#x2F;bin” &gt;&gt; $HOME&#x2F;.bashrcecho “export LD_LIBRARY_PATH&#x3D;$LD_LIBRARY_PATH:$HOME&#x2F;local&#x2F;openmpi-4.1.5&#x2F;lib” \\ $HOME&#x2F;.bashrcThis appends the two lines to your .bashrc file which is executed when starting a terminal session.或者vim ~&#x2F;.bashrc然后添加 export PATH=$PATH:$HOME/local/openmpi-4.1.5/bin export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/local/openmpi-4.1.5/lib To compile your MPI C++ programs you have to use mpicxx with the same arguments as you would use for g++. To run a program PRG with N MPI processes, you would then use mpirun -np N PRG. To uninstall OpenMPI just delete the folder opt&#x2F;openmpi in your home directory and remove the last two lines from the .bashrc file in your home directory. You can find more information on http://www.open-mpi.org","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"run mpi program over a cluster 在集群上跑mpi程序","slug":"run-mpi-program-over-a-cluster-在集群上跑mpi程序","date":"2023-04-02T08:13:41.000Z","updated":"2023-04-22T07:06:42.000Z","comments":true,"path":"2023/04/02/run-mpi-program-over-a-cluster-在集群上跑mpi程序/","link":"","permalink":"http://example.com/2023/04/02/run-mpi-program-over-a-cluster-%E5%9C%A8%E9%9B%86%E7%BE%A4%E4%B8%8A%E8%B7%91mpi%E7%A8%8B%E5%BA%8F/","excerpt":"","text":"https://mpitutorial.com/tutorials/running-an-mpi-cluster-within-a-lan/ OpenMPI 集群配置 - HelloWooo - 博客园 (cnblogs.com) 步骤：1. 建立连接 2. 运行mpi程序 建立连接Your machines are gonna be talking over the network via SSH 1. 配置&#x2F;etc&#x2F;hostsyour cluster:manager, worker manager上/etc/hosts有内容： 127.0.0.1 manager &lt;ip_address&gt; worker worker上： 127.0.0.1 worker &lt;ip_address&gt; manager 2. set up sshssh access from manager to worker： 可以相互ssh免密登录即可：（在manager上ssh worker可以去worker，在worker上ssh manager可以去manager（同一个用户名））manager上（worker上同理）： 在manager上ssh-keygen（如果manager上~&#x2F;.ssh&#x2F;下有id_rsa和id_rsa.pub，则此步不用进行） 然后ssh-copy-id worker 3. 关闭集群节点的防火墙如果是没有通信MPI call的简单程序，则主节点不需要关闭防火墙；通常是有通信call的，那么所有节点都要关闭防火墙： 防火墙操作命令：1:查看防火状态 systemctl status firewalld service iptables status 2:暂时关闭防火墙 systemctl stop firewalld service iptables stop 3:永久关闭防火墙 systemctl disable firewalld chkconfig iptables off 4:重启防火墙 systemctl enable firewalld service iptables restart 检查是否成功关闭下面两条命令都显示inactive或者没有服务才是完全关闭了 systemctl status firewalld service iptables status 下面运行的时候如果报错显示是连接的问题，通常是建立连接这步哪里没有ok比如 WARNING: Open MPI failed to TCP connect to a peer MPI process. This should not happen. Your Open MPI job may now hang or fail. Local host: s2 PID: 43860 Message: connect() to 115.157.197.31:1024 failed 这个的意思是s2到115.157.197.31:1024连接不上比如 A process or daemon was unable to complete a TCP connection to another process: Local host: s2 Remote host: s4 This is usually caused by a firewall on the remote host. Please check that any firewall (e.g., iptables) has been disabled and try again. 这个的意思是s2到s4连接不上 运行mpi程序 mpirun 都安装好open mpi（即可以用mpirun的命令） https://sites.google.com/site/rangsiman1993/comp-env/program-install/install-openmpi 在相同路径下有相同的可执行文件 当然也可以配置NFS来共享目录 运行命令：http://selkie.macalester.edu/csinparallel/modules/Patternlets/build/html/MessagePassing/RunningMPI.html -np是指明处理器数目 方法一：--host 然后在manager或worker上： mpirun -np 1 --host manager ./mpi-hello-world mpirun -np 2 --host manager,worker ./mpi-hello-world mpirun -np 4 --host manager:2,worker:2 ./mpi-hello-world 方法二：--hostfile manager和worker上在相同路径下有相同的host_file： manager worker 然后在manager或worker上： mpirun -np 10 --hostfile host_file ./mpi-hello-world 实验存档ssh无密码登录：s2-&gt;s4, s4-&gt;s2防火墙都关闭 s2和s4上都可以跑集群(s4,s2)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"MPI Reduce and Allreduce","slug":"MPI-Reduce-and-Allreduce","date":"2023-04-02T03:19:41.000Z","updated":"2023-05-28T08:33:14.000Z","comments":true,"path":"2023/04/02/MPI-Reduce-and-Allreduce/","link":"","permalink":"http://example.com/2023/04/02/MPI-Reduce-and-Allreduce/","excerpt":"","text":"https://mpitutorial.com/tutorials/mpi-reduce-and-allreduce/ An introduction to reduceData reduction involves reducing a set of numbers into a smaller set of numbers via a function. For example, let’s say we have a list of numbers [1, 2, 3, 4, 5]. Reducing this list of numbers with the sum function would produce sum([1, 2, 3, 4, 5]) = 15. Similarly, the multiplication reduction would yield multiply([1, 2, 3, 4, 5]) = 120. As you might have imagined, it can be very cumbersome to apply reduction functions across a set of distributed numbers. Along with that, it is difficult to efficiently program non-commutative reductions, i.e. reductions that must occur in a set order. Luckily, MPI has a handy function called MPI_Reduce that will handle almost all of the common reductions that a programmer needs to do in a parallel application. MPI_ReduceMPI_Reduce takes an array of input elements on each process and returns an array of output elements to the root process. The output elements contain the reduced result. MPI_Reduce( void* send_data, void* recv_data, int count, MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm communicator) The send_data parameter is an array of elements of type datatype that each process wants to reduce. The recv_data is only relevant on the process with a rank of root. The recv_data array contains the reduced result and has a size of sizeof(datatype) * count. （send_data的元素个数也是count，见下方的图片例子）The op parameter is the operation that you wish to apply to your data. MPI contains a set of common reduction operations that can be used. Although custom reduction operations can be defined, it is beyond the scope of this lesson. The reduction operations defined by MPI include: MPI_MAX - Returns the maximum element. MPI_MIN - Returns the minimum element. MPI_SUM - Sums the elements. MPI_PROD - Multiplies all elements. MPI_LAND - Performs a logical and across the elements. MPI_LOR - Performs a logical or across the elements. MPI_BAND - Performs a bitwise and across the bits of the elements. MPI_BOR - Performs a bitwise or across the bits of the elements. MPI_MAXLOC - Returns the maximum value and the rank of the process that owns it. MPI_MINLOC - Returns the minimum value and the rank of the process that owns it. Below is an illustration of the communication pattern of MPI_Reduce. In the above, each process contains one integer. MPI_Reduce is called with a root process of 0 and using MPI_SUM as the reduction operation. The four numbers are summed to the result and stored on the root process. It is also useful to see what happens when processes contain multiple elements. The illustration below shows reduction of multiple numbers per process. The processes from the above illustration each have two elements. The resulting summation happens on a per-element basis. exampleeach process creates random numbers and makes a local_sum calculation. The local_sum is then reduced to the root process using MPI_SUM int main(int argc, char** argv) &#123; if (argc != 2) &#123; fprintf(stderr, &quot;Usage: avg num_elements_per_proc\\n&quot;); exit(1); &#125; int num_elements_per_proc = atoi(argv[1]); MPI_Init(NULL, NULL); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // Create a random array of elements on all processes. srand(time(NULL)*world_rank); // Seed the random number generator to get different results each time for each processor float *rand_nums = NULL; rand_nums = create_rand_nums(num_elements_per_proc); // Sum the numbers locally float local_sum = 0; int i; for (i = 0; i &lt; num_elements_per_proc; i++) &#123; local_sum += rand_nums[i]; &#125; // Print the random numbers on each process printf(&quot;Local sum for process %d - %f, avg = %f\\n&quot;, world_rank, local_sum, local_sum / num_elements_per_proc); // Reduce all of the local sums into the global sum float global_sum; MPI_Reduce(&amp;local_sum, &amp;global_sum, 1, MPI_FLOAT, MPI_SUM, 0, MPI_COMM_WORLD); // Print the result if (world_rank == 0) &#123; printf(&quot;Total sum = %f, avg = %f\\n&quot;, global_sum, global_sum / (world_size * num_elements_per_proc)); &#125; // Clean up free(rand_nums); MPI_Barrier(MPI_COMM_WORLD); MPI_Finalize(); &#125; MPI_AllreduceMany parallel applications will require accessing the reduced results across all processes rather than the root process. MPI_Allreduce will reduce the values and distribute the results to all processes. The function prototype is the following: MPI_Allreduce( void* send_data, void* recv_data, int count, MPI_Datatype datatype, MPI_Op op, MPI_Comm communicator) MPI_Allreduce is the equivalent of doing MPI_Reduce followed by an MPI_Bcast Computing standard deviation with MPI_AllreduceTo find the standard deviation, one must first compute the average of all numbers. After the average is computed, the sums of the squared difference from the mean are computed. The square root of the average of the sums is the final result. MPI_Allreduce在求标准差时会用到，这是因为求“squared difference from the mean”时每个distributed number都需要知道mean，which is computed after one reduction（若只用MPI_reduce，则只有root process可以得到mean） int main(int argc, char** argv) &#123; if (argc != 2) &#123; fprintf(stderr, &quot;Usage: avg num_elements_per_proc\\n&quot;); exit(1); &#125; int num_elements_per_proc = atoi(argv[1]); MPI_Init(NULL, NULL); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // Create a random array of elements on all processes. srand(time(NULL)*world_rank); // Seed the random number generator of processes uniquely float *rand_nums = NULL; rand_nums = create_rand_nums(num_elements_per_proc); // Sum the numbers locally float local_sum = 0; int i; for (i = 0; i &lt; num_elements_per_proc; i++) &#123; local_sum += rand_nums[i]; &#125; // Reduce all of the local sums into the global sum in order to // calculate the mean float global_sum; MPI_Allreduce(&amp;local_sum, &amp;global_sum, 1, MPI_FLOAT, MPI_SUM, MPI_COMM_WORLD); // since MPI_Allreduce, now all process has correct global_sum float mean = global_sum / (num_elements_per_proc * world_size); // Compute the local sum of the squared differences from the mean float local_sq_diff = 0; for (i = 0; i &lt; num_elements_per_proc; i++) &#123; local_sq_diff += (rand_nums[i] - mean) * (rand_nums[i] - mean); &#125; // Reduce the global sum of the squared differences to the root process // and print off the answer float global_sq_diff; MPI_Reduce(&amp;local_sq_diff, &amp;global_sq_diff, 1, MPI_FLOAT, MPI_SUM, 0, MPI_COMM_WORLD); // The standard deviation is the square root of the mean of the squared // differences. if (world_rank == 0) &#123; float stddev = sqrt(global_sq_diff / (num_elements_per_proc * world_size)); printf(&quot;Mean - %f, Standard deviation = %f\\n&quot;, mean, stddev); &#125; // Clean up free(rand_nums); MPI_Barrier(MPI_COMM_WORLD); MPI_Finalize(); &#125; In the above code, each process computes the local_sum of elements and sums them using MPI_Allreduce. After the global sum is available on all processes, the mean is computed so that local_sq_diff can be computed. Once all of the local squared differences are computed, global_sq_diff is found by using MPI_Reduce. The root process can then compute the standard deviation by taking the square root of the mean of the global squared differences. 自定义reduce操作https://scc.ustc.edu.cn/zlsc/cxyy/200910/MPICH/mpi49.htm 举例typedef struct &#123; double real,imag; &#125; Complex; /* 用户自定义的函数 */ void myProd(Complex *in, Complex *inout, int *len, MPI_Datatype *dptr) &#123; int i; Complex c; for (i=0; i &lt; *len; ++i) &#123; c.real = inout-&gt;real*in-&gt;real - inout-&gt;imag*in-&gt;imag; c.imag = inout-&gt;real*in-&gt;imag + inout-&gt;imag*in-&gt;real; *inout = c; in++; inout++; &#125; &#125; /* 然后调用它 */ /* 每个进程都有一个100个元素的复数数组 */ Complex a[100], answer[100]; MPI_Op myOp; MPI_Datatype ctype; /* 告之MPI复数结构是如何定义的 */ MPI_Type_contiguous(2, MPI_DOUBLE, &amp;ctype); MPI_Type_commit(&amp;ctype); /* 生成用户定义的复数乘积操作 */ MPI_Op_create(myProd, True, &amp;myOp); MPI_Reduce(a, answer, 100, ctype, myOp, root, comm); /* 这时结果(为100个复数)就已经存放在根进程 */ MPI_OP_CREATEMPI_OP_CREATE自定义操作,可以用于函数MPI_REDUCE 、MPI_ALLREDUCEMPI_REDUCE_SCATTER和MPI_SCAN中. MPI_OP_CREATE(function, commute, op) IN function 用户自定义的函数(函数) IN commute 可交换则为true,否则为false OUT op 操作(句柄) int MPI_Op_create(MPI_User_function *function,int commute,MPI_Op *op) 参数介绍:commute: 用户自定义的操作被认为是可以结合的.如果commute&#x3D;true,则此操作是可交换且可结合的;如果commute&#x3D;false,则此操作的顺序是固定地按进程序列号升序方式进行,即从序列号为0的进程开始. function是用户自定义的函数,必须具备四个参数: invec, inoutvec, len和datatype. 在ANSI C中这个函数的原型是: typedef void MPI_User_function(void *invec, void *inoutvec, int *len, MPI_Datatype *datatype); 参数datatype用于控制传送给MPI_REDUCE的数据类型.用户的归约函数应当写成下列方式:当函数被激活时,令u[0],…,u[len-1]是通信缓冲区中len个由参数invec、len和datatype描述的元素;令v[0],…,v[len- 1]是通信缓冲区中len个由参数inoutvec、len和datatype描述的元素;当函数返回时,令w[0],…,w[len-1]是通信缓冲区中len个由参数inoutvec、len和datatype描述的元素;此时w[i] = u[i]·v[i] ,i从0到len-1,这里·是function所定义的归约操作. 从非正式的角度来看,我们可以认为invec和inoutvec是函数中长度为len的数组,归约的结果重写了inoutvec的值.每次调用此函数都导致了对这len个元素逐个进行相应的操作,例如:函数将invec[i]·inoutvec[i]的结果返回到inoutvec[i]中,i从0 到count-1,这里·是由此函数执行的归约操作. tips: 参数len可以使MPI_REDUCE不去调用输入缓冲区中的每个元素,也就是说,系统可以有选择地对输入进行处理.在C语言中,为了与Fortran语言兼容,此参数以引用的方式传送. 通过内部对数据类型参数datatype的值与已知的、全局句柄进行比较,就可能将一个用户自定义的操作作用于几种不同的数据类型. 通常的数据类型可以传给用户自定义的参数,然而互不相邻的数据类型可能会导致低效率. 在用户自定义的函数中不能调用MPI中的通信函数.当函数出错时可能会调用MPI_ABORT. 下面给出MPI_REDUCE本质的但非高效的实现过程. if (rank &gt; 0) &#123; RECV(tempbuf, count, datatype, rank-1,...) /* 从前一个rank接收数据 */ User_reduce(tempbuf, sendbuf, count, datatype) /* 用户定义的函数function */ &#125; if (rank &lt; groupsize-1) &#123; SEND(sendbuf, count, datatype, rank+1,...) /* 把结果发送给下一个rank */ &#125; /* 结果位于进程groupsize-1上,现在将其发送到根进程 */ if (rank == groupsize-1) &#123; SEND(sendbuf, count, datatype, root, ...) &#125; if (rank == root) &#123; RECV(recvbuf, count, datatype, groupsize-1,...) &#125; 归约操作顺序地、依次地从进程0计算到进程groupsize-1.这样选择顺序的原因是为了照顾用户自定义的User_reduce函数中有些操作的顺序是不可交换的.更有效的实现方法是采用可结合性的特点或应用对数树形归约法.对于在MPI_OP_CREATE 中 commute为true的情况,还可以利用可交换性的特点,也就是说可以对缓冲区中的一部分数据进行归约操作,这样通信和计算就可以流水执行,即可以传送的数据块的长度len可以小于count. MPI_OP_FREEMPI_OP_FREE(op) IN op 操作(句柄) int MPI_Op_free(MPI_Op *op) 如要将用户自定义的归约操作撤消,将op设置成MPI_OP_NULL.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"collective call example: Performing Parallel Rank with MPI","slug":"collective-call-example-Performing-Parallel-Rank-with-MPI","date":"2023-04-02T02:26:02.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/02/collective-call-example-Performing-Parallel-Rank-with-MPI/","link":"","permalink":"http://example.com/2023/04/02/collective-call-example-Performing-Parallel-Rank-with-MPI/","excerpt":"","text":"https://mpitutorial.com/tutorials/performing-parallel-rank-with-mpi/ Parallel rank - problem overviewWhen processes all have a single number stored in their local memory, it can be useful to know what order their number is in respect to the entire set of numbers contained by all processes. For example, a user might be benchmarking the processors in an MPI cluster and want to know the order of how fast each processor is relative to the others. This information can be used for scheduling tasks and so on. Parallel rank API definitionOur function needs to take a number on each process and return its associated rank our prototype for the rank function looks like this: TMPI_Rank( void *send_data, void *recv_data, MPI_Datatype datatype, MPI_Comm comm) TMPI_Rank takes a send_data buffer that contains one number of datatype type. The recv_data receives exactly one integer on each process that contains the rank value for send_data. The comm variable is the communicator in which ranking is taking place. Note - The MPI standard explicitly says that users should not name their own functions MPI_&lt;something&gt; to avoid confusing user functions with functions in the MPI standard itself. Thus, we will prefix functions in these tutorials with T. Solving the parallel rank problemThe easiest way: gathers the numbers to the root process, sorts the numbers to determine their ranks, and then scatters the ranks back to the requesting processes In the example code (tmpi_rank.c), the gather_numbers_to_root function is responsible for gathering all of the numbers to the root process. 每个process都会call这个函数，函数参数void*number是要发送给root的数字 // Gathers numbers for TMPI_Rank to process zero. Allocates space for // the MPI datatype and returns a void * buffer to process 0. // It returns NULL to all other processes. void *gather_numbers_to_root(void *number, MPI_Datatype datatype, MPI_Comm comm) &#123; int comm_rank, comm_size; MPI_Comm_rank(comm, &amp;comm_rank); MPI_Comm_size(comm, &amp;comm_size); // Allocate an array on the root process of a size depending // on the MPI datatype being used. int datatype_size; MPI_Type_size(datatype, &amp;datatype_size); void *gathered_numbers; if (comm_rank == 0) &#123; gathered_numbers = malloc(datatype_size * comm_size); &#125; // Gather all of the numbers on the root process MPI_Gather(number, 1, datatype, gathered_numbers, 1, datatype, 0, comm); return gathered_numbers; &#125; Sorting numbers and maintaining ownershipattaching the owning process to the numbers // Holds the communicator rank of a process along with the // corresponding number. This struct is used for sorting // the values and keeping the owning process information // intact. typedef struct &#123; int comm_rank; union &#123; float f; int i; &#125; number; &#125; CommRankNumber; The CommRankNumber struct holds the number we are going to sort (remember that it can be a float or an int, so we use a union) and it holds the communicator rank of the process that owns the number. // This function sorts the gathered numbers on the root process and // returns an array of ordered by the process&#39;s rank in its // communicator. Note - this function is only executed on the root // process. int *get_ranks(void *gathered_numbers, int gathered_number_count, MPI_Datatype datatype) &#123; int datatype_size; MPI_Type_size(datatype, &amp;datatype_size); // Convert the gathered number array to an array of CommRankNumbers. // This allows us to sort the numbers and also keep the information // of the processes that own the numbers intact. CommRankNumber *comm_rank_numbers = malloc( gathered_number_count * sizeof(CommRankNumber)); int i; for (i = 0; i &lt; gathered_number_count; i++) &#123; comm_rank_numbers[i].comm_rank = i; memcpy(&amp;(comm_rank_numbers[i].number), gathered_numbers + (i * datatype_size), datatype_size); &#125; // Sort the comm rank numbers based on the datatype if (datatype == MPI_FLOAT) &#123; qsort(comm_rank_numbers, gathered_number_count, sizeof(CommRankNumber), &amp;compare_float_comm_rank_number); &#125; else &#123; qsort(comm_rank_numbers, gathered_number_count, sizeof(CommRankNumber), &amp;compare_int_comm_rank_number); &#125; // Now that the comm_rank_numbers are sorted, make an array of rank // values for each process. The ith element of this array contains // the rank value for the number sent by process i. int *ranks = (int *)malloc(sizeof(int) * gathered_number_count); for (i = 0; i &lt; gathered_number_count; i++) &#123; ranks[comm_rank_numbers[i].comm_rank] = i; &#125; // Clean up and return the rank array free(comm_rank_numbers); return ranks; &#125; After the numbers are sorted, we must create an array of ranks in the proper order so that they can be scattered back to the requesting processes. Putting it all together注意，MPI_Scatter和MPI_Gather都是collective call，只有一个communicator中所有process都call MPI_Scatter（&#x2F;MPI_Gather）之后每个process才可能结束MPI_Scatter（&#x2F;MPI_Gather）的执行 // Gets the rank of the recv_data, which is of type datatype. The rank // is returned in send_data and is of type datatype. int TMPI_Rank(void *send_data, void *recv_data, MPI_Datatype datatype, MPI_Comm comm) &#123; // Check base cases first - Only support MPI_INT and MPI_FLOAT for // this function. if (datatype != MPI_INT &amp;&amp; datatype != MPI_FLOAT) &#123; return MPI_ERR_TYPE; &#125; int comm_size, comm_rank; MPI_Comm_size(comm, &amp;comm_size); MPI_Comm_rank(comm, &amp;comm_rank); // To calculate the rank, we must gather the numbers to one // process, sort the numbers, and then scatter the resulting rank // values. Start by gathering the numbers on process 0 of comm. void *gathered_numbers = gather_numbers_to_root(send_data, datatype, comm); // Get the ranks of each process int *ranks = NULL; if (comm_rank == 0) &#123; ranks = get_ranks(gathered_numbers, comm_size, datatype); &#125; // Scatter the rank results MPI_Scatter(ranks, 1, MPI_INT, recv_data, 1, MPI_INT, 0, comm); // Do clean up if (comm_rank == 0) &#123; free(gathered_numbers); free(ranks); &#125; &#125; 每个process都call这个函数 int main(int argc, char** argv) &#123; MPI_Init(NULL, NULL); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // Seed the random number generator to get different results each time srand(time(NULL) * world_rank); float rand_num = rand() / (float)RAND_MAX; int rank; TMPI_Rank(&amp;rand_num, &amp;rank, MPI_FLOAT, MPI_COMM_WORLD); printf(&quot;Rank for %f on process %d - %d\\n&quot;, rand_num, world_rank, rank); MPI_Barrier(MPI_COMM_WORLD); MPI_Finalize(); &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"MPI Scatter, Gather, and Allgather","slug":"MPI-Scatter-Gather-and-Allgather","date":"2023-04-02T01:50:54.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/02/MPI-Scatter-Gather-and-Allgather/","link":"","permalink":"http://example.com/2023/04/02/MPI-Scatter-Gather-and-Allgather/","excerpt":"","text":"https://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/ An introduction to MPI_ScatterMPI_Bcast sends the same piece of data to all processes while MPI_Scatter sends chunks of an array to different processes. 注意到MPI_Scatter会send chunk给root process the root process (process zero) contains the entire array of data, MPI_Scatter will copy the appropriate element into the receiving buffer of the process. MPI_Scatter( void* send_data, int send_count, MPI_Datatype send_datatype, void* recv_data, int recv_count, MPI_Datatype recv_datatype, int root, MPI_Comm communicator) The first parameter, send_data, is an array of data that resides on the root process. The second and third parameters, send_count and send_datatype, dictate how many elements of a specific MPI Datatype will be sent to each process. If send_count is one and send_datatype is MPI_INT, then process zero gets the first integer of the array, process one gets the second integer, and so on. If send_count is two, then process zero gets the first and second integers, process one gets the third and fourth, and so on. (In practice, send_count is often equal to the number of elements in the array divided by the number of processes. ) (for each receving process) The recv_data parameter is a buffer of data that can hold recv_count elements that have a datatype of recv_datatype. The last parameters, root and communicator, indicate the root process that is scattering the array of data and the communicator in which the processes reside. An introduction to MPI_Gather MPI_Gather takes elements from each process and gathers them to the root process. The elements are ordered by the rank of the process from which they were received. 注意到MPI_Scatter会从root process receive chunk MPI_Gather( void* send_data, int send_count, MPI_Datatype send_datatype, void* recv_data, int recv_count, MPI_Datatype recv_datatype, int root, MPI_Comm communicator) only the root process needs to have a valid receive buffer. All other calling processes can pass NULL for recv_data. Also, don’t forget that the recv_count parameter is the count of elements received per process, not the total summation of counts from all processes. Computing average of numbers with MPI_Scatter and MPI_Gather阅读方式：当做我是0；当做我不是0 注意，MPI_Scatter和MPI_Gather都是collective call，只有一个communicator中所有process都call MPI_Scatter（&#x2F;MPI_Gather）之后每个process才可能结束MPI_Scatter（&#x2F;MPI_Gather）的执行 注意，scatter会给root process也分配一个sub数组，看对sub_avgs求平均那里，分母是wolrd_size，即root process也求了一个sub_avg float avg = compute_avg(sub_avgs, world_size); int main(int argc, char** argv) &#123; if (argc != 2) &#123; fprintf(stderr, &quot;Usage: avg num_elements_per_proc\\n&quot;); exit(1); &#125; int num_elements_per_proc = atoi(argv[1]); // Seed the random number generator to get different results each time srand(time(NULL)); MPI_Init(NULL, NULL); // 进入每个线程私有的部分 int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // Create a random array of elements on the root process. Its total // size will be the number of elements per process times the number // of processes float *rand_nums = NULL; if (world_rank == 0) &#123; rand_nums = create_rand_nums(num_elements_per_proc * world_size); &#125; // For each process, create a buffer that will hold a subset of the entire // array float *sub_rand_nums = (float *)malloc(sizeof(float) * num_elements_per_proc); assert(sub_rand_nums != NULL); // Scatter the random numbers from the root process to all processes in // the MPI world MPI_Scatter(rand_nums, num_elements_per_proc, MPI_FLOAT, sub_rand_nums, num_elements_per_proc, MPI_FLOAT, 0, MPI_COMM_WORLD); // Compute the average of your subset float sub_avg = compute_avg(sub_rand_nums, num_elements_per_proc); // Gather all partial averages down to the root process float *sub_avgs = NULL; if (world_rank == 0) &#123; sub_avgs = (float *)malloc(sizeof(float) * world_size); assert(sub_avgs != NULL); &#125; MPI_Gather(&amp;sub_avg, 1, MPI_FLOAT, sub_avgs, 1, MPI_FLOAT, 0, MPI_COMM_WORLD); // Now that we have all of the partial averages on the root, compute the // total average of all numbers. Since we are assuming each process computed // an average across an equal amount of elements, this computation will // produce the correct answer. if (world_rank == 0) &#123; float avg = compute_avg(sub_avgs, world_size); printf(&quot;Avg of all elements is %f\\n&quot;, avg); // Compute the average across the original data for comparison float original_data_avg = compute_avg(rand_nums, num_elements_per_proc * world_size); printf(&quot;Avg computed across original data is %f\\n&quot;, original_data_avg); &#125; // Clean up if (world_rank == 0) &#123; free(rand_nums); free(sub_avgs); &#125; free(sub_rand_nums); MPI_Barrier(MPI_COMM_WORLD); MPI_Finalize(); &#125; MPI_Allgather and modification of average programGiven a set of elements distributed across all processes, MPI_Allgather will gather all of the elements to all the processes. In the most basic sense, MPI_Allgather is an MPI_Gather followed by an MPI_Bcast. The illustration below shows how data is distributed after a call to MPI_Allgather. Just like MPI_Gather, the elements from each process are gathered in order of their rank, except this time the elements are gathered to all processes. Pretty easy, right? The function declaration for MPI_Allgather is almost identical to MPI_Gather with the difference that there is no root process in MPI_Allgather. MPI_Allgather( void* send_data, int send_count, MPI_Datatype send_datatype, void* recv_data, int recv_count, MPI_Datatype recv_datatype, MPI_Comm communicator)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpi overall","slug":"mpi-overall","date":"2023-04-02T01:47:08.000Z","updated":"2023-04-22T03:02:31.000Z","comments":true,"path":"2023/04/02/mpi-overall/","link":"","permalink":"http://example.com/2023/04/02/mpi-overall/","excerpt":"","text":"https://mpitutorial.com/tutorials/mpi-hello-world/ 每个process的开始：MPI_Init之后MPI_Init之后初始化的变量是每个process一个copy的，在local memory中 Hello world code examples#include &lt;mpi.h&gt; #include &lt;stdio.h&gt; int main(int argc, char** argv) &#123; // Initialize the MPI environment MPI_Init(NULL, NULL); // Get the number of processes int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // Get the rank of the process int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); // Get the name of the processor char processor_name[MPI_MAX_PROCESSOR_NAME]; int name_len; MPI_Get_processor_name(processor_name, &amp;name_len); // Print off a hello world message printf(&quot;Hello world from processor %s, rank %d out of %d processors\\n&quot;, processor_name, world_rank, world_size); // Finalize the MPI environment. MPI_Finalize(); &#125; MPI_InitMPI environment must be initialized with: MPI_Init( int* argc, char*** argv) During MPI_Init, all of MPI’s global and internal variables are constructed. For example, a communicator is formed around all of the processes that were spawned, and unique ranks are assigned to each process. 编译运行编译（把gcc换成mpicc即可，或者把g++替换成mpicxx） mpicc -o mpi_hello_world mpi_hello_world.c 运行（单节点） mpirun -np 1 ./mpi-hello-world MPI_Abortint MPI_Abort(MPI_Comm comm, int errorcode) commcommunicator of tasks to aborterrorcodeerror code to return to invoking environment Terminates all MPI processes associated with the communicator comm; in most systems (all to date), terminates all processes.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"命令行查看环境变量 env","slug":"命令行查看环境变量-env","date":"2023-04-02T01:44:55.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/02/命令行查看环境变量-env/","link":"","permalink":"http://example.com/2023/04/02/%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%9F%A5%E7%9C%8B%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F-env/","excerpt":"","text":"env env | grep PATH","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpi时间测量 MPI_Wtime","slug":"mpi时间测量-MPI-Wtime","date":"2023-04-02T01:20:09.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/02/mpi时间测量-MPI-Wtime/","link":"","permalink":"http://example.com/2023/04/02/mpi%E6%97%B6%E9%97%B4%E6%B5%8B%E9%87%8F-MPI-Wtime/","excerpt":"","text":"https://mpitutorial.com/tutorials/mpi-broadcast-and-collective-communication/ Comparison of MPI_Bcast with MPI_Send and MPI_RecvMPI_Wtime takes no arguments, and it simply returns a floating-point number of seconds since a set time in the past. 注意更新计时变量前的Barrier，确保所有的process都执行到了MPI_Barrier这一行之后，才让它们更新total_my_bcast_time // Synchronize before starting timing MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time -= MPI_Wtime(); my_bcast(data, num_elements, MPI_INT, 0, MPI_COMM_WORLD); // Synchronize again before obtaining final time MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time += MPI_Wtime(); 注意在MPI_Init之后初始化的变量是每个process一个copy的，所以total_my_bcast_time是每个process一个copy的，不会有竞争 int main(int argc, char** argv) &#123; if (argc != 3) &#123; fprintf(stderr, &quot;Usage: compare_bcast num_elements num_trials\\n&quot;); exit(1); &#125; int num_elements = atoi(argv[1]); int num_trials = atoi(argv[2]); MPI_Init(NULL, NULL); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); double total_my_bcast_time = 0.0; double total_mpi_bcast_time = 0.0; int i; int* data = (int*)malloc(sizeof(int) * num_elements); assert(data != NULL); for (i = 0; i &lt; num_trials; i++) &#123; // Time my_bcast // Synchronize before starting timing MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time -= MPI_Wtime(); my_bcast(data, num_elements, MPI_INT, 0, MPI_COMM_WORLD); // Synchronize again before obtaining final time MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time += MPI_Wtime(); // Time MPI_Bcast MPI_Barrier(MPI_COMM_WORLD); total_mpi_bcast_time -= MPI_Wtime(); MPI_Bcast(data, num_elements, MPI_INT, 0, MPI_COMM_WORLD); MPI_Barrier(MPI_COMM_WORLD); total_mpi_bcast_time += MPI_Wtime(); &#125; // Print off timing information if (world_rank == 0) &#123; printf(&quot;Data size = %d, Trials = %d\\n&quot;, num_elements * (int)sizeof(int), num_trials); printf(&quot;Avg my_bcast time = %lf\\n&quot;, total_my_bcast_time / num_trials); printf(&quot;Avg MPI_Bcast time = %lf\\n&quot;, total_mpi_bcast_time / num_trials); &#125; free(data); MPI_Finalize(); &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"MPI Broadcast and Collective Communication","slug":"MPI-Broadcast-and-Collective-Communication","date":"2023-04-02T01:05:44.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/02/MPI-Broadcast-and-Collective-Communication/","link":"","permalink":"http://example.com/2023/04/02/MPI-Broadcast-and-Collective-Communication/","excerpt":"","text":"https://mpitutorial.com/tutorials/mpi-broadcast-and-collective-communication/ Collective communication and synchronization pointsOne of the things to remember about collective communication is that it implies a synchronization point among processes. This means that all processes must reach a point in their code before they can all begin executing again. MPI_Barrier(MPI_Comm communicator) the function forms a barrier, and no processes in the communicator can pass the barrier until all of them call the function Want to know how MPI_Barrier is implemented? Sure you do :-) Do you remember the ring program from the sending and receiving tutorial? To refresh your memory, we wrote a program that passed a token around all processes in a ring-like fashion. This type of program is one of the simplest methods to implement a barrier since a token can’t be passed around completely until all processes work together. Always remember that every collective call you make is synchronized. In other words, if you can’t successfully complete an MPI_Barrier, then you also can’t successfully complete any collective call. If you try to call MPI_Barrier or other collective routines without ensuring all processes in the communicator will also call it, your program will idle Broadcasting with MPI_BcastDuring a broadcast, one process sends the same data to all processes in a communicator. In MPI, broadcasting can be accomplished by using MPI_Bcast. The function prototype looks like this: MPI_Bcast( void* data, int count, MPI_Datatype datatype, int root, MPI_Comm communicator) Although the root process and receiver processes do different jobs, they all call the same MPI_Bcast function. When the root process (in our example, it was process zero) calls MPI_Bcast, the data variable will be sent to all other processes. When all of the receiver processes call MPI_Bcast, the data variable will be filled in with the data from the root process. Broadcasting with MPI_Send and MPI_Recv 广播的实现：tree-basedAt first, it might seem that MPI_Bcast is just a simple wrapper around MPI_Send and MPI_Recv. looks like this: void my_bcast(void* data, int count, MPI_Datatype datatype, int root, MPI_Comm communicator) &#123; int world_rank; MPI_Comm_rank(communicator, &amp;world_rank); int world_size; MPI_Comm_size(communicator, &amp;world_size); if (world_rank == root) &#123; // If we are the root process, send our data to everyone int i; for (i = 0; i &lt; world_size; i++) &#123; if (i != world_rank) &#123; MPI_Send(data, count, datatype, i, 0, communicator); &#125; &#125; &#125; else &#123; // If we are a receiver process, receive the data from the root MPI_Recv(data, count, datatype, root, 0, communicator, MPI_STATUS_IGNORE); &#125; &#125; The root process sends the data to everyone else while the others receive from the root process. very inefficient A smarter implementation is a tree-based communication algorithm that can use more of the available network links at once.比如当process0把data传递给了process1之后，process1也可以开始传播The network utilization doubles at every subsequent stage of the tree communication until all processes have received the data. （下图含义：每一行表示一个阶段， 第一行：最开始只有0可以发送消息。0发送给了1； 第二行：1收到消息后也开始发送消息，0也继续发送消息。0-&gt;2，1-&gt;3； 第三行：2和3收到消息后也开始发送消息，0和1也继续发送消息。0-&gt;4, 3-&gt;6, 1-&gt;5, 3-&gt;7） Comparison of MPI_Bcast with MPI_Send and MPI_RecvMPI_Wtime takes no arguments, and it simply returns a floating-point number of seconds since a set time in the past. 注意更新计时变量前的Barrier，确保所有的process都执行到了MPI_Barrier这一行之后，才让它们更新total_my_bcast_time // Synchronize before starting timing MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time -= MPI_Wtime(); my_bcast(data, num_elements, MPI_INT, 0, MPI_COMM_WORLD); // Synchronize again before obtaining final time MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time += MPI_Wtime(); 注意在MPI_Init之后初始化的变量是每个process一个copy的，所以total_my_bcast_time是每个process一个copy的，不会有竞争 int main(int argc, char** argv) &#123; if (argc != 3) &#123; fprintf(stderr, &quot;Usage: compare_bcast num_elements num_trials\\n&quot;); exit(1); &#125; int num_elements = atoi(argv[1]); int num_trials = atoi(argv[2]); MPI_Init(NULL, NULL); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); double total_my_bcast_time = 0.0; double total_mpi_bcast_time = 0.0; int i; int* data = (int*)malloc(sizeof(int) * num_elements); assert(data != NULL); for (i = 0; i &lt; num_trials; i++) &#123; // Time my_bcast // Synchronize before starting timing MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time -= MPI_Wtime(); my_bcast(data, num_elements, MPI_INT, 0, MPI_COMM_WORLD); // Synchronize again before obtaining final time MPI_Barrier(MPI_COMM_WORLD); total_my_bcast_time += MPI_Wtime(); // Time MPI_Bcast MPI_Barrier(MPI_COMM_WORLD); total_mpi_bcast_time -= MPI_Wtime(); MPI_Bcast(data, num_elements, MPI_INT, 0, MPI_COMM_WORLD); MPI_Barrier(MPI_COMM_WORLD); total_mpi_bcast_time += MPI_Wtime(); &#125; // Print off timing information if (world_rank == 0) &#123; printf(&quot;Data size = %d, Trials = %d\\n&quot;, num_elements * (int)sizeof(int), num_trials); printf(&quot;Avg my_bcast time = %lf\\n&quot;, total_my_bcast_time / num_trials); printf(&quot;Avg MPI_Bcast time = %lf\\n&quot;, total_mpi_bcast_time / num_trials); &#125; free(data); MPI_Finalize(); &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"2","slug":"daily-2023-4-2","date":"2023-04-02T01:03:09.000Z","updated":"2023-04-03T00:43:06.000Z","comments":true,"path":"2023/04/02/daily-2023-4-2/","link":"","permalink":"http://example.com/2023/04/02/daily-2023-4-2/","excerpt":"","text":"昨天出去玩啦！今天回归今日目标：上午和下午学完mpi；晚上开发hw多机版有时间看看敏感性分析和缺失数据补全（具体方法其实应该看看类似研究的文献） 上午下午晚上来自4.3：昨天主要只是学习了下基础版mpi+集群跑mpi啦x","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpi Point-to-Point Communication example: random walk","slug":"mpi-Point-to-Point-Communication-example-random-walk","date":"2023-04-01T02:37:09.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/01/mpi-Point-to-Point-Communication-example-random-walk/","link":"","permalink":"http://example.com/2023/04/01/mpi-Point-to-Point-Communication-example-random-walk/","excerpt":"","text":"https://mpitutorial.com/tutorials/point-to-point-communication-application-random-walk/ The basic problem definition of a random walk is as follows. Given a Min, Max, and random walker W, make walker W take S random walks of arbitrary length to the right（“a random walk of length&#x2F;size 6”的意思是，移动6步）. If the process goes out of bounds, it wraps back around. W can only move one unit to the right or left at a time. Parallelization of the random walking problemsplitting the domain across processes The random walk problem has a one-dimensional domain of size Max - Min + 1 (since Max and Min are inclusive to the walker). Assuming that walkers can only take integer-sized steps, we can easily partition the domain into near-equal-sized chunks across processes. For example, if Min is 0 and Max is 20 and we have four processes, the domain would be split like this. if the walker takes a walk of size six on process zero (using the previous domain decomposition), the execution of the walker will go like this: The walker starts taking incremental steps. When it hits value four, however, it has reached the end of the bounds of process zero. Process zero now has to communicate the walker to process one. Process one receives the walker and continues walking until it has reached its total walk size of six. The walker can then proceed on a new random walk. In this example, W only had to be communicated one time from process zero to process one. If W had to take a longer walk, however, it may have needed to be passed through more processes along its path through the domain. 代码逻辑 Initialize the walkers.（这个意思其实是”出题“） Progress the walkers with the walk function. Send out any walkers in the outgoing_walkers vector. Receive new walkers and put them in the incoming_walkers vector. Repeat steps two through four until all walkers have finished. first attempt, may lead to deadlock: // Find your part of the domain decompose_domain(domain_size, world_rank, world_size, &amp;subdomain_start, &amp;subdomain_size); // Initialize walkers in your subdomain initialize_walkers(num_walkers_per_proc, max_walk_size, subdomain_start, subdomain_size, &amp;incoming_walkers); while (!all_walkers_finished) &#123; // Determine walker completion later // Process all incoming walkers for (int i = 0; i &lt; incoming_walkers.size(); i++) &#123; walk(&amp;incoming_walkers[i], subdomain_start, subdomain_size, domain_size, &amp;outgoing_walkers); &#125; // Send all outgoing walkers to the next process. send_outgoing_walkers(&amp;outgoing_walkers, world_rank, world_size); // Receive all the new incoming walkers receive_incoming_walkers(&amp;incoming_walkers, world_rank, world_size); &#125; Deadlock and preventionthe above code will result in a circular chain of MPI_Send calls. It is worth noting that the above code will actually not deadlock most of the time. Although MPI_Send is a blocking call, the MPI specification says that MPI_Send blocks until the send buffer can be reclaimed. This means that MPI_Send will return when the network can buffer the message. If the sends eventually can’t be buffered by the network, they will block until a matching receive is posted. In our case, there are enough small sends and frequent matching receives to not worry about deadlock, however, a big enough network buffer should never be assumed. Since we are only focusing on MPI_Send and MPI_Recv in this lesson, the best way to avoid the possible sending and receiving deadlock is to order the messaging such that sends will have matching receives and vice versa. One easy way to do this is to change our loop around such that even-numbered processes send outgoing walkers before receiving walkers and odd-numbered processes do the opposite. Given two stages of execution, the sending and receiving will now look like this:（下图的意思：一行代表一个阶段，但是整个图代表一轮（对应一轮for (int m = 0; m &lt; maximum_sends_recvs; m++)循环中walk完后的处理）） 每一阶段（每一行）考察这个阶段开始时三个process的行为： 第一行：0尝试发给1，1尝试从0接收，2尝试发给3，3尝试从2接收： 01解决（0从发送中返回，1从接收中返回）；23解决 第二行：0从发送返回后执行接收（即0尝试从3接收），1从接收返回后执行发送（1尝试发送给2），2从发送返回后执行接收（即2尝试从1接收），3从接收返回后执行发送（3尝试发送给0）： 03解决；12解决 Note - Executing this with one process can still deadlock. To avoid this, simply don’t perform sends and receives when using one process. You may be asking, does this still work with an odd number of processes? We can go through a similar diagram again with three processes: 每一阶段（每一行）考察这个阶段开始时三个process的行为： 第一行：0尝试发给1，1尝试从0接收，2尝试发给0： 01解决（0从发送中返回，1从接收中返回）； 但是2发给0，这里会block，等待0接收 第二行：0从发送返回后执行接收（即0尝试从2接收），1从接收返回后执行发送（1尝试发送给2），2仍然block在发送给0中： 02解决，2从发送中返回（下一阶段将执行接收），0从接收中返回； 但是1会block在等待2的接收中 第三行：0从接收中返回后本轮的代码结束，1仍然block在发送给2中，2在上一阶段从发送返回后执行接收（2尝试从1接收）： 12解决，1从发送中返回，2从接收中返回 至此，都完成了各自的本轮代码 As you can see, at all three stages, there is at least one posted MPI_Send that matches a posted MPI_Recv, so we don’t have to worry about the occurrence of deadlock. Determining completion of all walkers cumbersome solution: have process zero keep track of all of the walkers that have finished and then tell all the other processes when to terminate. quite cumbersome since each process would have to report any completed walkers to process zero and then also handle different types of incoming messages. Since we know the maximum distance that any walker can travel and the smallest total size it can travel for each pair of sends and receives (the subdomain size), we can figure out the maximum amount of sends and receives needed to complete all walkers // Determine the maximum amount of sends and receives needed to // complete all walkers int maximum_sends_recvs = max_walk_size / (domain_size / world_size) + 1; for (int m = 0; m &lt; maximum_sends_recvs; m++) &#123; // Process all incoming walkers // ... // Send and receive if you are even and vice versa for odd // ... &#125; codehttps://github.com/mpitutorial/mpitutorial/tree/gh-pages/tutorials/point-to-point-communication-application-random-walk/code 阅读方法：读main // Author: Wes Kendall // Copyright 2011 www.mpitutorial.com // This code is provided freely with the tutorials on mpitutorial.com. Feel // free to modify it for your own use. Any distribution of the code must // either provide a link to www.mpitutorial.com or keep this header intact. // // Example application of random walking using MPI_Send, MPI_Recv, and // MPI_Probe. // #include &lt;iostream&gt; #include &lt;vector&gt; #include &lt;cstdlib&gt; #include &lt;time.h&gt; #include &lt;mpi.h&gt; using namespace std; typedef struct &#123; int location; int num_steps_left_in_walk; &#125; Walker; void decompose_domain(int domain_size, int world_rank, int world_size, int* subdomain_start, int* subdomain_size) &#123; if (world_size &gt; domain_size) &#123; // Don&#39;t worry about this special case. Assume the domain size // is greater than the world size. MPI_Abort(MPI_COMM_WORLD, 1); &#125; *subdomain_start = domain_size / world_size * world_rank; *subdomain_size = domain_size / world_size; if (world_rank == world_size - 1) &#123; // Give remainder to last process *subdomain_size += domain_size % world_size; &#125; &#125; void initialize_walkers(int num_walkers_per_proc, int max_walk_size, int subdomain_start, vector&lt;Walker&gt;* incoming_walkers) &#123; Walker walker; for (int i = 0; i &lt; num_walkers_per_proc; i++) &#123; // Initialize walkers at the start of the subdomain walker.location = subdomain_start; walker.num_steps_left_in_walk = (rand() / (float)RAND_MAX) * max_walk_size; incoming_walkers-&gt;push_back(walker); &#125; &#125; void walk(Walker* walker, int subdomain_start, int subdomain_size, int domain_size, vector&lt;Walker&gt;* outgoing_walkers) &#123; while (walker-&gt;num_steps_left_in_walk &gt; 0) &#123; if (walker-&gt;location == subdomain_start + subdomain_size) &#123; // Take care of the case when the walker is at the end // of the domain by wrapping it around to the beginning if (walker-&gt;location == domain_size) &#123; walker-&gt;location = 0; &#125; outgoing_walkers-&gt;push_back(*walker); break; &#125; else &#123; walker-&gt;num_steps_left_in_walk--; walker-&gt;location++; &#125; &#125; &#125; void send_outgoing_walkers(vector&lt;Walker&gt;* outgoing_walkers, int world_rank, int world_size) &#123; // Send the data as an array of MPI_BYTEs to the next process. // The last process sends to process zero. MPI_Send((void*)outgoing_walkers-&gt;data(), outgoing_walkers-&gt;size() * sizeof(Walker), MPI_BYTE, (world_rank + 1) % world_size, 0, MPI_COMM_WORLD); // Clear the outgoing walkers list outgoing_walkers-&gt;clear(); &#125; void receive_incoming_walkers(vector&lt;Walker&gt;* incoming_walkers, int world_rank, int world_size) &#123; // Probe for new incoming walkers MPI_Status status; // Receive from the process before you. If you are process zero, // receive from the last process int incoming_rank = (world_rank == 0) ? world_size - 1 : world_rank - 1; MPI_Probe(incoming_rank, 0, MPI_COMM_WORLD, &amp;status); // Resize your incoming walker buffer based on how much data is // being received int incoming_walkers_size; MPI_Get_count(&amp;status, MPI_BYTE, &amp;incoming_walkers_size); incoming_walkers-&gt;resize(incoming_walkers_size / sizeof(Walker)); MPI_Recv((void*)incoming_walkers-&gt;data(), incoming_walkers_size, MPI_BYTE, incoming_rank, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); &#125; int main(int argc, char** argv) &#123; int domain_size; int max_walk_size; int num_walkers_per_proc; if (argc &lt; 4) &#123; cerr &lt;&lt; &quot;Usage: random_walk domain_size max_walk_size &quot; &lt;&lt; &quot;num_walkers_per_proc&quot; &lt;&lt; endl; exit(1); &#125; domain_size = atoi(argv[1]); max_walk_size = atoi(argv[2]); num_walkers_per_proc = atoi(argv[3]); MPI_Init(NULL, NULL); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); srand(time(NULL) * world_rank); int subdomain_start, subdomain_size; vector&lt;Walker&gt; incoming_walkers, outgoing_walkers; // Find your part of the domain decompose_domain(domain_size, world_rank, world_size, &amp;subdomain_start, &amp;subdomain_size); // Initialize walkers in your subdomain initialize_walkers(num_walkers_per_proc, max_walk_size, subdomain_start, &amp;incoming_walkers); cout &lt;&lt; &quot;Process &quot; &lt;&lt; world_rank &lt;&lt; &quot; initiated &quot; &lt;&lt; num_walkers_per_proc &lt;&lt; &quot; walkers in subdomain &quot; &lt;&lt; subdomain_start &lt;&lt; &quot; - &quot; &lt;&lt; subdomain_start + subdomain_size - 1 &lt;&lt; endl; // Determine the maximum amount of sends and receives needed to // complete all walkers int maximum_sends_recvs = max_walk_size / (domain_size / world_size) + 1; for (int m = 0; m &lt; maximum_sends_recvs; m++) &#123; // Process all incoming walkers for (int i = 0; i &lt; incoming_walkers.size(); i++) &#123; walk(&amp;incoming_walkers[i], subdomain_start, subdomain_size, domain_size, &amp;outgoing_walkers); &#125; cout &lt;&lt; &quot;Process &quot; &lt;&lt; world_rank &lt;&lt; &quot; sending &quot; &lt;&lt; outgoing_walkers.size() &lt;&lt; &quot; outgoing walkers to process &quot; &lt;&lt; (world_rank + 1) % world_size &lt;&lt; endl; if (world_rank % 2 == 0) &#123; // Send all outgoing walkers to the next process. send_outgoing_walkers(&amp;outgoing_walkers, world_rank, world_size); // Receive all the new incoming walkers receive_incoming_walkers(&amp;incoming_walkers, world_rank, world_size); &#125; else &#123; // Receive all the new incoming walkers receive_incoming_walkers(&amp;incoming_walkers, world_rank, world_size); // Send all outgoing walkers to the next process. send_outgoing_walkers(&amp;outgoing_walkers, world_rank, world_size); &#125; cout &lt;&lt; &quot;Process &quot; &lt;&lt; world_rank &lt;&lt; &quot; received &quot; &lt;&lt; incoming_walkers.size() &lt;&lt; &quot; incoming walkers&quot; &lt;&lt; endl; &#125; cout &lt;&lt; &quot;Process &quot; &lt;&lt; world_rank &lt;&lt; &quot; done&quot; &lt;&lt; endl; MPI_Finalize(); return 0; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpi dynamic receive (dynamic means buffer size)","slug":"mpi-dynamic-receive-dynamic-means-buffer-size","date":"2023-04-01T02:32:26.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/01/mpi-dynamic-receive-dynamic-means-buffer-size/","link":"","permalink":"http://example.com/2023/04/01/mpi-dynamic-receive-dynamic-means-buffer-size/","excerpt":"","text":"https://mpitutorial.com/tutorials/dynamic-receiving-with-mpi-probe-and-mpi-status/ get received msg lenMPI_Status structure The three primary pieces of information include: The rank of the sender. .MPI_SOURCE The tag of the message. .MPI_TAG The length of the message. The length of the message does not have a predefined element in the status structure. Instead, we have to find out the length of the message with MPI_Get_count. MPI_Get_count( MPI_Status* status, MPI_Datatype datatype, int* count) #include &lt;mpi.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; int main(int argc, char** argv) &#123; MPI_Init(NULL, NULL); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); if (world_size != 2) &#123; fprintf(stderr, &quot;Must use two processes for this example\\n&quot;); MPI_Abort(MPI_COMM_WORLD, 1); &#125; int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); const int MAX_NUMBERS = 100; int numbers[MAX_NUMBERS]; int number_amount; if (world_rank == 0) &#123; // Pick a random amount of integers to send to process one srand(time(NULL)); number_amount = (rand() / (float)RAND_MAX) * MAX_NUMBERS; // Send the amount of integers to process one MPI_Send(numbers, number_amount, MPI_INT, 1, 0, MPI_COMM_WORLD); printf(&quot;0 sent %d numbers to 1\\n&quot;, number_amount); &#125; else if (world_rank == 1) &#123; MPI_Status status; // Receive at most MAX_NUMBERS from process zero MPI_Recv(numbers, MAX_NUMBERS, MPI_INT, 0, 0, MPI_COMM_WORLD, &amp;status); // After receiving the message, check the status to determine how many // numbers were actually received MPI_Get_count(&amp;status, MPI_INT, &amp;number_amount); // Print off the amount of numbers, and also print additional information // in the status object printf(&quot;1 received %d numbers from 0. Message source = %d, tag = %d\\n&quot;, number_amount, status.MPI_SOURCE, status.MPI_TAG); &#125; MPI_Barrier(MPI_COMM_WORLD); MPI_Finalize(); &#125; MPI_Probeyou can use MPI_Probe to query the message size before actually receiving it. MPI_Probe( int source, int tag, MPI_Comm comm, MPI_Status* status) #include &lt;mpi.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;time.h&gt; int main(int argc, char** argv) &#123; MPI_Init(NULL, NULL); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); if (world_size != 2) &#123; fprintf(stderr, &quot;Must use two processes for this example\\n&quot;); MPI_Abort(MPI_COMM_WORLD, 1); &#125; int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); int number_amount; if (world_rank == 0) &#123; const int MAX_NUMBERS = 100; int numbers[MAX_NUMBERS]; // Pick a random amont of integers to send to process one srand(time(NULL)); number_amount = (rand() / (float)RAND_MAX) * MAX_NUMBERS; // Send the amount of integers to process one MPI_Send(numbers, number_amount, MPI_INT, 1, 0, MPI_COMM_WORLD); printf(&quot;0 sent %d numbers to 1\\n&quot;, number_amount); &#125; else if (world_rank == 1) &#123; MPI_Status status; // Probe for an incoming message from process zero MPI_Probe(0, 0, MPI_COMM_WORLD, &amp;status); // When probe returns, the status object has the size and other // attributes of the incoming message. Get the size of the message. MPI_Get_count(&amp;status, MPI_INT, &amp;number_amount); // Allocate a buffer just big enough to hold the incoming numbers int* number_buf = (int*)malloc(sizeof(int) * number_amount); // Now receive the message with the allocated buffer MPI_Recv(number_buf, number_amount, MPI_INT, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(&quot;1 dynamically received %d numbers from 0.\\n&quot;, number_amount); free(number_buf); &#125; MPI_Finalize(); &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"mpi block send and receive","slug":"mpi-block-send-and-receive","date":"2023-04-01T01:56:00.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/04/01/mpi-block-send-and-receive/","link":"","permalink":"http://example.com/2023/04/01/mpi-block-send-and-receive/","excerpt":"","text":"https://mpitutorial.com/tutorials/mpi-send-and-receive/ Overview of sending and receiving with MPIA-&gt;B MPI’s send and receive calls operate in the following manner. First, process A decides a message needs to be sent to process B. Process A then packs up all of its necessary data into a buffer for process B. These buffers are often referred to as envelopes since the data is being packed into a single message before transmission (similar to how letters are packed into envelopes before transmission to the post office). After the data is packed into a buffer, the communication device (which is often a network) is responsible for routing the message to the proper location. The location of the message is defined by the process’s rank. Even though the message is routed to B, process B still has to acknowledge that it wants to receive A’s data. Once it does this, the data has been transmitted. Process A is acknowledged that the data has been transmitted and may go back to work. 更准确来说： the MPI specification says that MPI_Send blocks until the send buffer can be reclaimed. This means that MPI_Send will return when the network can buffer the message. If the sends eventually can’t be buffered by the network, they will block until a matching receive is posted. however, a big enough network buffer should never be assumed. Sometimes there are cases when A might have to send many different types of messages to B. Instead of B having to go through extra measures to differentiate all these messages, MPI allows senders and receivers to also specify message IDs with the message (known as tags). When process B only requests a message with a certain tag number, messages with different tags will be buffered by the network until B is ready for them. MPI_Send( void* data, int count, MPI_Datatype datatype, int destination, int tag, MPI_Comm communicator) MPI_Recv( void* data, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm communicator, MPI_Status* status) The first argument is the data buffer. The second and third arguments describe the count and type of elements that reside in the buffer. MPI_Send sends the exact count of elements, and MPI_Recv will receive at most the count of elements (more on this in the next lesson). The fourth and fifth arguments specify the rank of the sending&#x2F;receiving process and the tag of the message. The sixth argument specifies the communicator and the last argument (for MPI_Recv only) provides information about the received message. Elementary MPI datatypesThe MPI_Send and MPI_Recv functions utilize MPI Datatypes as a means to specify the structure of a message at a higher level. MPI datatype C equivalent MPI_SHORT short int MPI_INT int MPI_LONG long int MPI_LONG_LONG long long int MPI_UNSIGNED_CHAR unsigned char MPI_UNSIGNED_SHORT unsigned short int MPI_UNSIGNED unsigned int MPI_UNSIGNED_LONG unsigned long int MPI_UNSIGNED_LONG_LONG unsigned long long int MPI_FLOAT float MPI_DOUBLE double MPI_LONG_DOUBLE long double MPI_BYTE char you will learn how to create your own MPI datatypes for characterizing more complex types of messages. example program: ringIn this example, a value is passed around by all processes in a ring-like fashion // Author: Wes Kendall // Copyright 2011 www.mpitutorial.com // This code is provided freely with the tutorials on mpitutorial.com. Feel // free to modify it for your own use. Any distribution of the code must // either provide a link to www.mpitutorial.com or keep this header intact. // // Example using MPI_Send and MPI_Recv to pass a message around in a ring. // #include &lt;mpi.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; int main(int argc, char** argv) &#123; // Initialize the MPI environment MPI_Init(NULL, NULL); // Find out rank, size int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &amp;world_rank); int world_size; MPI_Comm_size(MPI_COMM_WORLD, &amp;world_size); // The ring program initializes a value from process zero, and the value is passed around every single process. // The program terminates when process zero receives the value from the last process. // MPI_Send and MPI_Recv will block until the message has been transmitted. // Because of this, the printfs should occur by the order in which the value is passed. // block的含义：A发消息给B，A会一直block在MPI_Send上直到收到B给A的acknowledgement，此时A继续执行MPI_Send之后的代码 // 代码阅读方式：点中心 // 先假装自己world_rank!=0，看程序是啥逻辑 // 会block在MPI_Recv上知道收到它上家传来的token，然后它会把收到的token发送给下家，它会block在MPI_Send上直到它下家确认收到了，然后它就结束 // 然后假装自己world_rank==0，看程序是啥逻辑 // 它会给下家发送token，发送完了之后就等待接收上家的消息：block在MPI_Recv上，收到之后就结束 int token; // Receive from the lower process and send to the higher process. Take care // of the special case when you are the first process to prevent deadlock. if (world_rank != 0) &#123; MPI_Recv(&amp;token, 1, MPI_INT, world_rank - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(&quot;Process %d received token %d from process %d\\n&quot;, world_rank, token, world_rank - 1); &#125; else &#123; // Set the token&#39;s value if you are process 0 token = -1; &#125; MPI_Send(&amp;token, 1, MPI_INT, (world_rank + 1) % world_size, 0, MPI_COMM_WORLD); // Now process 0 can receive from the last process. This makes sure that at // least one MPI_Send is initialized before all MPI_Recvs (again, to prevent // deadlock) if (world_rank == 0) &#123; MPI_Recv(&amp;token, 1, MPI_INT, world_size - 1, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(&quot;Process %d received token %d from process %d\\n&quot;, world_rank, token, world_size - 1); &#125; MPI_Finalize(); &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"31","slug":"daily-2023-3-31","date":"2023-03-31T06:12:33.000Z","updated":"2023-04-01T02:34:09.000Z","comments":true,"path":"2023/03/31/daily-2023-3-31/","link":"","permalink":"http://example.com/2023/03/31/daily-2023-3-31/","excerpt":"","text":"今日目标： 上午整理idea文档（救命）中午：看ccg论文 下午组会大创材料（救民 杀了我 杀了我） 晚上学mpi多节点跑mpi敏感性分析学习 来自4.1的记录：昨晚由于不想搞大创+突然想明天穿裙子，于是出去逛街了hhh然后回来的时候路过唱歌亭就进去唱了几首最近想唱但是从来没有唱过的歌hhh","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"敏感性分析（Sensitivity Analysis）","slug":"敏感性分析（Sensitivity-Analysis）","date":"2023-03-31T06:09:41.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/31/敏感性分析（Sensitivity-Analysis）/","link":"","permalink":"http://example.com/2023/03/31/%E6%95%8F%E6%84%9F%E6%80%A7%E5%88%86%E6%9E%90%EF%BC%88Sensitivity-Analysis%EF%BC%89/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/38568075 假设模型表示为 y &#x3D; f(x1, x2, …, xn)，敏感性分析就是令每个属性在可能的范围变动，研究和预测这些属性的变化对模型输出值的影响程度。 我们将影响程度的大小称为该属性的敏感性系数，敏感性系数越大，就说明属性对模型输出的影响越大。 一般来讲对于神经网络的敏感性分析方法可以分为变量敏感性分析、样本敏感性分析两种，变量敏感性分析用来检验输入属性变量对模型的影响程度，样本敏感性分析用来研究具体样本对模型的重要程度，也是敏感性分析研究的一个新方向。","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"30","slug":"daily-2023-3-30","date":"2023-03-30T07:15:01.000Z","updated":"2023-03-31T06:12:21.000Z","comments":true,"path":"2023/03/30/daily-2023-3-30/","link":"","permalink":"http://example.com/2023/03/30/daily-2023-3-30/","excerpt":"","text":"今日目标： 上午今天有够摆烂hh 上午打算学习下mpi，但是由于不是一开始就看很棒的教程而是绕弯路看维基百科和openmpi的文档，导致效率不够高；中午室友聚餐，然后中午就进入一种很放松的状态刷微博；下午和学委碰头交形策作业，很舒服的旅行状态hh；然后就是干很不动脑子的实验数据整理和补充，以及对齐idea文档今天这样感觉时间花了却既没有产出也没有收获！（开发和思考idea都会有产出，同时也会有收获，学习也会有收获） 下午晚上好啦operf牛逼 发现实现问题然后晚上把结果跑得很好看！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"open mpi 学习","slug":"open-mpi-学习","date":"2023-03-30T01:57:43.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/30/open-mpi-学习/","link":"","permalink":"http://example.com/2023/03/30/open-mpi-%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"conceptsMPI uses the notion of process rather than processor. Program copies are mapped to processors by the MPI runtime.Each process has its own rank(用于在程序中indentify这是哪个process), the total number of processes in the world, and the ability to communicate between them either with point-to-point (send&#x2F;receive) communication, or by collective communication among the group Derived data types 定义传递数据的数据类型Many MPI functions require that you specify the type of data which is sent between processes. This is because MPI aims to support heterogeneous environments where types might be represented differently on the different nodes[16] (for example they might be running different CPU architectures that have different endianness), in which case MPI implementations can perform data conversion.[16] Since the C language does not allow a type itself to be passed as a parameter, MPI predefines the constants MPI_INT, MPI_CHAR, MPI_DOUBLE to correspond with int, char, double, etc. Here is an example in C that passes arrays of ints from all processes to one. The one receiving process is called the “root” process, and it can be any designated process but normally it will be process 0. All the processes ask to send their arrays to the root with MPI_Gather, which is equivalent to having each process (including the root itself) call MPI_Send and the root make the corresponding number of ordered MPI_Recv calls to assemble all of these arrays into a larger one:[17] int send_array[100]; int root = 0; /* or whatever */ int num_procs, *recv_array; MPI_Comm_size(comm, &amp;num_procs); recv_array = malloc(num_procs * sizeof(send_array)); MPI_Gather(send_array, sizeof(send_array) / sizeof(*send_array), MPI_INT, recv_array, sizeof(send_array) / sizeof(*send_array), MPI_INT, root, comm); However, you may instead wish to send data as one block as opposed to 100 ints. To do this define a “contiguous block” derived data type: MPI_Datatype newtype; MPI_Type_contiguous(100, MPI_INT, &amp;newtype); MPI_Type_commit(&amp;newtype); MPI_Gather(array, 1, newtype, receive_array, 1, newtype, root, comm); For passing a class or a data structure, MPI_Type_create_struct creates an MPI derived data type from MPI_predefined data types, as follows: int MPI_Type_create_struct(int count, int *blocklen, MPI_Aint *disp, MPI_Datatype *type, MPI_Datatype *newtype) where: count is a number of blocks, and specifies the length (in elements) of the arrays blocklen, disp, and type. blocklen contains numbers of elements in each block, disp contains byte displacements of each block, type contains types of element in each block. newtype (an output) contains the new derived type created by this function The disp (displacements) array is needed for data structure alignment, since the compiler may pad the variables in a class or data structure. The safest way to find the distance between different fields is by obtaining their addresses in memory. This is done with MPI_Get_address, which is normally the same as C’s &amp; operator but that might not be true when dealing with memory segmentation.[18] Passing a data structure as one block is significantly faster than passing one item at a time, especially if the operation is to be repeated. This is because fixed-size blocks do not require serialization during transfer.[19] Given the following data structures: struct A &#123; int f; short p; &#125;; struct B &#123; struct A a; int pp, vp; &#125;; Here’s the C code for building an MPI-derived data type: static const int blocklen[] = &#123;1, 1, 1, 1&#125;; static const MPI_Aint disp[] = &#123; offsetof(struct B, a) + offsetof(struct A, f), offsetof(struct B, a) + offsetof(struct A, p), offsetof(struct B, pp), offsetof(struct B, vp) &#125;; static MPI_Datatype type[] = &#123;MPI_INT, MPI_SHORT, MPI_INT, MPI_INT&#125;; MPI_Datatype newtype; MPI_Type_create_struct(sizeof(type) / sizeof(*type), blocklen, disp, type, &amp;newtype); MPI_Type_commit(&amp;newtype); example c codeIn this example, we send a “hello” message to each processor, manipulate it trivially, return the results to the main process, and print the messages. /* &quot;Hello World&quot; MPI Test Program */ #include &lt;assert.h&gt; #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;mpi.h&gt; int main(int argc, char **argv) &#123; char buf[256]; int my_rank, num_procs; /* Initialize the infrastructure necessary for communication */ MPI_Init(&amp;argc, &amp;argv); /* Identify this process */ MPI_Comm_rank(MPI_COMM_WORLD, &amp;my_rank); /* Find out how many total processes are active */ MPI_Comm_size(MPI_COMM_WORLD, &amp;num_procs); /* Until this point, all programs have been doing exactly the same. Here, we check the rank to distinguish the roles of the programs */ if (my_rank == 0) &#123; int other_rank; printf(&quot;We have %i processes.\\n&quot;, num_procs); /* Send messages to all other processes */ for (other_rank = 1; other_rank &lt; num_procs; other_rank++) &#123; sprintf(buf, &quot;Hello %i!&quot;, other_rank); MPI_Send(buf, 256, MPI_CHAR, other_rank, 0, MPI_COMM_WORLD); &#125; /* Receive messages from all other processes */ for (other_rank = 1; other_rank &lt; num_procs; other_rank++) &#123; MPI_Recv(buf, 256, MPI_CHAR, other_rank, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); printf(&quot;%s\\n&quot;, buf); &#125; &#125; else &#123; /* Receive message from process #0 */ MPI_Recv(buf, 256, MPI_CHAR, 0, 0, MPI_COMM_WORLD, MPI_STATUS_IGNORE); assert(memcmp(buf, &quot;Hello &quot;, 6) == 0); /* Send message to process #0 */ sprintf(buf, &quot;Process %i reporting for duty.&quot;, my_rank); MPI_Send(buf, 256, MPI_CHAR, 0, 0, MPI_COMM_WORLD); &#125; /* Tear down the communication infrastructure */ MPI_Finalize(); return 0; &#125; When run with 4 processes, it should produce the following output:[47] $ mpicc example.c &amp;&amp; mpiexec -n 4 ./a.out We have 4 processes. Process 1 reporting for duty. Process 2 reporting for duty. Process 3 reporting for duty. Here, mpiexec is a command used to execute the example program with 4 processes, each of which is an independent instance of the program at run time and assigned ranks (i.e. numeric IDs) 0, 1, 2, and 3. The name mpiexec is recommended by the MPI standard, although some implementations provide a similar command under the name mpirun. The MPI_COMM_WORLD is the communicator that consists of all the processes. 更多例子和教程https://mpitutorial.com/tutorials/mpi-hello-world/zh_cn/","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"获取c builtin array 内置数组的长度 sizeof","slug":"获取c-builtin-array-内置数组的长度-sizeof","date":"2023-03-30T01:43:51.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/30/获取c-builtin-array-内置数组的长度-sizeof/","link":"","permalink":"http://example.com/2023/03/30/%E8%8E%B7%E5%8F%96c-builtin-array-%E5%86%85%E7%BD%AE%E6%95%B0%E7%BB%84%E7%9A%84%E9%95%BF%E5%BA%A6-sizeof/","excerpt":"","text":"int main() &#123; int send_array[100]; cout &lt;&lt; sizeof(send_array) &lt;&lt; endl; // 整个数组在栈上占的字节数 400 cout &lt;&lt; sizeof(send_array) / sizeof(*send_array) &lt;&lt; endl; // 数组长度 100 int *arr = new int[100]; cout &lt;&lt; sizeof(arr) &lt;&lt; endl; // arr这个指针在栈上占的字节数 8 delete[] arr; return 0; &#125;","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"29","slug":"daily-2023-3-29","date":"2023-03-29T01:41:12.000Z","updated":"2023-03-29T13:59:44.000Z","comments":true,"path":"2023/03/29/daily-2023-3-29/","link":"","permalink":"http://example.com/2023/03/29/daily-2023-3-29/","excerpt":"","text":"昨天摆烂，主要是思考了怎么解决路径过长的问题，然而并没有像前天一样有思路性的突破，只是完善了细节，并且做了些prmitive的实验验证解决方案的部分可行性 昨天刷微博和Xhs去了hhh今日目标：调试完idea原型并上大数据集跑看看是否有路径长度的缩减；hw单机内存解决；学习MPI；（有时间的话，ccg论文十个机器学习算法学习+python实现学习） 上午上午赖床+刷手机摆烂到9:50才开始正事hhh这连续两天的摆烂说明，在遇到没啥正反馈且必须去做的事情很可能是负反馈的时候，我就会逃避hh 1,2,3,4 好棒！粗略的idea有戏！貌似更快了！ 下午 1,2,3,4 果然还是会有bug的hh，暴露了bibfs_connect的disjoint风险问题，修改和debug 5,6,7 调完所有bug跑完结果然后晚餐属于是暴饮暴食奖励hhhh 晚上（由于晚餐吃多了所以去湘江边走了一趟x） 1时间817.861560.128567.137 路径长度（jump_when_first_meet）uk-2005 569 552 17arabic-2005 167 148 19twitter-2010 8 3 4","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"ROC AUC","slug":"ROC-AUC","date":"2023-03-27T08:58:01.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/27/ROC-AUC/","link":"","permalink":"http://example.com/2023/03/27/ROC-AUC/","excerpt":"","text":"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc ROC curveThis curve plots two parameters:True Positive Rate (recall)False Positive Rate An ROC curve plots TPR vs. FPR at different classification thresholds. 给不同的thresholds，会影响一个样本是分到positive类还是negative类 AUCAUC measures the entire two-dimensional area underneath the entire ROC curve (think integral calculus) from (0,0) to (1,1).AUC provides an aggregate measure of performance across all possible classification thresholds AUC ranges in value from 0 to 1. A model whose predictions are 100% wrong has an AUC of 0.0; one whose predictions are 100% correct has an AUC of 1.0.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"27","slug":"daily-2023-3-27","date":"2023-03-27T00:49:47.000Z","updated":"2023-03-27T07:34:41.000Z","comments":true,"path":"2023/03/27/daily-2023-3-27/","link":"","permalink":"http://example.com/2023/03/27/daily-2023-3-27/","excerpt":"","text":"今日目标：在实际大数据集上跑真实点对，检查idea正确性；思考目前idea输出路径过长的解决方法；help臭臭狗（发来的文献+文献中涉及的算法复习下）；（有时间的话，思考下hw下一步怎么走） 上午debug impltest large graph brtree indexdebug offline and testrerun index testtest brtree idea on all vp, and record time 下午grasp resultpath too long exact numberccg’s paper 晚上think and analyze path too long","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"26","slug":"daily-2023-3-26","date":"2023-03-26T00:25:23.000Z","updated":"2023-03-27T00:49:39.000Z","comments":true,"path":"2023/03/26/daily-2023-3-26/","link":"","permalink":"http://example.com/2023/03/26/daily-2023-3-26/","excerpt":"","text":"昨天上午把idea核心code写完啦！下午把核心code的部分分支测试完成，但是离线部分出现奇怪bug，晚上看铃芽之旅，晚上回来调试定位bug是啥今日目标：idea离线部分debug完成并且上大数据集跑；idea在线部分造数据测试所有分支 上午 1院士讲座 下午晚上今日目标全部完成，并且在调试在线时发现idea的问题并修正并编码，不过尚未调试","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"24","slug":"daily-2023-3-24","date":"2023-03-24T06:00:58.000Z","updated":"2023-03-26T00:25:48.000Z","comments":true,"path":"2023/03/24/daily-2023-3-24/","link":"","permalink":"http://example.com/2023/03/24/daily-2023-3-24/","excerpt":"","text":"今日目标： 上午hw测试与优化 下午 1 idea在线文档 晚上晚上开写idea code！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"vim find count 计数查找","slug":"vim-find-count-计数查找","date":"2023-03-23T02:38:35.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/23/vim-find-count-计数查找/","link":"","permalink":"http://example.com/2023/03/23/vim-find-count-%E8%AE%A1%E6%95%B0%E6%9F%A5%E6%89%BE/","excerpt":"","text":"https://stackoverflow.com/questions/49297579/how-to-count-search-results-in-vim You can count the number of matches using the n flag in the substitute command. Use the following to show number of times that some-word matches text in current buffer: :%s/some-word//gn","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"23","slug":"daily-2023-3-23","date":"2023-03-23T01:47:38.000Z","updated":"2023-03-24T06:01:54.000Z","comments":true,"path":"2023/03/23/daily-2023-3-23/","link":"","permalink":"http://example.com/2023/03/23/daily-2023-3-23/","excerpt":"","text":"今日目标：找到多线程没有scaleup的原因；scaleup之后跑十亿；做ppt（算法和时间内存性能）；有时间的话，写idea的code 上午 1,2 优化board safety的锁（两种）run+operf 3,4,5 数据生成脚本修改（去除不用的属性） 测试新生成数据是否可以 分析不scaleup的原因，测试任务划分粒度 下午1000上跑， operf safty_no_lock&amp;&amp;thread32factor1 对比safty_lock&amp;&amp;thread32factor15和safty_no_lock&amp;&amp;thread32factor1，最快的跑十亿 晚上 hw做ppt（fast）没有scaleup的原因分析 明明task函数中锁相关的时间仅占10%，但是32线程只是加快到原先的13倍（若去除锁相关时间，也只是加快14倍） 计算时间主要是从spine reach leaf的过程的时间 而且奇怪的是，8线程几乎只加倍了2倍，所以看起来也不是竞争的原因 不是线性scaleup说明有串行依赖，哪里有呢？ 新算法更慢（由于每个tsk1要一个board_safty副本，因此tsk1划分为每个线程一个）：无锁，但是tsk1结束之后再来合并各个线程的风险信息，然后再tsk2？ ideacode写在线文档 实际上晚上是开发到了12：30把内存优化到了比原来一半还少~","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"cpp读写锁 reader-writer-lock","slug":"cpp读写锁-reader-writer-lock","date":"2023-03-22T08:40:45.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/22/cpp读写锁-reader-writer-lock/","link":"","permalink":"http://example.com/2023/03/22/cpp%E8%AF%BB%E5%86%99%E9%94%81-reader-writer-lock/","excerpt":"","text":"examplehttps://stackoverflow.com/questions/244316/reader-writer-locks-in-cSince C++ 17 (VS2015) you can use the standard: #include &lt;shared_mutex&gt; typedef std::shared_mutex Lock; typedef std::unique_lock&lt;Lock&gt; WriteLock; typedef std::shared_lock&lt;Lock&gt; ReadLock; Lock myLock; void ReadFunction() &#123; ReadLock r_lock(myLock); //Do reader stuff &#125; void WriteFunction() &#123; WriteLock w_lock(myLock); //Do writer stuff &#125; std::shared_mutexIf one thread has acquired the exclusive lock (through lock, try_lock), no other threads can acquire the lock (including the shared). If one thread has acquired the shared lock (through lock_shared, try_lock_shared), no other thread can acquire the exclusive lock, but can acquire the shared lock. Only when the exclusive lock has not been acquired by any thread, the shared lock can be acquired by multiple threads. Within one thread, only one lock (shared or exclusive) can be acquired at the same time. Shared mutexes are especially useful when shared data can be safely read by any number of threads simultaneously, but a thread may only write the same data when no other thread is reading or writing at the same time. std::shared_lockshared mutex ownership wrapperLocking a shared_lock locks the associated shared mutex in shared mode (to lock it in exclusive mode, std::unique_lock can be used) std::unique_lockmutex ownership wrapper","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"cpp线程池 basic threadpool","slug":"cpp线程池-basic-threadpool","date":"2023-03-22T03:56:57.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/22/cpp线程池-basic-threadpool/","link":"","permalink":"http://example.com/2023/03/22/cpp%E7%BA%BF%E7%A8%8B%E6%B1%A0-basic-threadpool/","excerpt":"","text":"#ifndef _THREADPOOL_H #define _THREADPOOL_H #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; #include &lt;vector&gt; #include &lt;queue&gt; #if TIME_KILL_ENABLE == 1 extern bool is_time_out; #endif // #if TIME_KILL_ENABLE == 1 /* 1. worker() routine keeps fetch task from taskq until stop 2. TaskType requirement: default constructor; move constructor; move assignment operator 3. void TaskFunc(void* pointer_to_threadpool, void* pointer_to_task) */ template &lt;typename TaskType&gt; class ThreadPool &#123; std::vector&lt;std::thread&gt; workers; bool stop; // main_thread-&gt;worker_thread: notify worker thread to out of endless loop std::queue&lt;TaskType&gt; taskq; std::mutex taskq_mut; std::condition_variable taskq_nempty_cond; // notify queue not empty TaskFuncType TaskFunc; private: // endless loop to fetch task from taskq, if fetch one then execute the task void worker() &#123; while (1) &#123; TaskType tsk; &#123; std::unique_lock&lt;std::mutex&gt; lock(taskq_mut); // lock taskq_mut // wait for taskq be nonempty or stop(will sleep and release lock when waiting) taskq_nempty_cond.wait(lock, [this]() &#123; return stop || !taskq.empty() #if TIME_KILL_ENABLE == 1 || is_time_out #endif ; &#125;); if ((stop &amp;&amp; taskq.empty()) #if TIME_KILL_ENABLE == 1 || is_time_out #endif ) // worker stop here return; tsk = std::move(taskq.front()); taskq.pop(); // unlock taskq_mut &#125; TaskFunc(this, &amp;tsk); &#125; &#125; public: // worker_thread_num: besides main_thread ThreadPool(ThreadNumType worker_thread_num, std::queue&lt;TaskType&gt; &amp;&amp;taskq, TaskFuncType TaskFunc) : stop(0), taskq(std::move(taskq)), TaskFunc(TaskFunc), &#123; for (ThreadNumType i = 0; i &lt; worker_thread_num; ++i) workers.emplace_back(&amp;ThreadPool::worker, this); &#125; ~ThreadPool() &#123; &#123; std::lock_guard&lt;std::mutex&gt; lock(taskq_mut); stop = 1; &#125; taskq_nempty_cond.notify_all(); // then all worker thread will wake up and find stop==1 then end their routine(return from func worker, after finishing work queue) // wait for all workers and output thread ends for (auto &amp;th : workers) th.join(); &#125; void push_taskq(TaskType tsk) &#123; std::lock_guard&lt;std::mutex&gt; lock(taskq_mut); // lock taskq_mut taskq.emplace(std::move(tsk)); taskq_nempty_cond.notify_one(); // unlock taskq_mut &#125; &#125;; #endif //_THREADPOOL_H","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"22","slug":"daily-2023-3-22","date":"2023-03-22T00:20:01.000Z","updated":"2023-03-22T13:24:49.000Z","comments":true,"path":"2023/03/22/daily-2023-3-22/","link":"","permalink":"http://example.com/2023/03/22/daily-2023-3-22/","excerpt":"","text":"今日目标：上午完成单线程debug和massif和operf；下午和晚上完成多线程code+debug 上午 1,2,3,4 check start and spine_ty semantics follow one small case for debug 5,6,7,8 打桩 operf+massif 9,10 put collect into output run+operf 下午 1 分析operf 新的逻辑run+operf 新的choice code+run+operf 2,3,4 分析operf 设计和code多线程 晚上 1,2,3 code多线程 debug 打桩 run(8 thread)+operf(operf貌似不需要) run 32 thread去休息一下！ 4 不分线程operf，寻找没有scale up的原因 写一个最暴力的，仅依赖config信息，验证输出正确性 massif on choice3test_321.00% parent.resize Case2Tree.cpp:12013.32% old_spine_id.push_back Case2Tree.cpp:10929.97%+16.61% old_spine_id2new[ty][old_id] Case2Tree.cpp:108 operf on choice3lambda:Case2Tree::Graph::risky(std::vector&lt;unsigned int, std::allocator &gt;, std::vector&lt;Case2Tree::Graph::BoardSafty, std::allocatorCase2Tree::Graph::BoardSafty &gt;, std::__cxx11::basic_string&lt;char, std::char_traits, std::allocator &gt; const&amp;)::{lambda()#3}::operator()() const 数字在这里 not define PUT_COLLECT_TO_OUTPUTreach_from_spine: 2,263,230us39.4811 self12.1398 visited[] parent[] boardId[] leaf_offset[]3.2950 board_safty[] scan_safety(reset_visited): 42,471us45.7143 self8.5714 board_safty[] collect_pattern(scan_visited): 4,469,802us39.8587 edges[].push_back()24.3866 self4.9051 visited[] parent[]4.5813 edges[] (edges has pre-allocate) define PUT_COLLECT_TO_OUTPUTreach_from_spine&#x2F;scan_safety和not define一样 collect_pattern(scan_visited): 1,638,658us40.1552 self19.5567 visited[] parent[] new define PUT_COLLECT_TO_OUTPUT (comment ptn_belong[parent[v]] = leaf;)reach_from_spine&#x2F;scan_safety和not define一样 collect_pattern(scan_visited): 1,115,422us43.3635 self13.1032 visited[] parent[] operf on new choice3lambda:Case2Tree::Graph::risky(std::vector&lt;unsigned int, std::allocator &gt;, std::vector&lt;Case2Tree::Graph::BoardSafty, std::allocatorCase2Tree::Graph::BoardSafty &gt;, std::__cxx11::basic_string&lt;char, std::char_traits, std::allocator &gt; const&amp;)::{lambda()#2}::operator()() const 数字在这里 reach_from_spine: 3,243,857us33.5102 self 1,083,44815.2549 init visited 493,06613.5878 visited[] parent[] ptn_belong[] 441,164 boardId[] leaf_offset[]2.1331 board_safty[] 69,094 scan_safety: 36,062us45.9459 self8.1081 board_safty[] no collect_pattern operf on multi thread32 threadTask: 40% on lock related23.7422 self15.0670 shared_lock12.8931 ~shared_lock8.5413 parent[] visited[] ptn_belong[]6.0671 unique_lock5.7564 ~unique_lock1.0691 visited_mut[] board_safty_mut[]","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"data race 数据竞争","slug":"data-race-数据竞争","date":"2023-03-21T10:36:20.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/21/data-race-数据竞争/","link":"","permalink":"http://example.com/2023/03/21/data-race-%E6%95%B0%E6%8D%AE%E7%AB%9E%E4%BA%89/","excerpt":"","text":"data race常见举例：https://yourbasic.org/golang/data-races-explained/ 向相同的地址写同样的值是否存在数据竞争：https://stackoverflow.com/questions/8315931/does-writing-the-same-value-to-the-same-memory-location-cause-a-data-race read-modify-writesThere is a race, but in your example both threads will write the same values to the same addresses. Since you are not doing any read-modify-writes, but just writing predetermined numbers, this will be safe in most cases. Writing an int will be an atomic instruction on most systems. The exception would be if you ran this code on a 8-bit microprocessor that uses a sequence of instructions to store an int. In that case it also may still work, but depends on the implementation of the library code that does the multi-byte store.","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"21","slug":"daily-2023-3-21","date":"2023-03-21T01:06:41.000Z","updated":"2023-03-22T08:47:34.000Z","comments":true,"path":"2023/03/21/daily-2023-3-21/","link":"","permalink":"http://example.com/2023/03/21/daily-2023-3-21/","excerpt":"","text":"今日目标：性能瓶颈弄清楚，单线程版优化；设计和开写多线程版周二 三 四（做ppt） 加油！ 上午 1 operf分线程2500x 2operf结论： 下午毕设中期答辩 1 operf choice1，确定单线程的优化方向 思考choice1(visited数组)和choice2(visited集合)哪个更适合多线程 都少不了这个竞争，差不多 2 重新对比潜力：choice2可以避免锁，决定优化这个和写这个的多线程 得到choice3（晚上继续想想！） 晚上 1 设计choice3算法 2 code choice3 3 code choice3: besides graph load 4 code choice3: graph load 5 debug choice3 operf分析结论：实现choice1+choice2&#x3D;choice3:step1：从spine沿父亲搜索到interface，(为每个spine记录interface，并)更新board_safety[leaf]board，同时维护全顶点visited数组(内容是可达的interface)用于优化搜索 board_safety: CSR: leaf_offset, board_safety 可以设计成(Vertex,bool)是因为，如果&lt;2个spine可达这个boardId，则最多只有一个spine可达，之后用来去除visited信息时有这个spine信息就可以 读文件leaf-&gt;interface类型边时，分配board_safety 多线程：多个spine一个线程， per visited[v] a lock 读写锁（读者多+visited[v]只会有一个写者） per board_safety[leaf][board] a lock 读写锁step2：对于board_safety[leaf][board]bool&#x3D;&#x3D;0的spine，走到interface一路把visited数组清零（这样等下扫visited数组构造时就不会加入这些spine-&gt;leaf的路径了），发现visited[v]已经是0了则不用继续走 此过程没有data race，因为都是写成0，即使写相同的visited[v]也没问题；而对于读，不可能读到假的零，而若读到假的非零，也只是变身写者然后扫描visited数组，(visited[v]是interface)根据visited[v].leaf将p[v]-&gt;v记录到对应pattern step1:Case2Tree::Graph::risky(std::__cxx11::basic_string&lt;char, std::char_traits, std::allocator &gt; const&amp;)::{lambda()#1}::operator()() conststep2:Case2Tree::Graph::risky(std::__cxx11::basic_string&lt;char, std::char_traits, std::allocator &gt; const&amp;)::{lambda()#2}::operator()() constoutput_edges:Case2Tree::Graph::output_edges(std::vector&lt;unsigned int, std::allocator &gt;&amp;, unsigned long, Case2Tree::Graph::OutputType, std::ostream&amp;) choice2(not record path when search)step1: 5,053,860us 一个线程x个spine，perleaf[leaf][board] per lock(由于预先不知道每个board有多少spine，因此不能提前画好位置)36.095% map[]: perleaf[v][bdid] (perleaf[v]:mapspines&gt;) create entry in perleaf[v] for each meeting board 解决方案：pre-allocate21.6855% perleaf[v][bdid].push_back push_back spine to leaf’s board 解决方案：每个leaf的board的spine的bool数组：不对，我预先不知道每个board有多少spine perleaf结构修改：为每个spine记录可达的interface即可，perleaf[v][bdid]改成++13.0142% self8.1145% isEnable[] 2.7896% std::_Bit_reference::operator bool() const 解决方案：可以仅map isEnable&#x3D;&#x3D;1的spine，不过要存储中间漏了哪些，用于翻译回string-id2.4856% parent[] boardId[] lower bound: 125,335us step2(normal output): 72,152,582us 一个线程一个leaf’s board，无锁45.8412% output_edges39,683,920us:22.6213% visited.insert15.5867% visited.count2.8535% ~unordered_set(visited) 解决方案：全顶点visited数组替代unordered_set 且多线程的时候(一个leaf’s board一个线程)，不同的(leaf,board)一个visited数组即可，因为不同的(leaf,board)之间顶点没有交集，不会有竞争2.1778% self0.6288% append_edge lower bound: 249,532us0.3643% parent[] lower bound: 144,568us choice1(record path when search)若有办法把属于一个leaf’s board(或者属于同一个leaf)的spine放在一个线程里面，这里就不需要锁了 由spine.isEnable可以知道spine是否可以到达某leafstep1: 9,852,573us 理想的是只要visited[] parent[] boardId[]40.5746% map[]: perleaf[v][bdid] (perleaf[v]:mapedges&gt;) create entry in perleaf[v] for each meeting board 解决方案：pre-allocate17.5239% perleaf[v][bdid].push_back lower bound: 1,724,200us push_back edges to leaf’s board9.9925% self9.2607% std::vector visited(start[node_ty_num], (VertexIdType)-1ull); init visited 解决方案：由于interface的vertex-id不等于0（可以在图加载时控制），初始化不用全bit1，0可以4.4837% isEnable[] 1.4993% std::_Bit_reference::operator bool() const 解决方案：可以仅map isEnable&#x3D;&#x3D;1的spine，不过要存储中间漏了哪些，用于翻译回string-id 这样还可以缩短self的时间2.1628% visited[] parent[] boardId[] lower bound: 212,815us step2: 132,514,316us94.3131% output_edges1.1779% ostream::flush for we delete file?0.9913% std::basic_filebuf&lt;char, std::char_traits &gt;::sync()~1% std::basic_ostream3,975,429us:map.erase…","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"20","slug":"daily-2023-3-20","date":"2023-03-20T01:09:21.000Z","updated":"2023-03-20T12:33:22.000Z","comments":true,"path":"2023/03/20/daily-2023-3-20/","link":"","permalink":"http://example.com/2023/03/20/daily-2023-3-20/","excerpt":"","text":"今日目标：hw debug and test done (run large dataset if possible) 上午 1 code 非定长和非固定path schema 发现貌似不需要hhh 但是咱还是都写写啦 2 去除对path schema的依赖 3 去除对path schema的依赖 下午 1 debug hw 2 debug hw 怎么验证输出的正确性？即输出的是有风险的（一个boardId可以到达&gt;&#x3D;2个isEnable的spine），且有风险的都已经输出了（所有leaf；每个leaf的所有boardId；每个boardId的所有isEnable的spine） 3 gen large dataset and massif on small datasetmassif: test_376.15% parent.resize Case2Tree.cpp:7102.19% isEnable.push_back Case2Tree.cpp:5206.56% perleaf.push_back(add spine) Case2Tree.cpp:13505.25% perleaf[](add boardId entry) Case2Tree.cpp:135 4(half) code idea offline (add dfs tree) 晚上 1 run 2500x add output modify path record 2,3 2500x时间不ok，根据打桩调整代码逻辑洗头+毕设中期材料","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"19","slug":"daily-2023-3-19","date":"2023-03-19T01:00:10.000Z","updated":"2023-03-19T13:11:42.000Z","comments":true,"path":"2023/03/19/daily-2023-3-19/","link":"","permalink":"http://example.com/2023/03/19/daily-2023-3-19/","excerpt":"","text":"今日目标：上午完成毕设中期准备，希望今天可以开始code hw新算法！ 上午 1 read question preparation read ccks 2 read ccks read code 3 read code + ppt 下午 1 code hw new idea接林老师 晚上 1 code hw search 2 code hw prefix design 3 code load 4","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"18","slug":"daily-2023-3-18","date":"2023-03-18T00:58:34.000Z","updated":"2023-03-19T01:00:00.000Z","comments":true,"path":"2023/03/18/daily-2023-3-18/","link":"","permalink":"http://example.com/2023/03/18/daily-2023-3-18/","excerpt":"","text":"今日目标：idea离线部分完成；进阶：idea全部完成调试 上午 1 reform bc-decomp and test read layering code 2，3 code 下午调试完离线（然后跑离线，记录时间和内存）hw项目回顾 1 debug layer code debug code 2 code debug code 3 debug done! 晚上希望：数据性质获取；中规模上跑indexfree（监控内存和时间）；index打桩时间；中规模上跑index（监控内存和时间） 1 hw数据集生成脚本阅读和使用 2 观察数据集性质 3 code for schema 4 观察schema 5 确认schema","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"17","slug":"daily-2023-3-17","date":"2023-03-17T01:26:03.000Z","updated":"2023-03-17T14:09:54.000Z","comments":true,"path":"2023/03/17/daily-2023-3-17/","link":"","permalink":"http://example.com/2023/03/17/daily-2023-3-17/","excerpt":"","text":"3.14中午-3.16 臭臭狗来长沙 呜呜呜三天太幸福了呜呜呜 今天回归现实今日目标：完成毕设中期准备 上午 1 毕设中期（浏览资料和参考） 中期ppt制作（框架和目前工作主框架） 2 决定毕设放弃大盘hhhh 读代码（一点点） 读ccks2022我的论文（摘要+导引） 毕设预期（咱得有个清晰的目标还有不同层次的小目标以及对不同层次是否要达到的必要性的预期） 下午组会 晚上 1 复习idea离线部分 code 2 code 3 reform bc decompose 4 debug bc decompose明天上午完成idea的offline部分！并且希望可以开始写idea部分！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-3-14","date":"2023-03-14T01:05:07.000Z","updated":"2023-03-14T03:02:27.000Z","comments":true,"path":"2023/03/14/daily-2023-3-14/","link":"","permalink":"http://example.com/2023/03/14/daily-2023-3-14/","excerpt":"","text":"今日目标： 上午 1 思考idea 2 检索LCA确定 debug test 3 debug test1,test2,test3 4 debug texti_nx 5 打桩测时间+massif分析（现在内存占用大） 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"LCA","slug":"LCA","date":"2023-03-14T01:04:52.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/14/LCA/","link":"","permalink":"http://example.com/2023/03/14/LCA/","excerpt":"","text":"https://cp-algorithms.com/graph/lca.html Before answering the queries, we need to preprocess the tree. We make a DFS traversal starting at the root and we build a list $\\text{euler}$ which stores the order of the vertices that we visit (a vertex is added to the list when we first visit it, and after the return of the DFS traversals to its children). This is also called an Euler tour of the tree. It is clear that the size of this list will be $O(N)$ .We also need to build an array $\\text{first}[0..N-1]$ which stores for each vertex $i$ its first occurrence in $\\text{euler}$ .Also by using the DFS we can find the height of each node (distance from root to it) and store it in the array $\\text{height}[0..N-1]$ . LCA(v1,v2):Consider the vertices that we visit in the Euler tour between the first visit of $v_1$ and the first visit of $v_2$ .the $\\text{LCA}(v_1, v_2)$ is the vertex with the lowest height on this path So the $\\text{LCA}(v_1, v_2)$ can be uniquely determined by finding the vertex with the smallest height in the Euler tour between $\\text{first}(v_1)$ and $\\text{first}(v_2)$ .-&gt; RMQ problem (finding the minimum in an range)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"13","slug":"daily-2023-3-13","date":"2023-03-13T01:24:24.000Z","updated":"2023-03-13T14:10:15.000Z","comments":true,"path":"2023/03/13/daily-2023-3-13/","link":"","permalink":"http://example.com/2023/03/13/daily-2023-3-13/","excerpt":"","text":"今日目标：尽量完成调试，因为和臭臭狗一起玩的时候愿意想idea但是完全不愿意调试！ 上午 1(请求一个单位来思考idea hhh) 多点对思考又有进展了！真.分析-&gt;idea！ 2(我还是想思考idea hhh) think debug 下午 1 debug test (one cc) 2 debug test done! 晚上 1 思考idea 2 test1 (one cc, less cutpoint, larger block) test2 (same as above + no solution) 3,4 test3 (same as above)改了一点逻辑，明天重新debugtest1_2x (two cc)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"树的高度","slug":"树的高度","date":"2023-03-12T02:56:11.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/12/树的高度/","link":"","permalink":"http://example.com/2023/03/12/%E6%A0%91%E7%9A%84%E9%AB%98%E5%BA%A6/","excerpt":"","text":"https://www.geeksforgeeks.org/roots-tree-gives-minimum-height/Given an undirected graph, which has tree characteristics (any connected graph without simple cycles is a tree.). It is possible to choose any node as root, the task is to find those nodes only which minimize the height of tree. Example:In below diagram all node are made as root one by one, we can see that when 3 and 4 are root, height of tree is minimum(2) so {3, 4} is our answer. We can solve this problem by first thinking about the 1-D solution, that is if the longest graph is given, then the node which will minimize the height will be mid node if total node count is odd or mid-two-node if total node count is even. This solution can be reached by the following approach – Start two pointers from both ends of the path and move one step each time until pointers meet or one step away, at the end pointers will be at those nodes which will minimize the height because we have divided the nodes evenly so the height will be minimum. The same approach can be applied to a general tree also. The center lies in the middle of diameter of this tree. Start pointers from all leaf nodes and move one step inside each time, keep combining pointers which overlap while moving, at the end only one pointer will remain on some vertex or two pointers will remain at one distance away. Those nodes represent the root of the vertex which will minimize the height of the tree. So we can have only one root or at max two roots for minimum height depending on tree structure as explained above. For the implementation we will not use actual pointers instead we’ll follow BFS like approach, In starting all leaf node are pushed into the queue, then they are removed from the tree, next new leaf node is pushed in the queue, this procedure keeps on going until we have only 1 or 2 node in our tree, which represent the result. another solution:https://stackoverflow.com/questions/4020122/finding-center-of-the-tree run 2 BFS: Select any vertex v1 on your tree. Run BFS from this vertex. The last vertex (v2) you will proceed will be the furthest vertex from v1. Now run another BFS, this time from vertex v2 and get the last vertex v3. The path from v2 to v3 is the diameter of the tree and your center lies somewhere on it. More precisely it lies in the middle of it","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"12","slug":"daily-2023-3-12","date":"2023-03-12T02:29:55.000Z","updated":"2023-03-13T01:24:08.000Z","comments":true,"path":"2023/03/12/daily-2023-3-12/","link":"","permalink":"http://example.com/2023/03/12/daily-2023-3-12/","excerpt":"","text":"今日目标：完成部分debug和自己想啥时候思考idea就可以无条件去思考idea 上午 1 思考glpn路径长度的bound 2 思考glpn路径长度的bound 简单检索最小化dfs树高度 3 看之前检索过的红蓝树论文，检查idea 下午献血+摆烂+思考idea（新的方向，更厉害了！） 晚上 1 2009TON充分理解（并没有hhh） 1，2 brain storm idea!","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"c++模板类申明（在定义前申明）","slug":"c-模板类申明（在定义前申明）","date":"2023-03-11T13:35:02.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/11/c-模板类申明（在定义前申明）/","link":"","permalink":"http://example.com/2023/03/11/c-%E6%A8%A1%E6%9D%BF%E7%B1%BB%E7%94%B3%E6%98%8E%EF%BC%88%E5%9C%A8%E5%AE%9A%E4%B9%89%E5%89%8D%E7%94%B3%E6%98%8E%EF%BC%89/","excerpt":"","text":"在一些情况下我们先定义类A，再定义类B（这样的定义顺序是因为类B有个成员函数返回类型A（而不是A的引用或指针）），但是在类A中有一个数据成员的类型是类B的引用，此时便需要在类A的定义前先申明B // 申明模板类Graph template &lt;typename BatchSetType&gt; class Graph; // 定义模板类BlockCutTree template &lt;typename BatchSetType&gt; class BlockCutTree &#123; friend Graph&lt;BatchSetType&gt;; // 友元模板类Graph const Graph&lt;BatchSetType&gt; &amp;g; // 模板类Graph的引用类型 public: BlockCutTree(const Graph&lt;BatchSetType&gt; &amp;g):g(g)&#123;&#125; &#125;; // 定义模板类Graph template &lt;typename BatchSetType&gt; class Graph &#123; public: BlockCutTree&lt;BatchSetType&gt; func(); // 返回模板类BlockCutTree类型的参数 &#125;;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"11","slug":"daily-2023-3-11","date":"2023-03-11T01:09:52.000Z","updated":"2023-03-11T13:58:26.000Z","comments":true,"path":"2023/03/11/daily-2023-3-11/","link":"","permalink":"http://example.com/2023/03/11/daily-2023-3-11/","excerpt":"","text":"今日目标：完成code编写（剩下debug） 上午 1,2,3,4 code block-cut-decompose中午读了几篇费曼的发现的乐趣，艹，费曼真的人生导师，写的话要么产生共鸣要么超级有道理！有启发我怎么研究问题，“我知道真正弄懂一件事情有多难 我知道弄懂一件事情意味着什么 他们没有做足够的工作，没有充分的检验，做的实验也不够严谨 因此我知道他们没有完全弄懂” 下午阴差阳错地思考科研idea，有进展！爬岳麓山hhh 岳麓山风景一般般，但是就算再一般的有历史的山，山上都有很多树木，很多古树，古树让岳麓山有意思起来！ 晚上 1 code block-cut-decompose for one cc and outline 2 code outline and fill CSR of block-cut-tree 3 code track_path code msbibfs: search part 4 code msbibfs: track part code msbfs_path pass compile 先调试通过再打桩测时间今天的主要代码工作都是改代码（即之前写过类似的函数，复制过来然后修改），一点成就感都没有！还好今天科研有进展！研究问题，弄明白问题！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"二连通图 two-connected-graph biconnected-graph","slug":"二连通图-two-connected-graph-biconnected-graph","date":"2023-03-10T08:46:11.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/10/二连通图-two-connected-graph-biconnected-graph/","link":"","permalink":"http://example.com/2023/03/10/%E4%BA%8C%E8%BF%9E%E9%80%9A%E5%9B%BE-two-connected-graph-biconnected-graph/","excerpt":"","text":"https://www.techiedelight.com/2-vertex-connectivity-graph/http://www.cs.rpi.edu/~goldberg/14-GT/08-block.pdf 无向图DFSWe can find Articulation points in a graph using Depth–first search (DFS).We can say that the graph is 2–vertex connected if and only if for every vertex u in the graph, there is at least one back-edge that is going out of the subtree rooted at u to some ancestor of u. When we say subtree rooted at u, we mean all u’s descendants (excluding vertex u).In other words, when we backtrack from a vertex u, we need to ensure that there is some back-edge from some descendant (children) of u to some ancestor (parent or above) of u.There is an exception to this rule for the root of the tree. If the root has more than one child, then it is an articulation point; otherwise, not. for an edge u —&gt; v, to check whether u is articulation point or not we run DFS on v How can we modify DFS so that we can check if there is a back-edge going out of every subtree rooted at u?We can modify DFS such that DFS(v) returns the smallest arrival time to which there is a back edge from the subtree rooted at v (including v) to some ancestor of vertex u “the smallest arrival time”其实即low point 二连通图上DFS的例子二连通图上dfs树的一个例子（下图中的GLPV其实即low point） 无向图DFS树的高度boundlower boundhttps://cs.stackexchange.com/questions/12851/upper-bound-on-the-number-of-edges-relative-to-the-height-of-a-dfs-tree Let T be a depth-first search tree of a connected undirected graph G and h be the height of T.After running a DFS, all the edges in G can be classified as tree edges or back edges. Each back edge connects a vertex on the tree to one of it’s ancestors. For each vertex it can point to at most h−1 ancestors, thus you can have at most (h−1)|V| back edges. There are |V|−1 tree edges. You can have at most h|V|−1 edges.therefore, |E|&lt;&#x3D;h|V|-1 -&gt;h&gt;&#x3D;(|E|+1)&#x2F;|V|","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"10","slug":"daily-2023-3-10","date":"2023-03-10T01:10:44.000Z","updated":"2023-03-10T14:03:29.000Z","comments":true,"path":"2023/03/10/daily-2023-3-10/","link":"","permalink":"http://example.com/2023/03/10/daily-2023-3-10/","excerpt":"","text":"今日目标： 上午 1 code Index: prove and design algorithm 2 code Index: init seen and queue in bctree 3 code Index: msbfs例会 下午组会+思考独立路径idea 很久没想了，现在没有压力了，感觉不会被原先Idea框架束缚住 研究它！有很多东西可以insight和检验！ 晚上 1 code Index: outline 2 code Index: expand 3 code Index: expand 4 code Index: only leave three function to fill~","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"use git in debug mode git输出详细过程信息","slug":"use-git-in-debug-mode-git输出详细过程信息","date":"2023-03-09T10:52:42.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/09/use-git-in-debug-mode-git输出详细过程信息/","link":"","permalink":"http://example.com/2023/03/09/use-git-in-debug-mode-git%E8%BE%93%E5%87%BA%E8%AF%A6%E7%BB%86%E8%BF%87%E7%A8%8B%E4%BF%A1%E6%81%AF/","excerpt":"","text":"https://www.shellhacks.com/git-verbose-mode-debug-fatal-errors/ Git Verbose Mode in Linux&#x2F;MacOSDebug Git command: $ GIT_TRACE=true \\ GIT_CURL_VERBOSE=true \\ GIT_SSH_COMMAND=&quot;ssh -vvv&quot; \\ git clone git://host.xz/path/to/repo.git # or other git command Debug Git-related issues with the maximum level of verbosity: $ GIT_TRACE=true \\ GIT_CURL_VERBOSE=true \\ GIT_SSH_COMMAND=&quot;ssh -vvv&quot; \\ GIT_TRACE_PACK_ACCESS=true \\ GIT_TRACE_PACKET=true \\ GIT_TRACE_PACKFILE=true \\ GIT_TRACE_PERFORMANCE=true \\ GIT_TRACE_SETUP=true \\ GIT_TRACE_SHALLOW=true \\ git clone git://host.xz/path/to/repo.git","categories":[{"name":"tools","slug":"tools","permalink":"http://example.com/categories/tools/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"c++时间测量 chrono","slug":"c-时间测量-chrono","date":"2023-03-09T02:41:39.000Z","updated":"2023-11-15T07:34:07.000Z","comments":true,"path":"2023/03/09/c-时间测量-chrono/","link":"","permalink":"http://example.com/2023/03/09/c-%E6%97%B6%E9%97%B4%E6%B5%8B%E9%87%8F-chrono/","excerpt":"","text":"microseconds, us std::chrono::microseconds has_tag_delete_time = std::chrono::microseconds::zero(); auto d_t0 = std::chrono::steady_clock::now(); // do something auto d_t1 = std::chrono::steady_clock::now(); has_tag_delete_time += std::chrono::duration_cast&lt;std::chrono::microseconds&gt;(d_t1-d_t0); long long t = has_tag_delete_time.count(); tools.h #include &lt;chrono&gt; #define TIME_MEASURE_SZ 5 template &lt;typename UnitType&gt; // std::chrono::nanoseconds, microseconds, milliseconds, seconds ... class TimeMeasure &#123; std::chrono::_V2::system_clock::time_point start; int idx; public: static int64_t time_measure[TIME_MEASURE_SZ]; static const char *unit_str; TimeMeasure(int idx) : start(std::chrono::system_clock::now()), idx(idx) &#123;&#125; ~TimeMeasure() &#123; auto end = std::chrono::system_clock::now(); UnitType duration = std::chrono::duration_cast&lt;UnitType&gt;(end - start); // see here time_measure[idx] += duration.count(); &#125; &#125;; main.cpp #include &quot;tools.h&quot; template &lt;typename UnitType&gt; int64_t TimeMeasure&lt;UnitType&gt;::time_measure[TIME_MEASURE_SZ]; template &lt;typename UnitType&gt; const char *TimeMeasure&lt;UnitType&gt;::unit_str = &quot;us&quot;; #define TIME_UNIT std::chrono::microseconds int main() &#123; TimeMeasure&lt;TIME_UNIT&gt;::time_measure[0]=0; &#123; TimeMeasure&lt;TIME_UNIT&gt; ins(0); // do something, measure time take up with unit microseconds &#125; std::cout&lt;&lt;TimeMeasure&lt;TIME_UNIT&gt;::time_measure[0]&lt;&lt;TimeMeasure&lt;TIME_UNIT&gt;::unit_str&lt;&lt;std::endl; return 0; &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"9","slug":"daily-2023-3-9","date":"2023-03-09T01:11:51.000Z","updated":"2023-03-09T13:49:38.000Z","comments":true,"path":"2023/03/09/daily-2023-3-9/","link":"","permalink":"http://example.com/2023/03/09/daily-2023-3-9/","excerpt":"","text":"今日目标： 上午 1 新增细分时间逻辑（不明白为啥leaf数目不变时间却增加） 2 分析大图时间分布 进一步细分 3 时间分布更新代码 发现时间瓶颈啦芜湖！ 新的时间测量（更标准） 4(half) new time unit pretty print interger 下午 1 发现bug，改bug 跑10^6xr和5*10^7xr，根据时间分布得到瓶颈去了趟岳麓书院休息~（妈的图书馆真是个好地方随时半小时就可以旅游一趟hhh） 2 合并获取leaf和spine到graph load中 3 改扫描逻辑（config macro control），重新测试时间分布 新的优化果然有用！分析时间分布yyds！下午去湘江边上转了趟~枯水期河床露出来了，下面超级安静！ 晚上 1 check result of big graph gen new big graph and run solve some problem related to git 2 review and modify Index code 3 review and modify Index code 4 review and modify Index code 开发完无索引算法后，现在果然对这个问题的情形相当的熟悉和清楚hhhh舒服！（拖了几天的和老师微信汇报今天终于发出去了hhh然后居然是秒回+对线）大哥要多和导师对线一下，像以前和李老师那样，对线多了就觉得没啥且可以充分发挥聪明才智 5(half) 明天： （老师提醒我了，可以）找一些公开的运维网络的数据集测试下 或者公路网，这可能也挺相似的 索引算法的开发","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"少用vector<vector>","slug":"少用vector-vector","date":"2023-03-08T02:53:47.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/03/08/少用vector-vector/","link":"","permalink":"http://example.com/2023/03/08/%E5%B0%91%E7%94%A8vector-vector/","excerpt":"","text":"massif分析实践表明，vector&lt;vector&lt;builtin-type&gt;&gt;要比CSR 两个vector&lt;builtin-type&gt;占用的内存大很多，尤其当nbrs部分和offset部分仅2、3倍的时候，vector&lt;vector&gt;的第一层vector开销的内存甚至可以占第二层vector的3倍","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"8","slug":"daily-2023-3-8","date":"2023-03-08T01:26:34.000Z","updated":"2023-03-08T14:31:38.000Z","comments":true,"path":"2023/03/08/daily-2023-3-8/","link":"","permalink":"http://example.com/2023/03/08/daily-2023-3-8/","excerpt":"","text":"今日目标： 上午 1chao! massif太好用了！ 18.25% nbrs 67 07.98% offset 66 07.98% label 29 07.97% spines 354 05.32% agg_owner 106 05.32% aggs[].push_back 51 31.90% aggs.emplace_back 46 - 内存分布，修改aggs结构 2 测试新修改 看逐渐增长的内存来源 3 根据分析结果调整 还是感叹，massif太牛了！！ get新的分析 4 继续优化 01.28% lf_can_reach_spine[lf].assign(jed, 0); 576 18.65% nbrs 93 08.16% offset 92 08.16% label 29 05.44% aggs 66 03.50% agg_offset 58 04.24% agg_owner 138 12.10%([])+09.08%(emplace_back) patterns 652 04.66%(reserve 369)+01.55%(emplace_back 376) leaf2fault 369 376 02.12% spines 363 01.06% leaves 365 02.37% batches 389 - 优化后1500x重新massif测试 更新后，test3_10000x：加载完图划分完batch之后是峰值： Graph.cpp 23.86% nbrs 93 10.44% offset 92 10.44% label 29 06.96% aggs 66 04.47% agg_offset 58 06.52% agg_owner 138 IndexFree.cpp 03.26%(push_back 386) leaf2fault 386 03.26% spines 363 01.63% leaves 365 tools.h 11.93% list.emplace_back in knapsack 131 01.91% batches.back().leafs.emplace_back() 132 02.61% merge batch, push_back one batch to another 176 04.89% to_del 175 稳定运行时： 32.04% nbrs 93 14.02% offset 92 14.02% label 29 09.34% aggs 66 06.01% agg_offset 58 08.75% agg_owner 138 04.37%(push_back) leaf2fault 386 01.34%(reserve) leaf2fault_offset 370 04.37% spines 363 02.19% leaves 365 01.25% lf_can_reach_spine[lf].assign(jed, 0) 595 最后： 32.44% nbrs 93 14.19% offset 92 14.19% label 29 09.46% aggs 66 06.08% agg_offset 58 08.86% agg_owner 138 04.43%(push_back) leaf2fault 386 01.35%(reserve) leaf2fault_offset 370 04.43% spines 363 02.21% leaves 365 下午 1 改划分Batch的内存消耗list为vector 可能在读完顶点就进行，然后再读CSR 2 测试new batches profile新的 3 分析profile 发现仍然有bug 晚上 1 batches新的优化code+debug git push问题解决 2 分析优化list后的内存分布（主要看list那块的占用有没有下来） 确实有噢 服务器上跑test3_1000000xr 3(half) 分析test3_1000000xr内存占用（评估跑5*10^7xr的可能性）test3_1000000xr快到最后峰值运行时（n&#x3D;&#x3D;23） 41.32% nbrs 93 18.08% offset 92 18.08% label 29 12.05% aggs 66 07.75% agg_offset 58 02.71% agg_owner 138 n&#x3D;&#x3D;33(趋势同n&#x3D;&#x3D;23) 502,431KBn&#x3D;&#x3D;61(peak) 569,535KB 图存储类上 08.84% spines 363 4 上大图跑test3_50000000xr最后heap 42.48% nbrs 93 18.58% offset 92 18.58% label 29 12.39% aggs 66 07.96% agg_offset 58 回顾index方法代码","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"7","slug":"daily-2023-3-7","date":"2023-03-07T10:49:51.000Z","updated":"2023-03-07T12:52:56.000Z","comments":true,"path":"2023/03/07/daily-2023-3-7/","link":"","permalink":"http://example.com/2023/03/07/daily-2023-3-7/","excerpt":"","text":"今日目标： 上午思考translate（由test3启发的） 下午新的图存储 晚上目标：通过小测试和中测试，开始跑10亿大图，明天开始开发二连通分量分解算法 1 over新的图存储相关代码更新 generate small case 2，3，4 generate test debug test","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"6","slug":"daily-2023-3-6","date":"2023-03-06T01:43:15.000Z","updated":"2023-03-09T13:43:53.000Z","comments":true,"path":"2023/03/06/daily-2023-3-6/","link":"","permalink":"http://example.com/2023/03/06/daily-2023-3-6/","excerpt":"","text":"今日目标： 上午 1 add output time average over leaf run test1_c15000x 确认查询定义 严重怀疑hw老师觉得问题弱智不回答hhh（xx 快中午的时候破案了：原因是周末hhh 2 debug test3 下午 1，2 和导师汇报进度，咨询师兄分布式 3 学习师姐的CSR 晚上 改现在graph load，占用内存太大了，可以处理存储文件（咱们生成的时候就可以好好写，写成nbr+offset） 直接存原图nbr+offset（这个信息可以用来在transfer图上travel和翻译；agg给vertex id从N开始；agg2interface-nodes） 生成10亿点10亿边的数据，测试 一个leaf 100leaf 7bit 0 0-1 0-4 0-15 18 18-8 18-13 邹老师好，华为项目中独立路径部分的进度如下： 1.进展：已开发单机版程序，在我生成的数据上能满足时延要求（10亿点10亿边），内存尚未达标（是要求的2倍） 2.问题：①数据和性质尚未给到；②除了单机版的，还需要开发分布式版的，这方面我没有经验需要学习；③单机版内存不达标 3.下一步：①进一步优化目前程序（时延和内存）；②学习和开发分布式版本；③数据给到之后重新测试单机时延是否达标；④想到了另一个算法，实现下单机版看看 华为项目这边李友焕老师几乎没有参与，邹老师有问题直接问我就可以~ 艹 居然是秒回！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"profile memory takeup 测量程序内存占用","slug":"profile-memory-takeup-测量程序内存占用","date":"2023-03-05T08:21:05.000Z","updated":"2023-08-08T06:23:44.000Z","comments":true,"path":"2023/03/05/profile-memory-takeup-测量程序内存占用/","link":"","permalink":"http://example.com/2023/03/05/profile-memory-takeup-%E6%B5%8B%E9%87%8F%E7%A8%8B%E5%BA%8F%E5%86%85%E5%AD%98%E5%8D%A0%E7%94%A8/","excerpt":"","text":"内存占用峰值：time -f$ /usr/bin/time -f &quot;%M KB&quot; &lt;command_and_args&gt; 注意给time传递参数的时候，bash user需要给定time的绝对路径time -f ... ...会报错-f: command not found，这实际上uses an internal version of time, provided as a shell keyword Users of the bash shell need to use an explicit path in order to run the external time command and not the shell builtin variant. time输出程序运行的time memory IOhttps://man7.org/linux/man-pages/man1/time.1.html man time: it output lots of usefulinformation, not only about time used, but also on otherresources like memory, I&#x2F;O and IPC calls (where available). Theoutput is formatted using a format string that can be specifiedusing the -f option or the TIME environment variable. Memory%M Maximum resident set size of the process during its lifetime, in Kbytes.%t (Not in tcsh(1).) Average resident set size of the process, in Kbytes.%K Average total (data+stack+text) memory use of the process, in Kbytes.%F Number of major page faults that occurred while the process was running. These are faults where the page has to be read in from disk. time%e (Not in tcsh(1).) Elapsed real time (in seconds). IO time命令的输出重定向到文件的方法https://blog.csdn.net/rong11417/article/details/87932769#%E6%97%A0%E6%95%88%E7%9A%84%E4%BE%8B%E5%AD%90%EF%BC%91 time是输出到标准错误的单一的 &gt; 和 &gt;&gt; 符号默认只会重新定向标准输出。 使用 1 代表标准输入，2 代表标准错误。或者使用&amp;&gt; 同时将标准输入和标准输出重定向 $ rm none-exit-file 2&gt; error.log # 将错误输出到error.log文件中 $ ls 1&gt; output.log 2&gt; error.log # 将标准输出流导入文件output.log，将标准错误输出到error.log $ ls &amp;&gt; output_error.log # 将标准输出和标准错误指向同一个文件。 详细堆内存&#x2F;all内存占用：massif 超级好用！优化程序内存占用的时候再也不用手工检查哪些地方是瓶颈了！https://valgrind.org/docs/manual/ms-manual.htmlis shipped within Valgrind.By default Massif measures only heap memory, i.e. memory allocated with malloc, calloc, realloc, memalign, new, new[], and a few other, similar functions. (And it can optionally measure stack memory, --stacks=yes) This means it does not directly measure memory allocated with lower-level system calls such as mmap, mremap, and brk.if you wish to measure all the memory used by your program, you can use the --pages-as-heap=yes (then Massif’s normal heap block profiling is replaced by lower-level page profiling: Every page allocated via mmap and similar system calls is treated as a distinct block) 使用方法 compile with debugging info (the -g option) run Massif itself to gather the profiling information valgrind --tool=massif prog # The program will execute (slowly) # output to file massif.out.&lt;pid&gt; # --massif-out-file run ms_print to present it in a readable way. ms_print massif.out.&lt;pid&gt; ms_print will produce(a) a graph showing the memory consumption over the program’s execution - By default, Massif uses “instructions executed” as the unit of time(b) detailed information about the responsible allocation sites at various points in the program, including the point of peak memory allocation. Each vertical bar represents a snapshot, i.e. a measurement of the memory usage at a certain point in time. ms_print得到(a)图 Note that for very short-run programs, most of the graph empty, with only a couple of bars at the very end: most of the executed instructions involve the loading and dynamic linking of the program. The execution of main (and thus the heap allocations) only occur at the very end. For a short-running program like this, we can use the --time-unit=B option to specify that we want the time unit to instead be the number of bytes allocated&#x2F;deallocated on the heap and stack(s). bar字符的含义： Most snapshots are normal, and only basic information is recorded for them. Normal snapshots are represented in the graph by bars consisting of ‘:’ characters. Some snapshots are detailed. Information about where allocations happened are recorded for these snapshots, as we will see shortly. Detailed snapshots are represented in the graph by bars consisting of ‘@’ characters. The text at the bottom show that 3 detailed snapshots were taken for this program (snapshots 9, 14 and 24). By default, every 10th snapshot is detailed, although this can be changed via the –detailed-freq option. ms_print得到的(b)snapshot info注意，每个snapshot的内存占比来源分析，都是当前快照下内存的全部实际来源，而不是仅仅看此快照和上一个快照时间之间执行的代码申请的内存噢！所以超级好用！比如我好奇峰值的时候内存分布，直接去看峰值snapshot的内存来源分析就可以了！normal snapshot The next snapshot is detailed. As well as the basic counts, it gives an allocation tree which indicates exactly which pieces of code were responsible for allocating heap memory: 下面最后部分的含义：n&#x3D;14的snapshots的主要堆内存占用from three different code locations: line 20, which is responsible for 10,000B (49.74%); line 5, which is responsible for 8,000B (39.79%); and line 10, which is responsible for 2,000B (9.95%).","categories":[{"name":"tools","slug":"tools","permalink":"http://example.com/categories/tools/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"5","slug":"daily-2023-3-5","date":"2023-03-05T00:55:30.000Z","updated":"2023-03-05T12:12:03.000Z","comments":true,"path":"2023/03/05/daily-2023-3-5/","link":"","permalink":"http://example.com/2023/03/05/daily-2023-3-5/","excerpt":"","text":"今日目标：new case和测试；test1旋转生成15000x(2leaf, 45000faults and 30000faults)-&gt;平行生成大图，测试（时间和内存占用） 上午 1 generate new case 2 debug new case 3 debug new case: pass new case 4 (just parallel) scale_up.py -&gt; cpp 下午 1 generate test_c15000x_5000x (10^9 nodes) learn profile memory take up of program 2 learn profile memory 3 run test_c15000x 晚上 1,2 check result of test1_c15000x add time measure run test2_15000x","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"4","slug":"daily-2023-3-4","date":"2023-03-04T01:33:26.000Z","updated":"2023-03-04T14:01:50.000Z","comments":true,"path":"2023/03/04/daily-2023-3-4/","link":"","permalink":"http://example.com/2023/03/04/daily-2023-3-4/","excerpt":"","text":"今日目标：基础版indexfree完成测试，并运行大图（可能的话设计多线程，注意一定要想清楚再开始coding） 上午 1 写代码比对输出结果 2 debug cross batch可能解决了！下午写python比对下scale up结果对不对，然后再跑下22x的看看cross batch现象以及对不对 下午 1 比对输出结果 debug 2 debug: 现有的例子全部通过 晚上（吃东西+打电话hhh） 1 generate new case and test 2，3 debug, pass new case","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"3","slug":"daily-2023-3-3","date":"2023-03-03T00:44:48.000Z","updated":"2023-03-03T14:09:43.000Z","comments":true,"path":"2023/03/03/daily-2023-3-3/","link":"","permalink":"http://example.com/2023/03/03/daily-2023-3-3/","excerpt":"","text":"今日目标： 上午 1 debug outline 2 debug msbfs_reach debug lambda 3 debug msbfs_pattern考虑设计更多leaf且是子图的图例来测试（妈的测试原先那个例子居然这么简单hhh说明代码写得好doge） 下午 组会和吃面包x 1 create new test case debug test2 2 debug test2 3 debug test2也测试通过啦！ 晚上 1 generate new case: with leaf cross batches 2，3，4 发现原先算法没有考虑连通分量的漏洞，重写，明天在生成的小例子上重新测试","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"2","slug":"daily-2023-3-2","date":"2023-03-02T02:57:12.000Z","updated":"2023-03-03T00:44:36.000Z","comments":true,"path":"2023/03/02/daily-2023-3-2/","link":"","permalink":"http://example.com/2023/03/02/daily-2023-3-2/","excerpt":"","text":"今日目标：完成小规模调试 上午 1 debug graph load 2 debug graph translate 下午 1 debug batches 2 pass main compile debug bits op 晚上听讲座没有完成今日目标","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"1","slug":"daily-2023-3-1","date":"2023-03-01T01:27:50.000Z","updated":"2023-03-01T13:10:45.000Z","comments":true,"path":"2023/03/01/daily-2023-3-1/","link":"","permalink":"http://example.com/2023/03/01/daily-2023-3-1/","excerpt":"","text":"给自己弄了一个打卡的，上午下午晚上，工作够了时间才可以打勾，不够的要后面补起来（昨天旷工4小时，咱今明补起来呜呜呜）今日目标：无索引基本方法：graph load + test batches + small debug 上午 1 design translate 2 design translate 3 code translate 下午 1 redesign+code translate 2 code translate 3 modify print design+code graph load 晚上 1 code graph load 2 重写误删的batchset test bits_all_zero create small graph case只完成了graph load且连测试都没有搞hhh今天感觉有点被山河令持续影响的感觉","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"28","slug":"daily-2023-2-28","date":"2023-02-28T01:09:52.000Z","updated":"2023-03-01T01:31:04.000Z","comments":true,"path":"2023/02/28/daily-2023-2-28/","link":"","permalink":"http://example.com/2023/02/28/daily-2023-2-28/","excerpt":"","text":"今日目标：完成图加载+main caller+小规模数据生成和调试 上午 1 update index alg caller indexfree alg caller 2 graph load: vertex 下午 1 一些了解人的侦探行为hh 晚上呜呜 昨天中午和晚上看山河令花絮去了然后就旷工了（感觉这种放松没有热情的状态和我开始写无索引基本方法的外周代码+战线拖太长了+俊哲真的好磕有关（呜呜呜他俩真的好 但是内娱有自己对关系的理解和处理 以及一方出了原则性错误 这什么无解 以及也不需要我们完全以常人的关系和相处去期待和看待他们的关系 不过不管怎么说 拍一部戏要4个月，一年的三分之一，演员一生能拍戏的时间不过20年，那么就是最多60部戏，每部中朝夕相处的对手应该多少会留在印象里 何况这还是成名之作以及从综艺来看确实是相互有好感且相处融洽）（艹我觉得哲评价俊俊傻呵呵的 很可爱很真诚，真的很好，我也觉得是这样，我觉得哲真的很喜欢俊俊呜呜呜（说明，此处的喜欢不是磕cp，是像朋友之间相互喜欢那种）真好）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"vscode快捷键","slug":"vscode快捷键","date":"2023-02-27T01:24:12.000Z","updated":"2024-01-29T03:24:30.000Z","comments":true,"path":"2023/02/27/vscode快捷键/","link":"","permalink":"http://example.com/2023/02/27/vscode%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"https://juejin.cn/post/7029129486348058654 笔记本键盘home/end: fn+左右方向键光标移动、选中、删除的规律：ctrl表示以单词为单位 文件&#x2F;目录&#x2F;工作区navigationctrl+R 从最近打开的一些工作区中选择一个打开ctrl+shift+N new window ctrl+P 以文件名搜索当前目录中的文件并打开ctrl+T 以文件内容搜索当前目录中的文件并打开 ctrl+shift+E 键入字母会定位到前缀Matching的目录 代码编辑ctrl+shift+K 删除当前行alt+上/下方向键 把当前行上移&#x2F;下移shift+alt+下方向键 double当前行 ctrl+/ 注释当前行 未熟练掌握ctrl+L 选中当前行（或者双击鼠标）ctrl+X 剪切当前行（或全部选中部分） ctrl+backspace 删除光标前的一个单词ctrl+delete 删除光标后的一个单词 光标移动未熟练掌握撤销光标操作：ctrl+U单位：操作alt+左/右方向键 回到之前&#x2F;之后的光标位置 单位：单词ctrl+左/右方向键 以单词为单位移动光标ctrl+shift+左/右方向键 同上，但是在移动的同时还选中移动经过的范围 单位：行home/end 行首行尾home/end+shift 选中光标到当前行行首&#x2F;行尾CTRL+SHIFT+END/HOME 从选中行开始向上&#x2F;下选中所有行ctrl+shift+上下方向键 选中当前光标到下一行或上一行的相同位置（没有就行首行尾） 单位：代码块Ctrl + Shift + \\ 跳转到当前所在代码块（或其后最近的代码块）的结束处（{}()[]的后括号），然后在这对括号间跳转 单位：符号（比如函数，类等）Ctrl + Shift + . 会出现一个符号列表，上下方向键移动跳转到哪个符号 单位：文件Ctrl + Home/End 文档首尾 单位：问题跳转到下一个&#x2F;上一个问题：F8 &#x2F; Shift + F8 多光标esc：放弃操作，回到之前的一个光标相同元素：ctrl+D 选中元素，然后按下ctrl+D，会选中下一个相同的元素并创建光标；再按再创建，依次类推行的相同位置：ctrl+alt+上/下方向键 复制光标到上下行的相同位置 vscodectrl+shift+P 打开命令面板ctrl+J 打开&#x2F;收起下方的terminal&#x2F;output…ctrl+B 打开&#x2F;收起左方目录树ctrl+shift+右/左方向键 split当前列并把当前文件移动到右边新列中&#x2F;收起 ctrl+, 打开设置ctrl+K, ctrl+T 主题颜色设置","categories":[{"name":"tools","slug":"tools","permalink":"http://example.com/categories/tools/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"27","slug":"daily-2023-2-27","date":"2023-02-27T01:05:08.000Z","updated":"2023-02-28T01:09:41.000Z","comments":true,"path":"2023/02/27/daily-2023-2-27/","link":"","permalink":"http://example.com/2023/02/27/daily-2023-2-27/","excerpt":"","text":"今日目标：完成除了图加载以外的全部基础版无索引算法开发 上午 1 msbfs_pattern: search vscode shortcut learning 2 msbfs_pattern: track: search 下午(看完了山河令 真的很喜欢BL！指耽改的BL，就是程度很清水但是又有端倪的那种hhh) 晚上 1 msbfs_pattern: track: write 2 replace agg node 3 design grouping alg code above 艹除了main中的调用真的完成了今日目标！冲！ 但是晚上的时候大老师貌似跟小老师说觉得没啥进度感觉有点不被信任，不过确实是我还没有和大老师说进度了决定要尽快做完无索引全内存单线程的实验，然后和大老师讲一下进度，并且说明下小老师没有参与（省的小老师这边责任不好搞）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"26","slug":"daily-2023-2-26","date":"2023-02-26T01:42:30.000Z","updated":"2023-02-27T01:04:47.000Z","comments":true,"path":"2023/02/26/daily-2023-2-26/","link":"","permalink":"http://example.com/2023/02/26/daily-2023-2-26/","excerpt":"","text":"今日目标：除了背包部分完成所有的无索引开发（除测试） 上午 1 design pattern construct msbfs code outing of above 2 code+design msbfs_pattern interface 3 determine msbfs_pattern interface code above 下午 1 code msbfs_pattern caller 2 msbfs_pattern caller done 3 merge map reform code: separate index and indexfree method code 晚上 1 msbfs_reach然后和家里打电话+回去洗头啦","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"shift __m128i","slug":"shift-m128i","date":"2023-02-25T12:30:14.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/25/shift-m128i/","link":"","permalink":"http://example.com/2023/02/25/shift-m128i/","excerpt":"","text":"https://stackoverflow.com/questions/34478328/the-best-way-to-shift-a-m128i/34482688#34482688 逻辑右移__m128i reg b比特（逻辑右移reg &gt;&gt; b） __m128i right_shift_128i(__m128i reg, int b)&#123; assert(b&gt;=0 &amp;&amp; b&lt;128); // __m128i _mm_bsrli_si128 (__m128i a, int imm8): Shift a right by imm8 bytes while shifting in zeros __m128i high64 = _mm_bsrli_si128(reg, 8); // high 64 bits of reg shifting to starting from 0th bit if (b &lt; 64) &#123; // high64:low64 -&gt; high64&gt;&gt;b:high64[0:b):low64&gt;&gt;b // _mm_srli_epi64(reg,b) == high64&gt;&gt;b:low64&gt;&gt;b // _mm_slli_epi64(high64,64-b) == 0:high64[0:b):(64-b)bits return _mm_or_si128(_mm_srli_epi64(reg, b), _mm_slli_epi64(high64, 64 - b)); &#125; else // high64bits are shifted to low64bits return _mm_srli_epi64(high64, b - 64); &#125;","categories":[{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"}],"tags":[{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"25","slug":"daily-2023-2-25","date":"2023-02-25T00:28:07.000Z","updated":"2023-02-25T13:09:11.000Z","comments":true,"path":"2023/02/25/daily-2023-2-25/","link":"","permalink":"http://example.com/2023/02/25/daily-2023-2-25/","excerpt":"","text":"今日目标：写完基础版无索引算法 上午 1 思考和更新算法的可扩展性 检查无索引算法，持续修复 2 更新算法描述 思考msbfs实现 3 code indexfree msbfs: 框架 4 code indexfree msbfs: 框架 下午爬岳麓山和吃麦当劳+巧克力蛋糕~（咳咳咳） 晚上 1 code+modify reachable and batches 2 reachable处理 batchset的连续比特操作 3 __m128i right shift 设计msbfs for pattern + code","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"24","slug":"daily-2023-2-24","date":"2023-02-24T00:53:02.000Z","updated":"2023-02-24T12:30:14.000Z","comments":true,"path":"2023/02/24/daily-2023-2-24/","link":"","permalink":"http://example.com/2023/02/24/daily-2023-2-24/","excerpt":"","text":"今日目标：code加载和索引闭环，测试，code无索引方法果然昨天晚上回去就看山河令摆烂了完全没有开发hhhh 上午 1 记录无索引算法和分析实现必要性 rethink indexfree alg create chatgpt acount for ccg 2 rethink indexfree alg rethink the query 班级通知优秀毕业生 3 组会 思考无索引算法 先把有索引的框架和TODO写好，然后写无索引算法 下午 1 fix bfs only in comp bug 写完有索引闭环 2 index alg pass compilation relax: 图书馆里瞎逛，借了一本彩铅画植物的教程书hhh 3 确认query：是否只考虑leaf的一阶邻居聚合顶点中的割点（leaf的一阶邻居中不是聚合顶点的割点是否意味着风险呢） 发现新的考虑情况，重新审视有无索引算法 确认图性质 晚上 1 继续思考和确认关于风险的定义 2 对风险 结果一些触发对面对场景和算法的思考，然后给自己挖坑hhh但是自己的思考可以触发对面的思考，并且可能收获更有挑战且自己会的任务，还是很兴奋+骄傲的！ 根据新得到的关于风险的信息，重新思考算法，更新注释和算法brief","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"23","slug":"daily-2023-2-23","date":"2023-02-23T00:59:57.000Z","updated":"2023-02-23T10:57:50.000Z","comments":true,"path":"2023/02/23/daily-2023-2-23/","link":"","permalink":"http://example.com/2023/02/23/daily-2023-2-23/","excerpt":"","text":"今日目标： 上午 1 get free vpn and chatgpt environment coding first bfs 2 coding second bfs design and coding graph pattern data structure 3 newly design pattern NO done 下午plan: 离线在线写完闭环-[希望今日完成]-&gt;测试NO-&gt;within leaf-&gt;测试-&gt;among leaf 1 play chatgpt plan how to restore aggregate node 2 code restore fix NO 3 output help ccg some problem about IE and vpn 4 design load 晚上 1 fix offset del bug design agg in load","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"22","slug":"daily-2023-2-22","date":"2023-02-22T01:14:51.000Z","updated":"2023-02-22T13:01:55.000Z","comments":true,"path":"2023/02/22/daily-2023-2-22/","link":"","permalink":"http://example.com/2023/02/22/daily-2023-2-22/","excerpt":"","text":"今日目标： 上午 1 设计数据结构实现 2 设计数据结构实现 coding 3 hw例会 下午 1 全内存coding 2 msbfs与否的接口确定 全内存、bctree结构加载&#x2F;计算后的接口 3 实现外围和确定算法：NO层msbfs-&gt;within leaf层-&gt;among leaf层-&gt;离线or在线加载 晚上 1 实现NO 2 实现NO 3 实现NO明天继续实现NO（从实现两个bfs开始，写完这俩就写完NO了）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"21","slug":"daily-2023-2-21","date":"2023-02-21T01:36:58.000Z","updated":"2023-02-22T01:14:28.000Z","comments":true,"path":"2023/02/21/daily-2023-2-21/","link":"","permalink":"http://example.com/2023/02/21/daily-2023-2-21/","excerpt":"","text":"今日目标： 上午 1 确认hw case2的指标和具体查询以及之前的数据集 2 对问题，确认理解查询场景 需要确认：是否允许离线构建索引 3 hw case2 single thread: start 下午 1 重新思考算法 2 思考算法 晚上山河令（艹这部耽改比陈情令还敢）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"20","slug":"daily-2023-2-20","date":"2023-02-20T02:09:48.000Z","updated":"2023-02-20T13:02:39.000Z","comments":true,"path":"2023/02/20/daily-2023-2-20/","link":"","permalink":"http://example.com/2023/02/20/daily-2023-2-20/","excerpt":"","text":"17-19去北京出差（实际上只是去旅行+改ppt）立flag：希望从今天开始，日报只有周六的时候停更今日目标： 上午 1 看gstore lcr源码 下午 1 get windows 番茄钟 gstore开发环境 gstore开发文档确认和测试确认 清除halo博客 清理c盘 2 测试已有的正则路径查询 设计测试查询（修改代码前不能处理的查询） 读gstore源码寻找怎么获取所有的subject和object id 除了上述接口其他部分写好 可能问到了上述接口 3 实现接口中 要破坏封装性好不爽hhh 晚上 1 实现lcr并通过编译 2 测试和修bug 3 解决bug，交付工作","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"B+树","slug":"B-树","date":"2023-02-18T09:23:24.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/18/B-树/","link":"","permalink":"http://example.com/2023/02/18/B-%E6%A0%91/","excerpt":"","text":"","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"写paper学习 Chapter 3 Breaking Up Long Sentences","slug":"写paper学习-Chapter-3-Breaking-Up-Long-Sentences","date":"2023-02-17T05:54:47.000Z","updated":"2024-01-03T14:13:15.000Z","comments":true,"path":"2023/02/17/写paper学习-Chapter-3-Breaking-Up-Long-Sentences/","link":"","permalink":"http://example.com/2023/02/17/%E5%86%99paper%E5%AD%A6%E4%B9%A0-Chapter-3-Breaking-Up-Long-Sentences/","excerpt":"","text":"can process word by word and thus understand the build-up of the author’slogic immediately, rather than only being able to reach their interpretation ofthe whole meaning at the end of the sentence … splitting the sentence up into different units of thought.","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"15","slug":"daily-2023-2-15","date":"2023-02-15T00:57:14.000Z","updated":"2023-02-15T08:56:22.000Z","comments":true,"path":"2023/02/15/daily-2023-2-15/","link":"","permalink":"http://example.com/2023/02/15/daily-2023-2-15/","excerpt":"","text":"今日目标： 上午 1 修改调研ppt的结构：分类 2 修改调研ppt的结构：分类+大纲 3 扫描vldb’23 检查搜集的文章的摘要进行筛选 4 扫描vldb’22’21, sigmod’21 检索PMA资料 下午 1 检索引用graphone的 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"chrome自定义路径安装:默认安装后移动","slug":"chrome自定义路径安装-默认安装后移动","date":"2023-02-14T04:16:25.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/14/chrome自定义路径安装-默认安装后移动/","link":"","permalink":"http://example.com/2023/02/14/chrome%E8%87%AA%E5%AE%9A%E4%B9%89%E8%B7%AF%E5%BE%84%E5%AE%89%E8%A3%85-%E9%BB%98%E8%AE%A4%E5%AE%89%E8%A3%85%E5%90%8E%E7%A7%BB%E5%8A%A8/","excerpt":"","text":"https://blog.csdn.net/yhcwjh/article/details/106806083","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"edge浏览器收藏夹导出到chrome","slug":"edge浏览器收藏夹导出到chrome","date":"2023-02-14T03:55:37.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/14/edge浏览器收藏夹导出到chrome/","link":"","permalink":"http://example.com/2023/02/14/edge%E6%B5%8F%E8%A7%88%E5%99%A8%E6%94%B6%E8%97%8F%E5%A4%B9%E5%AF%BC%E5%87%BA%E5%88%B0chrome/","excerpt":"","text":"edge浏览器中右键收藏夹栏 - 管理收藏夹(manage favorite bar) - 右上角三个点 - 导出(export favorites)，从而导出收藏夹信息保存到html文件 chrome浏览器中 右上角三个点 - 设置(settings) - 导入书签和设置(import bookmarks and settings) - 下拉选择导入源为HTML - 选择从edge浏览器导出的html文件 不推荐的方式：chrome浏览器中”导入书签和设置”选择从edge浏览器导入这种方式通常会有问题","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-2-14","date":"2023-02-14T02:31:01.000Z","updated":"2023-02-14T10:57:24.000Z","comments":true,"path":"2023/02/14/daily-2023-2-14/","link":"","permalink":"http://example.com/2023/02/14/daily-2023-2-14/","excerpt":"","text":"今日目标： 上午 1 读资讯 解决代理git push的问题 科学上网整合到开始屏幕 2 转移edge-&gt;chrome 下午 1 复习时态图调研ppt 检索temporal子图匹配 2 检索temporal子图匹配 3 扫描sigmod2022 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"科学上网存档","slug":"科学上网存档","date":"2023-02-13T15:15:33.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/13/科学上网存档/","link":"","permalink":"http://example.com/2023/02/13/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E5%AD%98%E6%A1%A3/","excerpt":"","text":"windows：https://protonvpn.com/ 是个免费、高颜值、牛逼的vpn 但是这个网站访问可能需要科学上网hhh于是这个时候可以先用下面的仅chrome科学上网的方法访问上面的(- windows chrome: https://github.com/bannedbook/fanqiang/wiki/Chrome%E4%B8%80%E9%94%AE%E7%BF%BB%E5%A2%99%E5%8C%85) 安卓: https://github.com/bannedbook/fanqiang/wiki/%E5%AE%89%E5%8D%93%E7%BF%BB%E5%A2%99%E8%BD%AF%E4%BB%B6","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"火车随笔","slug":"writing-2023-2-13-火车随笔","date":"2023-02-13T13:35:08.000Z","updated":"2023-02-13T13:35:47.000Z","comments":true,"path":"2023/02/13/writing-2023-2-13-火车随笔/","link":"","permalink":"http://example.com/2023/02/13/writing-2023-2-13-%E7%81%AB%E8%BD%A6%E9%9A%8F%E7%AC%94/","excerpt":"","text":"（在火车上看窗外风景想着这一火车人在站台上上下下，有些是学生，到开学时间因此前往学校，可以看到这里有一部分的秩序或者协议导致了这些上上下下，hhh然后不知道为什么就跳到去思考人怎么对社会产生影响这个问题上了hhh）人如何为社会创造价值→人如何对社会产生影响：通过人在社会中的角色 比如小时候人的角色在家是儿女，在校是学生，如果有所超长还可以是作者、博主、艺术家等等，通过角色和社会交互，对这个角色定义所在的范围产生影响（如儿女角色的范围即家庭，孩子的行为对爹妈产生影响）不同的角色以及角色不同的行为对社会产生的影响以及程度有所不同，如多数的普通人产生的影响多对于较小的范围，且持续较短的时间（即较小而不是长远、深远的影响），但有些角色却能影响不仅仅同辈，更至后辈的人类，诸如某项技术或科学发现，一方面在这项智慧成果还直接有用期间，直接对使用到它的人们产生影响（比如港珠澳大桥的设计，细胞呼吸的机理等），另一方面，它也可能作为未来思想的启发或基石，这将进一步在时间和广度上对社会产生影响。还有些具体接地气的例子，曾经建设火车轨道的人，他们建造的轨道如今服务着经过这段铁轨的火车和乘客，同时又提供铁道养护员等工作，这是他们对社会的影戏的一部分，没有他们建造铁轨我们这一车乘客不会有这趟车坐，由此还有其他的基础，这里可以看出来人们确实通过社会紧密的联系在一起，同一时间有许许多多人扮演不同的角色，另外还涉及更早时间点的人们扮演的角色 一个人的人生定位、人生目标、人生意义是怎么回事呢？可以说，人生定位决定人生目标，或者人生定位即人生目标。人生定位，即对于自己每个阶段扮演哪些角色，以及这些角色分别要怎样扮演（秉持怎样的原则，达成怎样的标准）的认识和标定。而人生意义，是自这个人诞生以来至今扮演的所有角色对社会产生的所有影响的累积，所以人生意义不应该说是用来达成的，更合适的说法是人生意义是不断赋予的，不断累积的因此说法应该是思考人生定位，不断积累人生意义当然，思考人生定位的时候，一方面可以根据角色所能达到的上限和自己的预期来设定定位，另一方面可以先确定大致的人生意义，然后根据人生意义所需要实现的程度反推人生定位各个阶段各个角色的标准 本次坐火车看窗外产生有逻辑且非常流畅不卡顿的思考 带来的启发：交通途中，70%的意识可以用于神游的时候，适合思考另外，窗外所见身边所见，是自己开始思考的问题的主要来源之一 这提供给我一个新的视角去评价自己的行为和调节自我评价（比如我容易想起过去一些不尽人意的行为然后苦恼不已，这个时候可以思考下这个片段中我扮演着怎样的角色，我对环境产生了怎样的影响，这样的行为不尽人意是不可原谅的吗），还提供给我思考人生意义的提纲（我想了一下我将来的角色，我会是母亲，妻子，女儿，姐姐，maybe大学教师，maybe科研人员，开发者，志愿者，当然还有一个角色，那就是“我”，比如旅行、做美食等追逐兴趣爱好娱乐的时候我扮演的角色是“我”），还提供了反思自己行为的提纲（比如寒假后半段纵欲看墨家三宝浪了20多天，反思这期间，我主要扮演的角色几乎只有“我”，追逐的乐趣是近乎一次性的追剧磕cp，由此对社会几乎没有产生一点影响，对自己也没有产生积极影响）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"13","slug":"daily-2023-2-13","date":"2023-02-13T01:05:19.000Z","updated":"2023-02-13T12:22:02.000Z","comments":true,"path":"2023/02/13/daily-2023-2-13/","link":"","permalink":"http://example.com/2023/02/13/daily-2023-2-13/","excerpt":"","text":"今日目标： 上午 1 BatchHL 5.2一半 2 BatchHL 5.2 5.3 3 阅读新闻和评论文章 Idea ppt复习（不得不说自己之前做的ppt真的yyds！逻辑清晰，循循善诱，很容易看懂，且信息全面） 下午 1 texstudio基础操作和英语语法检查 2 preview临时文件移除 修改论文语法错误 晚上 1 大致科研计划 复习已写论文垃圾","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"Latex本地开发环境 texlive+texstudio","slug":"Latex本地开发环境-texlive-texstudio","date":"2023-02-12T12:12:43.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/12/Latex本地开发环境-texlive-texstudio/","link":"","permalink":"http://example.com/2023/02/12/Latex%E6%9C%AC%E5%9C%B0%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83-texlive-texstudio/","excerpt":"","text":"https://zhuanlan.zhihu.com/p/80603542 windows安装 安装texlive方法一： 下载install-tl.zip http://mirror.lzu.edu.cn/CTAN/systems/texlive/tlnet/ 解压install-tl.zip 运行install-tl-windows.bat（安装时间较长，&gt;1h）方法二： 下载xxx.iso https://mirrors.tuna.tsinghua.edu.cn/CTAN/systems/texlive/Images/ 解压xxx.iso 运行install-tl-advanced.bat（安装时间较长，&gt;1h） 测试一下是否安装成功：命令行中tex -v 安装texstudio 下载windows installer https://texstudio.sourceforge.net/ 运行 配置：options - configure texstudio - commands和build中配置程序的路径 texstudio使用文档https://texstudio-org.github.io/index.html 编译 F6 查看pdf F7 打开工程：texstudio没有打开工程一说，打开主.tex文件即可，texstudio就会自动识别这个tex文件引用的、和这个tex文件同级以及子目录中的文件 清除编译的临时文件：Tools - Clean Auxiliary Files.. 配置英语语法检查：回答二，按链接配置完成后重启texstudio，打开工程就有语法检查啦（鼠标悬停给出提示信息，右击显示可能的修改方式）","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"tex","slug":"tex","permalink":"http://example.com/tags/tex/"}],"author":"zhiqiuyuan"},{"title":"chatGPT guide","slug":"chatGPT-guide","date":"2023-02-08T09:19:32.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/08/chatGPT-guide/","link":"","permalink":"http://example.com/2023/02/08/chatGPT-guide/","excerpt":"","text":"参考https://sms-activate.org/en/info/ChatGPThttps://mp.weixin.qq.com/s/zti8CCIY8vAG8NU0YpzpAg 一些其他信息 官网：https://chat.openai.com/ 桌面应用：https://github.com/lencx/ChatGPT 第三方的 ChatGPT 桌面应用。把 ChatGPT 放到你的桌面，支持快捷键、斜杠命令、划词搜索、导出记录等实用的功能，适用于 macOS、Windows、Linux 操作系统 步骤 科学上网 （推荐免费vpn https://account.protonvpn.com/downloads） 官网邮箱注册账号 https://chat.openai.com/ （我是直接邮箱注册成功的，用谷歌或微软的账号可能也可以） 验证邮箱之后还会验证手机，china不支持，可以在https://sms-activate.org 买临时手机号 可能要多尝试几个国家，购买的某个手机号如果没有收到短信可以全额退的，我尝试了印度尼西亚、印度、马来西亚，马来西亚可以 访问官网或者桌面应用：早上9点是低峰时期 问题解决403forbidden解决：followchain.org&#x2F;403-forbidden-chatgpt&#x2F;我这里问题是科学上网不彻底，于是安装了这篇博客中有推荐的免费vpn：https://account.protonvpn.com/downloads","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"rust宏 缺失值 Some","slug":"rust宏-缺失值-Some","date":"2023-02-08T07:05:38.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/08/rust宏-缺失值-Some/","link":"","permalink":"http://example.com/2023/02/08/rust%E5%AE%8F-%E7%BC%BA%E5%A4%B1%E5%80%BC-Some/","excerpt":"","text":"_x 会将值绑定到变量，而 _ 则完全不会绑定: let s = Some(String::from(&quot;Hello!&quot;)); if let Some(_s) = s &#123; println!(&quot;found a string&quot;); &#125; println!(&quot;&#123;:?&#125;&quot;, s); s 是一个拥有所有权的动态字符串，在上面代码中，我们会得到一个错误，因为 s 的值会被转移给 _s，在 println! 中再次使用 s 会报错： error[E0382]: borrow of partially moved value: `s` --&gt; src/main.rs:8:22 | 4 | if let Some(_s) = s &#123; | -- value partially moved here ... 8 | println!(&quot;&#123;:?&#125;&quot;, s); | ^ value borrowed here after partial move 只使用下划线本身，则并不会绑定值，因为 **s 没有被移动进 _**： #![allow(unused)] fn main() &#123; let s = Some(String::from(&quot;Hello!&quot;)); if let Some(_) = s &#123; println!(&quot;found a string&quot;); &#125; println!(&quot;&#123;:?&#125;&quot;, s); &#125;","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"rust流程控制","slug":"rust流程控制","date":"2023-02-08T06:54:38.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/08/rust流程控制/","link":"","permalink":"http://example.com/2023/02/08/rust%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6/","excerpt":"","text":"if elseif else语句块是表达式 fn main() &#123; let condition = true; let number = if condition &#123; 5 &#125; else &#123; 6 &#125;; println!(&quot;The value of number is: &#123;&#125;&quot;, number); &#125; for用法使用 for 时我们往往使用集合的引用形式（比如我们这里使用了 container 的引用）： for item in &amp;container &#123; // ... &#125; 如果不使用引用的话，所有权会被转移（move）到 for 语句块中，后面就无法再使用这个集合了)： for item in container &#123; // ... &#125; 对于实现了 copy 特征的数组(例如 [i32; 10] )而言， for item in arr 并不会把 arr 的所有权转移，而是直接对其进行了拷贝，因此循环之后仍然可以使用 arr 。 转移所有权for item in collection不可变借用for item in &amp;collectionfor item in collection.iter()可变借用for item in &amp;mut collectionfor item in collection.iter_mut() 遍历数组rust中的array的[]会进行越界检查，上述的for container则不会触发这种检查，因为编译器会在编译时就完成分析并证明这种访问是合法的所以遍历数组使用for container方式开销更小 looploop 是一个表达式 break continuebreak 可以单独使用，也可以带一个返回值 fn main() &#123; let mut counter = 0; let result = loop &#123; counter += 1; if counter == 10 &#123; break counter * 2; &#125; &#125;; println!(&quot;The result is &#123;&#125;&quot;, result); &#125; 当有多层循环时，你可以使用 continue 或 break 来跳到外层指定的循环。要实现这一点，外部的循环必须拥有一个标签 ‘label, 然后在 break 或 continue 时指定该标签 fn main() &#123; let mut count = 0; &#39;outer: loop &#123; &#39;inner1: loop &#123; if count &gt;= 20 &#123; // 这只会跳出 inner1 循环 break &#39;inner1; // 这里使用 `break` 也是一样的 &#125; count += 2; &#125; count += 5; &#39;inner2: loop &#123; if count &gt;= 30 &#123; break &#39;outer; &#125; continue &#39;outer; &#125; &#125; assert!(count == 30) &#125;","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"rust结构体","slug":"rust结构体","date":"2023-02-08T03:55:55.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/02/08/rust结构体/","link":"","permalink":"http://example.com/2023/02/08/rust%E7%BB%93%E6%9E%84%E4%BD%93/","excerpt":"","text":"内存布局struct File &#123; name: String, data: Vec&lt;u8&gt;, &#125; fn main() &#123; let f1 = File &#123; name: String::from(&quot;f1.txt&quot;), data: Vec::new(), &#125;; &#125; 上面定义的 File 结构体在内存中的排列如下图所示 引用类型的数据成员生命周期能确保结构体的作用范围要比它所借用的数据的作用范围要小。如果你想在结构体中使用一个引用，就必须加上生命周期，否则就会报错： struct User &#123; username: &amp;str, email: &amp;str, sign_in_count: u64, active: bool, &#125; fn main() &#123; let user1 = User &#123; email: &quot;someone@example.com&quot;, username: &quot;someusername123&quot;, active: true, sign_in_count: 1, &#125;; &#125; 编译器会抱怨它需要生命周期标识符： error[E0106]: missing lifetime specifier --&gt; src/main.rs:2:15 | 2 | username: &amp;str, | ^ expected named lifetime parameter | help: consider introducing a named lifetime parameter | 1 ~ struct User&lt;&#39;a&gt; &#123; 2 ~ username: &amp;&#39;a str, | 初始化创建结构体实例赋值时，每个字段和let一样 #[derive(Debug)] struct User &#123; active: bool, username: String, email: String, sign_in_count: u64, &#125; fn main() &#123; let user1 = User &#123; email: String::from(&quot;someone@example.com&quot;), username: String::from(&quot;someusername123&quot;), active: true, sign_in_count: 1, &#125;; let user2 = User &#123; active: user1.active, username: user1.username, // move occur email: String::from(&quot;another@example.com&quot;), sign_in_count: user1.sign_in_count, &#125;; println!(&quot;&#123;&#125;&quot;, user1.active); // 下面这行会报错 println!(&quot;&#123;:?&#125;&quot;, user1); &#125; -&gt; 运算符到哪去了：方法调用中的“自动引用和解引用”在 C&#x2F;C++ 语言中，有两个不同的运算符来调用方法：. 直接在对象上调用方法，而 -&gt; 在一个对象的指针上调用方法，这时需要先解引用指针。换句话说，如果 object 是一个指针，那么 object-&gt;something() 和 (*object).something() 是一样的。 Rust 并没有一个与 -&gt; 等效的运算符；相反，Rust 有一个叫 自动引用和解引用的功能。方法调用是 Rust 中少数几个拥有这种行为的地方。 他是这样工作的：当使用 object.something() 调用方法时，Rust 会自动为 object 添加 &amp;、&amp;mut 或 * 以便使 object 与方法签名匹配。也就是说，这些代码是等价的： obj1不是引用类型 obj1.distance(); // normal (&amp;obj1).distance(); // just for presentation p1是引用类型 (*p1).distance(); // normal as for grammer p1.distance(); // more concise 这种自动引用的行为之所以有效，是因为方法有一个明确的接收者———— self 的类型。在给出接收者和方法名的前提下，Rust 可以明确地计算出方法是仅仅读取（&amp;self），做出修改（&amp;mut self）或者是获取所有权（self）。事实上，Rust 对方法接收者的隐式借用让所有权在实践中更友好。 举例（含“自动引用和解引用”的举例）struct Point &#123; x: f64, y: f64, &#125; // `Point` 的关联函数都放在下面的 `impl` 语句块中 impl Point &#123; // 关联函数的使用方法跟构造器非常类似 fn origin() -&gt; Point &#123; Point &#123; x: 0.0, y: 0.0 &#125; &#125; // 另外一个关联函数，有两个参数 fn new(x: f64, y: f64) -&gt; Point &#123; Point &#123; x: x, y: y &#125; &#125; &#125; struct Rectangle &#123; p1: Point, p2: Point, &#125; impl Rectangle &#123; // 这是一个方法 // `&amp;self` 是 `self: &amp;Self` 的语法糖 // `Self` 是当前调用对象的类型，对于本例来说 `Self` = `Rectangle` fn area(&amp;self) -&gt; f64 &#123; // 使用点操作符可以访问 `self` 中的结构体字段 let Point &#123; x: x1, y: y1 &#125; = self.p1; let Point &#123; x: x2, y: y2 &#125; = self.p2; // `abs` 是一个 `f64` 类型的方法，会返回调用者的绝对值 ((x1 - x2) * (y1 - y2)).abs() &#125; fn perimeter(&amp;self) -&gt; f64 &#123; let Point &#123; x: x1, y: y1 &#125; = self.p1; let Point &#123; x: x2, y: y2 &#125; = self.p2; 2.0 * ((x1 - x2).abs() + (y1 - y2).abs()) &#125; // 该方法要求调用者是可变的，`&amp;mut self` 是 `self: &amp;mut Self` 的语法糖 fn translate(&amp;mut self, x: f64, y: f64) &#123; self.p1.x += x; self.p2.x += x; self.p1.y += y; self.p2.y += y; &#125; &#125; // `Pair` 持有两个分配在堆上的整数 struct Pair(Box&lt;i32&gt;, Box&lt;i32&gt;); impl Pair &#123; // 该方法会拿走调用者的所有权 // `self` 是 `self: Self` 的语法糖 fn destroy(self) &#123; let Pair(first, second) = self;// 这里的语法是模式匹配(变量名和字段名相同的简写) // 模式匹配和let一样，这里会发生所有权转移 println!(&quot;Destroying Pair(&#123;&#125;, &#123;&#125;)&quot;, first, second); // `first` 和 `second` 在这里超出作用域并被释放 &#125; &#125; fn main() &#123; let rectangle = Rectangle &#123; // 关联函数的调用不是通过点操作符，而是使用 `::` p1: Point::origin(), p2: Point::new(3.0, 4.0), &#125;; // 方法才是通过点操作符调用 // 注意，这里的方法需要的是 `&amp;self` 但是我们并没有使用 `(&amp;rectangle).perimeter()` 来调用，原因在于： // 编译器会帮我们自动取引用 // `rectangle.perimeter()` === `Rectangle::perimeter(&amp;rectangle)` println!(&quot;Rectangle perimeter: &#123;&#125;&quot;, rectangle.perimeter()); println!(&quot;Rectangle area: &#123;&#125;&quot;, rectangle.area()); let mut square = Rectangle &#123; p1: Point::origin(), p2: Point::new(1.0, 1.0), &#125;; // 错误！`rectangle` 是不可变的，但是这个方法要求一个可变的对象 // rectangle.translate(1.0, 0.0); // 可以！可变对象可以调用可变的方法 square.translate(1.0, 1.0); let pair = Pair(Box::new(1), Box::new(2)); pair.destroy(); // Error! 上一个 `destroy` 调用拿走了 `pair` 的所有权 // pair.destroy(); &#125;","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"8","slug":"daily-2023-2-8","date":"2023-02-08T00:46:30.000Z","updated":"2023-02-08T12:06:19.000Z","comments":true,"path":"2023/02/08/daily-2023-2-8/","link":"","permalink":"http://example.com/2023/02/08/daily-2023-2-8/","excerpt":"","text":"今日目标： 上午 1 搜集和阅读sigmod2022论文（作为心中参照之一（idea创新程度上），毕竟是要投稿的人） 阅读完成-4 2 读5.1中 3 读完5.1 4 开例会 hw第三阶段的需求理解下（主要是case2） 下午 1 转移rust笔记 2 搞定科学上网 3 chatgpt：网站崩了，暂时未注册好 4 思考hw stage3 case2问题 晚上 对齐关于hw stage3 case2的问题 碎碎念：希望明天可以看完这篇在看的sigmod以及2013年的vldb，并且复习下自己的idea和已经写了的论文垃圾hhh，还有时间的话希望学习下english，还有时间的话play一下~（话说都攒了一大堆list了www）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"7","slug":"daily-2023-2-7","date":"2023-02-07T04:30:20.000Z","updated":"2023-02-07T04:30:47.000Z","comments":true,"path":"2023/02/07/daily-2023-2-7/","link":"","permalink":"http://example.com/2023/02/07/daily-2023-2-7/","excerpt":"","text":"今日目标： 上午 1 搭svn开发环境（环境+vscode集成：可以直接上手开发） 下午晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"svn安装和使用","slug":"svn安装和使用","date":"2023-02-07T04:01:28.000Z","updated":"2023-12-25T15:57:11.000Z","comments":true,"path":"2023/02/07/svn安装和使用/","link":"","permalink":"http://example.com/2023/02/07/svn%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","excerpt":"","text":"简介：SVN，版本管理，和git用起来类似 安装tortoiseSVN，记得勾选安装命令行工具（命令行比GUI用得舒服hhh另外如果下面要集成到vscode中用svn插件，也需要装这个）： https://tortoisesvn.net/ 常用svn命令：https://svnbucket.com/posts/svn-commands-tutorial/列出命令说明 svn help svn help status # 列出svn status命令的帮助信息 vscode集成svn使用： 安装：安装插件SVN 使用： 命令面板(ctrl+shift+P)中SVN: XXX 打开svn项目，可以方便查看文件修改（点击左侧sidebar的分支项，可以选择文件查看对比） svn statusThe first seven columns in the output are each one character wide: First column: Says if item was added, deleted, or otherwise changed ‘ ‘ no modifications ‘A’ Added ‘C’ Conflicted ‘D’ Deleted ‘I’ Ignored ‘M’ Modified ‘R’ Replaced ‘X’ an unversioned directory created by an externals definition ‘?’ item is not under version control ‘!’ item is missing (removed by non-svn command) or incomplete ‘~’ versioned item obstructed by some item of a different kind Second column: Modifications of a file’s or directory’s properties ‘ ‘ no modifications ‘C’ Conflicted ‘M’ Modified Third column: Whether the working copy is locked for writing by another Subversion client modifying the working copy ‘ ‘ not locked for writing ‘L’ locked for writing Fourth column: Scheduled commit will create a copy (addition-with-history) ‘ ‘ no history scheduled with commit (item was newly added) ‘+’ history scheduled with commit (item was copied) Fifth column: Whether the item is switched or a file external ‘ ‘ normal ‘S’ the item has a Switched URL relative to the parent ‘X’ a versioned file created by an eXternals definition Sixth column: Whether the item is locked in repository for exclusive commit (without -u) ‘ ‘ not locked by this working copy ‘K’ locked by this working copy, but lock might be stolen or broken (with -u) ‘ ‘ not locked in repository, not locked by this working copy ‘K’ locked in repository, lock owned by this working copy ‘O’ locked in repository, lock owned by another working copy ‘T’ locked in repository, lock owned by this working copy was stolen ‘B’ not locked in repository, lock owned by this working copy is broken Seventh column: Whether the item is the victim of a tree conflict ‘ ‘ normal ‘C’ tree-Conflicted If the item is a tree conflict victim, an additional line is printed after the item’s status line, explaining the nature of the conflict. The out-of-date information appears in the ninth column (with -u): ‘*’ a newer revision exists on the server ‘ ‘ the working copy is up to date","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"4","slug":"daily-2023-2-4","date":"2023-02-04T06:05:53.000Z","updated":"2023-02-04T07:52:22.000Z","comments":true,"path":"2023/02/04/daily-2023-2-4/","link":"","permalink":"http://example.com/2023/02/04/daily-2023-2-4/","excerpt":"","text":"之前反思：如你所见，1.21到昨天都一直在摆烂hhh过年直到初七都一直在追剧追小说（陈情令，魔道祖师漫画，陈情令魔道祖师同人，天官赐福漫画，天官赐福小说），回来后和臭臭狗出去玩以及看天官赐福小说摆烂，然后去苏州，然后回来之后还是在看天官赐福以及同人hhh今天到图书馆来以及臭臭狗晚上要返校，我11中午返校（晚上到学校），我要找回状态了（一些后悔碎碎念：之前还在成新的时候每天学很多以为找到了寒假以及新东西持续摄入的状态，但是被出去玩以及“追剧追番”纵欲给拖没了呜呜呜 一些后悔 追剧需谨慎）还有多少天：6天半：2.4(下午) 5 6 7 8 9 10(上午) 11(上午) [2.12-3.31]希望： 独立路径论文 看3篇sigmod论文（对于其上发表的论文水平有所了解） English for paper writing 复习已经写的论文 复习idea （写论文） 时态图 看3篇时态图论文并更新仓库 搜集的本地的(-&gt;考虑那篇综述引用的工作-&gt;检索graph stream) 代码状态 每天刷leetcode*2并记录笔记和题解 （mit os课程完成3课） 今日目标： 上午下午 2:10-2:53 梳理要干啥 2:53-3:52 三角计数论文 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"rust字符串 切片","slug":"rust字符串-切片","date":"2023-01-21T13:10:22.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/21/rust字符串-切片/","link":"","permalink":"http://example.com/2023/01/21/rust%E5%AD%97%E7%AC%A6%E4%B8%B2-%E5%88%87%E7%89%87/","excerpt":"","text":"学习自 rust圣经 切片：全在栈上的对象，一个指针+一个长度 fn main() &#123; let s = String::from(&quot;hello world&quot;); let hello = &amp;s[0..5]; let world = &amp;s[6..11]; &#125; world： 四种不同的类型：String（如上图的s），&amp;String（如下图的s），str（如下一段代码的hello，字符内容是硬编码在可执行文件中的），&amp;str（字符串切片，如上图的world） 其中String和&amp;str用得很多 都是utf-8编码，每个字符所占的字节数是变化的(1 - 4) 而Rust 中的字符是 Unicode 类型，每个字符占据 4 个字节内存空间 注意字符串切片是以字节为单位取（因此比如下述，一个中文是3个字节，下述会有问题index 2 is not a char boundary fn main() &#123; let hello = &quot;中国人&quot;; let s = &amp;hello[0..2]; &#125; 如何将 String 类型转为 &amp;str 类型呢？取引用即可。这种灵活用法是因为 deref 隐式强制转换 fn main() &#123; let s = String::from(&quot;hello,world!&quot;); say_hello(&amp;s); say_hello(&amp;s[..]); say_hello(s.as_str()); &#125; fn say_hello(s: &amp;str) &#123; println!(&quot;&#123;&#125;&quot;,s); &#125;","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"rust所有权","slug":"rust所有权","date":"2023-01-21T12:22:16.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/21/rust所有权/","link":"","permalink":"http://example.com/2023/01/21/rust%E6%89%80%E6%9C%89%E6%9D%83/","excerpt":"","text":"学习自 rust圣经 强烈建议：https://gcc.godbolt.org/ 看反汇编注意，下文的“新建栈上对象”，其实不是“申请”，而是机器代码控制，在函数体对应的机器代码之前，栈顶就保留了足够长的栈，然后栈底+offset是栈上对象的起始地址 rust所有权规则 每一个值(内存对象)都被一个变量所拥有，该变量被称为值的所有者 一个值(内存对象)同时(同一个作用域内)只能被一个变量所拥有，或者说一个值只能拥有一个所有者 当所有者(变量)离开作用域范围时，这个值将被丢弃(drop) 具体来说，栈上内存是编译器控制释放的（机器代码栈顶栈底），堆上内存等其他资源是类型的drop方法控制实现的，离开作用域时编译器产生调用drop的汇编代码 let底层3个let典型例子 全在栈上的对象 fn main() &#123; let x = 5; // 栈上新建内存对象，其中内容放5(mov a 5这样子的) let y = x; // 栈上新建内存对象，其中内容是复制x绑定的栈上内存对象的内容 &#125; 栈上内存+堆上内存 fn main() &#123; // String类型如下图所示 let s1 = String::from(&quot;hello&quot;); // 栈上新建内存对象，内容是指向堆的指针和长度；堆上新建内存对象，内容是hello的utf-8编码的字节数组 let s2 = s1; // 栈上新建内存对象，内容是s1栈上内存对象的拷贝 // （这样的话自然指针是指向原先堆上的那个数组的） // s1之后不能被借用了 println!(&quot;&#123;&#125;, world!&quot;, s1); // 会报错 &#125; 引用：全在栈上的对象 fn main() &#123; // 引用就是一个栈上对象，是一个指针，如下图所示 let x: &amp;str = &quot;hello, world&quot;; let y = x; println!(&quot;&#123;&#125;,&#123;&#125;&quot;,x,y); &#125; 图示最左边的方块是&amp;String类型 所以总结let：新建栈上对象（拷贝右值的栈上对象，或字面值（字面值会编码到机器指令中）），如果右值对象有堆上对象，且没有实现Copy trait，则新对象的堆上对象就是右值对象的堆上对象(毕竟栈上对象是直接拷贝右值的，指针值还是指向原先的堆上对象)，而右值对象会被编译器强制失效，不能再使用了 函数参数和返回值传递参数，跟let语句一样 fn main() &#123; let s = String::from(&quot;hello&quot;); // 新建堆栈对象 takes_ownership(s); // 看函数的注释 // s失效 let x = 5; // 新建栈对象 makes_copy(x); // 看函数的注释 // x仍然有效 &#125; fn takes_ownership(some_string: String) &#123; // 新建栈对象，是拷贝传递来的参数的栈对象；堆对象是参数的堆对象，传递来的参数被失效 println!(&quot;&#123;&#125;&quot;, some_string); &#125; // 这里，some_string 移出作用域并调用 `drop` 方法。堆内存被释放 fn makes_copy(some_integer: i32) &#123; // 新建栈对象。由于i32是copy的，因此传递进来的参数不会被失效 println!(&quot;&#123;&#125;&quot;, some_integer); &#125; 返回值：把返回值的栈上部分放寄存器 fn main() &#123; let s1 = gives_ownership(); // gives_ownership 将返回值 // 移给 s1 let s2 = String::from(&quot;hello&quot;); // s2 进入作用域 let s3 = takes_and_gives_back(s2); // s2 被移动到 // takes_and_gives_back 中, // 它也将返回值移给 s3 &#125; // 这里, s3 移出作用域并被丢弃。s2 也移出作用域，但已被移走， // 所以什么也不会发生。s1 移出作用域并被丢弃 fn gives_ownership() -&gt; String &#123; let some_string = String::from(&quot;hello&quot;); some_string // 返回 some_string 并移出给调用的函数 &#125; // takes_and_gives_back 将传入字符串并返回该值 fn takes_and_gives_back(a_string: String) -&gt; String &#123; // a_string 进入作用域 a_string // 返回 a_string 并移出给调用的函数 &#125; 引用的作用域引用的作用域 s 从创建开始，一直持续到它最后一次使用的地方，这个跟变量的作用域有所不同，变量的作用域从创建持续到某一个花括号 } fn main() &#123; let mut s = String::from(&quot;hello&quot;); let r1 = &amp;s; let r2 = &amp;s; println!(&quot;&#123;&#125; and &#123;&#125;&quot;, r1, r2); // 新编译器中，r1,r2作用域在这里结束 let r3 = &amp;mut s; // 新编译器中，这样的代码不违反 同一时间不能同时有可变和不变引用 println!(&quot;&#123;&#125;&quot;, r3); &#125; // 老编译器中，r1、r2、r3作用域在这里结束 // 新编译器中，r3作用域在这里结束","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"摆烂分析","slug":"writing-2023-1-21-摆烂分析","date":"2023-01-21T01:22:55.000Z","updated":"2023-01-21T01:54:58.000Z","comments":true,"path":"2023/01/21/writing-2023-1-21-摆烂分析/","link":"","permalink":"http://example.com/2023/01/21/writing-2023-1-21-%E6%91%86%E7%83%82%E5%88%86%E6%9E%90/","excerpt":"","text":"现象：尽管从成新来时已经养成了很好的学习routine，但是19和20还是摆烂了原因： 19号学习MIT os课效率低下，没有迅速学到很多东西，到了18晚上就直接顺势摆烂了 之前出去玩拍写真让心情不想学习 陈情令好看hhh 需要马上做的hw任务一点也不想做，但是这本来是必须做的第一件正事，于是一直摆烂逃避不想开始干正事解决： 尝试接受学东西不一定每时每刻都学得效率很高；另外每次课间时注意留心自己的学习效率是否达到预期，没有的话可能需要修改学习方式或内容 不想做的必须做的事情，划一个或两个课时开始，如果一拖再拖只会增加压力其他现象：不好的影响： 从时态图调研汇报成功和可以开始写论文中获得的科研自信和在课题组的信心又被惶恐代替了，因为 hw任务是和课题组师姐合作的，但是现在离约定ddl已经过了两天 由于摆烂掉了两天（再加上出去玩两天），科研上没有进展（还需要有方案创新的），于是又有点担心了解决（寒假利用角度）：接下来的寒假如何度过：空闲时间+合理的任务目标 时间：有空时间[21 22 23 24 25 26 27]春节 全天+手机碎片[28]下午回家 晚上[29]下午晚上出去玩 上午[30]晚上9:30出发苏州 上午下午[31 1]苏州[2]上午从苏州返程，晚上去滕王阁 下午[3]全天[4]送臭臭狗 晚上[5 6 7 8 9 10 11]南昌一人食生活！全天[12]返校 目标：春节期间 hw任务 English for paper writing：一半 MIT os 课程+作业+实验：一半 daily：背单词，学rust *搜集的sigmod论文","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"21","slug":"daily-2023-1-21","date":"2023-01-21T01:21:20.000Z","updated":"2023-01-21T12:20:49.000Z","comments":true,"path":"2023/01/21/daily-2023-1-21/","link":"","permalink":"http://example.com/2023/01/21/daily-2023-1-21/","excerpt":"","text":"19+20：摆烂看陈情令+回老家 上午 1 写分析和规划接下来的计划 下午晚上学三节rust","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"unix 文件-inode-文件名-文件描述符 的关系","slug":"unix-文件-inode-文件名-文件描述符-的关系","date":"2023-01-18T07:44:42.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/18/unix-文件-inode-文件名-文件描述符-的关系/","link":"","permalink":"http://example.com/2023/01/18/unix-%E6%96%87%E4%BB%B6-inode-%E6%96%87%E4%BB%B6%E5%90%8D-%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6-%E7%9A%84%E5%85%B3%E7%B3%BB/","excerpt":"","text":"如图所示 蓝色箭头：一对一 橙色&#x2F;绿色箭头：多对一","categories":[{"name":"linux","slug":"linux","permalink":"http://example.com/categories/linux/"},{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"},{"name":"os","slug":"course/os","permalink":"http://example.com/categories/course/os/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"18","slug":"daily-2023-1-18","date":"2023-01-18T01:21:29.000Z","updated":"2023-01-18T08:23:11.000Z","comments":true,"path":"2023/01/18/daily-2023-1-18/","link":"","permalink":"http://example.com/2023/01/18/daily-2023-1-18/","excerpt":"","text":"今日目标： 上午 1 读sigmod’14图流综述 2 读sigmod’14图流综述 有些地方没有看懂，寄，之后看看原始论文 3 读sigmod’14图流综述 整理github 下午 1 6.S081 lec1 preparation - 1.1-1.2 2 6.S081 lec1 preparation - 1.3-1.5 3 6.S081 lab1环境 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"17","slug":"daily-2023-1-17","date":"2023-01-17T03:46:08.000Z","updated":"2023-01-18T01:21:17.000Z","comments":true,"path":"2023/01/17/daily-2023-1-17/","link":"","permalink":"http://example.com/2023/01/17/daily-2023-1-17/","excerpt":"","text":"今日目标： 上午 1 read graphone 2 read graphone 3 读2016sigmod图流算法综述 下午 拍写真！ 晚上 火锅！ 修图！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"2023达摩院十大科技趋势","slug":"writing-2023-1-16-2023达摩院十大科技趋势","date":"2023-01-16T12:06:07.000Z","updated":"2023-01-16T12:07:42.000Z","comments":true,"path":"2023/01/16/writing-2023-1-16-2023达摩院十大科技趋势/","link":"","permalink":"http://example.com/2023/01/16/writing-2023-1-16-2023%E8%BE%BE%E6%91%A9%E9%99%A2%E5%8D%81%E5%A4%A7%E7%A7%91%E6%8A%80%E8%B6%8B%E5%8A%BF/","excerpt":"","text":"链接：https://damo.alibaba.com/techtrends/2023?lang=zhmark一下，了解科技趋势+扫盲科普~","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"16","slug":"daily-2023-1-16","date":"2023-01-16T09:27:29.000Z","updated":"2023-01-16T12:24:57.000Z","comments":true,"path":"2023/01/16/daily-2023-1-16/","link":"","permalink":"http://example.com/2023/01/16/daily-2023-1-16/","excerpt":"","text":"今日目标： 上午 9点半起+补办身份证+试汉服和拍照hh 下午 鱼尾洲公园~ 1 今天找到好用的pdf editor: Adobe Acrobat 非常方便地添加文字、画画、高亮，并且可以修改原本pdf的内容 画画要点击注释功能，然后会出现画笔 新建awesome temporal graph 起因：发现现有的dynamic awesome和graph analysis推荐的论文都比较垃圾，还是自己搞的权威 至此，形成完整文献学习工具链~ 晚上 1 读graphone 2 读graphone 3 hellogithub、达摩院等读资讯 读graphone","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"windows实时绘图工具推荐 live-draw","slug":"windows实时绘图工具推荐-live-draw","date":"2023-01-15T09:35:10.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/15/windows实时绘图工具推荐-live-draw/","link":"","permalink":"http://example.com/2023/01/15/windows%E5%AE%9E%E6%97%B6%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90-live-draw/","excerpt":"","text":"好用的实时画图工具，免安装就是个可以运行的exe文件，在任何情况下的屏幕上画画，支持保存，超方便呀！https://github.com/antfu/live-draw","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"tex文献引用","slug":"tex文献引用","date":"2023-01-15T03:35:36.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/15/tex文献引用/","link":"","permalink":"http://example.com/2023/01/15/tex%E6%96%87%E7%8C%AE%E5%BC%95%E7%94%A8/","excerpt":"","text":"举例main.tex指定引用所在文件和引用样式 \\documentclass&#123;article&#125; \\begin&#123;document&#125; \\bibliographystyle&#123;ACM-Reference-Format&#125; \\bibliography&#123;main&#125; % 引用在文件/main.bib中 ... are employed for improving network fault tolerance \\cite&#123;DBLP:journals/ton/JayaveluRY09&#125; \\end&#123;document&#125; main.bib&#96;&#96;&#96;bibtex@article{DBLP:journals&#x2F;ton&#x2F;JayaveluRY09, % 这个DBLP:journals/ton/JayaveluRY09是引用这个reference的label author &#x3D; {Giridhar Jayavelu and Srinivasan Ramasubramanian and Ossama Younis}, title &#x3D; {Maintaining colored trees for disjoint multipath routing under node failures}, journal &#x3D;","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"tex","slug":"tex","permalink":"http://example.com/tags/tex/"}],"author":"zhiqiuyuan"},{"title":"使用默认pypi源出现连接超时","slug":"使用默认pypi源出现连接超时","date":"2023-01-15T02:39:15.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/15/使用默认pypi源出现连接超时/","link":"","permalink":"http://example.com/2023/01/15/%E4%BD%BF%E7%94%A8%E9%BB%98%E8%AE%A4pypi%E6%BA%90%E5%87%BA%E7%8E%B0%E8%BF%9E%E6%8E%A5%E8%B6%85%E6%97%B6/","excerpt":"","text":"https://cloud.tencent.com/developer/article/1354614 报错： &#39;Connection to pypi.python.org timed out. (connect timeout=15)&#39;)&#39; 原因：采用了默认的pypi源(国外的pypi源)，出现连接超时问题 解决办法 国内常用的pypi源如下： 阿里云 http://mirrors.aliyun.com/pypi/simple/ 中国科技大学 https://pypi.mirrors.ustc.edu.cn/simple/ 豆瓣(douban) http://pypi.douban.com/simple/ 清华大学 https://pypi.tuna.tsinghua.edu.cn/simple/ 中国科学技术大学 http://pypi.mirrors.ustc.edu.cn/simple/ 在你需要安装的xx后面添加-i + pypi源： pip install xx -i http://pypi.douban.com/simple/ 如果还出现下面的情况： pypi.douban.com is not a trusted or secure host and is being ignored... 那么命令就变成这样： pip install xx -i http://pypi.douban.com/simple --trusted-host pypi.douban.com","categories":[{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"昨日论文效率低原因","slug":"writing-2023-1-15-昨日论文效率低原因","date":"2023-01-15T01:40:39.000Z","updated":"2023-01-15T02:03:50.000Z","comments":true,"path":"2023/01/15/writing-2023-1-15-昨日论文效率低原因/","link":"","permalink":"http://example.com/2023/01/15/writing-2023-1-15-%E6%98%A8%E6%97%A5%E8%AE%BA%E6%96%87%E6%95%88%E7%8E%87%E4%BD%8E%E5%8E%9F%E5%9B%A0/","excerpt":"","text":"论文初稿历程回顾：昨天把初稿的abstract+introduction(除了方法概述和贡献部分)+preliminaries部分完成，回顾历程： abstract用时半个下午(寻找写作方法+阅读English for paper writing+阅读model paper+总结要点)+一个晚上(阅读model paper+总结要点+写)，并明确了初学者写每个章节的routine introduction打算的是第二天整天干完，实际上是 整个上午(阅读English for paper writing+阅读model paper+总结要点)-&gt;中午摆烂看陈情令-&gt;半个下午(阅读model paper+总结要点+列提纲)-&gt;整个晚上(写了1&#x2F;4的introduction)-&gt;第二天上午9点前写了一点点introduction-&gt;老家喜酒-&gt;晚上回家后写了1&#x2F;3的introduction-&gt;第二天上午写完introduction除方法和贡献的部分-&gt;路途-&gt;晚上写preliminaries部分，寻找合适的作graph工具，尝试了一堆都不好用-&gt;第二天白天写preliminaries-&gt;晚上继续寻找合适作图工具，终于尝试到合适的可以看到，阻碍主要有两点： 写别人的工作或者一些铺垫的部分，这部分内容不好写 对于别人工作的广泛了解还不够 主要：英语写作水平不行，很早就已经有了提纲（含写什么内容，每点又有哪些点），但是就是不想写写不出来 作graph工具寻找不力。以往寻找得力工具都是谷歌上一搜，第一条推荐的就是最好用的，这样试错成本很低，迅速就得到高生产力的回报，但这次是试验了几个网页的多个工具都不好用，或者无法满足全部需求，可能和搜索关键词不够准确有关（中英文的research paper graph theory draw都搜索了，但是这组关键词容易被理解成广泛的科研作图），也和搜到的工具很多都是要安装然后下载等耗时较长有关，还和各作图工具的教程虽有但是质量不高有关，最后成功找到得心应手工具是源于某网页看到推荐networkx的作图，然后搜networkx的官方文档，其上推荐了四个专门画图的工具，然后其中一个就是这个最终得心应手的工具，不过当时并没有尝试到它，依次尝试networkx推荐的工具时先尝试了别的，因为这个的文档比较复杂hhh，后面发现都不能满足需求就又去搜寻了一下工具推荐，后面看到老师给的例子中是用tex画图的，语法还挺可以理解的，于是把老师例子中搬过来，但是发现稍有修改就有些奇怪的bug，然后最终还是去看官方文档，发现挺好用的hhh 一个教训：官方文档yyds，当然可能先从读者友好的官方文档，比如tex画图看overleaf文档中的TikZ的文档，这个比TikZ官方几百面的文档友好，开箱即用 另外，搜寻工具，除非是非常广泛使用的功能，这种一大波试错是可能的，如果遇到这种境遇，应有清晰的需求+尝试思路，并且在尝试的时候不死磕+选择友好的官方文档，最后是如果找到了舒服的工具，博客记录一下 关于死磕：在我尝试失败了很多次之后，如果某操作和预期不一样，我会进入一种死磕的状态，多次尝试不相信，并且弄坏心情。进入死磕之后推荐思考一下，刚刚干了什么，自己干这个的目的是什么，接下来干什么","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"15","slug":"daily-2023-1-15","date":"2023-01-15T01:40:19.000Z","updated":"2023-01-15T12:12:39.000Z","comments":true,"path":"2023/01/15/daily-2023-1-15/","link":"","permalink":"http://example.com/2023/01/15/daily-2023-1-15/","excerpt":"","text":"今日目标： 上午 1 写反思 整理论文工具链 2 寻找谷歌翻译平替 写tex画图的博客 3 写tex伪代码和文献引用的博客 4 转战mendeley文献阅读和管理 以后文献越读越多，不可能全部存本机的 虽然mendeley有部分数据丢失，但是丢失一点其实问题不大 需要：打算以“粗分类+精细标签”的方式管理 整理以前的mendeley：保留阅读过的文章，没有阅读过的删除掉 现在的本机文献：已经阅读过的全部导入，放入正确分类，给正确标签 摸索文献阅读模式：对于不好标记的pdf：导入mendeley放入分类（期刊和年份），在其上阅读，且完成阅读后添加标签 或者对于好标记的pdf：在本机阅读，阅读完成后如果有意思则导入mendeley，加正确标签和分类 下午 1 整理以前的mendeley 2 不需要整理本机文献到mendeley：采用”懒整理”方式，啥时候用到啥本机文献，再整理到mendeley 整理edge浏览器的收藏 整理本机的temporal文献 3 读A new approach to rectangle intersections 4 win画图软件搜索 有些示意图或者读文章的时候打草稿，这和论文画图不一样 搜到了一个，牛逼，https://github.com/antfu/live-draw 晚上 1 pdf-editor工具寻找，需要能够方便高亮文字、加文字、画画 这个体验不错，不知道软件有没有啥限制 https://www.pdf2go.com/edit-pdf 软件版本要注册账号才能用，注册账号目前存在问题 搜寻其他编辑工具+解决账号注册问题 目前搜到的非在线或在线版本都会限制任务次数mmp 这样的话目前仍然没有形成阅读文献tool chain 之前想的是在本地用舒服的pdf编辑器编辑阅读完，然后上传mendeley，因为mendeley不支持添加直接的文字和画图 pdf编辑和绘图工具，我能不能搞一个镜像呢？比如镜像https://github.com/ShizukuIchi/pdf-editor english for paper writing第二章","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"tex作图TikZ","slug":"tex作图TikZ","date":"2023-01-15T01:40:02.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/15/tex作图TikZ/","link":"","permalink":"http://example.com/2023/01/15/tex%E4%BD%9C%E5%9B%BETikZ/","excerpt":"","text":"https://www.overleaf.com/learn/latex/TikZ_package主要是面向画图论的图 单文件和语法举例\\node和\\draw后面的[]中传入样式参数\\begin&#123;tikzpicture&#125;后面的[]中也是传参，定义这个画图环境中的一些变量 1\\documentclass&#123;article&#125; \\usepackage&#123;tikz&#125; \\usetikzlibrary&#123;positioning&#125; \\begin&#123;document&#125; \\begin&#123;tikzpicture&#125;[ roundnode/.style=&#123;circle, draw=green!60, fill=green!5, very thick, minimum size=7mm&#125;, squarednode/.style=&#123;rectangle, draw=red!60, fill=red!5, very thick, minimum size=5mm&#125;, ] %Nodes %\\node[样式] (id) [位置描述] &#123;显示在图上的标签&#125; \\node[squarednode] (maintopic) &#123;2&#125;; \\node[roundnode] (uppercircle) [above=of maintopic] &#123;1&#125;; \\node[squarednode] (rightsquare) [right=of maintopic] &#123;3&#125;; \\node[roundnode] (lowercircle) [below=of maintopic] &#123;4&#125;; %Lines %\\draw[样式(-&gt;是有向边)] (id，可以加上.方向) 边类型(--是直线) (id，可以加上.方向) \\draw[-&gt;] (uppercircle.south) -- (maintopic.north); \\draw[-&gt;] (maintopic.east) -- (rightsquare.west); \\draw[-&gt;] (rightsquare.south) .. controls +(down:7mm) and +(right:7mm) .. (lowercircle.east); \\end&#123;tikzpicture&#125; \\end&#123;document&#125; 效果： 2\\documentclass&#123;article&#125; \\usepackage&#123;tikz&#125; \\usetikzlibrary&#123;positioning&#125; \\begin&#123;document&#125; \\begin&#123;tikzpicture&#125;[ normalnode/.style=&#123;circle, draw=black!60, fill=white!5, very thick, minimum size=5mm&#125;, rednode/.style=&#123;circle, draw=red!60, fill=red!5, very thick, minimum size=5mm&#125;, ] %Nodes \\node[normalnode] (4) &#123;4&#125;; \\node[rednode] (1) [above=of 4] &#123;1&#125;; \\node[normalnode] (3) [left=of 4] &#123;3&#125;; \\node[rednode] (0) [below=of 3] &#123;0&#125;; \\node[normalnode] (2) [below=of 4] &#123;2&#125;; %Lines \\draw[very thick] (0) -- (3); \\draw[very thick] (3) -- (1); \\draw[very thick] (0) -- (4); \\draw[very thick] (4) -- (1); \\draw[] (3) -- (4); \\draw[] (0) -- (2); \\draw[] (2) -- (4); % % directed edge: % \\draw[-&gt;] (4) -- (1); \\end&#123;tikzpicture&#125; \\end&#123;document&#125; 效果： 3\\documentclass&#123;article&#125; \\usepackage&#123;tikz&#125; \\usetikzlibrary&#123;positioning&#125; \\begin&#123;document&#125; \\begin&#123;tikzpicture&#125;[ normalnode/.style=&#123;circle, draw=black!60, fill=white!5, very thick, minimum size=5mm&#125;, rednode/.style=&#123;circle, draw=red!60, fill=red!5, very thick, minimum size=5mm&#125;, deletednode/.style=&#123;circle, draw=black!40, fill=white!5, text=black!40, minimum size=5mm&#125;, deletedline/.style=&#123;black!40, dashed&#125;, ] %Nodes \\node[rednode] (1&#39;) &#123;1&#39;&#125;; \\node[normalnode] (4&#39;) [below=of 1&#39;] &#123;4&#39;&#125;; \\node[normalnode] (3&#39;&#39;) [left=of 4&#39;] &#123;3&#39;&#39;&#125;; \\node[normalnode] (3&#39;) [left=of 3&#39;&#39;] &#123;3&#39;&#125;; \\node[normalnode] (4&#39;&#39;) [right=of 4&#39;] &#123;4&#39;&#39;&#125;; \\node[normalnode] (2&#39;) [below=of 4&#39;] &#123;2&#39;&#125;; \\node[normalnode] (2&#39;&#39;) [right=of 2&#39;] &#123;2&#39;&#39;&#125;; \\node[rednode] (0&#39;&#39;) [below=of 3&#39;&#39;] &#123;0&#39;&#39;&#125;; \\node[deletednode] (0&#39;) [left=of 0&#39;&#39;] &#123;0&#39;&#125;; \\node[deletednode] (1&#39;&#39;) [right=of 1&#39;] &#123;1&#39;&#39;&#125;; %Lines \\draw[very thick,-&gt;] (0&#39;&#39;) -- (3&#39;); \\draw[very thick,-&gt;] (3&#39;) -- (3&#39;&#39;); \\draw[very thick,-&gt;] (3&#39;&#39;) -- (1&#39;); \\draw[very thick,-&gt;] (0&#39;&#39;) -- (4&#39;); \\draw[very thick,-&gt;] (4&#39;) -- (4&#39;&#39;); \\draw[very thick,-&gt;] (4&#39;&#39;) -- (1&#39;); \\draw[-&gt;] (3&#39;&#39;) -- (4&#39;); \\draw[-&gt;] (4&#39;&#39;.north) .. controls +(up:10mm) and +(left:5mm) .. (3&#39;.north); \\draw[-&gt;] (0&#39;&#39;) -- (2&#39;); \\draw[-&gt;] (2&#39;&#39;) -- (4&#39;); \\draw[-&gt;] (4&#39;&#39;) -- (2&#39;); \\draw[-&gt;] (2&#39;) -- (2&#39;&#39;); \\draw[deletedline,-&gt;] (0&#39;) -- (0&#39;&#39;); \\draw[deletedline,-&gt;] (1&#39;) -- (1&#39;&#39;); \\draw[deletedline,-&gt;] (3&#39;&#39;) -- (0&#39;); \\draw[deletedline,-&gt;] (4&#39;&#39;) -- (0&#39;); \\draw[deletedline,-&gt;] (2&#39;&#39;) .. controls +(down:10mm) and +(left:2mm).. (0&#39;.south); \\draw[deletedline,-&gt;] (1&#39;&#39;) -- (3&#39;); \\draw[deletedline,-&gt;] (1&#39;&#39;) -- (4&#39;); \\end&#123;tikzpicture&#125; \\end&#123;document&#125; 效果： 多文件举例（分离画图环境定义的变量和画图内容）main.texmain.tex中引入包和定制画图环境 \\documentclass&#123;article&#125; \\usepackage&#123;tikz&#125; \\usetikzlibrary&#123;positioning&#125; \\newcommand&#123;\\picfolder&#125;&#123;pic&#125; % Define a macro to hold the path，这样以后\\picfolder就是pic，编译器会做这个替换 \\input&#123;\\picfolder/control&#125; % 直接把/pic/control.tex的内容粘贴过来，这个文件中定制了画图环境 \\begin&#123;document&#125; \\input&#123;doc&#125; % 直接把/doc.tex的内容粘贴过来 \\end&#123;document&#125; control.tex其中的定制文件control.tex，这样在引入这个定制文件之后整个工程中，这些定义的变量都可以在tikzpicture环境中使用 \\tikzset&#123;% normalnode/.style=&#123;circle, draw=black!60, fill=white!5, very thick, minimum size=5mm&#125;, rednode/.style=&#123;circle, draw=red!60, fill=red!5, very thick, minimum size=5mm&#125;, greennode/.style=&#123;circle, draw=green!60, fill=green!5, very thick, minimum size=5mm&#125;, deletednode/.style=&#123;circle, draw=black!40, fill=white!5, text=black!40, minimum size=5mm&#125;, deletedline/.style=&#123;black!40, dashed&#125;, &#125; ``` ### doc.tex 文章内容`doc.tex`，一张图片，图片的引用标签是`fig:example_graph`，图片内容在`/pic/example_graph.tex`中 ```tex This a picture \\ref&#123;fig:example_graph&#125;. \\begin&#123;figure&#125;[h] % [h]指定图片在页面上的位置 \\centering % 图片左右居中 \\input&#123;\\picfolder/example_graph&#125; % 直接把`/pic/example_graph.tex`的内容粘贴过来 \\caption&#123;$G'$&#125; \\label&#123;fig:example_graph&#125; \\end&#123;figure&#125; ``` ### example_graph.tex 其中引入的图片`example_graph.tex`，内容即单文件示例中`\\begin&#123;tikzpicture&#125;`-`\\end&#123;tikzpicture&#125;`间的内容 ```tex \\begin&#123;tikzpicture&#125; %Nodes \\node[normalnode] (4) &#123;4&#125;; \\node[rednode] (1) [above=of 4] &#123;1&#125;; \\node[normalnode] (3) [left=of 4] &#123;3&#125;; \\node[rednode] (0) [below=of 3] &#123;0&#125;; \\node[normalnode] (2) [below=of 4] &#123;2&#125;; %Lines \\draw[very thick] (0) -- (3); \\draw[very thick] (3) -- (1); \\draw[very thick] (0) -- (4); \\draw[very thick] (4) -- (1); \\draw[] (3) -- (4); \\draw[] (0) -- (2); \\draw[] (2) -- (4); % % directed edge: % \\draw[->] (4) -- (1); \\end&#123;tikzpicture&#125; ``` ### 目录结构和效果 &#123;% asset_img image-20230115111259898.png %&#125; &#123;% asset_img image-20230115111312159.png %&#125; ## subfigure多个子图 对于上述多文件工程 ### 修改main.tex 引入`\\usepackage&#123;subcaption&#125;` ### 修改doc.tex ```tex A example is given in figure \\ref&#123;fig:example_graph&#125;. Another example is given in figure \\ref&#123;fig:example_graph2&#125;. \\begin&#123;figure&#125;[h!] \\newcommand&#123;\\mylinewidth&#125;&#123;\\linewidth&#125; \\centering \\begin&#123;subfigure&#125;[t]&#123;0.3\\linewidth&#125; \\centering \\raisebox&#123;0.16\\height&#125; % 把这张图片上移一点，因为之前没有上移的时候这俩图片的视觉中心不是很对齐所以想着调整一下 &#123; \\resizebox&#123;0.8\\mylinewidth&#125;&#123;!&#125; &#123;\\input&#123;\\picfolder/example_graph&#125;&#125; &#125; \\caption&#123;$G$&#125; \\label&#123;fig:example_graph&#125; \\end&#123;subfigure&#125; \\begin&#123;subfigure&#125;[t]&#123;0.6\\linewidth&#125; \\centering \\resizebox&#123;\\mylinewidth&#125;&#123;!&#125; &#123;\\input&#123;\\picfolder/example_graph2&#125;&#125; \\caption&#123;$G&#39;$&#125; \\label&#123;fig:example_graph2&#125; \\end&#123;subfigure&#125; \\caption&#123;examples&#125; \\label&#123;fig:example&#125; \\end&#123;figure&#125; 新增example_graph2.tex单文件例子3中\\begin&#123;tikzpicture&#125;-\\end&#123;tikzpicture&#125;间的内容 \\begin&#123;tikzpicture&#125; % ... \\end&#123;tikzpicture&#125; 目录结构和效果","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"tex","slug":"tex","permalink":"http://example.com/tags/tex/"}],"author":"zhiqiuyuan"},{"title":"tex伪代码","slug":"tex伪代码","date":"2023-01-15T01:38:45.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/15/tex伪代码/","link":"","permalink":"http://example.com/2023/01/15/tex%E4%BC%AA%E4%BB%A3%E7%A0%81/","excerpt":"","text":"比特操作\\mathbin&#123;\\&amp;&#125; % and \\mathbin&#123;|&#125; % or \\ll % shift left \\gg % shift right \\ensuremath&#123;\\mathord&#123;\\sim&#125;&#125; % not 伪代码举例文档参考：https://www.overleaf.com/learn/latex/Algorithms在premmable中引入包\\usepackage&#123;algorithm&#125;和\\usepackage&#123;algpseudocode&#125;在document中 Algorithm A is shown in list \\ref&#123;alg:msbfs&#125;. \\begin&#123;algorithm&#125; \\caption&#123;MS-BFS&#125;\\label&#123;alg:msbfs&#125; \\begin&#123;algorithmic&#125;[1] % 1: 有行编号，从1开始 \\State \\textbf&#123;Input:&#125; $G, \\textbf&#123;B&#125;, S$ \\Comment&#123;\\textbf&#123;B&#125;: a set of BFSes&#125; \\For&#123;each $bi \\in \\textbf&#123;B&#125;$&#125; \\State $seen[ si ] \\gets 1 \\ll bi$ \\State $visit[ si ] \\gets 1 \\ll bi$ \\EndFor \\State reset $visitNext$ \\While&#123;$visit \\neq \\emptyset$&#125; \\For&#123;$i = 1, . . . , N$&#125; \\If&#123;$visit[vi] = \\textbf&#123;B&#125;_&#123;\\emptyset&#125;$&#125; \\Comment&#123;$\\textbf&#123;B&#125;_&#123;\\emptyset&#125;$: empty BFS set&#125; \\State skip \\EndIf \\For&#123;each $n \\in neighbors[vi]$&#125; \\State $D \\gets visit[vi] \\mathbin&#123;\\&amp;&#125; \\ensuremath&#123;\\mathord&#123;\\sim&#125;&#125;seen[n]$ \\If&#123;$D \\neq \\textbf&#123;B&#125;_&#123;\\emptyset&#125;$&#125; \\State $visitNext[n] \\gets visitNext[n] \\mathbin&#123;|&#125; D$ \\State $seen[n] \\gets seen[n] \\mathbin&#123;|&#125; D$ \\State do BFS computation on $n$ \\EndIf \\EndFor \\EndFor \\State $visit \\gets visitNext$ \\State reset $visitNext$ \\EndWhile \\end&#123;algorithmic&#125; \\end&#123;algorithm&#125; 效果：","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"tex","slug":"tex","permalink":"http://example.com/tags/tex/"}],"author":"zhiqiuyuan"},{"title":"14","slug":"daily-2023-1-14","date":"2023-01-14T02:32:02.000Z","updated":"2023-01-15T01:37:22.000Z","comments":true,"path":"2023/01/14/daily-2023-1-14/","link":"","permalink":"http://example.com/2023/01/14/daily-2023-1-14/","excerpt":"","text":"今日目标： 上午 1 formulation表格和bug 修改introduction引入baseline 2 修改introduction引入baseline和msbfs 3 复习baseline 4 preliminaries-baseline的第一步 下午 1 preliminaries-baseline的第二步（步骤，没有讨论） 2 preliminaries-baseline的第二步讨论和第三四步 3 preliminaries-baseline的性质 4 preliminaries-msbfs文字和伪代码（伪代码有bug） 晚上 1 msbfs文字和伪代码 修改Baseline格式 忘记记录了 完成例子作图 写一点点contribution","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"画graph(for research paper)的工具推荐","slug":"画graph-for-research-paper-的工具推荐","date":"2023-01-13T11:05:06.000Z","updated":"2024-01-03T14:06:29.000Z","comments":true,"path":"2023/01/13/画graph-for-research-paper-的工具推荐/","link":"","permalink":"http://example.com/2023/01/13/%E7%94%BBgraph-for-research-paper-%E7%9A%84%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/","excerpt":"","text":"哪些工具推荐Graphviz from https://networkx.org/documentation/stable/reference/drawing.htmlwe highly recommend that people visualize their graphs with tools dedicated to that task. Notable examples of dedicated and fully-featured graph visualization tools are Cytoscape, Gephi, Graphviz and, for LaTeX typesetting, PGF&#x2F;TikZ. 其他：https://csacademy.com/app/graph_editor/在线，输入点边数据出图，不过这个导出的png像素不高 draw.iolatex的tikzGephi使用 安装 导入csv文件：文件-导入 基本操作：https://blog.csdn.net/hei653779919/article/details/106851481 Graphviz使用安装后是一些命令有在线版本https://dreampuf.github.io/GraphvizOnline/ DOT语言举例：https://renenyffenegger.ch/notes/tools/Graphviz/examples/indexDOT语言文档：https://graphviz.org/doc/info/lang.html","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"13","slug":"daily-2023-1-13","date":"2023-01-13T00:42:09.000Z","updated":"2023-01-13T11:44:45.000Z","comments":true,"path":"2023/01/13/daily-2023-1-13/","link":"","permalink":"http://example.com/2023/01/13/daily-2023-1-13/","excerpt":"","text":"前面几天和老爸和弟弟回老家喝酒了hhh成果是陈情令+论文写完abstract和introduction的2&#x2F;5今日目标： 上午 1 修改introduction-gap(VP2 literature) 2 写introduction-gap(share literature) （不含讨论为啥不能直接用到解决disjoint path中） 3 写introduction-gap(share 讨论为啥prefixsolve没用) 下午 1 写introduction-gap(share 讨论为啥msbfs不够) 2 修改introduction前半部分 晚上 1 preliminaries的notation部分修改 尝试画图举例子（独立路径定义，baseline举例） 2 搜寻画图工具，锁定gephi","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"写paper学习-chapter14 Review of the Literature","slug":"写paper学习-chapter14-Review-of-the-Literature","date":"2023-01-11T02:59:08.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/11/写paper学习-chapter14-Review-of-the-Literature/","link":"","permalink":"http://example.com/2023/01/11/%E5%86%99paper%E5%AD%A6%E4%B9%A0-chapter14-Review-of-the-Literature/","excerpt":"","text":"from “English for Writing Research Papers” provide readers with just the right amount of literature regarding the sequence of events leading up to the current situationas support for the author’s approach.“The authors do not seem to be aware of the state of the art, I strongly recommend they widen their literature search”gradually prepared the readers for the focus of your work 问自己几个问题 What are the seminal works on my topic? Do I need to mention these? What progress has been made since these seminal works? What are the most relevant recent works? What is the best order to mention these works? What are the achievements and limitations of these recent works? What gap do these limitations reveal? How does my work intend to fill this gap self-assessmentyou can ask yourself the following questions. Are the papers I have mentioned in a logical order? Is it clear why I have chosen these papers and not others? Have I removed any redundancy when reporting the literature? makes it easy for the reader to immediately identify the key points of the literature","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"写paper学习-chapter13 Introduction","slug":"写paper学习-chapter13-Introduction","date":"2023-01-11T02:00:51.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/11/写paper学习-chapter13-Introduction/","link":"","permalink":"http://example.com/2023/01/11/%E5%86%99paper%E5%AD%A6%E4%B9%A0-chapter13-Introduction/","excerpt":"","text":"from “English for Writing Research Papers” The Introduction presents the background knowledge that readers need so that theycan appreciate how the findings of the paper are an advance on current knowledgein the fieldYou need to have a deep knowledge about everything that has been previouslywritten on the topic and decide what is important for the reader to know 问自己几个问题 What is the problem? Are there any existing solutions (i.e. in the literature)? Which solution is the best? What is its main limitation? (i.e. What gap am I hoping to fill?) What do I hope to achieve? structureYour Introduction will not necessarily include all ten parts nor sequence them in the same order(* is a must)In brackets is a very approximate indication of how many sentences you will probably need for each part. general context + specific topic + why the topic is important (1–3) notations, technical definitions, and explanations of key words gives information that readers should already be familiar with and suggests why the topic is important and of interest may be less familiar for your readers. Readers want to quickly learn what the specific topic of your research is the problem to be resolved and why the problem is important (2–4)* exactly what the problem is gap(with literature and maybe with examples) contribution part could be incorporated here. survey of pertinent literature draws attention to problems that have still not been solved. only need to describe what is necessary for the specific purposes of your paper. Much of this literature will then be used for comparative purposes in the Discussion authors’ objectives + idea overall how we intend to fill the gap objectives: so that the referee (and readers) are 100% clear about the objectives of your research and the expected outcome. contribution part could be incorporated here. authors’ contribution (1–2)* a very clear statement of how what they describe in the paper represents an advance on current knowledge (i.e. the knowledge outlined in problem and gap part). main results of the present work (1–4) future implications of the work (1–2) outline of structure (3–4 very short sentences) beginavoiding stock phrases (i.e. typical phrases that everyone uses) at the beginning of the introduction. For example:Recent advances in ... The last few years have seen ...Instead they recommended beginning in a more direct way difference between abstract and introductionThere is some overlap between an Abstract and the Introduction. However, a frequent problem is that authors may cut and paste from their Abstract into their Introduction, which can be very repetitive for readers. what elements from the Abstract the Introduction expands on how sentences from the Abstract are paraphrased in the Introductioneg: The Abstract immediately tells the readers the specific topic of the paper and thenwhat the author’s goal is (Parts 2, 3 and 7). The Introduction sets the context in very general terms (Parts 2). self-assessmentyou can ask yourself the following questions. Is my research question clear? Is it sufficiently different from the Abstract, without any cut and pastes? (someoverlap is fine) Have I mentioned only what my readers specifically need to know and what I will subsequently refer to in the Discussion? Have I been as concise as possible?","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"写paper学习-charpter12 Abstract","slug":"写paper学习-charpter12-Abstract","date":"2023-01-10T10:05:37.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/10/写paper学习-charpter12-Abstract/","link":"","permalink":"http://example.com/2023/01/10/%E5%86%99paper%E5%AD%A6%E4%B9%A0-charpter12-Abstract/","excerpt":"","text":"from “English for Writing Research Papers” Abstract is designed to ‘sell’ your research contentYou can use the answers to these questions to structure your Abstract. background &#x2F; context no more than 25% whether the context is clear for readers eg, sometimes: There is no background information because the context is well known the gap I plan to fill What was new compared to previous research? research problem methods What was new compared to previous research? 通常以method begin+problem开始，比如 we propose a algorithm for computing connected component… results What was new compared to previous research? implications and&#x2F;or conclusion begin反例：readers have to wait up to 15 words before reaching a key word that enables them to understand the potential relevance of the topic.例子：the reader learns either immediately or very quickly what the author has done to fill the knowledge gap self-assessmentyou can ask yourself the following questions. Whenever I have given my readers information, will it be 100% clear to themwhy they are being given this information? Can I make my Abstract less redundant? If I tried to reduce it by 25% wouldI really lose any key content?","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"java程序命令行运行","slug":"java程序命令行运行","date":"2023-01-09T07:21:25.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/09/java程序命令行运行/","link":"","permalink":"http://example.com/2023/01/09/java%E7%A8%8B%E5%BA%8F%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BF%90%E8%A1%8C/","excerpt":"","text":"源文件hello.java public class Hello&#123; public static void main(String[] args)&#123; System.out.println(&quot;Hello World&quot;); &#125; &#125; 方法一编译，将在当前目录下生成hello.class javac hello.java 指定编码方式-encoding UTF-8（默认是ANSI编码方式的，中文编码是gbk，utf-8编码的文件有中文会编译报错） javac -encoding UTF-8 hello.java 运行 java hello 方法二运行 java hello.java","categories":[{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python java程序执行过程","slug":"python-java程序执行过程","date":"2023-01-09T07:18:17.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/09/python-java程序执行过程/","link":"","permalink":"http://example.com/2023/01/09/python-java%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/","excerpt":"","text":"https://www.cnblogs.com/shangping/p/11666551.html C：将源代码编译成可执行的二进制文件，即把源代码翻译成机器代码 Python和Java都是半编译半解释：从源代码中产生一组字节码，它并不是机器代码，但是不管是在Linux还是Windows的机器上，同样的源代码产生的字节码都是一样的，同时它还有个虚拟机，虚拟机会一条一条执行字节码，生成可执行的机器代码交给CPU执行","categories":[{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"},{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"9","slug":"daily-2023-1-9","date":"2023-01-09T06:50:05.000Z","updated":"2023-01-09T06:51:43.000Z","comments":true,"path":"2023/01/09/daily-2023-1-9/","link":"","permalink":"http://example.com/2023/01/09/daily-2023-1-9/","excerpt":"","text":"今日目标： 上午 背单词 两道leetcode 下午 hw二阶段数据集生成 pkumod生产环境恢复 回老家 晚上","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"乱七八糟分析","slug":"writing-2023-1-8-乱七八糟分析","date":"2023-01-08T14:39:18.000Z","updated":"2023-01-08T14:43:53.000Z","comments":true,"path":"2023/01/08/writing-2023-1-8-乱七八糟分析/","link":"","permalink":"http://example.com/2023/01/08/writing-2023-1-8-%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F%E5%88%86%E6%9E%90/","excerpt":"","text":"现象：今晚看english for paper writing，学到了新东西，然后终于摆脱了乱七八糟、没干什么的状态分析：包括昨天到今天都是，比如学Latex和看english for paper writing的第一章，都是感觉没有“以聪明的速度学到新东西”，其中“聪明的速度”和“新东西”二者缺一不可，而今晚属于是35分钟看了挺多东西，还被英语的word order、这本书写得好给惊艳到了，属于二者都有，这带来学到了且还想学的感受","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"写paper学习-chapter2 Word Order","slug":"写paper学习-chapter2-Word-Order","date":"2023-01-08T13:07:51.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/08/写paper学习-chapter2-Word-Order/","link":"","permalink":"http://example.com/2023/01/08/%E5%86%99paper%E5%AD%A6%E4%B9%A0-chapter2-Word-Order/","excerpt":"","text":"from “English for Writing Research Papers” 加*的例句：错误的例子 If these parts come in a different order, this requires more effort by the native reader to understand the whole meaning Basic word order in English: keep the subject, verb, direct object and indirect object as close to each other as possibleS1 shows an example of this order.S1. The researchers sent their manuscript to the journal.This order is rarely altered. It is: subject (the researchers) verb (sent) direct object (their manuscript) indirect object (the journal) The key is to keep the subject, verb, direct object and indirect object as close to each other as possible.S2(correct). Last week the researchers sent their manuscript to the journal for the second time.S3(wrong). The researchers last week sent for the second time to the journal their manuscript.S3: The position of last week and for the second time is wrong, and the indirect object comes before the direct object. Put the subject before the verb Keep the subject and verb as close as possible to each otherwrong： correct： make the meaning &#x2F; direction of the sentence immediately clear Avoid inserting parenthetical information between the subject and the verbSentences are much easier to read if they flow logically from step to step, without any deviations Don’t separate the verb from its direct object: place the direct object before the indirect object sometimes the direct object is very long and consists of a series of items: Put the direct object before the indirect object Choose the subject that is the most relevantClear English requires that you put the subject at the beginning of the sentence, however you may have a choice of possible subjects. eg:X was elicited by Y.Y elicited X. S1. Particularly interesting for researchers in physics is the new feature, named X, for calculating velocity.S2. Physics now has a new feature, named X, for calculating velocity.S3(maybe best). Velocity can now be calculated with a new feature, named X, which is particularly interesting for physicists.S4(maybe best). X is a new feature for calculating velocity. It is particularly interesting for physicists. choose the subject that will give the shortest sentenceS1. The most significant values are highlighted in Table 1.S2(choose this). Table 1 highlights the most significant values.Shorter sentences are often obtained by using active (S2) rather than passive (S1)verbs Don’t make the impersonal it the subject of the sentencePutting it first often delays the subjectwrong eg: It is probable that this is due to poor performance Don’t use a pronoun (it, they) before you introduce the noun (i.e. the subject of the sentence) that the pronoun refers toIt is OK to use a pronoun at the beginning of the sentence, provided that this pronounrefers back to a noun in a previous sentence (i.e. a backward reference). For example:S1. Beeswax is a very important substance because ... In fact, it is ...In S1 it is clear that it refers to beeswax.But in S2 it refers to a noun that comes after (i.e. a forward reference). The reader does not know what the pronoun refers to and thus has to wait to find out.S2. *Although it is a very stable and chemically inert material, studies have verified that the composition of beeswax is …S3. Although beeswax is a very stable and chemically inert material, studies have verified that its composition is … Where to put adverbs of consequence and additionYour aim is to try to put the subject at the beginning of the sentence. So if possible try to delay adverbs that indicate a consequence or add further support to a positive situation. Thus S1 and S2 below would normally be better rewritten as S3 and S4. Put adjectives before the noun they describe, or use a relative clause Do not insert an adjective between two nouns or before the wrong nounS1. *The editor main interface S2. *The algorithm computational complexity S3. The main interface of the editor S4. The computational complexity of the algorithm S5. *The main document contribution S6. The main contribution of the document Avoid creating strings of nouns that describe other nouns you cannot say art state technology (state-of-the-art technology) or mass destruction weapons (weapons of mass destruction). But you can say a software program or an aluminum tube Native speakers do tend to string nouns together, but they intuitively know how to do it. recommend that you verify on Google Scholar that your proposed string of nouns already exists and has been used by native English-speaking authors Ensure there is no ambiguity in the order of the wordsAmbiguity arises when a phrase can be interpreted in more than one way. S1. *Professors like annoying students. In S1 it is not clear if ‘annoying’ describes the students, or it refers to what professors enjoy doing. Depending on the meaning, S1 could be disambiguated as in S3 or S4: S3. Professors like to annoy their students. S4. Professors like students who are annoying. S2. *I spoke to the professor with a microphone. In S2 – did I use the microphone or was the professor holding it? Depending on the meaning, S2 could be disambiguated as in S5 or S6: S5. Using a microphone, I spoke to the professor. S6. I spoke to the professor who was holding a microphone. S7. *To obtain red colors, insects and plant roots were used by indigenous people. In S7 readers may initially think that red colors and insects are part of the same list. Readers will only understand that insects and plant roots is the subject of the verb when they get to the end of the sentence. To avoid this problem there are two possible solutions. S8 puts insects and plant roots as the main subject and S9 primitive people. S8. Insect and plant roots were used to obtain red colors. S9. To obtain red colors, primitive people used insects and plant roots S10. *The European Union (EU) adopted various measures to combat these phenomena. This resulted in smog and pollution levels reduction. We tend to read words in small groups. Often we think that if two or three words immediately follow each other they must be related in some way. When we read resulted in smog and pollution, our initial interpretation is that the smog and pollution are the result of the EU’s measures. Then when we move on and read levels we have to reprocess the information S11. The European Union adopted various measures to combat this phenomena. This resulted in a reduction in smog and pollution [levels] S12. *We also demonstrated that x does not equal y as suggested by Walker (2011). Does S12 mean that Walker suggested that x is equal to y and is thus in contrast to what you are saying (S13 and S14), or that he, like you, found that x does not equal y (S15). S13. Unlike what was suggested by Walker (2011), we demonstrated that x does not equal y. S14. Our findings do not concur with Walker (2011). In fact, we demonstrated that x does not equal y. S15. In agreement with Walker (2011), we demonstrated that x does not equal y","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"梳理科研todo","slug":"writing-2023-1-8-梳理科研todo","date":"2023-01-08T08:08:41.000Z","updated":"2023-01-08T08:50:52.000Z","comments":true,"path":"2023/01/08/writing-2023-1-8-梳理科研todo/","link":"","permalink":"http://example.com/2023/01/08/writing-2023-1-8-%E6%A2%B3%E7%90%86%E7%A7%91%E7%A0%94todo/","excerpt":"","text":"起因：前天大致搞定方案，老师说可以开始写论，但是我对于现在的方案还是没有太大信息，觉得创新还不够，于是现在处于一种有点混乱、什么都想搞但是不是很清楚先搞啥的感觉（英语基础积累，目标会议的论文学习积累，开始思考和写论文，生产环境搭建）分析和基础： 中午看english for paper writing，看到一个写作顺序，和我的逻辑 一致，具有可操作性 打算后天再开始写论文，这是因为现在还没有啥用英语表达的概念，也没有生产环境，先把基础搭起来 一个让人心烦意乱的点：我觉得现在科研相对轻松，应该开始安排其他的事情，但是在安排的时候感觉到很多want_to_do_list，不知道选什么是不是还是要搞一下科研 这是因为没有决定接下来要做什么的原则体系解决： 原则： 每日科研4节课 每节课开始前选自己最想干的事情开始干 科研todo大致计划 [今天-1.10] 生产环境搭建（知道怎么开始开发） english for paper writing 2022sigmod，选一篇作为model 如果看不下去论文，可以开始根据写作顺序写论文 [1.11-1.15] Abstract+Preliminaries(+Methods) 根据写作顺序写论文 期间可能产生新想法 写method的时候同时思考图性质怎么影响method的效果 写论文的时候参考model怎么表达和衔接 english for paper writing","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"写paper学习-chapter1 Planning and Preparation","slug":"写paper学习-chapter1 Planning and Preparation","date":"2023-01-08T03:37:00.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/08/写paper学习-chapter1 Planning and Preparation/","link":"","permalink":"http://example.com/2023/01/08/%E5%86%99paper%E5%AD%A6%E4%B9%A0-chapter1%20Planning%20and%20Preparation/","excerpt":"","text":"from “English for Writing Research Papers” writing orderyou might write several sections simultaneously It is generally best to start with a very rough draft of the Abstract, and then whichever section is clearest in your head (generally the Materials and Methods)A typical order for writing the various sections is thus: Abstract (very rough draft) start with the Abstract will help you to focus &#x2F; orient your ideas on what are the key aspects of your research. Preliminaries Methods Results Discussion It is a good idea to write the Results and Discussion before the Introduction. This is because you will only truly understand the significance of what you have done after you have written these two sections Introduction major part: Laying the background foundations on which you can highlight the significance of your research Conclusions Abstract (final version) Decide what your key findings arebefore you start writing you need to have an absolutely clear idea of:• what your research goal was• what your most important findings are and how you can demonstrate that theyare true• how these findings differ from, and add to, previous knowledge Analyzing the literature, and discussing and presenting your findings to colleagues should help you to identify what your key findings are English levelhow the paper flows and how easy it is to readAll referees will appreciate it if you use simple language Write directly in Englishwith a model paper written by a native English speaker in front of you, which you can follow step by step, it should be quicker than translating from your own language Write in a way that even a non-expert can understand","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"分课时安排的新体会","slug":"writing-2023-1-8-分课时安排的新体会","date":"2023-01-08T00:18:02.000Z","updated":"2023-01-08T00:21:31.000Z","comments":true,"path":"2023/01/08/writing-2023-1-8-分课时安排的新体会/","link":"","permalink":"http://example.com/2023/01/08/writing-2023-1-8-%E5%88%86%E8%AF%BE%E6%97%B6%E5%AE%89%E6%8E%92%E7%9A%84%E6%96%B0%E4%BD%93%E4%BC%9A/","excerpt":"","text":"get新心得：list今天想干的事情，和安排啥时候做这些事情以及做啥时间，相分离，而不是耦合在一起，list今天干的的事情比如清早进行，安排则发生在每节课开始时，这样可以更为有效地制定安排（以前我总是list完想干的事情，然后就按照这个顺序执行下去，一件执行完再执行下一件，顺序和时长上都可能有不合理之处，这样的安排方式需要自己全天状态比较稳定且对自己心中实际上想先做什么有清楚的把握，并且对于今天要做之事的轻重缓急有个清楚的认识，这样难度还是比较高的，可行性不是太好）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"8","slug":"daily-2023-1-8","date":"2023-01-08T00:16:39.000Z","updated":"2023-01-08T13:23:41.000Z","comments":true,"path":"2023/01/08/daily-2023-1-8/","link":"","permalink":"http://example.com/2023/01/08/daily-2023-1-8/","excerpt":"","text":"今日目标：今天是小事情时间！ 上午 1 拿一下新结果 还没有跑完 看之前老师写的main 发现之前写的是动态场景的，看来问题定义这些真的可以写！ 搜集2022sigmod 2 拿一下新结果：更新记录，分析结果，记录异常 3 毕设开题材料修改和上传 中途叉回家hhh 4 english for paper writing page23-34 sigmod2024写作要求 下午出去玩hhh 1 梳理了下现在科研的执行路径 简单分析了下twitter上异常实验结果的原因 背单词 晚上 1 分析twitter上异常实验结果的原因，做验证实验 2 搜集了一点图性质，没有很有启发性，还是需要借助写论文写method的时候促进自己思考 latex生产环境搞起来：overleaf开箱即用很方便噢 3 english for paper writing page34-47","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"Latex入门","slug":"Latex入门","date":"2023-01-07T12:20:52.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/07/Latex入门/","link":"","permalink":"http://example.com/2023/01/07/Latex%E5%85%A5%E9%97%A8/","excerpt":"","text":"编辑器： vscode插件 在线编辑器overleaf：开箱即用 Latex语法这个教程好 https://www.overleaf.com/learn/latex/Learn_LaTeX_in_30_minutes注释：%开头举例： \\documentclass&#123;article&#125; \\begin&#123;document&#125; Subscripts(下标) in math mode are written as $a_b$ and superscripts(上标) are written as $a^b$. These can be combined and nested to write expressions such as \\[ T^&#123;i_1 i_2 \\dots i_p&#125;_&#123;j_1 j_2 \\dots j_q&#125; = T(x^&#123;i_1&#125;,\\dots,x^&#123;i_p&#125;,e_&#123;j_1&#125;,\\dots,e_&#123;j_q&#125;) \\] We write integrals(积分) using $\\int$ and fractions(分数) using $\\frac&#123;a&#125;&#123;b&#125;$. Limits are placed on integrals using superscripts and subscripts: \\[ \\int_0^1 \\frac&#123;dx&#125;&#123;e^x&#125; = \\frac&#123;e-1&#125;&#123;e&#125; \\] Lower case Greek letters are written as $\\omega$ $\\delta$ etc. while upper case Greek letters are written as $\\Omega$ $\\Delta$. Mathematical operators are prefixed with a backslash as $\\sin(\\beta)$, $\\cos(\\alpha)$, $\\log(x)$ etc. \\end&#123;document&#125; 效果： vscode插件 LaTeX Workshop安装https://github.com/James-Yu/LaTeX-Workshop/wiki/Install 装支持: 装texlive并添加环境变量 https://www.tug.org/texlive restart vscode 装插件 外加：如果想卸载texlive on windows:goto texlive installation folder (Default install path is C:\\texlive\\2019\\tlpkg\\installer) and run uninst.bat file 入门使用https://github.com/James-Yu/LaTeX-Workshop/wiki/Install#usage open a .tex file and have a look at the TeX sidebar to access all the extension features 编译：ctrl+alt+b or command palate build latex 或者设置ctrl+l,alt+b https://github.com/James-Yu/LaTeX-Workshop/wiki/FAQ#i-cannot-use-ctrlalt-in-a-shortcut 多文件工程https://github.com/James-Yu/LaTeX-Workshop/wiki/Compile#multi-file-projects While it is fine to write all contents in one .tex file, it is common to split things up for simplicity.For such LaTeX projects, the file with \\begin{document} is considered as the root file, which serves as the entry point to the project.LaTeX Workshop intelligently finds the root file when a new document is opened, the active editor is changed, or any LaTeX Workshop command is executed. Once the root file is determined, it is parsed to discover all the files it includes using input, include, InputIfFileExists, subfile, import and subimport and the process goes on recursively. All these files are called dependencies and are considered to define a LaTeX project 在线编辑器overleaf导入project点击new project，可以选择导入工程 黑暗模式打开一个project，编辑界面左上角的menu进去可以设置主题还有其他设置噢","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[{"name":"tex","slug":"tex","permalink":"http://example.com/tags/tex/"}],"author":"zhiqiuyuan"},{"title":"7","slug":"daily-2023-1-7","date":"2023-01-07T02:30:01.000Z","updated":"2023-01-07T12:51:00.000Z","comments":true,"path":"2023/01/07/daily-2023-1-7/","link":"","permalink":"http://example.com/2023/01/07/daily-2023-1-7/","excerpt":"","text":"今日目标：补充实验和老师发的写论文材料 上午 调试vins的去除1step2 下午 1 - 完成调试，开始跑实验 - 重新实现baseline 2 - 实现完baseline 晚上 1 - 完成调试baseline，重新跑baseline - 跑完baseline和vins_no1step2更新下ppt和表格的实验数据 2 - 看投稿材料-&gt;发现是latex参考hhh - 搜投稿时间 - 学latex和配latex环境 今日反思今天没干啥事的原因： 早上10点半开始，比较晚 昨晚感觉快达成寒假的一个重大目标，心情比较放松 搞的实验主要是增量修改和调试工作，相比于设计和开发比较无聊 上午和下午有在学习的时候唱歌hhhh主要还是心情比较放松+任务不是很让人激动","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"科研计划-时态图","slug":"writing-科研计划-时态图","date":"2023-01-06T15:05:50.000Z","updated":"2023-02-15T02:49:45.000Z","comments":true,"path":"2023/01/06/writing-科研计划-时态图/","link":"","permalink":"http://example.com/2023/01/06/writing-%E7%A7%91%E7%A0%94%E8%AE%A1%E5%88%92-%E6%97%B6%E6%80%81%E5%9B%BE/","excerpt":"","text":"这可能成为你的研究方向噢！所以请对这个研究邻居有哪些研究问题、算法、数据结构，都非常了解且follow最前沿噢！（前沿：即顶会近年） todo调研 泛调研：下述，以及辐射的其他文献 sigmod’22’21 vldb’23’22’21","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"今日汇报的成功原因","slug":"writing-2023-1-6-今日汇报的成功原因","date":"2023-01-06T15:03:59.000Z","updated":"2023-01-06T15:27:10.000Z","comments":true,"path":"2023/01/06/writing-2023-1-6-今日汇报的成功原因/","link":"","permalink":"http://example.com/2023/01/06/writing-2023-1-6-%E4%BB%8A%E6%97%A5%E6%B1%87%E6%8A%A5%E7%9A%84%E6%88%90%E5%8A%9F%E5%8E%9F%E5%9B%A0/","excerpt":"","text":"现象：今日汇报（两类：问题调研和进度汇报）都很成功原因： 问题调研： 全面，框架很好 前期调研和做ppt，积累了知识 在思考ppt逻辑的时候想到分析了为啥要专门研究时态图-&gt;和静态图分析有啥区别，然后在思考区别的时候发现调研的东西正好可以用区别来组织 逻辑清晰（框架很好是其中一部分） 做ppt的一个原则：讲自己懂的东西，不懂的东西并不“尝试摆上去之后通过写好稿子绕过去” 符合这一原则的ppt有如下性质：做完ppt之后不需要准备讲稿（在做ppt的时候从框架、逻辑到每个地方放什么文字什么图片 都是你根据自己的逻辑设计的，做完自然是胸有成竹） 起初框架是讲每个系统，每个系统都有些细碎的部分，我不完全懂且担心会漏掉一些，做完ppt之后有些ppt页面都不知道怎么讲，这说明我放上ppt的内容不是我想讲的内容，不是我完全懂的内容 之后在回顾已经做好的introduction部分觉得导引没有引出接下来要讲的内容，于是开始思考为啥要研究时态图的分析，然后就有了现在的框架 舒服始于梳理逻辑 有效的梳理逻辑可能并不发生在做ppt之前，在做ppt的过程中也在帮助你思考，期间出现有效的对于逻辑的思考 进度汇报： 主要是因为效果不错+进展可以（提出的优化比较多且有效果） 呈现逻辑以后这样：对于每种优化，先摆效果（让听众心中有数），再讲方法细节 进度汇报必然满足前述“做ppt的一个原则”：自己做的实验自己想出的idea，必然很懂的hhh 插入学到的东西：被师姐夸研究细致，这是得益于自己之前有从头到尾思考过问题的转化和解决。以及我们目前提出的创新点到底有哪些，在这个思考的过程中会发现漏掉了哪些实验或者发现了哪些优化空间等等，补齐上去就很严密啦 三思而后行！ 这个一个表现是最近都是在实验之前先思考逻辑体系，做这个实验可以干啥（与xx进行对比说明xx的效果等），想完之后再思考确认一下，确定需要做再动手 上述俩共同原因： 表达清楚，词达意 讲一页ppt的时候，用鼠标辅助，且以符合读者观看一页ppt的习惯顺序讲东西（这个其实主要是在做ppt的阶段，设计每页ppt布局的时候考虑的）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"科研计划-独立路径","slug":"writing-科研计划-独立路径","date":"2023-01-06T12:45:21.000Z","updated":"2023-02-14T10:29:43.000Z","comments":true,"path":"2023/01/06/writing-科研计划-独立路径/","link":"","permalink":"http://example.com/2023/01/06/writing-%E7%A7%91%E7%A0%94%E8%AE%A1%E5%88%92-%E7%8B%AC%E7%AB%8B%E8%B7%AF%E5%BE%84/","excerpt":"","text":"ddlsigmod2024 4.15截止投稿https://2024.sigmod.org/calls_papers_important_dates.shtml icde2024 7.15截止投稿https://waset.org/data-engineering-conference-in-july-2024-in-vienna vldb2024 20th of each month until 2024.3截止投稿 需要干的事：方案： 算法加速效果是对所有图都一样的吗还是会受图性质怎样的影响 图性质(参考社交网络选修课学的图性质)：度分布等分布，直径等测度参数，kcore等聚集参数 加速效果和图性质的关系：直接的解释 base: 路径问题，算法效果一定和图性质有关系 若论文中写算法效果的时候，说明适用于哪种图并解释为啥，或者对于不同性质的图有不同的效果以及原因，这样对问题的研究更全面 论文：2月： 调研下述：还是不是很确定我们的idea是否已经有人做了 单点对最大流：对于拆分图性质的利用是否已经有人研究 写method 写experiment 补充实验 加数据集 对比实验all-to-one3月： 对比实验all-to-one 写related work 整理已经调研的work 调研sigmod和vldb：调研也让你更加清楚你的key findings是哪些，有多重要 调研disjoint path idea改进和实验 投稿要求sigmod2024https://2024.sigmod.org/calls_papers_sigmod_research.shtml Length Length for submitted papers: The main content of the paper must be no more than 12 pages in length for Data Management papers,8 pages for Data Science papers, and 8 pages for the Data-centric Applications papers, although we will allow an unlimited number of pages for the bibliography. No appendix will be allowed Length for revised and camera ready papers: the length of camera ready papers can be up to: 13 pages (+ unlimited references) for the Data Management papers and 9 pages (+ unlimited references) for the Data Science and Data-centric Applications papers. formatsample-sigconf.tex template provided at https://www.acm.org/publications/proceedings-template for LaTeX (version 2e) Submission websitehttps://cmt3.research.microsoft.com/SIGMOD2024 artifacts and reproducibilitywe expect all papers to make their code, data, scripts, and notebooks available if this is possiblethe link and materials should preserve anonymity. For example this may be an anonymous GitHub repository. You may want to make sure that the link you provide is not indexed by search engines. On GitHub, you can do so by adding the following to the page head:&lt;meta name=&quot;robots&quot; content=&quot;noindex&quot;&gt;a reasonably clean version of the state of the code","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"6","slug":"daily-2023-1-6","date":"2023-01-06T03:10:29.000Z","updated":"2023-01-06T15:46:36.000Z","comments":true,"path":"2023/01/06/daily-2023-1-6/","link":"","permalink":"http://example.com/2023/01/06/daily-2023-1-6/","excerpt":"","text":"今日目标： 上午 1 今天上午是从10点半开始的hhhh（昨晚追两不疑去了hhhh） 和老师讨论科研进展，可以开始写论文了 2 改独立路径ppt 修改msbfs_1step2实现，重新实验 如果加速比还是一般般，要加最快方法insV的非1step2的实现 不，检查了下msbfs_1step2的实现不用改，决定实现下最快方法insV的无1step2 下午 追两不疑hhh 晚上 刷b站，跑步 汇报调研情况和科研进展，可以开始写论文啦 同时继续研究问题扩展方案 留给明天hhh 实现下最快方法insV的无1step2（证明1step2有用，在msbfs上无用是因为path1反向记录的结构的限制） 学习下老师发的投稿材料 学Latex 思考写Abstract，Introduction，Formulation（问题定义或者Preliminaries） 总的来说今天追剧磕cp成分过重hhh一些一段时间收官的摆烂行为明天给爷冲","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"5","slug":"daily-2023-1-5","date":"2023-01-05T00:08:38.000Z","updated":"2023-01-05T11:40:27.000Z","comments":true,"path":"2023/01/05/daily-2023-1-5/","link":"","permalink":"http://example.com/2023/01/05/daily-2023-1-5/","excerpt":"","text":"今日目标： 早晨 1 检查和分析昨天的实验结果 还有insV_merge没有跑，其他实验结果符合预期 上午 1 收集实验数据（先对实验体系和要展示的实验组有个底，实验数据都有了只是有俩版本较早） 要不要加一个msbfs_1step2呢？(msbfs_merge+一步走两步)不行，一步走两步需要数据结构的支持 感觉需要 实现msbfs_1step2 2 调试msbfs_1step2 跑Vins_merge的arabic(只有这个图的Vins_merge比insV_merge_map慢) 跑msbfs_1step2 3 背单词 ppt提纲：【大概意思到即可，少细节】问题定义贴总时间对比 判断&#x2F;求解先过滤 Baseline（讲一下算法：拆分图和反向边） msbfs（2014VLDB；拆分图的实现（拆分图性质：v的入邻居和v+N的出邻居都是nbrs[v]），反向边的简单实现，路径记录的简单实现） 路径合并（数据结构prec+succ+joint，反向p1的算法，调整翻译p1p2的算法） 一步走两步（拆分图性质在反向前后总保持“只有一个邻居+交替”，且在反向前可以直接在普通图上搜索，一步走两步后的找p1p2） ij结构（onPath1顶点的观察） ij结构的实现 insv 简单map 二级 vins （下一步：思考比特操作） vij 下午 1 做ppt 实验结果页的结果 过滤点对页 2 做ppt 实验结果页完善（起目录作用） 晚上 1 做ppt 逻辑很舒服、精简地呈现自己的idea真的要花精力www 2 做ppt","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"ubuntu修改nameserver DNS服务器","slug":"ubuntu修改nameserver-DNS服务器","date":"2023-01-04T16:27:27.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/05/ubuntu修改nameserver-DNS服务器/","link":"","permalink":"http://example.com/2023/01/05/ubuntu%E4%BF%AE%E6%94%B9nameserver-DNS%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"修改/etc/resolv.conf即可比如在其中添加 nameserver 8.8.8.8 nameserver 8.8.4.4","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"gcc内置统计1比特数 leading zero counts","slug":"gcc内置统计1比特数-leading-zero-counts","date":"2023-01-04T02:21:02.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/04/gcc内置统计1比特数-leading-zero-counts/","link":"","permalink":"http://example.com/2023/01/04/gcc%E5%86%85%E7%BD%AE%E7%BB%9F%E8%AE%A11%E6%AF%94%E7%89%B9%E6%95%B0-leading-zero-counts/","excerpt":"","text":"https://www.geeksforgeeks.org/builtin-functions-gcc-compiler/ __builtin_clz(x): This function is used to count the leading zeros of the integer. Note : clz &#x3D; count leading zero’sExample: It counts number of zeros before the first occurrence of one(set bit).__builtin_clzl(x) &amp; __builtin_clzll(x) for long and long long data types. a = 16 Binary form of 16 is 00000000 00000000 00000000 00010000 Output: 27 __builtin_ctz(x): This function is used to count the trailing zeros of the given integer. Note : ctz &#x3D; count trailing zeros.Example: Count no of zeros from last to first occurrence of one(set bit).__builtin_ctzl(x) &amp; __builtin_ctzll(x) for long and long long data types. a = 16 Binary form of 16 is 00000000 00000000 00000000 00010000 Output: ctz = 4","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"gcc","slug":"c/gcc","permalink":"http://example.com/categories/c/gcc/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"4","slug":"daily-2023-1-4","date":"2023-01-03T23:42:34.000Z","updated":"2023-01-04T16:16:05.000Z","comments":true,"path":"2023/01/04/daily-2023-1-4/","link":"","permalink":"http://example.com/2023/01/04/daily-2023-1-4/","excerpt":"","text":"今日目标： 早晨 1 分析实验结果（输出表格式） 实现和跑idea_merge_map 设计新增msbfs_merge，因此实验体系： msbfs msbfs_merge: 比1(msbfs)加路径合并 idea_sep: 比1(msbfs)加二级rev结构 idea_sep_map: 比1(msbfs)加map rev结构 idea_merge: 比3(idea_sep)加路径合并 idea_merge_map: 比4(idea_sep_map)加路径合并 2 思考二级的必要性（二级的创新性有，但是和Map又有啥区别呢？） map和两级都是解决这个问题：（每个instance一个记录）不同instance用相同的键去索引，且存储占用尽量每个instance只记录自己需要记录的 更新友好？ 发现实验结果idea_merge比idea_merge_map慢，决定再跑一次idea_merge 上午 1 分析下idea_merge和idea_merge_map的时间分布，二级慢在哪里？ 每一个阶段都慢了，但是path1阶段应该是完全一样的，所以要重新跑idea_merge 转移开发模式：本地调试，服务器跑，git同步（两处可增量） 需要修改下m128实现和传递数据集文件 学习AVX和AVX2下AVX512的平替 2 重新跑idea_merge AVX和AVX2和AVX512的实现（完成，尚未测试正确性） 下午 1 是否有必要实验msbfs_merge呢？感觉没必要，实验体系如下： msbfs degreeDescending msbfs oneHopNbrDegCross idea_sep: 比2加二级rev结构+一步走两步 idea_sep_map: 比2加map rev结构+一步走两步 idea_merge: 比3加路径合并 idea_merge_map: 比4加路径合并 背单词 实验结果中5和6的找p1时间有不小差异，为什么会呢？检查下找p1的源码，按理这俩只有rev结构的差异 检查了源码，按理5和6的找p1代码一模一样，可能是服务器的状态的原因 思考有没有加快二级结构的地方呢？ 实现：不是两级都vector动态增长 改下这个试一试 二级rev的大小（目前是路径长度的中位数） 2 调试AVX和AVX2和AVX512的实现（比特操作的接口正确性） 这个通过test测试了，但是仍然有bug，disjoint_test的找p1有bug 改二级rev的实现（更新idea_sep和idea_merge_map实验结果） 二级rev的实现目前想到的修改点是在构造时，即rev_p1时产生影响的，但是这个阶段和map相差不大 主要要思考加速读 3 调整路径阶段也应该时间差不多 检查下时间和代码：确实代码和rev结构的实现没有关系，但是时间差异在 所以说一定要重新实验下 整理了下实验数据跑步（二级rev有没有优于map的地方呢？） 4 跑步的时候想到了新的一种数据结构：[vertex][instance]-&gt;ij，实验 晚上 1 实现vins merge（完成，开始调试） 2 完成调试，开始跑实验 3 vins merge 如果效果好的话，新实验体系： 1-&gt;2 (i,j)发现和一步走两步 2-&gt;3路径合并 3&amp;4&amp;5&amp;6数据结构存(i,j) msbfs (oneHopNbrDegCross) insV_sep_map: 比1加：insV_map rev结构+一步走两步 insV_merge_map: 比1加：insV map rev结构+一步走两步+路径合并 insV_merge: 比1加：insV二级rev结构+一步走两步+路径合并 Vins_merge: 比1加：Vins rev结构+一步走两步+路径合并 (running) Vij_merge: 比1加：Vij rev结构+一步走两步+路径合并 实现Vij_merge 4 检查Vins_merge实验结果 完成调试Vij_merge，跑 back 1 发现msbfs实现问题，更新之后也要重新跑 实现msbfs_merge 跑insV_merge,msbfs_merge,msbfs","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"劝说臭臭狗事件","slug":"writing-2023-1-3-劝说臭臭狗事件","date":"2023-01-03T15:53:15.000Z","updated":"2023-01-03T15:59:31.000Z","comments":true,"path":"2023/01/03/writing-2023-1-3-劝说臭臭狗事件/","link":"","permalink":"http://example.com/2023/01/03/writing-2023-1-3-%E5%8A%9D%E8%AF%B4%E8%87%AD%E8%87%AD%E7%8B%97%E4%BA%8B%E4%BB%B6/","excerpt":"","text":"事件：中午的时候臭臭狗比较暴躁地和老妈说早点煮饭，我当时借题发挥了一下指出臭臭狗在家就比较暴躁且这是她自己的问题分析： 确实有暴躁这点，和臭臭狗性格确实有关，需要指出 但是并非完全只是性格的问题，我忽略了寒假回家效率的变化情况，我 和臭臭狗是不一样的，我是效率更高，而臭臭狗更低 指出的时机不对，不应该在人家着急去上课且处于生气状态时以责怪的方式指出问题 指出的表达方式和语气不对，是以指责和道德制高点的态度进行的学到：有问题确实可以帮别人指出来，但是注意时机和方式另外判断问题轻重要注意下同理心，站在别人的角度观察和考虑事情，而不是单纯代入自己","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"c++模板类继承，成员获取","slug":"c-模板类继承，成员获取","date":"2023-01-03T03:13:11.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/03/c-模板类继承，成员获取/","link":"","permalink":"http://example.com/2023/01/03/c-%E6%A8%A1%E6%9D%BF%E7%B1%BB%E7%BB%A7%E6%89%BF%EF%BC%8C%E6%88%90%E5%91%98%E8%8E%B7%E5%8F%96/","excerpt":"","text":"public继承普通类，子类中可以直接用父类的protected和public成员 class base &#123; protected: int a; typedef int value_type; &#125;; class child : public base &#123; public: void set(int o) &#123; a = o; &#125; void print() &#123; cout &lt;&lt; a &lt;&lt; endl; value_type i = a; cout &lt;&lt; i &lt;&lt; endl; &#125; &#125;; public继承模板类：1.得用父类::来使用父类的成员（或者using语法一次性引用），直接使用将报错undefined2.另外typedef的using语法需要添加typename template &lt;typename T&gt; class base &#123; protected: T a; &#125;; template &lt;typename T&gt; class child : public base&lt;T&gt; &#123; protected: T b; using base&lt;T&gt;::a; // 注意这里 1 typedef int value_type; public: void set(T o) &#123; a = o; &#125; void print() &#123; cout &lt;&lt; a &lt;&lt; endl; &#125; &#125;; template &lt;typename T&gt; class childchild : public child&lt;T&gt; &#123; protected: using child&lt;T&gt;::a; // 注意这里 1 using child&lt;T&gt;::b; // 注意这里 1 using typename child&lt;T&gt;::value_type; // 注意这里 2 public: void set(T o) &#123; a = o; b = o; &#125; void print() &#123; cout &lt;&lt; a &lt;&lt; &#39; &#39; &lt;&lt; b &lt;&lt; endl; value_type i = a; cout &lt;&lt; i &lt;&lt; endl; &#125; &#125;;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"3","slug":"daily-2023-1-3","date":"2023-01-03T01:31:07.000Z","updated":"2023-01-03T16:04:23.000Z","comments":true,"path":"2023/01/03/daily-2023-1-3/","link":"","permalink":"http://example.com/2023/01/03/daily-2023-1-3/","excerpt":"","text":"今日目标：完成InsVertex的第一种实现+调试+实验 上午 1 背单词 新增play 2 思考新增实验：有必要确认下二级reverse有没有必要：本来最简单实现是直接用map，这样还不需要用onPath1来映射onpath1顶点 因此实验变成：新增了2 (done)基准msbfs：实现原先的数据结构用分开的路径记录结构 InsVertex.map.separate：比1改了数据结构（map reverse），且加上trick(1step-&gt;2step) (done)InsVertex.separate：比1改了数据结构（二级reverse），且加上trick(1step-&gt;2step) InsVertex：比3改了路径合并 [2种实现：控制变量实现：(在路径记录合并前)一种是理论上更快，另一种是实验上更快] 实现instance-vertex的合并（基于InsV） 实现instance-vertex的合并（基于InsV_slower） 实现InsVertex.map.separate（完成代码结构修改和反向结构） 3 实现InsVertex.map.separate（完成代码，通过编译中） 学习模板类继承的成员访问 下午 1 实现和调试InsVertex.map.separate（编译+调试） 跑实验InsVertex.map.separate 2 实现InsVertex-基于InsV（完成path2和调整路径） 实现合并路径是不可避免的，就算3没有2快，合并路径也可以对2进行加快 3 实现InsVertex-基于InsV（完成路径翻译） 调试（进行中） 晚上 1 分析InsVertex.map.separate和InsVertex.separate的时间分布（这个决定二级结构的价值） 这两次的找p1的时间不一样，相差不是特别小，等下晚上的时候全部重新跑一遍看看 idea_sep和idea_sep_map 调试InsVertex-基于InsV（单点对） 2 调试InsVertex-基于InsV（多点对；小图完成） 3 浅跑 InsVertex-基于InsV：发现在中图上有Bug 修bug：定位bug原因：solution被乱写了，除了solution[0]，后面的都是被写乱了 4 调试，没有解决bug 调试存档 bug现象：128的batch，solution[0:3]被乱写，但是后面没问题 (gdb) p solution[0][0].size() $19 = 316753783116 (gdb) p solution[1][0].size() $20 = 934626759737181 (gdb) p solution[2][0].size() $21 = 1160669814397384 (gdb) p solution[3][0].size() $22 = 18446405066571923009 (gdb) p solution[4][0].size() $23 = 2 (gdb) p solution[5][0].size() $25 = 2 (gdb) p solution[6][0].size() $26 = 2 (gdb) p solution[126][0].size() $27 = 2 (gdb) p solution[127][0].size() $28 = 2 (gdb) p solution[128][0].size() $29 = 13628 (gdb) 把数组改vector之后是上述现象，改之前是solution[0]没有被乱写，solution[1:2]有被乱写，后面的没有检查 - b BatchVertexPairs/IdeaMerge.cpp:1443 if pos==1 - 1000点对时 pos==1对应(24578 93371)点对 pos==01对应(24578 93371)(21699 62280)点对，只跑这两对没有问题 - 实在不行的话，跟踪1000点对（翻译block），可能问题暴露不是很慢（c num可以continue num次） - 睡觉之前：跑idea_sep和idea_sep_map 5 解决Bug：果然是前面有数组越界，同时Get新知识：vector也不会对越界进行检查 浅跑看效果 三个实验都跑起来~明天上午分析结果和做ppt！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"play","slug":"writing-play","date":"2023-01-03T01:27:28.000Z","updated":"2024-02-21T02:52:59.610Z","comments":true,"path":"2023/01/03/writing-play/","link":"","permalink":"http://example.com/2023/01/03/writing-play/","excerpt":"","text":"小豹开发1.1 PM 式程序员：gpt-pilot主语言：Python为何管它叫 PM&#x2F;PD 式程序员项目呢？因为你只要负责提需求，向 gpt-pilot 描述你想要的产品功能，以及相关的技术，然后你就可以像一个产品经理一样，等着验收 gpt-pilot 为你产出的代码，做个 review 工作，不满意再返工优化。GitHub 地址→github.com&#x2F;Pythagora-io&#x2F;gpt-pilot 1.2 初级代码工：sweep主语言：Python 本周明星项目，一个帮你实现代码的编码初级工，你在项目的 issue 区，描述清楚你的需求，无论是 bugfix 还是 feature 开发，你在 issue 区描述清楚之后，它就能帮你生成代码，像是下图这样。 与 Copilot 不同，它只提供基于 IDE 的自动补全功能，Sweep 处理整个流程的始终如一。与 ChatGPT 不同，Sweep 不需要粘贴文件。 GitHub 地址→https://github.com/sweepai/sweep 2.2 应用构建：dioxus本周 star 增长数：450+，主语言：Rust Dioxus 可用于生成网页前端、桌面应用、静态网站、移动端应用、TUI 程序、等多类平台应用。特性： 基于本地环境运行的桌面应用（并非 Electron 的封装） 符合强大且人性化的状态管理 全面的内置文档 运行效率高，内存占用低 优秀的异步能力 GitHub 地址→https://github.com/DioxusLabs/dioxus 2.3 你的 App 后端服务：appwrite本周 star 增长数：2,250+，主语言：TypeScript、PHP一个适用于 Flutter、Vue、Angular、React、iOS、Android 的完整后端服务。Appwrite 基于 Docker 提供的微服务库可应用于网页端，移动端，以及后端。Appwrite 支持用户验证、外部授权、用户数据读写检索、文件储存、图像处理、云函数计算等多种服务，此外它提供了可视化界面，方便开发者高效地开发应用.GitHub 地址→github.com&#x2F;appwrite&#x2F;appwrite 2.5 可视化开发：webstudio本周 star 增长数：650+，主语言：TypeScript 释放 CSS 魅力，让你可视化地进行 Web 开发。同 Webflow 类似，有了 Webstudio 设计师也能有 CSS 代码。 GitHub 地址→https://github.com/webstudio-is/webstudio 监控工具2.4 实时监控：netdata本周 star 增长数 450+，主语言：C Netdata 是一款监控工具，兼顾颜值、分布式、高保真、预配置、实时等特性，可用来收集系统、硬件、容器、应用等上千个指标，是一个排除系统故障的好帮手。 GitHub 地址→https://github.com/netdata/netdata 13、nezha：国产的轻量级服务器监控工具。这是一款名为“哪吒”的服务器监控面板，它安装简单、开箱即用，支持监控多个服务器的系统状态、SSL 证书状态、报警通知、流量监控、设置定时任务等功能，适用于 Linux、Windows、macOS、OpenWRT 等主流系统。来自 @两双筷子sqldc 的分享 地址：https://github.com/naiba/nezha 3、Opserver：Stack Exchange 团队开源的监控系统。这是一个采用 .Net 开发的轻量级监控系统，它可以监控包括服务器、日志、SQL Server 集群、Redis 在内的多种服务，支持修改 JSON 配置文件自定义仪表盘展示。Stack Exchange 也是一个网站，它和程序员常用的 Stack Overflow 背后都是同一家公司。地址：https://github.com/opserver/Opserver 9、1Panel：现代化、开源的 Linux 服务器运维管理面板。这是一款 Go 写的 Linux 服务器的在线管理系统，它安装简单、安全可靠，同时集成了 WordPress 等应用、域名绑定、SSL 证书配置、备份等功能，支持快速建站。来自 @llei.wang 的分享地址：https://github.com/1Panel-dev/1Panel Web 服务构建2.5 Web 服务构建：leptos本周 star 增长数：400+，主语言：RustRust 编写的高性能 Web 构建工具，具有：全栈、同构、精细化响应、声明式等特性：全栈：Leptos 可以用来构建在浏览器中运行的应用程序（客户端渲染），在服务器上运行的应用程序（服务器端渲染），或者通过在服务器上呈现 HTML，然后在浏览器中添加交互性；同构：它提供了编写同构服务器函数的基本原理，即可以使用“相同形状”在客户端或服务器上调用但只能在服务器上运行的函数；标准 Web：基于 Web 标准构建应用；框架：提供了现代 Web 应用所需的绝大部分功能；精细化响应：响应式语言构建的 Leptos，可以用极低的开销来编写高质量代码；声明式：只要告诉 Leptos 页面如何显示，它会告诉浏览器如何实现GitHub 地址→https://github.com/leptos-rs/leptos 2.4 Python 搞定 Web：reflex本周 star 增长数 450+，主语言：Python New Reflex 可让你用 Python 开发高质量的定制化 Web 服务，安装和使用也非常简单，在示例部分给出了围绕 DALL·E 创建的一个图像生成的用户界面： GitHub 地址→https://github.com/reflex-dev/reflex 2.5 Python 中的 React（在 Python 中构建用户界面的库）：reactpy本周 star 增长数：3,650+，主语言：Python New “It’s React, but in Python” 这是 reactpy 的项目介绍，非常简洁明了。展开来说，它是一个在 Python 中构建用户界面的库，不需要 JavaScript 就能搞。它的界面同 React 类似，由各种组件构成。即便是新手，从未从事过 Web 开发，也能很快上手。btw，这个项目的 logo 也非常有意思，仔细一看，是 3 条 Python 蛇。 GitHub 地址→https://github.com/reactive-python/reactpy 2.5 快速构建 React 应用（Web 应用程序）：refine本周 star 增长数：1,050+，主语言：TypeScript Refine 是一个基于 React 的框架，用于快速开发 Web 应用程序，它减少了工程师 CRUD 所需的重复工具，并为关键部分（如身份验证、访问控制、路由、网络、状态管理和 i18n）提供行业标准解决方案。 GitHub 地址→https://github.com/refinedev/refine 应用构建2.2 你的个人主页：homepage本周 star 增长数：600+，主语言：JavaScript一款现代、完全静态、快速、安全、高度可定制的应用控制面板，集成了超过 100 个服务，并支持多语言。通过 YAML 文件或者通过 Docker 标签发现，来轻松配置你的主页。部分功能：国际化：支持 40+ 语言；服务和网页书签：可在主页上添加自定义链接；Docker 集成：可查看容器状态和统计信息，并通过标签自动进行服务发现；实用小工具：天气、时间、搜索等等；适配多平台：支持 AMD64、ARM64、ARMv7 和 ARMv6 等架构；安全：所以后端接收的 API 请求都被代理了，从而隐藏你的 API 密钥；GitHub 地址→github.com&#x2F;gethomepage&#x2F;homepage yao：一款 Go 写的应用引擎。通过该项目最快几分钟，就能从零构建出一套系统，适合用于开发接口服务、管理后台、数据可视化平台、自建低代码平台等系统。地址：https://github.com/YaoApp/yao 19、illa-builder：一款灵活、清秀的低代码平台。功能上内置图表、表格、表单等数十种常用组件，直接拖拽即可使用。还支持 GUI 连接数据库或 API，分分钟构建出企业内部应用，支持在线、云服务和 Docker 本地部署多种使用方式。地址：https://github.com/illacloud/illa-builder 2.2 程序构建：dioxus本周 star 增长数：450+，主语言：Rust Dioxus 可用于生成网页前端、桌面应用、静态网站、移动端应用、TUI 程序、等多类平台应用。特性： 基于本地环境运行的桌面应用（并非 Electron 的封装）符合强大且人性化的状态管理全面的内置文档运行效率高，内存占用低优秀的异步能力GitHub 地址→https://github.com/DioxusLabs/dioxus 2.3 快速构建 Python 应用：Tkinter-Designer本周 star 增长数：800+，主语言：Python 一个简单快捷的方法来创建 Python 图形用户界面，Tkinter Designer 旨在加速 Python 中的 GUI 开发过程。因为使用到 Figma，所以它能方便地在 Python 中创建漂亮的 Tkinter GUI。它借助 Figma API 来分析设计文件并创建 GUI 所需的相应代码和文件。 GitHub 地址→https://github.com/ParthJadhav/Tkinter-Designer 实用工具全能 GPT：Auto-GPT（不需要过多的人为干预）主语言：PythonNew 这周很火的一个项目，收割了 52k+ star，Auto-GPT 的 Auto 本就有自动之意，你可以理解为它更加自主，它能完成你指定任务，用过 ChatGPT 或者其他 GPT 应用的小伙伴可能知道在整个交互过程中，你是需要不断地调整你的 prompt，以便生成你想要的结果。Auto-GPT 可以代替你的提示工作，你指定一个任务之后，它能自主地完成它，不需要过多的人为干预。简单来说，它的自我迭代能力更强大，而且你只要有个 Docker 环境，就能给 Auto-GPT 发布任务让它来完成了。GitHub 地址→https://github.com/Significant-Gravitas/Auto-GPT 1.1 在你的计算机里跑模型：open-interpreter主语言：Python New 这是一个在你计算机里运行语言模型的项目，支持 Python、JavaScript、Shell 等等。安装后，通过在终端中运行 $ interpreter，就可以通过类似 ChatGPT 的界面与 open-interpreter 聊天。比如，像是 demo 里，让它将系统主题变暗黑，btw，这个项目开源没到一周，便获得了 15k+ star，可见其受欢迎程度。 GitHub 地址→github.com&#x2F;KillianLucas&#x2F;open-interpreter 1.1 开屏跳过：Android-Touch-Helper主语言：Java 一个开屏广告自动跳过助手，连广告的倒计时都可以省省了。一般来说，广告跳过是基于安卓的 Accessibility “无障碍服务” 实现，这里涉及到你的个人信息存在泄漏可能。Android-Touch-Helper 不需要网络权限、存储权限，安全可靠地绕开开屏广告。 GitHub 地址→https://github.com/zfdang/Android-Touch-Helper 3.1 自定义屏幕点击：gkd主语言：Kotlin该项目是基于无障碍功能的手机自动点击工具，支持自定义或订阅点击规则，可用来自动完成点击跳过广告、同意按钮、领红包等操作。HG 评价地址→hellogithub.com&#x2F;repository&#x2F;9fa01263b1eb408596722394362ec55b 开发者的ppt工具 https://cn.sli.dev/https://github.com/rust-lang/mdBook 将 Markdown 文件制作成在线书籍downkyi：一款多功能的 B 站视频下载工具。这是一款简单易用的哔哩哔哩视频下载工具，它拥有简洁的操作界面，使用起来十分方便。支持批量下载、音视频提取、去水印等功能。地址：https://github.com/leiurayer/downkyi TeamViewer alternativehttps://github.com/rustdesk/rustdeskThe open source TeamViewer alternative. Display and control your PC and Android devices from anywhere at anytime. 20、qinglong：支持多种脚本语言的定时任务管理平台。这是一款定时执行脚本的平台，提供了在线管理脚本、环境变量、查看日志、秒级定时任务等功能，支持 Python3、JavaScript、shell 等脚本语言。地址：https://github.com/whyour/qinglong 2.1 桌面通知：ntfy本周 star 增长数：150+，主语言：Go New ntfy 允许你用 PUT &#x2F; POST 向你的手机或桌面发送推送通知。有了这个简单的基于 HTTP 的发布-订阅通知服务，你就能通过脚本或使用 REST API 向手机或桌面发送通知。 GitHub 地址→https://github.com/binwiederhier/ntfy https://github.com/nonebot/nonebot2 异步的 Python 聊天机器人框架有效地帮助开发人员快速构建聊天机器人、消息通知等项目 2.3 手机图像备份：immich本周 star 增长数：300+，主语言：Dart、TypeScript现在你可以用 immich 直接通过手机来自主托管照片和视频了。部分特性：共享相册软件运行自动备份多用户支持可通过元数据、对象、标签检索内容支持 OAuthGitHub 地址→https://github.com/immich-app/immich 3.2 跨系统文件传输工具：FlyingCarpet主语言：Rust 这是一个支持在 Android、iOS、Linux、macOS 和 Windows 系统之间通过 WiFi 点对点(Ad-Hoc)传输文件的工具。它不需要网络基础设施，只需要两台支持 WiFi 的设备，即可实现近距离无线传输。 HG 评价地址→https://hellogithub.com/repository/469182cc105346629d85fc0452b4fbf2 2.2 下载工具：Hitomi-Downloader本周 star 增长数：400+，主语言：Python Hitomi-Downloader 知名下载工具，只需要一个 url 就能下载对应的图片、视频、音频。部分特性： 简洁的用户界面支持下载加速，也支持限速支持单任务由 24 个线程支持多种下载方式GitHub 地址→https://github.com/KurtBestor/Hitomi-Downloader 6、kdeconnect-kde：Linux 上的设备互联工具。这是一款由 KDE(知名 Linux 桌面环境) 开源的，方便手机与电脑实现无线互联的应用。支持手机和电脑之间共享剪贴板、通知、文件、运行命令等功能，还可以将手机作为电脑的触控板、键盘和幻灯片遥控器等外接设备。地址：https://github.com/KDE/kdeconnect-kde 18、EasySpider：一款可视化爬虫工具。该项目可以让用户在图形化界面下，无需写代码实现自动采集&#x2F;爬虫的功能。用户只需要在网页上选择想要爬的内容，并根据提示框操作即可完成爬虫的设计和执行。地址：https://github.com/NaiboWang/EasySpider c 实现应用学习1、kilo：不到 1 千行代码实现的迷你文本编辑器。该项目是 Redis 作者用 C 语言写的迷你文本编辑器，支持语法高亮和搜索等功能。它不依赖第三方库、代码简洁优雅，去掉注释和空行后不到 1000 行，且只有一个文件，源码阅读起来十分清爽。 地址：https://github.com/antirez/kiloc c++ 实现算法学习1.2 推特推荐算法：the-algorithm主语言：Scala、JavaNew 愚人节开源的 Twitter For You（为你推荐）的推荐算法，作为海外主流的社交平台，想必推特的推荐算法对做社交推荐有一定的参考性。此外，你还可以了解到相关的推荐设计和代码实现。官方的这篇博客 https://blog.twitter.com/engineering/en_us/topics/open-source/2023/twitter-recommendation-algorithm 详细介绍了推荐算法。GitHub 地址→https://github.com/twitter/the-algorithm 2.5 数据搜索：manticoresearch本周 star 增长数：950+，主语言：C++ 用来搜索的高效数据库搜索，它是一个很好的 Elasticsearch 替代品，它有着良好的性能： 比 MySQL 快 182x；在日志分析方面，比 ES 快 29x；在不同的数据量下，是 ES 的 4-15x；单服务器的最大吞吐量比 ES 高 2x；GitHub 地址→https://github.com/manticoresoftware/manticoresearch opencv-mobile：最小化的 OpenCV 库。这是一个比官方版本小 10 多倍的 OpenCV 库，它对模块进行了删减，仅保留了最基本的运算模块和常见的图像处理功能，适用于 Android、iOS、Windows、Linux、macOS 等平台。 地址：https://github.com/nihui/opencv-mobile c++ 实现底层学习7、dragonfly：一款为取代 Redis 而生的内存数据库。它与当下最流行的两款内存数据库 Redis 和 Memcached 的 API 完全兼容，所以无需修改代码即可完成迁移。性能上更是爆炸，官方表示单实例可支持数百万量级的 QPS，而且吞吐量是 Redis 的 25 倍，并可以应对 TB 级别的内存数据集。地址：https://github.com/dragonflydb/dragonfly（c艹项目） oceanbase：一款国产的原生分布式数据库。这是由蚂蚁集团开源的一款基于 Paxos 协议和分布式架构的企业级分布式关系型数据库。它同时支持 OLTP 和 OLAP 的混合负载，具有高可用、高性能、水平扩展、兼容 SQL 语法等特点。地址：https://github.com/oceanbase/oceanbase（c艹项目） 2.1 消息队列：blazingmq本周 star 增长数：450+，主语言：C++ New 高性能的消息队列系统，具有高效、可靠、功能丰富的特性。BlazingMQ 的核心功能是提供持久化、高容错、高性能和高可用的队列，同时，它具备了消息路由策略（例如：工作队列、优先级、fan-out、广播等等）、压缩、强一致性等功能。 GitHub 地址→https://github.com/bloomberg/blazingmq 2.3 更快的链接器：mold本周 star 增长数：650+，主语言：C++ mold 是现有 Unix 链接器（连结器）的替代品，因为它更快：它比第二快的开源链接器 LLVM lld 快几倍，mold 旨在通过缩短构建时间来提高开发者的生产力，特别是在快速调试-编辑-重建循环中。 GitHub 地址→https://github.com/rui314/mold 2、naxsi：高效、易用的 Nginx 防火墙。这是一款专业的 Nginx Web 应用防火墙，可用来抵御 SQL 注入、XSS 攻击等。它采用白名单的防御方式，规则配置简单、功能强大，支持拦截和学习模式。学习模式可辅助发现未知攻击，生成、优化白名单规则。语言：c 地址：https://github.com/nbs-system/naxsi c++ win工具实现学习3.2 内存管理应用：memreduct主语言：C 这是一款 Windows 内存管理工具，可以实时监控计算机内存和清理系统缓存。它体积小(6MB)、内存释放效果明显，兼容 Windows XP 及更高版本。https://github.com/henrypp/memreduct 7、clink：Windows 命令行增强工具。该项目可以让 Windows 原生的 cmd.exe 拥有类似 bash 一样强大的自动补全、历史记录、行编辑等功能，就像在 Linux 终端上一样。来自 @孤胆枪手 的分享地址：https://github.com/chrisant996/clink rust 实现底层实现2.1 向量数据库：qdrant本周 star 增长数：2,750+，主语言：Rust 大模型火了之后，向量数据库也因此得到关注。而 Qdrant(读作：quadrant) 是一款向量相似性搜索引擎和向量数据库。它生产可用，具有方便的 API 来存储、搜索和管理点和带有额外负载的向量。Qdrant 专为支持扩展过滤而设计。所以，对各种神经网络或基于语义的匹配、分面搜索和其他应用非常有效。 GitHub 地址→https://github.com/qdrant/qdrant 底层工具https://github.com/corkami/pics 文件执行剖析2.2 逆向工程（比如反汇编）：ghidra本周 star 增长数：700+，主语言：Javaghidra 是美国国家安全局 (NSA) 开源的一个软件逆向工程（SRE）框架，包括一套功能齐全的高端软件分析工具，使用户能够在各种平台上分析编译后的代码，支持 Windows、macOS 和 Linux。它支持的功能包括反汇编、汇编、反编译、绘图和脚本，以及数百个其他功能，它也支持各种处理器指令集和可执行格式，可以在用户交互模式和自动模式下运行，你还可以用公开的 API 开发自己的 ghidra 插件和脚本。GitHub 地址→https://github.com/NationalSecurityAgency/ghidra 2.4 二进制工具：fq本周 star 增长数 1,250+，主语言：Go 这是一个老项目，主要用来处理二进制和文本格式。你可以用它来查看二进制文件，它的设计之初是为了查询、检查、调试媒体解码器，像是 mp4、flac、mp3、jpeg 等等。不过，它现在已经扩展到各种格式，像是 JOSN、YAML、XML 等等主流格式。此外，它还有处理 url、十六进制的转换等等功能。 GitHub 地址→https://github.com/wader/fq python数据处理21、cudf：支持 GPU 的数据库处理 Python 库。它相当于支持 GPU 的 pandas，处理数据的速度直接起飞。提供了类似 pandas 的 API，支持加载、合并、聚合、过滤等方式操作数据。 import cudf, requests from io import StringIO url = &quot;https://github.com/plotly/datasets/raw/master/tips.csv&quot; content = requests.get(url).content.decode(&#39;utf-8&#39;) tips_df = cudf.read_csv(StringIO(content)) tips_df[&#39;tip_percentage&#39;] = tips_df[&#39;tip&#39;] / tips_df[&#39;total_bill&#39;] * 100 # display average tip by dining party size print(tips_df.groupby(&#39;size&#39;).tip_percentage.mean()) 地址：https://github.com/rapidsai/cudf 7、pybind11：简化 Python 调用 C++ 代码的库。这是一个仅头文件的 C++ 库，它可以将 C++ 代码转化成 Python 可直接引用的模块，轻松实现 Python 调用 C++ 代码。通过这种混合编程的方式，可以提高 Python 代码的性能。地址：https://github.com/pybind/pybind11 前端3.2 超好看的主题配色方案：catppuccin主语言：TypeScript 该项目是由社区驱动的配色方案，内含以暖色调为主、色彩丰富的主题，可用于 VSCode、JetBrains、Vim 等编辑器和 IDE，同样适用于各种编程语言的开发库、终端、操作系统、浏览器等应用。 HG 评价地址→hellogithub.com&#x2F;repository&#x2F;b7b99914e8b34916a1359d494ba7ebde 10、pokemon-cards-css：炫酷的神奇宝贝卡牌 CSS 效果。该项目是口袋怪兽卡高级 CSS 样式集合，使用了 3D 变换、滤镜、渐变等技术，实现了眩光、纹理、银河全息、垂直光束等效果。 地址：https://github.com/simeydotme/pokemon-cards-css 9、layui：面向后端开发者的 Web UI 组件库。这是一款采用原生态 HTML&#x2F;CSS&#x2F;JS 开发模式的免费 Web UI 组件库，它拿来即用无需构建工具，极易上手、UI 简约清爽，深受广大后端开发者们的喜爱。 开始使用 Layui &lt;script src=&quot;./layui/layui.js&quot;&gt;&lt;/script&gt; &lt;script&gt; // 使用组件 layui.use([&#39;layer&#39;, &#39;form&#39;], function()&#123; var layer = layui.layer; var form = layui.form; // 欢迎语 layer.msg(&#39;Hello World&#39;); &#125;); &lt;/script&gt; 图片 地址：https://github.com/layui/layui 18、react-login-page：漂亮的 React 登录页组件。用于快速构建登录页面的 React 组件，内含十几款封装好的界面炫酷、即插即用的登陆页。地址：https://github.com/uiwjs/react-login-page 好玩视频2.5 文本到视频：Tune-A-Video本周 star 增长数：1,050+，主语言：Python文本到视频生成的图像扩散模型的一次调优，简单来说，现在你也可以输入一段文字来获得一段视频了。GitHub 地址→https://github.com/showlab/Tune-A-Video 1.2 让画作动起来：AnimatedDrawings主语言：PythonNew Facebook 研究所开源的动画库，它能让你的画作动起来。无论是你家小朋友，还是你画的卡通人物，AnimatedDrawings 都能让它跟着你一起舞动起来。GitHub 地址→https://github.com/facebookresearch/AnimatedDrawings 37、DeepFaceLive：实时直播和视频 AI 换脸程序。该项目可以对摄像头和本地视频文件中的人物，进行实时 AI 换脸，可用于 PC 直播、视频等场景。 地址：https://github.com/iperov/DeepFaceLive 1、AI4Animation：AI 生成游戏角色动画。该项目可以基于原始的动作捕捉数据，生成更加自然、可控的角色动画，解决两足、四足动物的动画生成问题，比如无需人为干涉就能生成坐下、跳跃、开门、武术等复杂动作的动画。来自 @松果 的分享地址：https://github.com/sebastianstarke/AI4Animation 音乐40、audiocraft：Meta 开源的文本生成音乐的库。该项目可根据文本提示词生成高质量、高保真的音频和音乐，比如吹着风吹口哨、一段适合海滩场景的流行舞曲，生成效果十分惊艳。地址：https://github.com/facebookresearch/audiocraft 文本转语音 https://github.com/neonbjb/tortoise-tts命令 文本转语音：bark主语言：Python New 基于你输入的文本 prompt 生成的语音，你甚至可以指定特定背景，比如：我爱吃披萨（大笑），对应生成的语音并有爽朗的笑声。除了笑声、叹息、哭声等常见情绪音，它还可以模拟音乐、声效，比传统的文本转语音更有智能。 GitHub 地址→https://github.com/suno-ai/bark 1.1 文本生成音乐：audiocraft主语言：Python New 现在已经有文本生成文本的对话模型 ChatGPT，也有文本生成图片的 Stable Diffusion &#x2F; Midjourney 之类的工具，现在多了一个文本生成音乐的 Audiocraft。它是由 facebooksearch 团队开源的音乐生成语言模型，基于 PyTroch 深度学习的音频处理和生成库。目前，它含有 MusicGen 代码，一个目前最先进的文本生成音乐模型。 你可以去示例页面感受下文本生成的音乐，比如下图的沙滩音乐，听下来个人感觉 MusicGen 模型生成出来的效果是最好的。 GitHub 地址→https://github.com/facebookresearch/audiocraft 3.1 AI 翻唱：so-vits-svc主语言：Python 它提供了一种歌声转换的 AI 算法，能够实现高质量的歌声转换。更有网友玩出了花样，用它训练出来的模型翻唱流行歌曲，效果惊人。但需要注意的是训练数据集的授权问题，否则 AI 生成的内容将面临侵权的风险，目前该项目已停维护。 HG 评价地址→https://hellogithub.com/repository/43e8a074c0264cf295f2b512d0852134 1.2 Whisper 网页版：whisper-turbo主语言：TypeScriptNew 作为网页版 Whisper 项目，它由 Rust、WebAssembly 和 WebGPU 提供支持，可以达到 ~20 倍的实时速度。作为一个客户端，它具有以下优点：实时流（WIP）–只需对着麦克风说话，就能像科幻电影一样实时观看文本显示；完全私密和离线；GitHub 地址→https://github.com/FL33TW00D/whisper-turbo 地理25、prettymaps：绘制好看的地图海报的 Python 库。该项目可以将 OpenStreetMap 的地图数据绘制成漂亮的地图海报，上手简单可自定义填充颜色。 地址：https://github.com/marceloprates/prettymaps 1.2 跨平台 GIS（地理信息系统）：QGIS主语言：C++ 一个功能齐全、用户友好、免费的开源地理信息系统，即 GIS，它可运行在 Unix、Windows、macOS 等系统之上。具有以下特性： 可管理空间数据精美的制图，下图便是根据梵高的经典画作绘制的地图地理空间分析支持高度定制化，具有良好的可扩展性GitHub 地址→https://github.com/qgis/QGIS 图片41、Fooocus：一款开箱即用的图片生成软件。该项目在设计时吸收了 Stable Diffusion 和 Midjourney 的优点，它安装简单、操作方便，省去了复杂的参数调节步骤。用户只需要输入提示词，就可以生成与 Midjourney 水平相当的图片。支持本地部署、离线使用，最低配置要求 8GB 内存和 4GB 的 Nvidia 显卡。来自 @刘三非 的分享地址：https://github.com/lllyasviel/Fooocus 43、sd-webui-EasyPhoto：你的智能 AI 照片生成工具。这是一款用于生成 AI 肖像画的 WebUI 插件，可用于生成专业质感的照片，相当于免费、可本地部署的妙鸭相机。 地址：https://github.com/aigc-apps/sd-webui-EasyPhoto https://github.com/excalidraw/excalidraw 手绘风流程图style2paints 是一个给草图上色的 AI 工具，你上传一张线稿之后，指定风格和光源，等着收上色成品即可。GitHub 地址→https://github.com/lllyasviel/style2paints 2D 变 3D：pix2pix3DGitHub 地址→https://github.com/dunbar12138/pix2pix3D 4、geometrize：将图像用几何图形重绘的工具。该项目可以用圆形、三角形、矩形等几何图形重新绘制图像，并将结果导出为 SVG、PNG、JPG、GIF 等格式。地址：https://github.com/Tw1ddle/geometrize 1.1 漂亮的二维码：qrbtf主语言：JavaScript 这是一个本周刷屏社交圈的艺术二维码，大概是下图这个样子： 图片它主要是通过 Checkpoint + LoRA + QR Code ControlNet 方法实现，简单来说它是并不是一个开源的项目，而是由模型生成的二维码，当然你可以在这篇文章《AI 生成可扫码图像 — 新 ControlNet 模型展示》中下载到中国传统纹样、浮世绘、二次元、插画等多种风格的艺术二维码。不过这里，其实想推荐这篇文章作者开源的二维码生成器：qrbtf。 虽然相较于 ControlNet 模型，qrbtf 显得有点平平无奇。但是胜在兼顾了便捷和美观，毕竟不是谁都有条件训练一个模型出来的。 qrbtf 的使用非常简单，项目克隆下来之后，有 npm 的话直接 start 即可使用，支持导出 SVG 和 JPG 格式的图像。 GitHub 地址→https://github.com/ciaochaos/qrbtf 1.2 3D 生成器：shap-e主语言：Python New OpenAI(ChatGPT 开发商) 又开源了一款新模型，这个模型能实现输入文本或者图片，生成对应的 3D 对象，下图便是“An airplane that looks like a banana” 的 3D 图。而它的使用也非常简单，安装一个包即可： pip install -e .GitHub 地址→https://github.com/openai/shap-e 42、GFPGAN：腾讯开源的人脸修复算法。它可以用于修复像素低、模糊、破损的人脸图像，尤其是在脸部细节和清晰度方面，修复效果尤为出色。地址：https://github.com/TencentARC/GFPGAN 43、ImageBind：连接多种感官数据的 AI 模型。这是一个由 Meta AI 开源的新型多模态 AI 模型，支持在图像、文本、音频等六种不同模态之间任意转换。比如它可以根据一段火车的音频，自动生成火车的照片、视频和一段文本。地址：https://github.com/facebookresearch/ImageBind 图像&#x2F;视频工具图像31、oxipng：多线程的 PNG 图片压缩工具。这是一个 Rust 写的命令行 PNG 无损压缩工具，支持多线程压缩速度快，还可作为 Rust 库使用。地址：https://github.com/shssoichiro/oxipng 39、DragGAN：拖动 GAN 完成 P 图。这是 DragGAN 的官方源码，它支持通过鼠标拖拽的方式对图像进行编辑。任何人都可以通过精确控制像素去向，轻松修改图像中物体的姿态、表情、形状、布局等。例如，可以让图片上原本站着的小狗坐下。 地址：https://github.com/XingangPan/DragGAN 2.4 快速去背景：background-removal-js本周 star 增长数 1,950+，主语言：TypeScript New 不知道有多少小伙伴用过一个去背景服务叫做 remove.bg，这是一个开源的去背景服务，不用受限于 remove.bg 的清晰度限制，你可以自己抠掉图像中的背景。当然它提供了在线试用链接：https://img.ly/showcases/cesdk/web/background-removal/web GitHub 地址→https://github.com/imgly/background-removal-js 2.2 抠图神器：sam-hq本周 star 增长数：1,250+ New Segment Anything in High Quality 是一个高质量的目标识别、分割项目。如果你不是一个 AI 从业者，你可以试试用它来抠图，会非常好用。项目的代码将在下周公布，有兴趣的小伙伴也可以阅读下 HQ-SAM 论文：https://arxiv.org/abs/2306.01567。 GitHub 地址→https://github.com/SysCV/sam-hq 视频3.1 GIF 录屏工具：ScreenToGif主语言：C#一款 Windows 上的免费 GIF 录屏工具，易安装、好上手，支持录制指定区域画面，且可以将视频导出为 gif 等文件格式。 7、shotcut：一款功能强大的免费视频剪辑软件。这款软件虽然免费但在功能上完全不输收费的视频剪辑工具，可作为 Pr 的开源替代品。它拥有中文和直观的操作界面，支持数百种音频和视频格式、素材原生编辑、多时间线等功能，适用于 Windows、Linux、macOS 系统。地址：https://github.com/mltframework/shotcut 19、lossless-cut：视频&#x2F;音频无损编辑的工具。该项目支持快速、无损地切割&#x2F;合并大型视频和音频文件，比如摄像机、GoPro、无人机等设备录制的原始文件都很大，通过粗剪可以减小文件体积、节省空间。来自 @coolxy 的分享地址：https://github.com/mifi/lossless-cut pdf工具16、Stirling-PDF：允许对 PDF 文件做各种操作的 Web 应用。这是一款功能强大、开箱即用的 PDF 工具，支持拆分&#x2F;合并文件、添加&#x2F;提取图片、压缩、加水印、添加&#x2F;删除密码等功能，满足你对 PDF 文件的所有需求。 地址：https://github.com/Frooodle/Stirling-PDF 笔记工具2.3 文档管理：paperless-ngx本周 star 增长数：450+，主语言：Python、TypeScriptPaperless-ngx 是一款文档管理系统，可将你的实体文件转化为可搜索的在线档案，从而减少纸张的使用。Paperless-ngx 从 paperless-ng fork，后者于今年 2 月已经归档不再更新，因此 paperless-ngx 将项目 fork 出来自行维护。GitHub 地址→github.com&#x2F;paperless-ngx&#x2F;paperless-ngx 2.1 知识管理工具：AFFiNE本周 star 增长数：1,250+，主语言：TypeScript 一个类 Notion 的知识管理工具，支持离线使用。同 Notion 一样，集成了笔记、表格、数据库等功能。 GitHub 地址→https://github.com/toeverything/AFFiNE 开发工具借助 GPT 模型帮助那些向文档提问（比如查sklearn的文档我怎么构建朴素贝叶斯模型）、检索的人快速得到准确、全面的答案。GitHub 地址→https://github.com/arc53/DocsGPT 3、ttyd：简单的网络共享终端的命令行工具。地址：https://github.com/tsl0922/ttyd 10、rr：Linux 上的轻量级 C&#x2F;C++ 调试工具（可反复调试）。这是一款 Linux 上的轻量级调试 C&#x2F;C++ 代码的工具，支持录制、重放和反向执行等操作，提供了一个可反复调试的环境，大大提升了调试效率。地址：https://github.com/rr-debugger/rr 12、sourcegraph：一款强大的代码搜索平台。该项目能够对代码库进行语义索引和分析，支持正则表达式搜索、输入搜索条件时的自动补全、类似 IDE 的跳转到定义和引用。它可以用于构建公司内部的代码搜索平台，帮助程序员完成跨项目的代码查找、代码审查、代码追踪等。 图片地址：https://github.com/sourcegraph/sourcegraph 1.1.2 代码检索：bloop主语言：TypeScript、RustNew 采用 GPT-4 实现的，代码搜索引擎，支持用自然语言、正则、过滤查询等找寻你在本地、远端仓的代码。你也可以用它来帮你讲解他人的代码。GitHub 地址→https://github.com/BloopAI/bloop 2.5 Windows 实用集：PowerToys本周 star 增长数：1,700+，主语言：C#、C++ Microsoft PowerToys 是一套实用工具，希望提升进阶用户的 Windows 使用体验，提高工作效率。 GitHub 地址→github.com&#x2F;microsoft&#x2F;PowerToys 1.1 实用 Windows（Windows 工具箱与精简win）：winutil主语言：PowerShell Windows 它自带的某些组件是非必要的，那么如何提高 Windows 系统的效率呢？winutil 便是一个工程师的 Windows 工具箱，它不仅提供了开发工具的一键安装，还通过配置关闭了系统更新和多余的功能，精简了 Windows 正在运行的进程，可用来快速配置出一个简洁、高效的 WIndows 系统环境。 GitHub 地址→https://github.com/ChrisTitusTech/winutil 10、gitpod：随时准备好编码的云开发环境。这是一个提供在线开发环境的 K8s 应用程序，通过配置文件可以快速地为 GitHub、GitLab 上的项目，创建一个集成了在线 IDE、库、依赖项等工具的在线开发环境。地址：https://github.com/gitpod-io/gitpod 用于制作美观、结构化和信息丰富的README的命令行工具。md文件。由OpenAI语言模型API提供支持。https://github.com/eli64s/README-AI 大模型15、Flowise：用拖拽的方式构建大模型应用。该项目可以让你通过可视化、拖拽组件的方式自定义大模型(LLM)流程，轻松构建 LLM 应用，支持 Docker 一键启动服务。 图片 地址：https://github.com/FlowiseAI/Flowise TeamSmart AI 允许你组建一个人工智能助手团队来帮助你完成日常任务是一款Chrome浏览器扩展，旨在提高您的生产力并增强您的ChatGPT体验。它允许你组建一个人工智能助手团队来帮助你完成日常任务。它可以与您自己的OpenAI API密钥一起使用。https://www.teamsmart.ai/ 一键部署设计良好的ChatGPT web UI在Vercel。界面经过抛光，支持响应式设计、暗模式和PWA。具有内置提示库，对话压缩和将聊天记录导出为Markdown文件等功能。https://github.com/Yidadaa/ChatGPT-Next-Web ChatPDF 与他们的PDF文件进行口头交流是一种创新的工具，它允许用户与他们的PDF文件进行口头交流，从而更容易从手册、法律合同和研究论文等大型文档中提取信息。https://www.chatpdf.com/ Visual ChatGPT 在聊天过程中发送和接收图像是一个web应用程序，它将ChatGPT和一系列Visual Foundation Models连接起来，以便在聊天过程中发送和接收图像。https://github.com/microsoft/visual-chatgpt ChatBox是OpenAI API的跨平台桌面客户端，也是一个即时调试和管理工具。https://github.com/Bin-Huang/chatbox opencat 本机桌面ChatGPT客户端，利用您自己的API密钥，提供更快和增强的聊天体验。https://opencat.app/ 多媒体GPT 连接OpenAI GPT与视觉和音频。用户现在可以发送图像、视频和录音，并获得文本和图像格式的回复。https://github.com/fengyuli2002/multimedia-gpt 微信聊天机器人 zhayujie&#x2F;chatgpt-on-wechatChatGPT for Wechat 业务工具19、talk：点开即用的在线视频应用。打视频电话的 JavaScript这是一款基于 WebRTC 构建的 P2P 在线视频应用，它免费、无需下载和注册、点开即用。地址：https://github.com/vasanthv/talk 医学IT2.5 医疗影像领域的深度学习：MONAI（基于 PyTorch 的开源框架）本周 star 增长数：950+，主语言：Python MONAI 是一个基于 PyTorch 的开源框架，用于医疗影像领域的深度学习。有了它，你可以创建医疗影像端到端训练工作流程，让 AI 在医疗领域进行应用。 GitHub 地址→https://github.com/Project-MONAI/MONAI 攻略personal-security-checklist：保护你的数字安全和隐私的清单。这是一份教你如何保护个人信息的列表，包括密码、浏览网页、电子邮件、社交网络、手机、电脑等方面。 地址：https://github.com/Lissy93/personal-security-checklist 未分类","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"知识项","slug":"writing-知识项","date":"2023-01-03T01:27:28.000Z","updated":"2023-02-20T02:14:06.000Z","comments":true,"path":"2023/01/03/writing-知识项/","link":"","permalink":"http://example.com/2023/01/03/writing-%E7%9F%A5%E8%AF%86%E9%A1%B9/","excerpt":"","text":"红黑树 B+树 LDBC benchmark","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"开源项目","slug":"writing-开源项目","date":"2023-01-03T01:27:28.000Z","updated":"2023-02-23T01:00:41.000Z","comments":true,"path":"2023/01/03/writing-开源项目/","link":"","permalink":"http://example.com/2023/01/03/writing-%E5%BC%80%E6%BA%90%E9%A1%B9%E7%9B%AE/","excerpt":"","text":"graphone graphchi CUB: Main Page (nvlabs.github.io) leveldb nginx redis OceanBase linux项目源码学习：大数据计算引擎图数据库","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"如何平衡科研和其他学习","slug":"writing-2023-1-2-如何平衡科研和其他学习","date":"2023-01-02T14:11:26.000Z","updated":"2023-01-02T14:17:01.000Z","comments":true,"path":"2023/01/02/writing-2023-1-2-如何平衡科研和其他学习/","link":"","permalink":"http://example.com/2023/01/02/writing-2023-1-2-%E5%A6%82%E4%BD%95%E5%B9%B3%E8%A1%A1%E7%A7%91%E7%A0%94%E5%92%8C%E5%85%B6%E4%BB%96%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"目前发现的一个有效的方法： 35分钟一节课为单位来安排任务，课间思考接下来要干啥，并且记录下每节课干了啥 早上下午晚上开始之前先思考要干啥怎么干 提高科研效率 达咩从早到晚干科研，卡住了可以先放一下，转角遇见灵感 行前三思，先思考再行动","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"为啥汇报前担心","slug":"writing-2023-1-2-为啥汇报前担心","date":"2023-01-02T14:03:04.000Z","updated":"2023-01-02T14:10:17.000Z","comments":true,"path":"2023/01/02/writing-2023-1-2-为啥汇报前担心/","link":"","permalink":"http://example.com/2023/01/02/writing-2023-1-2-%E4%B8%BA%E5%95%A5%E6%B1%87%E6%8A%A5%E5%89%8D%E6%8B%85%E5%BF%83/","excerpt":"","text":"现象：自己在汇报之前（不管是组会汇报还是简单的毕设开题），都会处于一种不是很轻松的状态；同时如果很有把握很懂的话，处于一种“热乎”的状态的话，也会觉得很有把握汇报前担心的原因： 听众很重要 是否对于讲解的内容真正很懂 在注意到产生感受的时候，是否还记得 讲之前复习下，但是不是过度复习讲解内容，复习多了会变成背诵的 知识层面自己是不是懂 讲之前确实变成专家。注意不是总复习讲解内容 讲解的内容呈现是不是按你自己舒服、欣赏的逻辑解决：除了上述针对每次汇报的好好准备+舒服逻辑，还有多多锻炼~","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"2","slug":"daily-2023-1-2","date":"2023-01-02T01:37:31.000Z","updated":"2023-01-03T01:30:42.000Z","comments":true,"path":"2023/01/02/daily-2023-1-2/","link":"","permalink":"http://example.com/2023/01/02/daily-2023-1-2/","excerpt":"","text":"上午 1 新增daily管理 思考独立路径idea的分析：发现了idea比理论慢的新的原因（虽然但是，这仍然只是比较弱的创新，核心创新还是在msbfs发现一些insight，和普通msbfs不一样的地方） 打算开始： vertex-ij的合并（这个不打算了，比下述慢） instance-vertex的合并（这个更快，先实现它） 2 分析instance-vertex的第二种实现为何比第一种慢很多 计划实验： 基准msbfs：实现原先的数据结构用分开的路径记录结构 InsVertex.separate：比1改了数据结构，且加上trick(1step-&gt;2step) InsVertex：比2改了路径合并 [2种实现：控制变量实现：(在路径记录合并前)一种是理论上更快，另一种是实验上更快] 实现instance-vertex的合并（基于InsV） 实现instance-vertex的合并（基于InsV_slower） 设计3的实现 3 设计1的实现 实现1 4 实现1（还差main和调试） 下午 1 背单词 写完1的main和完成调试 2 调整之前idea实现的代码结构 设计和实现3的第一个 3 设计和实现3的第一个：完成path1 4 设计和实现3的第一个：设计和完成部分reverse_path1 晚上 1 图系统开会（本来要汇报结果被鸽了hhhh）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"鸡汤~","slug":"writing-鸡汤","date":"2023-01-02T01:22:53.000Z","updated":"2023-01-21T12:21:46.000Z","comments":true,"path":"2023/01/02/writing-鸡汤/","link":"","permalink":"http://example.com/2023/01/02/writing-%E9%B8%A1%E6%B1%A4/","excerpt":"","text":"坚定信念，付诸行动，勇敢地去追逐生命里那些“有意义的事情” 收获太多 只能和大家浅浅分享以下几点贯穿始终的线索&#x2F;杰出科学家体现出的共性：1 保持怀疑，don’t take anything for granted. 对于“不可逾越的困难”，逐条分析构成困难的原因，对其中存在的细小裂缝（逻辑漏洞）穷追不舍。2 从重大问题的大局观开始，一步一步解决问题。前提是对领域内何为重大问题保持敏感，这又要求对基础知识有深且广的了解。3 设计严谨的实验并高效执行，习惯随之而来的失败，深入分析每次失败的原因。同时通过推进并行的项目以转换心情、与collaborator商讨等方式尽量保持健康的心态。4 以开放的心态分享自己的研究进展、与他人合作。5 保持热爱。6 严格遵守学术规范。某种程度上，这几条属于“道理我都懂”的范畴，但优秀的老师们以极具分量的亲身经历为它们提供了注脚，令我的理解再深入了一层，也更能将这些“道理”运用于自己的科研中。另外，因为事前仔细考虑了自己的预期、定下了每场讲座至少听懂motivation、问题定义和大致脉络，并尽量问一个问题的KPI（？）所以惊喜地发现自己接受新知识和提出问题的能力在四天高强度的锻炼下有不小的提升","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"年终反思转化为每日打卡","slug":"writing-2023-1-1-年终反思转化为每日打卡","date":"2023-01-01T15:52:30.000Z","updated":"2023-01-01T15:54:31.000Z","comments":true,"path":"2023/01/01/writing-2023-1-1-年终反思转化为每日打卡/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-%E5%B9%B4%E7%BB%88%E5%8F%8D%E6%80%9D%E8%BD%AC%E5%8C%96%E4%B8%BA%E6%AF%8F%E6%97%A5%E6%89%93%E5%8D%A1/","excerpt":"","text":"起因：2022年终反思最后变成了大概7条的“希望新的一年”，为了让这个希望不至于只存在于一个上午，决定用软件小日常的每日打卡来每日审视自己是否有努力去做到这7条本文目的：mark一下，观察效果，随时调整","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"2022年终","slug":"writing-2023-1-1-2022年终","date":"2023-01-01T15:47:23.000Z","updated":"2023-01-01T15:47:40.000Z","comments":true,"path":"2023/01/01/writing-2023-1-1-2022年终/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-2022%E5%B9%B4%E7%BB%88/","excerpt":"","text":"回忆大四上学期：放松+摆烂科研 一周周，每周只干了科研还没啥进展 每天很多时间在划手机、和林老师约会、走路、发呆，晚上经常熬夜（在和林老师在一起之后才不熬夜以及刷手机变少晚上不追剧）为了追剧hhh（间谍过家家，好想告诉你，鬼灭之刃，夏日重现，relife，进击的巨人）， 但是也有一些尝试：都是生活上的hhh 三分钟热度：吉他，做美食 有坚持：饮食控制，出去玩 时间线：2022.7.4晚饭吃沙茶面的时候得知ok之后，到回家，到去重庆，到去外婆家，到去秦皇岛，从秦皇岛回来的时候就一直想玩，然后到国庆回家和妈妈臭军军玩耍，回来和老师分手，然后又在一起，直到11月底，期间一直是总和林老师约会、追番，从秦皇岛回来以后，也就是大四下学期，基本上只是有最多连续几天的内驱努力（内在的很想干科研，而不是被自己觉得需要而被迫做科研）和享受努力，总体而言没有干能力之外的事情，没有学自己保研前想的要干的事情 现状和改变 精神： 精神荒芜、思考力退化，一方面对外没有观察，满足于追番追剧，另一方面对内很久”没有转过一个念头” 看书少了：输入带来思考 用写作和看书代替无目的有目的刷手机和追剧追番 刺激少了，没有榜样对比：有对比有刺激带来思考 了解优秀的人在干什么 身边大佬的博客和周报 Github大佬的仓库 结交优秀的人：和优秀的人的直接相处能非常有效有力地刺激思考 实习 对”人生意义是什么”没有答案，且不清楚自己想要成为什么样的人，几乎没有思考过未来，没有根据未来想怎么样来规划现在（进高校还是进企业，这导致现在很不一样的努力） 需要判断进企业和搞科研哪个是我想的： 进企业：大四下学期和暑假去实习 搞科研：好好读研（包括研零），观察自己搞科研的潜力，以及是否快乐 专业： 技术水平很菜但是总是只做手头上最紧的事情（科研），并且丧失技术提升的内驱热情（可以看到同级的大佬在这一年都参加了更多的比赛做出了更多的成果，在超越自己能力的事情上获得成长，而我这一年比本科前两年摆烂得多，没有主动去争取机会，而是躺平在李老师课题组完成李老师分配的任务和一直在做没有进展的科研，能力始终原地踏步） 安于现状躺平，没有关注更没有尝试专业上有趣的事情 躺平和没有内驱动力是因为不了解或者了解不够，不了解业界动态，不觉得有意思，没有新东西，局限于李老师组分发的任务的视野，这必然导致一潭死水 Hellogithub了解趋势 看论文（比如三大会近三年，了解有哪些研究方向，又有哪些方法，顶级论文就是了解前沿和趋势的一手资料！） 性格和软实力： 内向胆小（但不是自卑，自信倒是有），独当一面&#x2F;被交付未做过的事情的时候首先感受到的是害怕、担心、没有把握，通常不能马上发挥自己原本的实力和智力 获得独当一面&#x2F;承但挑战的机会，锻炼自己： 大四下学期和暑假去实习（不一定大厂了，比如tl去的岳麓区的人工智能的企业，比如dzx去了杭州网易实习） 这样的话寒假要：独立路径方案完成+毕设方案完成 研究生阶段参加一些学生工作 生活： 沉溺于小红书+追剧+磕cp，完成之后后悔。本学期内总是反复，10-12月超级多的cp图，8月追了很多番，和林老师一起散步后早睡停了一段时间，寒假早睡也停了一段时间，但是小红书一下回来+科研上没有进展就又会开始：这是浪费生命 小红书除了做美食和旅行的时候下回来看攻略以外，禁止下载 不熬夜 用写作和看书代替无目的有目的刷手机和追剧追番 寒假开始坚持了健康生活习惯： 请坚持：早中晚运动 + 多喝水 + 记录饮食控制饮食 + 不熬夜 对于做饭做美食获得了热情 对于出去玩和旅行获得了热情，这是全身心自由和愉快的事情 对于生活（自己或和家人和关系亲密的人出去玩、追番放松等）和事业有了新的认知观，事业重要，生活同样重要，这点值得肯定，但是现在有点跑偏成：”关注生活的意义和烟火气”有点变成享受和影视放松，”事业重要，生活同样重要”有点变成摆烂合理、事业没有生活重要、甚至丧失了事业提升的热情 断断续续地读完了战争与和平，开始看约翰克里斯朵夫，看书真的会影响一个人，可能不是直接在价值观上，但是在比如观察力、走在街上的关注点有所影响 谈了男朋友，对恋爱关系有所启蒙 没有朋友，亲密关系只在林老师和臭臭狗 希望新的一年 坚持健康生活全套~（早晚运动+十一点半前睡觉+喝够四保温杯水+记录饮食） 持续上升态势~（感觉有所成长，而不是持久躺平始终做舒适圈中或者被安排的事情）平衡生活和事业~（但不是放弃事业偏重生活） 性格上勇敢地独当一面的突破~（内向和胆小希望在新的一年通过独当一面的机会和挑战得到锻炼） 无目的或有目的刷手机和追剧适可而止了！解锁旅行新地点或旅行新资本~（旅行的快乐更彻底~旅行的资本：专业上的上升（能力资本）+硬性事情的完成（时间资本）啦） 通过阅读和写作把思考力锻炼起来~ 坚持通过60s+hellogithub+阮一峰科技周报了解世界和业界动态~ 通过看最新论文把握前沿动态、收获科研上较为全局和主动的姿态~（比如三大会近三年，了解有哪些研究方向，又有哪些方法，顶级论文就是了解前沿和趋势的一手资料！）","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"大四下学期要做","slug":"writing-2023-1-1-大四下学期要做","date":"2023-01-01T15:44:02.000Z","updated":"2023-01-01T15:44:15.000Z","comments":true,"path":"2023/01/01/writing-2023-1-1-大四下学期要做/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-%E5%A4%A7%E5%9B%9B%E4%B8%8B%E5%AD%A6%E6%9C%9F%E8%A6%81%E5%81%9A/","excerpt":"","text":"必须做：- 驾照- 吉他- 实习（1.判断企业适合否2.获得独当一面的锻炼机会 3.结交优秀的人） 大四上学期总是以科研为理由拒绝很多事情，但是实际上自己并不能做到完全投入科研、完全快乐地内驱做科研，这样的结果就是只干了科研但是科研也没干什么，这样会后悔的（比如大四上学期没有实习）所以我相信上面的事情一定是可以在学习之余兼顾的！","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"年终说说总想反复看","slug":"writing-2023-1-1-年终说说总想反复看","date":"2023-01-01T15:35:33.000Z","updated":"2023-01-01T15:42:53.000Z","comments":true,"path":"2023/01/01/writing-2023-1-1-年终说说总想反复看/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-%E5%B9%B4%E7%BB%88%E8%AF%B4%E8%AF%B4%E6%80%BB%E6%83%B3%E5%8F%8D%E5%A4%8D%E7%9C%8B/","excerpt":"","text":"原因： 陶醉 修图花了精力：陶醉于修图的设计 这个是可以避免的，尽量别修图签字 选图是自己想展示给大家的：陶醉于图片的内容 这个是可以理解的，比如一段美好的旅行，发朋友圈是选了最开心的照片，之后翻看朋友圈回忆旅行快乐，这是可以理解的~ 展示给别人自己想展示的：陶醉于让别人看你想展示的一面的虚荣 这个成分挺重的，根源是虚荣心 check点赞 原因： 别人对于自己看重的照片和修图的反应和认可度 展示给别人看你想看的一面的“炫耀感”，“看我这么牛逼&#x2F;好看xxx” 手头上的正事自己没有足够的内驱热情 今天 本来想的是找独立路径idea的实现问题，但是这个实在没啥动力去搞 觉得有必要反思，于是开始弄年终总结，进入一种轻松的写反思的状态","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"今天为啥白搞了写作博客","slug":"writing-2023-1-1-今天为啥白搞了写作博客","date":"2023-01-01T15:27:51.000Z","updated":"2023-01-01T15:34:18.000Z","comments":true,"path":"2023/01/01/writing-2023-1-1-今天为啥白搞了写作博客/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-%E4%BB%8A%E5%A4%A9%E4%B8%BA%E5%95%A5%E7%99%BD%E6%90%9E%E4%BA%86%E5%86%99%E4%BD%9C%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"现象：今天想到“想要和博客首页一样的显示效果但是又不在首页显示，且writing在本地是和技术博客在不一样的目录下，也是按时间归类的”，然后没有思考，凭感觉觉得可以新建一个博客一个新的github pages，然后指向就可以。实际上可以直接修改原博客来做到这点的原因：觉得是个不值得花时间+简单的需求，可以拍脑袋想解决方案，拍脑袋想到之后也没有思考这个方案的成本和可行性，没有简单推导下过程判断可行性，而是觉得先做了再说改进：小事情小需求也可以稍微思考下方案，选择最优的，拒绝拍脑袋；确定了方案之后，稍微推导演绎一下，简单判断下成本和可行性","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"分课时管理","slug":"writing-2023-1-1-分课时管理","date":"2023-01-01T15:11:47.000Z","updated":"2023-01-01T15:24:44.000Z","comments":true,"path":"2023/01/01/writing-2023-1-1-分课时管理/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-%E5%88%86%E8%AF%BE%E6%97%B6%E7%AE%A1%E7%90%86/","excerpt":"","text":"决定尝试以“40分钟一节课”为单元进行任务的时间安排原因： 现在总是以几个小时来划分时间 如果不干科研会慌（即必须先干一点）：划分时间片，40分钟后还有较多时间可以干别的事情，不至于几个小时都是科研 干科研或者别的容易不思考直接开干这样几个小时之后冷静下来发现方向不对：提供反思和思考的时间：时间片一到可以思考下前一个片干了啥对不对，以及下一个片干啥 容易温水煮青蛙摆烂+等待到时间去吃饭摆烂：提升效率实现：番茄todo倒计时35分钟+5分钟休息","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"hexo主题volantis自定义页面","slug":"hexo主题volantis自定义页面","date":"2023-01-01T14:04:00.000Z","updated":"2023-04-03T02:51:21.000Z","comments":true,"path":"2023/01/01/hexo主题volantis自定义页面/","link":"","permalink":"http://example.com/2023/01/01/hexo%E4%B8%BB%E9%A2%98volantis%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/","excerpt":"","text":"知识 在source/目录下的index.md的链接：source/about/index.md的访问链接为博客链接/about，在.yml文件中导航栏处配置url时写about/ font-matter中layout: docs指定使用themes/layout/下哪个ejs文件作为模板，比如上述的index.md文件 post.&lt;name&gt;可以获取每篇博客的font-matter中的值 举例：新建类似首页的显示个人随笔的页面新增页面首先在source下新建目录writing，然后在source/writing下新建index.md，内容：&#96;&#96;&#96;markdownlayout: writingtitle: 所有随笔sidebar: [blogger]其中layout指定模板使用`themes/layout/writing.ejs`，`sidebar`是定制侧边栏的内容 ### 文章的控制传参 对于仅在这个页面显示而不在博客首页显示的文章，在font-matter中新增一个键： ```markdown --- is_writing: true --- 模板文件新增themes/layout/writing.ejs文件内容如下：参考首页(index.ejs) &lt;%- partial(&#39;_pre&#39;) %&gt; &lt;div id=&quot;l_main&quot; class=&#39;&lt;%- page.sidebar == false ? &#39; no_sidebar&#39; : &#39;&#39; %&gt;&#39;&gt; &lt;%- partial(&#39;_partial/writing&#39;) %&gt; &lt;/div&gt; &lt;%- partial(&#39;_partial/side&#39;) %&gt; 以及themes/layout/_partial/writing.ejs文件：参考首页(_partial/archive.ejs)，主要是根据post.is_writing来判断文章性质 &lt;% if (site.posts &amp;&amp; site.posts.length &gt; 0) &#123; %&gt; &lt;section class=&quot;post-list&quot;&gt; &lt;% site.posts.each(function(post)&#123; %&gt; &lt;% if (post.pin &amp;&amp; post.is_writing) &#123; %&gt; &lt;div class=&#39;post-wrapper&#39;&gt; &lt;%- partial(&#39;post&#39;, &#123;post: post&#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;% site.posts.each(function(post)&#123; %&gt; &lt;% if (!post.pin &amp;&amp; post.is_writing) &#123; %&gt; &lt;div class=&#39;post-wrapper&#39;&gt; &lt;%- partial(&#39;post&#39;, &#123;post: post&#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;/section&gt; &lt;% &#125; %&gt; 导航栏增加一项导航栏增加一项指向新增的页面：修改_config.volantis.yml navbar: menu: - name: 随笔 icon: fa-solid fa-info-circle url: writing/","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}],"author":"zhiqiuyuan"},{"title":"写作题目","slug":"writing-写作题目","date":"2023-01-01T11:20:20.000Z","updated":"2023-02-20T02:12:58.000Z","comments":true,"path":"2023/01/01/writing-写作题目/","link":"","permalink":"http://example.com/2023/01/01/writing-%E5%86%99%E4%BD%9C%E9%A2%98%E7%9B%AE/","excerpt":"","text":"","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"LSM tree","slug":"LSM-tree","date":"2022-12-22T13:30:23.000Z","updated":"2023-02-18T09:31:12.000Z","comments":true,"path":"2022/12/22/LSM-tree/","link":"","permalink":"http://example.com/2022/12/22/LSM-tree/","excerpt":"","text":"LSM树详解 - 知乎 (zhihu.com) rocksdb的存储方式就是这种 LSM树简介 https://cloud.tencent.com/developer/article/1441835 写1，当收到一个写请求时，会先把该条数据记录在WAL Log里面，用作故障恢复。 2，当写完WAL Log后，会把该条数据写入内存的SSTable里面（删除是墓碑标记，更新是新记录一条的数据），也称Memtable。注意为了维持有序性在内存里面可以采用红黑树或者跳跃表相关的数据结构。 3，当Memtable超过一定的大小后，会在内存里面冻结，变成不可变的Memtable，同时为了不阻塞写操作需要新生成一个Memtable继续提供服务。 4，把内存里面不可变的Memtable给dump到到硬盘上的SSTable层中，此步骤也称为Minor Compaction，这里需要注意在L0层的SSTable是没有进行合并的，所以这里的key range在多个SSTable中可能会出现重叠，在层数大于0层之后的SSTable，不存在重叠key。 5，当每层的磁盘上的SSTable的体积超过一定的大小或者个数，也会周期的进行合并。此步骤也称为Major Compaction，这个阶段会真正 的清除掉被标记删除掉的数据以及多版本数据的合并，避免浪费空间，注意由于SSTable都是有序的，我们可以直接采用merge sort进行高效合并。 读1，当收到一个读请求的时候，会直接先在内存里面查询，如果查询到就返回。 2，如果没有查询到就会依次下沉，知道把所有的Level层查询一遍得到最终结果。 优化读思考查询步骤，我们会发现如果SSTable的分层越多，那么最坏的情况下要把所有的分层扫描一遍，对于这种情况肯定是需要优化的，如何优化？在 Bigtable 论文中提出了几种方式： 1，压缩 SSTable 是可以启用压缩功能的，并且这种压缩不是将整个 SSTable 一起压缩，而是根据 locality 将数据分组，每个组分别压缩，这样的好处当读取数据的时候，我们不需要解压缩整个文件而是解压缩部分 Group 就可以读取。 2，缓存 因为SSTable在写入磁盘后，除了Compaction之外，是不会变化的，所以我可以将Scan的Block进行缓存，从而提高检索的效率 3，索引，Bloom filters 正常情况下，一个读操作是需要读取所有的 SSTable 将结果合并后返回的，但是对于某些 key 而言，有些 SSTable 是根本不包含对应数据的，因此，我们可以对每一个 SSTable 添加 Bloom Filter，因为布隆过滤器在判断一个SSTable不存在某个key的时候，那么就一定不会存在，利用这个特性可以减少不必要的磁盘扫描。 4，合并 这个在前面的写入流程中已经介绍过，通过定期合并瘦身， 可以有效的清除无效数据，缩短读取路径，提高磁盘利用空间。但Compaction操作是非常消耗CPU和磁盘IO的，尤其是在业务高峰期，如果发生了Major Compaction，则会降低整个系统的吞吐量，这也是一些NoSQL数据库，比如Hbase里面常常会禁用Major Compaction，并在凌晨业务低峰期进行合并的原因。 rocksdb未完待续… memtable https://github.com/facebook/rocksdb/wiki/MemTableMemTable is an in-memory data structure holding data before they are flushed to SST files. It serves both read and write - new writes always insert data to memtable, and reads has to query memtable before reading from SST files, because data in memtable is newer.Once a memtable is full, it becomes immutable and replaced by a new memtable.A background thread will flush the content of the memtable into a SST file, after which the memtable can be destroyed. The default implementation of memtable is based on skiplist.(跳跃表可以参考这篇博客) journal https://github.com/facebook/rocksdb/wiki/JournalJournals are key to RocksDB’ integrity and recovery. RocksDB has two types of journals: Write Ahead Log (WAL) for journaling the in-memory state updates, and MANIFEST for journaling the on-disk state updates.","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"Gremlin入门","slug":"Gremlin入门","date":"2022-12-21T09:42:14.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/21/Gremlin入门/","link":"","permalink":"http://example.com/2022/12/21/Gremlin%E5%85%A5%E9%97%A8/","excerpt":"","text":"resource 入门 Apache TinkerPop Introduction to Gremlin Gremlin Query Language - JanusGraph TinkerPop Documentation (apache.org) start-steps 详细（或速查，目录是按字母序的所有steps）TinkerPop Documentation (apache.org) graph-traversal-steps Germlin core steps 来自TinkerPop Documentation (apache.org) graph-traversal-steps As Stepprovide a label to the step that can later be accessed by steps and data structures AddEdge Stephttps://tinkerpop.apache.org/docs/3.5.3/reference/#addedge-step add edge eg: Add co-developer edge with a year-property between marko and his collaborators. gremlin&gt; g.V(1).as(&#39;a&#39;).out(&#39;created&#39;).in(&#39;created&#39;).where(neq(&#39;a&#39;)).addE(&#39;co-developer&#39;).from(&#39;a&#39;).property(&#39;year&#39;,2009) ==&gt;e[13][1-co-developer-&gt;4] ==&gt;e[14][1-co-developer-&gt;6] Graph Step (V E)read vertices, V(), or edges, E(), from the graph Has Stephttps://tinkerpop.apache.org/docs/3.5.3/reference/#has-step filter vertices, edges, and vertex properties based on their properties Select Stephttps://tinkerpop.apache.org/docs/3.5.3/reference/#select-step select() select an element based on a&#x2F;many static key a traversal that emits a key eg: a static key gremlin&gt; g.V().out().out() ==&gt;v[5] ==&gt;v[3] gremlin&gt; g.V().out().out().path() ==&gt;[v[1],v[4],v[5]] ==&gt;[v[1],v[4],v[3]] gremlin&gt; g.V().as(&#39;x&#39;).out().out().select(&#39;x&#39;) ==&gt;v[1] ==&gt;v[1] gremlin&gt; g.V().out().as(&#39;x&#39;).out().select(&#39;x&#39;) ==&gt;v[4] ==&gt;v[4] gremlin&gt; g.V().out().out().as(&#39;x&#39;).select(&#39;x&#39;) // pointless ==&gt;v[5] ==&gt;v[3] eg: many static keys gremlin&gt; g.V().as(&#39;a&#39;).out().as(&#39;b&#39;).out().as(&#39;c&#39;).select(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;) ==&gt;[a:v[1],b:v[4],c:v[5]] ==&gt;[a:v[1],b:v[4],c:v[3]]","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"cpp priority_queue","slug":"cpp-priority-queue","date":"2022-12-21T04:23:02.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/21/cpp-priority-queue/","link":"","permalink":"http://example.com/2022/12/21/cpp-priority-queue/","excerpt":"","text":"概述 最大堆 时间复杂度： 取堆顶（最大元素）：O(1) 插入&#x2F;删除堆顶：O(logn)，n为堆中元素数目 自定义判断“大”的函数：方法一：&lt;操作符成员函数class T &#123; ... bool operator&lt;(const T&amp;r)&#123;...&#125; &#125;; priority_queue&lt;T&gt; q; 方法二：小于函数auto my_less = [](const T&amp;l, const T&amp;r)&#123;...&#125;; // or: auto my_less = [](T l, T r)&#123;...&#125;; priority_queue&lt;T, vector&lt;T&gt;, decltype(my_less)&gt; q(my_less); 注意： 第二个模板参数是必须的 构造函数需要传参自定义的比较函数 成员函数 取堆顶 top shan’chu堆顶 pop 入堆 push, emplace","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"vscode思维导图 draw.io插件","slug":"vscode思维导图-draw-io插件","date":"2022-12-20T08:16:28.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/20/vscode思维导图-draw-io插件/","link":"","permalink":"http://example.com/2022/12/20/vscode%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE-draw-io%E6%8F%92%E4%BB%B6/","excerpt":"","text":"用vscode画思维导图、流程图等好用的插件：draw.io.Integration 装好之后，用vscode打开后缀名为 .drawio, .dio, .drawio.svg or .drawio.png中任意文件，即可进入画图界面：","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python3 mkdir","slug":"python3-mkdir","date":"2022-12-20T04:15:38.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/20/python3-mkdir/","link":"","permalink":"http://example.com/2022/12/20/python3-mkdir/","excerpt":"","text":"import os create dir：recusive, create if not exists, else throw error os.makedirs(path[,mode]) check path exists： if(os.path.)","categories":[{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"language","slug":"python/language","permalink":"http://example.com/categories/python/language/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"python3 cmd debug pdb","slug":"python3-cmd-debug-pdb","date":"2022-12-20T03:42:11.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/20/python3-cmd-debug-pdb/","link":"","permalink":"http://example.com/2022/12/20/python3-cmd-debug-pdb/","excerpt":"","text":"单文件debug app.py in app.py import pdb; pdb.set_trace() cmd: python3 -m pdb app.py arg1 arg2 然后就开始debug，和gdb类似的界面和指令","categories":[{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"debug","slug":"python/debug","permalink":"http://example.com/categories/python/debug/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"c++编译坑","slug":"c-编译坑","date":"2022-12-11T05:34:42.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/11/c-编译坑/","link":"","permalink":"http://example.com/2022/12/11/c-%E7%BC%96%E8%AF%91%E5%9D%91/","excerpt":"","text":"给gcc的文件的顺序https://stackoverflow.com/questions/19901934/libpthread-so-0-error-adding-symbols-dso-missing-from-command-line找不到symbol定义可能是顺序不对，或者循环依赖的库没有写到后面重复出现 gcc还是g++找不到symbol定义可能是写成gcc了：比如，gcc和g++版本不一样，而symbol是在高版本g++标准库中才有定义的，这样会报错","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"nm 符号表 各段","slug":"nm 符号表 各段","date":"2022-12-10T15:59:01.622Z","updated":"2022-12-10T15:59:01.622Z","comments":true,"path":"2022/12/10/nm 符号表 各段/","link":"","permalink":"http://example.com/2022/12/10/nm%20%E7%AC%A6%E5%8F%B7%E8%A1%A8%20%E5%90%84%E6%AE%B5/","excerpt":"","text":"linux下强大的文件分析工具 – nm - 知乎 (zhihu.com) 检查分析二进制文件、库文件、可执行文件中的符号表，返回二进制文件中各段的信息。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"objdump 反汇编","slug":"objdump 反汇编","date":"2022-12-10T15:57:36.065Z","updated":"2022-12-10T15:57:36.065Z","comments":true,"path":"2022/12/10/objdump 反汇编/","link":"","permalink":"http://example.com/2022/12/10/objdump%20%E5%8F%8D%E6%B1%87%E7%BC%96/","excerpt":"","text":"objdump options &lt;可执行文件名&gt; -d:将代码段反汇编 -S:将代码段反汇编的同时，将反汇编代码和源代码交替显示，**编译时需要给出-g**，即需要调试信息。 -C:将C++符号名逆向解析。 -l（这个是L）:反汇编代码中插入源代码的文件名和行号。 -j section:仅反汇编指定的section。可以有多个-j参数来选择多个section。 举例objdump -j .text -l -C -S a.out # 仅反汇编.text段，打印源文件名和行号且逆向解析符号 AT&amp;T汇编语法* 寄存器命名原则 AT&amp;T: %eax Intel: eax * 源/目的操作数顺序 AT&amp;T: movl %eax, %ebx Intel: mov ebx, eax * 常数/立即数的格式 AT&amp;T: movl $_value, %ebx Intel: mov eax, _value 把value的地址放入eax寄存器 AT&amp;T: movl $0xd00d, %ebx Intel: mov ebx, 0xd00d * 操作数长度标识 AT&amp;T: movw %ax, %bx Intel: mov bx, ax * 寻址方式 AT&amp;T: immed32(basepointer, indexpointer, indexscale) Intel: [basepointer + indexpointer × indexscale + imm32)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"bison 匹配模式执行动作 语法匹配","slug":"bison 匹配模式执行动作 语法匹配","date":"2022-12-10T15:51:06.501Z","updated":"2022-12-10T15:53:04.645Z","comments":true,"path":"2022/12/10/bison 匹配模式执行动作 语法匹配/","link":"","permalink":"http://example.com/2022/12/10/bison%20%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%BC%8F%E6%89%A7%E8%A1%8C%E5%8A%A8%E4%BD%9C%20%E8%AF%AD%E6%B3%95%E5%8C%B9%E9%85%8D/","excerpt":"","text":"基础用法.y每个 Bison 文件由 %% 分成三部分。 %&#123; ##include &lt;stdio.h&gt; /* 这里是序曲 */ /* 这部分代码会被原样拷贝到生成的 .c 文件的开头 */ int yylex(void); void yyerror(const char *s); %&#125; /* 这些地方可以输入一些 bison 指令 */ /* 比如用 %start 指令指定起始符号，用 %token 定义一个 token */ %start reimu %token REIMU %% /* 从这里开始，下面是解析规则 */ reimu : marisa &#123; /* 这里写与该规则对应的处理代码 */ puts(&quot;rule1&quot;); &#125; | REIMU &#123; /* 这里写与该规则对应的处理代码 */ puts(&quot;rule2&quot;); &#125; ; /* 规则最后不要忘了用分号结束哦～ */ /* 这种写法表示 ε —— 空输入 */ marisa : &#123; puts(&quot;Hello!&quot;); &#125; %% /* 这里是尾声 */ /* 这部分代码会被原样拷贝到生成的 .c 文件的末尾 */ int yylex(void) &#123; int c = getchar(); // 从 stdin 获取下一个字符 switch (c) &#123; case EOF: return YYEOF; case &#39;R&#39;: return REIMU; default: return 0; // 返回无效 token 值，迫使 bison 报错 &#125; &#125; void yyerror(const char *s) &#123; fprintf(stderr, &quot;%s\\n&quot;, s); &#125; int main(void) &#123; yyparse(); // 启动解析 return 0; &#125; 另外有一些值得注意的点： Bison 传统上将 token 用大写单词表示，将 symbol 用小写字母表示。 Bison 能且只能生成解析器源代码（一个 .c 文件），并且入口是 yyparse，所以为了让程序能跑起来，你需要手动提供 main 函数（但不一定要在 .y 文件中——你懂“链接”是什么，对吧？）。 Bison 不能检测你的 action code 是否正确——它只能检测文法的部分错误，其他代码都是原样粘贴到 .c 文件中。 Bison 需要你提供一个 yylex 来获取下一个 token。 Bison 需要你提供一个 yyerror 来提供合适的报错机制。 顺便提一嘴，上面这个 .y 是可以工作的——尽管它只能接受两个字符串。把上面这段代码保存为 reimu.y，执行如下命令来构建这个程序： 编译运行$ bison reimu.y $ gcc reimu.tab.c $ ./a.out R&lt;-- 不要回车在这里按 Ctrl-D rule2 $ ./a.out &lt;-- 不要回车在这里按 Ctrl-D Hello! rule1 $ ./a.out blablabla &lt;-- 回车或者 Ctrl-D Hello! rule1 &lt;-- 匹配到了 rule1 syntax error &lt;-- 发现了错误 于是我们验证了上述代码的确识别了该文法定义的语言 &#123; &quot;&quot;, &quot;R&quot; &#125;。 一个好教程：https://www.oreilly.com/library/view/flex-bison/9780596805418/ch01.html","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"flex 匹配模式执行动作 词法匹配","slug":"flex 匹配模式执行动作 词法匹配","date":"2022-12-10T15:50:34.845Z","updated":"2022-12-10T15:53:11.643Z","comments":true,"path":"2022/12/10/flex 匹配模式执行动作 词法匹配/","link":"","permalink":"http://example.com/2022/12/10/flex%20%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%BC%8F%E6%89%A7%E8%A1%8C%E5%8A%A8%E4%BD%9C%20%E8%AF%8D%E6%B3%95%E5%8C%B9%E9%85%8D/","excerpt":"","text":"定义%&#123; Declarations %&#125; Definitions %% Rules %% User subroutines 输入文件的第 1 段 %{ 和 %} 之间的为 声明（Declarations） ，都是 C 代码，这些代码会被原样的复制到 lex.yy.c 文件中，一般在这里声明一些全局变量和函数，这样在后面可以使用这些变量和函数。 第 2 段 %} 和 %% 之间的为 定义（Definitions），在这里可以定义正则表达式中的一些名字，可以在 规则（Rules） 段被使用，如本文件中定义了 WORD 为 ([^ \\t\\n\\r\\a]+) ， 这样在后面可以用 {WORD} 代替这个正则表达式。 第 3 段为 规则（Rules） 段；会按从上往下的顺序尝试匹配。By default, any text not matched by a flex scanner is copied to the output 第 4 段为 用户定义过程（User subroutines） 段，也都是 C 代码，本段内容会被原样复制到 yylex.c 文件的最末尾，一般在此定义第 1 段中声明的函数。 函数和变量yywrapyywrap 函数的作用是将多个输入文件打包成一个输入，当 yylex 函数读入到一个文件结束（EOF）时，它会向 yywrap 函数询问， yywrap 函数返回 1 的意思是告诉 yylex 函数后面没有其他输入文件了，此时 yylex 函数结束，yywrap 函数也可以打开下一个输入文件，再向 yylex 函数返回 0 ，告诉它后面还有别的输入文件，此时 yylex 函数会继续解析下一个输入文件。总之，由于我们不考虑连续解析多个文件，因此此处返回 1 。 关于刚刚匹配到的字符串 flex 提供的两个全局变量 yytext 和 yyleng，分别用来表示刚刚匹配到的字符串以及它的长度 简单举例1https://www.oreilly.com/library/view/flex-bison/9780596805418/ch01.html文件test.l /* just like Unix wc */ %&#123; int chars = 0; int words = 0; int lines = 0; %&#125; %% [a-zA-Z]+ &#123; words++; chars += strlen(yytext); &#125; \\n &#123; chars++; lines++; &#125; /* 注意，.不会匹配\\n字符 */ . &#123; chars++; &#125; %% int main(int argc, char **argv) &#123; yylex(); printf(&quot;%8d%8d%8d\\n&quot;, lines, words, chars); &#125; 运行flex + gcc简单举例1中的代码运行： $ flex test.l # tell flex to translate our program $ gcc -lfl lex.yy.c # compile lex.yy.c; link it with the flex library, -lfl $ ./a.out # run it; and type a little input for it to count. The boy stood on the burning deck shelling peanuts by the peck ^D 2 12 63 $ 如果link flex lib步骤中ld报错找不到库的话，可以这样定位下问题：输出ld实际上想找哪些库： ld -lfl --verbose 可以看到没有你要的如果你需要的libfl.so文件在目录/path/to/lib下： gcc -L/path/to/lib -lfl lex.yy.c &#x2F;home&#x2F;yuanzhiqiu&#x2F;built&#x2F;flex-2.6.4&#x2F;lib 简单举例2http://web.mit.edu/gnu/doc/html/flex_1.html#:~:text=An%20Overview%20of%20flex%2C%20with%20Examples%201%20Text-Substitution,Language%20Scanner%20A%20somewhat%20more%20complicated%20example%3A%20 /* scanner for a toy Pascal-like language */ %&#123; /* Declarations */ /* need this for the call to atof() below */ #include &lt;math.h&gt; %&#125; /* Definitions */ DIGIT [0-9] ID [a-z][a-z0-9]* %% /* Rules */ /* pattern &#123;action&#125; */ &#123;DIGIT&#125;+ &#123; printf( &quot;An integer: %s (%d)\\n&quot;, yytext, atoi( yytext ) ); &#125; &#123;DIGIT&#125;+&quot;.&quot;&#123;DIGIT&#125;* &#123; printf( &quot;A float: %s (%g)\\n&quot;, yytext, atof( yytext ) ); &#125; if|then|begin|end|procedure|function &#123; printf( &quot;A keyword: %s\\n&quot;, yytext ); &#125; &#123;ID&#125; &#123; printf( &quot;An identifier: %s\\n&quot;, yytext ); &#125; &quot;+&quot;|&quot;-&quot;|&quot;*&quot;|&quot;/&quot; &#123; printf( &quot;An operator: %s\\n&quot;, yytext ); &#125; &quot;&#123;&quot;[^&#125;\\n]*&quot;&#125;&quot; &#123;&#125; /* no action: eat up one-line comments */ [ \\t\\n]+ &#123;&#125; /* no action: eat up whitespace */ . &#123; printf( &quot;Unrecognized character: %s\\n&quot;, yytext ); &#125; %% /* User subroutines */ int main(int argc, char **argv) &#123; if ( argc &gt; 1 ) yyin = fopen( argv[1], &quot;r&quot; ); else yyin = stdin; yylex(); /* entry */ &#125; 编译安装https://github.com/westes/flex/blob/master/INSTALL.mdhttps://github.com/westes/flex/releases 正则表达式https://www.jianshu.com/p/cb721b883b57 一些语法x 匹配字符 x. 除换行符外的任何字符[xyz] 字符类别；匹配x、y、z[abj-oZ] 具有范围的字符类；匹配 a， b， j到o中的任何字母或 Z[^A-Z] 否定字符类，即该类中的字符以外的任何字符 [^A-Z\\n] 除大写字母或换行符外的任何字符 r* 零个或多个r，其中r是任何正则表达式（如何确定r：*前的子表达式）r+ 一个或多个 rr？ 零或一个rr{2,5} 从两到五​​个r{2,} 两个或多个r{4} 恰好4个上面这些默认是最长匹配，加一个?则是最短匹配*? 重复任意次，但尽可能少重复+? 重复1次或更多次，但尽可能少重复?? 重复0次或1次，但尽可能少重复{n,m}? 重复n到m次，但尽可能少重复{n,}? 重复n次以上，但尽可能少重复 {name} 扩展name定义，把别处定义的name拿过来用 \\X 普通字符(不是特殊字符，比如不是*,&quot;等)不转义，就是表示\\x。否则，为字符X 举例：”[xyz]&quot;foo” 表示[xyz]&quot;foo，外面的””表示是一个字符串，里面的&quot;表示是一个转义字符，匹配&quot;\\0 一个NUL字符（ASCII代码0）\\123 八进制值123的字符\\x2a 十六进制值为2a的字符 (r) 匹配r；定义子表达式；括号用于改变优先级；且可以和\\1等配合进行捕获 rs 正则表达式r后跟正则表达式s，称为串联r|s r或sr&#x2F;s 一个r，但前提是其后跟一个s。确定此规则是否为最长匹配项时， 将包含用s匹配的文本，但在执行操作之前，该文本将返回到输入。因此， 该操作只会看到与r匹配的文本。这种模式称为尾随上下文。 （flex不能正确 匹配某些r&#x2F;s组合。有关危险的尾随上下文，请参见限制。） ^r 一个r，但仅在一行的开头（即刚开始扫描时，或在扫描换行符之后）。r$ 一个r，但只能在一行的末尾（即，在换行符之前）。等同于r&#x2F;\\n。 请注意，flex的”换行符”概念与C编译器用来将flex解释为\\n的情况完全相同。 特别是，在某些DOS系统上，您必须自己过滤掉输入中的\\r， 或显式地将” r &#x2F;\\r\\ n”用作” r $”。 r 一个r，但仅在起始条件s中（请参阅”起始条件”以了解起始条件）。&lt;s1，s2，s3&gt; r 同上，但在任何启动条件s1，s2或s3中。&lt;*&gt; r 任何开始条件下的r，甚至是排他条件。&lt;&lt; EOF &gt;&gt; 文件结束。&lt;s1,s2&gt;&lt;&gt; 在开始条件s1或s2中的文件结束 匹配任意字符串注意这样不行：[.\\n]* 这样会匹配.或\\n而不是任意字符要这样写：(.|\\n)*","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"awk 行处理","slug":"awk 行处理","date":"2022-12-10T15:49:59.867Z","updated":"2022-12-10T15:49:59.867Z","comments":true,"path":"2022/12/10/awk 行处理/","link":"","permalink":"http://example.com/2022/12/10/awk%20%E8%A1%8C%E5%A4%84%E7%90%86/","excerpt":"","text":"对于文本中每一行（匹配Pattern的部分）根据分隔符划分，并做action操作 分隔符可指定，默认空格或tab 比如 log.txt文本内容如下： 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange,apple,mongo 行匹配基础用法awk &#39;&#123;[pattern] action&#125;&#39; &#123;filenames&#125; #行匹配语句 awk &#39;&#39; 只能用单引号 # 或者可以管道传入要处理的文本 ls -i |awk &#39;&#123;print $1&#125;&#39; 实例： # 每行按空格或TAB分割，输出文本中的1、4项 $ awk &#39;&#123;print $1,$4&#125;&#39; log.txt --------------------------------------------- 2 a 3 like This&#39;s 10 orange,apple,mongo # 格式化输出 $ awk &#39;&#123;printf &quot;%-8s %-10s\\n&quot;,$1,$4&#125;&#39; log.txt --------------------------------------------- 2 a 3 like This&#39;s 10 orange,apple,mongo -F 指定分割字符 变量awk -F #-F相当于内置变量FS, 指定分割字符 实例： # 使用&quot;,&quot;分割 $ awk -F, &#39;&#123;print $1,$2&#125;&#39; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange apple # 或者使用内建变量 $ awk &#39;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&#39; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange apple # 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割（看-F &#39;&#39;中传递的字符，第一个是空格，第二个是,） $ awk -F &#39;[ ,]&#39; &#39;&#123;print $1,$2,$5&#125;&#39; log.txt --------------------------------------------- 2 this test 3 Are awk This&#39;s a 10 There apple # 分割结果这样： 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange apple mongo -v 设置变量，可用于分割结果的拼接或计算awk -v # 设置变量 实例： $ awk -va=1 &#39;&#123;print $1,$1+a&#125;&#39; log.txt # 设置变量a --------------------------------------------- 2 3 3 4 This&#39;s 1 10 11 $ awk -va=1 -vb=s &#39;&#123;print $1,$1+a,$1b&#125;&#39; log.txt --------------------------------------------- 2 3 2s 3 4 3s This&#39;s 1 This&#39;ss 10 11 10s 设置了变量b和a $1b 表示拼接 $1+a 表示如果$1是数字则做计算，否则就是a -f awk脚本awk -f &#123;awk脚本&#125; &#123;文件名&#125; 实例： $ awk -f cal.awk log.txt 常用给每行行尾添加字符awk ‘{print $0 “A”}’ filename给filename每行尾添加字符A 删除每行最后10个字符 sub替换成空字符串awk ‘{sub(&#x2F;.{10}$&#x2F;,””); print $0 }’ filename$匹配行末位置，.匹配任意一个非换行字符 替换字符串 gsubawk ‘{ gsub(&#x2F;AAAA&#x2F;,”BBBB”); print $0 }’ filename把字符串AAAA替换成BBBB","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"grep 正则匹配过滤","slug":"grep 正则匹配过滤","date":"2022-12-10T15:49:20.418Z","updated":"2022-12-10T15:49:20.418Z","comments":true,"path":"2022/12/10/grep 正则匹配过滤/","link":"","permalink":"http://example.com/2022/12/10/grep%20%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E8%BF%87%E6%BB%A4/","excerpt":"","text":"grep [-acinv] [--color=auto] &#39;搜寻字符串&#39; filename -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’的次数 -i ：忽略大小写的不同 -n ：顺便输出行号 -v ：反向选择，不含搜寻字符串的 grep -i &#39;D&#39; &lt;file2.txt | sort &gt; result.txt 搜索 file2.txt 中的d字母，将输出分类并写入分类文件到 result.txt tail -f /usr/loca/apache/logs/access.log |grep -v &#39;.jpg&#39; 输出不含‘.jpg’的","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"less head tail sed","slug":"less head tail sed","date":"2022-12-10T15:48:41.646Z","updated":"2022-12-10T15:48:41.646Z","comments":true,"path":"2022/12/10/less head tail sed/","link":"","permalink":"http://example.com/2022/12/10/less%20head%20tail%20sed/","excerpt":"","text":"lessless /etc/profile 参数 -N 显示行号 less的动作命令: j 向下移动一行；同vi k 向上移动一行；同vi f 向下滚动一屏；forword b 向上滚动一屏；backword 以上部分命令，请使用q退出 head tailhead -n 10 /etc/profile #显示/etc/profile的前10行内容 tail -n 5 /etc/profile #显示/etc/profile的最后5行内容 sed显示所有内容，包括不可打印的字符 sed -n l &lt;filename&gt; Linux 打印文本部分行内容（前几行，指定行，中间几行，跨行，奇偶行，后几行，最后一行，匹配行） (jiangliheng.github.io) 使用sed剪切复制（这篇文章还介绍了sed如何工作的，以及模式空间和保留空间）https://zhuanlan.zhihu.com/p/374606460","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"文本文件编码方式查看与修改","slug":"文本文件编码方式查看与修改","date":"2022-12-10T15:47:49.197Z","updated":"2022-12-10T15:47:49.197Z","comments":true,"path":"2022/12/10/文本文件编码方式查看与修改/","link":"","permalink":"http://example.com/2022/12/10/%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F%E6%9F%A5%E7%9C%8B%E4%B8%8E%E4%BF%AE%E6%94%B9/","excerpt":"","text":"linux下 修改文件编码方式从utf-8到ansi iconv -f utf8 -t gbk -o ansi.txt utf8.txt -f: from -t: to 查看文件编码方式 file &lt;filename&gt; # cp @ cp in ~/cp_lab/src/lexer [10:38:09] $ file lexical_analyzer_utf8.l lexical_analyzer_utf8.l: C source, UTF-8 Unicode text, with CRLF line terminators #utf-8 # cp @ cp in ~/cp_lab/src/lexer [10:38:17] $ file lexical_analyzer.l lexical_analyzer.l: C source, ISO-8859 text, with CRLF line terminators #ansi 或者vim之后 :set fileencoding windows下notepad++下","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"stat 文件元数据查看","slug":"stat 文件元数据查看","date":"2022-12-10T15:45:35.423Z","updated":"2022-12-10T15:45:35.423Z","comments":true,"path":"2022/12/10/stat 文件元数据查看/","link":"","permalink":"http://example.com/2022/12/10/stat%20%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE%E6%9F%A5%E7%9C%8B/","excerpt":"","text":"stat file display file or file system status $ stat answer1 File: answer1 Size: 82 Blocks: 8 IO Block: 4096 regular file Device: 805h/2053d Inode: 1634042 Links: 1 Access: (0664/-rw-rw-r--) Uid: ( 1000/yuanzhiqiu) Gid: ( 1000/yuanzhiqiu) Access: 2022-03-25 20:00:39.873936779 +0800 Modify: 2022-03-24 17:58:23.341854352 +0800 Change: 2022-03-24 17:58:23.341854352 +0800 Birth: -","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux命令行 限制管理","slug":"linux命令行 限制管理","date":"2022-12-10T15:41:30.352Z","updated":"2022-12-10T15:41:30.352Z","comments":true,"path":"2022/12/10/linux命令行 限制管理/","link":"","permalink":"http://example.com/2022/12/10/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%20%E9%99%90%E5%88%B6%E7%AE%A1%E7%90%86/","excerpt":"","text":"概述软硬极限极限分为软性和硬性。 The hard limit is the maximum value that is allowed for the soft limit. Any changes to the hard limit require root access. The soft limit is the value that Linux uses to limit the system resources for running processes. The soft limit cannot be greater than the hard limit. 通过 ulimit 命令，用户可更改软极限 ulimit命令作用对象由于 ulimit 命令影响当前 shell 环境，所以它将作为 shell 常规内置命令提供。如果在独立的命令执行环境中调用该命令，则不影响调用者环境的文件大小极限。 关于用户和系统资源极限的更多信息，请参见 AIX 5L Version 5.2 Technical Reference: Base Operating System and Extensions Volume 1 中的 getrlimit、setrlimit 或 vlimit子例程。 参数-a 列出所有当前资源极限。 -c 以 512 字节块为单位，指定核心转储的大小。 -d 以 K 字节为单位指定数据区域的大小。 -f 使用 Limit 参数时设定文件大小极限（以块计），或者在未指定参数时报告文件大小极限。缺省值为 -f 标志。 -H 指定设置某个给定资源的硬极限。如果用户拥有 root 用户权限，可以增大硬极限。任何用户均可减少硬极限。 -m 以 K 字节为单位指定物理存储器的大小。 -n 指定一个进程可以拥有的文件描述符的数量的极限。 -s 以 K 字节为单位指定堆栈的大小。 -S 指定为给定的资源设置软极限。软极限可增大到硬极限的值。如果 -H 和 -S 标志均未指定，极限适用于以上二者。 -t 指定每个进程所使用的秒数。 ulimit -a命令 To review the hard ulimit settings, enter the following command: ulimit -aH user1@host1 ˜$ ulimit -aH core file size (blocks, -c) unlimited data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 100000 max locked memory (kbytes, -l) unlimited max memory size (kbytes, -m) unlimited open files (-n) 100000 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) unlimited cpu time (seconds, -t) unlimited max user processes (-u) 257262 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited To review the soft ulimit, enter the following command: ulimit -aS Command output similar to the following example is displayed: user1@host1 ˜$ ulimit -aS core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 100000 max locked memory (kbytes, -l) unlimited max memory size (kbytes, -m) unlimited open files (-n) 100000 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 10240 cpu time (seconds, -t) unlimited max user processes (-u) 257262 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 字段含义 fsize 用户创建的文件大小限制。此定义值（512字节为单位）为该用户可以生成的最大文件的大小。 core 生成的core文件大小的限制（512字节为单位）。 cpu 用户进程可用cpu的限定值（以秒为单位）。普通用户只能将此值减小，root可以将此值增大。这里要注意的是进程使用CPU的时间取决于AIX Kernel（核心程序）进程调度算法，该值在此仅做参考。 data 进程数据段大小的限定值（以字节为单位）。 stack 进程**堆栈段大小的限定值（以字节**为单位）。 rss 进程常驻内存段的限定值（以字节为单位）。AIX核心并不参考此限定。 nofiles 进程中打开文件的最大数量。 修改limit修改文件change the hard and soft ulimit settings for InfoSphere Streams administrators that belong to the @streamsadmin user group. On RHEL and CentOS, edit the &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;91-nofile.conf file as shown in the following example: @streamsadmin - nofile open-files-value @streamsadmin hard nproc max-user-processes-value @streamsadmin soft nproc max-user-processes-value @streamsadmin hard stack unlimited @streamsadmin soft stack 20480 ulimit临时修改ulimit -c unlimited #-c:core file size 修改核心转储文件允许的大小为无限制","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux命令行进程管理","slug":"linux命令行进程管理","date":"2022-12-10T15:40:30.090Z","updated":"2022-12-10T15:40:30.090Z","comments":true,"path":"2022/12/10/linux命令行进程管理/","link":"","permalink":"http://example.com/2022/12/10/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"","text":"管理jobs要启动一个进程到后台，追加一个“&amp;”到命令后面 kill 发信号kill -STOP [pid] 发送SIGSTOP (17,19,23)停止一个进程，而并不消灭这个进程。 kill -CONT [pid] 发送SIGCONT (19,18,25)重新开始一个停止的进程。 kill -KILL [pid] 发送SIGKILL (9)强迫进程立即停止，并且不实施清理操作。 kill -9 -1 终止你拥有的全部进程。 kill -STOP 1234 将该进程暂停。 如果要让它恢复到后台，用kill -CONT 1234 （很多在前台运行的程序这样是不行的） 如果要恢复到前台，请在当时运行该进程的那个终端用jobs命令查询暂停的进程。 然后用 fg 〔job号〕把进程恢复到前台。 举例：gdb调试时ctrl+z如何重启此时会进入收到SIGINT的提示界面， 另外起一个终端把暂停的进程的PID启动 如果在显示这个界面后再次ctrl+z，此时会把gdb进程给挂起，这样fg的话程序还是暂停状态，要把暂停的父进程 PPID也发送-CONT才行 gdb里面显示收到CONT信号就c 比如 PID PPID %MEM %CPU COMMAND 198765 198757 0.5 98.5 baseline 两次ctrl+z之后，要重启需要fg %1并且kill -CONT 198757（父进程）","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"pmap","slug":"pmap","date":"2022-12-10T15:39:20.787Z","updated":"2022-12-10T15:39:20.787Z","comments":true,"path":"2022/12/10/pmap/","link":"","permalink":"http://example.com/2022/12/10/pmap/","excerpt":"","text":"pmap（对于每个进程）pmap 命令可以查看进程的内存映像信息，其输出内容来自于/proc/&lt;pid&gt;/maps和/proc/&lt;pid&gt;/smaps这两个文件，maps文件包含了每一段内存的大概描述，smaps里包含了具体每段的详细信息 pmap [options] pid 参数 Options 功能 -x, –extended 显示扩展格式 -d, –device 显示设备格式 -q, –quiet 不显示头尾行 -A, –range low,high 显示给定地址范围的结果，参数以逗号分隔 -X 显示比 -x 选项更详细的信息， 信息来自文件 /proc/PID/smaps -XX 显示 kernel能提供的一切信息 -c, –read-rc 读取默认配置 -V, –version 显示版本信息 举例pmap -x 7642 命令打印进程 7642 的内存信息，其中 扩展格式和设备格式字段含义如下 字段 含义 Address 映像起始地址 Kbytes 映像大小 RSS 驻留集大小 Dirty 脏页大小 Mode 映像权限 Mapping 映像支持文件,[anon]为已分配内存,[stack]为程序堆栈 Offset 文件偏移 Device 设备名 # 进程启动命令 7642: java -Xmx256m -server -XX:+PrintGCApplicationStoppedTime -jar bin/center.jar Address Kbytes RSS Dirty Mode Mapping 0000000000400000 4 0 0 r-x-- java 0000000000600000 4 4 4 rw--- java 00000000018dc000 1208 1092 1092 rw--- [ anon ] 00000000f0000000 257536 134672 134672 rw--- [ anon ] 00000000ffb80000 4608 0 0 ----- [ anon ] 0000000100000000 12080 12052 12052 rw--- [ anon ] 0000000100bcc000 1036496 0 0 ----- [ anon ] 00007f53dda8d000 256 60 60 rw--- [ anon ] ...... 12345678910111213","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"iostat","slug":"iostat","date":"2022-12-10T15:38:39.596Z","updated":"2022-12-10T15:38:39.596Z","comments":true,"path":"2022/12/10/iostat/","link":"","permalink":"http://example.com/2022/12/10/iostat/","excerpt":"","text":"iostat（对于每个设备）显示所有设备负载情况 iostat [选项] [&lt;指定设备名&gt;] [&lt;时间间隔&gt;] [&lt;次数&gt;] 参数 -c： 显示CPU使用情况 -d： 显示磁盘使用情况 -N： 显示磁盘阵列(LVM) 信息 -n： 显示NFS 使用情况 -t： 报告每秒向终端读取和写入的字符数和CPU的信息 -p： [磁盘] 显示磁盘和分区的情况 -k： 以 KB 为单位显示 -m： 以 M 为单位显示 -V： 显示版本信息 -x： 显示详细信息 (-c)cpu %user：CPU处在用户模式下的时间百分比。 %nice：CPU处在带NICE值的用户模式下的时间百分比。 %system：CPU处在系统模式下的时间百分比。 %iowait：CPU等待输入输出完成时间的百分比。 如果%iowait的值过高，表示硬盘存在I&#x2F;O瓶颈 %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。 %idle：CPU空闲时间百分比。 %idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。 %idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 (-d)disk **device: **磁盘名称 tps: 每秒钟发送到的I&#x2F;O请求数. Blk_read&#x2F;s:每秒读取的block数. Blk_wrtn&#x2F;s:每秒写入的block数. **Blk_read:**读入的block总数. **Blk_wrtn:**写入的block总数. 举例 频率 iostat 1 5间隔1秒，总共显示5次 iostat -d 2每隔2秒,显示一次磁盘统计信息. iostat -d 2 3每隔2秒,显示一次磁盘统计信息.总共输出3次. iostat -d sda显示指定硬盘信息 iostat -x sda sdb 2 3每隔2秒显示一次sda, sdb两个设备的扩展统计信息,共输出3次. iostat -p sda 2 3每隔2秒显示一次sda及上面所有分区的统计信息,共输出3次. iostat -m以M为单位显示所有信息 ps（对于每个进程）ps #列出所有你启动的进程 ps -eo pid,ppid,%mem,%cpu,stat,comm --sort=-%cpu | head ps：命令名字 -e：选择所有进程 -o：自定义输出格式 –sort=-%cpu：基于 CPU 使用率对输出结果排序 PID：进程的 ID PPID：父进程的 ID %MEM：进程使用的 RAM 比例 %CPU：进程占用的 CPU 比例 Command：进程名字 stat：进程状态 ps -efT #线程","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"pidstat","slug":"pidstat","date":"2022-12-10T15:38:02.167Z","updated":"2022-12-10T15:38:02.167Z","comments":true,"path":"2022/12/10/pidstat/","link":"","permalink":"http://example.com/2022/12/10/pidstat/","excerpt":"","text":"pidstat（对于每个进程）Linux 运行进程实时监控pidstat命令详解 pidstat主要用于监控全部或指定进程占用系统资源的情况，如CPU，内存、设备IO、任务切换、线程等。 pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。 pidstat [ 选项 ] [ &lt;时间间隔&gt; ] [ &lt;次数&gt; ] 指定采样周期和采样次数pidstat命令指定采样周期和采样次数，命令形式为”pidstat [option] interval [count]”，以下pidstat输出以2秒为采样周期，输出10次cpu使用统计信息： pidstat 2 10 **cpu(-u)**（默认参数）使用-u选项，pidstat将显示各活动进程的cpu使用统计，执行”pidstat -u”与单独执行”pidstat”的效果一样。 linux:~ # pidstat Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 11:37:19 PID %usr %system %guest %CPU CPU Command …… 11:37:19 11452 0.00 0.00 0.00 0.00 2 bash 11:37:19 11509 0.00 0.00 0.00 0.00 3 dd 含义： PID：进程ID %usr：进程在用户空间占用cpu的百分比 %system：进程在内核空间占用cpu的百分比 %guest：进程在虚拟机占用cpu的百分比 %CPU：进程占用cpu的百分比 CPU：处理进程的cpu编号 Command：当前进程对应的命令 内存(-r)linux:~ # pidstat -r -p 13084 1 Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 15:08:18 PID minflt/s majflt/s VSZ RSS %MEM Command 15:08:19 13084 133835.00 0.00 15720284 15716896 96.26 mmmm 15:08:20 13084 35807.00 0.00 15863504 15849756 97.07 mmmm 15:08:21 13084 19273.87 0.00 15949040 15792944 96.72 mmmm 以上各列输出的含义如下： minflt&#x2F;s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数 majflt&#x2F;s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生 VSZ: 该进程使用的**虚拟内存**(以kB为单位) RSS: 该进程使用的**物理内存**(以kB为单位) %MEM: 该进程使用**物理内存的百分比** Command: 拉起进程对应的命令 IO(-d)linux:~ # pidstat -d 1 2 Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 17:11:36 PID kB_rd/s kB_wr/s kB_ccwr/s Command 17:11:37 14579 124988.24 0.00 0.00 dd 17:11:37 PID kB_rd/s kB_wr/s kB_ccwr/s Command 17:11:38 14579 105441.58 0.00 0.00 dd 输出信息含义 kB_rd&#x2F;s: 每秒进程从磁盘读取的数据量(以kB为单位) kB_wr&#x2F;s: 每秒进程向磁盘写的数据量(以kB为单位) Command: 拉起进程对应的命令 针对特定进程统计(-p)使用-p选项，我们可以查看特定进程的系统资源使用情况： linux:~ # pidstat -r -p 1 1 Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 18:26:17 PID minflt/s majflt/s VSZ RSS %MEM Command 18:26:18 1 0.00 0.00 10380 640 0.00 init 18:26:19 1 0.00 0.00 10380 640 0.00 init …… 举例pidstat -u 1 pidstat -r 1 pidstat -d 1 以上命令以1秒为信息采集周期，分别获取cpu、内存和磁盘IO的统计信息。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux进程状态 ps指定stat字段可查看","slug":"linux进程状态 ps指定stat字段可查看","date":"2022-12-10T15:36:45.536Z","updated":"2022-12-10T15:36:45.536Z","comments":true,"path":"2022/12/10/linux进程状态 ps指定stat字段可查看/","link":"","permalink":"http://example.com/2022/12/10/linux%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%20ps%E6%8C%87%E5%AE%9Astat%E5%AD%97%E6%AE%B5%E5%8F%AF%E6%9F%A5%E7%9C%8B/","excerpt":"","text":"[转载] Linux进程状态解析之R、S、D、T、Z、X-阿里云开发者社区 (aliyun.com) stat字段比如R+ R (TASK_RUNNING)，可执行状态只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。 很多操作系统教科书将正在CPU上执行的进程定义为RUNNING状态、而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下统一为 TASK_RUNNING状态。 S (TASK_INTERRUPTIBLE)，可中断的睡眠状态。处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。 通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。 D (TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态。与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号（所以此状态下kill发信号也无法终止进程）（When the process is sleeping uninterruptibly, the signal will be noticed when the process returns from the system call or trap.）。 是由于**在等待IO**，比如磁盘IO，网络IO，其他外设IO，如果进程正在等待的IO在较长的时间内都没有响应，那么就被ps看到了，同时也就意味着很有可能有IO出了问题，可能是外设本身出了故障，也可能是比如挂载的远程文件系统已经不可访问等操作时出现的问题。 引起D状态的根本原因是由于IO等待，若你对某个磁盘的IO操作特别频繁，就会造成后续的IO操作处于等待状态，即处于D状态。此时，你可以使用iostat命令查看当前操作的磁盘的IO是否达到瓶颈值，若达到可以从用户层面入手调整IO操作。 TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。（参见《linux内核异步中断浅析》）在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到 T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态。向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。 对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。 Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。进程在退出的过程中，处于TASK_DEAD状态。 在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。 父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。 通过下面的代码能够制造一个EXIT_ZOMBIE状态的进程： #include void main() &#123; if (fork()) while(1) sleep(100); &#125; 编译运行，然后ps一下： kouu@kouu-one:~/test$ ps -ax | grep a\\.out 10410 pts/0 S+ 0:00 ./a.out 10411 pts/0 Z+ 0:00 [a.out] 10413 pts/1 S+ 0:00 grep a.out 只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程“收尸”？当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。 1号进程，pid为1的进程，又称init进程。linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命：1、执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）；2、在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作；init进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态，“收尸”过程中则处于TASK_RUNNING状态。 X (TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁。而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。 进程的初始状态进程是通过fork系列的系统调用（fork、clone、vfork）来创建的，内核（或内核模块）也可以通过kernel_thread函数创建内核进程。这些创建子进程的函数本质上都完成了相同的功能——将调用进程复制一份，得到子进程。（可以通过选项参数来决定各种资源是共享、还是私有。）那么既然调用进程处于TASK_RUNNING状态（否则，它若不是正在运行，又怎么进行调用？），则子进程默认也处于TASK_RUNNING状态。另外，在系统调用调用clone和内核函数kernel_thread也接受CLONE_STOPPED选项，从而将子进程的初始状态置为 TASK_STOPPED。 进程状态变迁进程自创建以后，状态可能发生一系列的变化，直到进程退出。而尽管进程状态有好几种，但是进程状态的变迁却只有两个方向——从TASK_RUNNING状态变为非TASK_RUNNING状态、或者从非TASK_RUNNING状态变为TASK_RUNNING状态。也就是说，如果给一个TASK_INTERRUPTIBLE状态的进程发送SIGKILL信号，这个进程将先被唤醒（进入TASK_RUNNING状态），然后再响应SIGKILL信号而退出（变为TASK_DEAD状态）。并不会从TASK_INTERRUPTIBLE状态直接退出。 进程从非TASK_RUNNING状态变为TASK_RUNNING状态，是由别的进程（也可能是中断处理程序）执行唤醒操作来实现的。执行唤醒的进程设置被唤醒进程的状态为TASK_RUNNING，然后将其task_struct结构加入到某个CPU的可执行队列中。于是被唤醒的进程将有机会被调度执行。 而进程从TASK_RUNNING状态变为非TASK_RUNNING状态，则有两种途径：1、响应信号而进入TASK_STOPED状态、或TASK_DEAD状态；2、执行系统调用主动进入TASK_INTERRUPTIBLE状态（如nanosleep系统调用）、或TASK_DEAD状态（如exit系统调用）；或由于执行系统调用需要的资源得不到满足，而进入TASK_INTERRUPTIBLE状态或TASK_UNINTERRUPTIBLE状态（如select系统调用）。显然，这两种情况都只能发生在进程正在CPU上执行的情况下。 stat字段低位&lt; 优先级高的进程 N 优先级较低的进程 L 有些页被锁进内存 s 进程的领导者（在它之下有子进程） l 多进程的（使用 CLONE_THREAD, 类似 NPTL pthreads） + 位于后台的进程组","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"命令行颜色","slug":"命令行颜色","date":"2022-12-10T15:28:58.394Z","updated":"2022-12-10T15:28:58.394Z","comments":true,"path":"2022/12/10/命令行颜色/","link":"","permalink":"http://example.com/2022/12/10/%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%A2%9C%E8%89%B2/","excerpt":"","text":"ANSI转义序列 - 维基百科，自由的百科全书 (wikipedia.org) Build your own Command Line with ANSI escape codes (lihaoyi.com) Red: \\u001b[31m Reset: \\u001b[0m This \\u001b character is the special character that starts off most Ansi escapes echo -e &quot;\\x1b[31mhello world\\x1b[0m&quot; 用期望颜色替换 31(代表红色) 即可 \\x1b[&lt;color_code&gt;m \\x1b[0m debug output level： | ERROR | 红色(31) | 表示发生严重错误，很可能或者已经导致程序崩溃 || WARN | 黄色(93) | 表示发生不常见情况，但是并不一定导致系统错误 || INFO | 蓝色(34) | 比较中庸的选项，输出比较重要的信息，比较常用 || DEBUG | 绿色(32) | 输出信息较多，在 debug 时使用 || TRACE | 灰色(90) | 最详细的输出，跟踪了每一步关键路径的执行 | 名称 前景色代码 背景色代码 黑 30 40 红 31 41 绿 32 42 黄 33 43 蓝 34 44 品红 35 45 青 36 46 白 37 47 亮黑（灰） 90 100 亮红 91 101 亮绿 92 102 亮黄 93 103 亮蓝 94 104 亮品红 95 105 亮青 96 106 亮白 97 107","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"ls","slug":"ls","date":"2022-12-10T15:28:20.916Z","updated":"2022-12-10T15:28:20.916Z","comments":true,"path":"2022/12/10/ls/","link":"","permalink":"http://example.com/2022/12/10/ls/","excerpt":"","text":"-luse a long listing format missing:~$ ls -l /home drwxr-xr-x 1 missing users 4096 Jun 15 2019 missing First, the d at the beginning of the line tells us that missing is a directory. Then follow three groups of three characters (rwx). These indicate what permissions the owner of the file (missing), the owning group (users), and everyone else respectively have on the relevant item. A - indicates that the given principal does not have the given permission -i-inode print the index number of each file","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"文件系统查看 df","slug":"文件系统查看 df","date":"2022-12-10T15:27:53.158Z","updated":"2022-12-10T15:27:53.158Z","comments":true,"path":"2022/12/10/文件系统查看 df/","link":"","permalink":"http://example.com/2022/12/10/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9F%A5%E7%9C%8B%20df/","excerpt":"","text":"report file system disk space usage Filesystem Size Used Avail Use% Mounted on -h-h, –human-readable print sizes in powers of 1024 (e.g., 1023M) df -h –max-depth-a, –all include pseudo, duplicate, inaccessible file systems du -ah --max-depth=1 &lt;目录，缺省为当前目录&gt; 单独列出&lt;目录路径&gt;各一级子项占用的容量 -sdu -sh &lt;目录，缺省为当前目录&gt; 查看&lt;目录路径&gt;总共占的容量（而不单独列出各子项占用的容量） -Tprint file system type Filesystem Type 1K-blocks Used Available Use% Mounted on","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"bash快捷键","slug":"bash快捷键","date":"2022-12-10T15:26:19.635Z","updated":"2022-12-10T15:26:19.635Z","comments":true,"path":"2022/12/10/bash快捷键/","link":"","permalink":"http://example.com/2022/12/10/bash%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"ctrl+R 可以搜索历史输入指令","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash文件判断和比较","slug":"bash文件判断和比较","date":"2022-12-10T15:25:50.468Z","updated":"2022-12-10T15:26:30.803Z","comments":true,"path":"2022/12/10/bash文件判断和比较/","link":"","permalink":"http://example.com/2022/12/10/bash%E6%96%87%E4%BB%B6%E5%88%A4%E6%96%AD%E5%92%8C%E6%AF%94%E8%BE%83/","excerpt":"","text":"比较符 说明 举例 -e filename 如果filename存在，则为真 [ -e &#x2F;var&#x2F;log&#x2F;syslog ] -d filename 如果filename为目录，则为真 [ -d &#x2F;tmp&#x2F;mydir ] -f filename 如果filename常规文件，则为真 [ -f &#x2F;usr&#x2F;bin&#x2F;grep ] -L filename 如果filename为符号链接，则为真 [ –L &#x2F;usr&#x2F;bin&#x2F;grep ] -r filename 如果filename可读，则为真 [ –r &#x2F;var&#x2F;log&#x2F;syslog ] -w filename 如果filename可写，则为真 [ –w &#x2F;varmytmp.txt ] -x filename 如果filename可执行，则为真 [ –x &#x2F;usr&#x2F;bin&#x2F;grep ] -s filename 如果filename不是空白文件，则为真 -u filename 如果filename有SUID属性，则为真 -g filename 如果filename有SGID属性，则为真 -k filename 如果filename有stickybit属性，则为真 file1 –nt file2 如果file1比file2新，则为真 file1 –ot file2 如果file1比file2旧，则为真","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash特殊符号 特殊变量","slug":"bash特殊符号 特殊变量","date":"2022-12-10T15:24:22.958Z","updated":"2022-12-10T15:24:22.958Z","comments":true,"path":"2022/12/10/bash特殊符号 特殊变量/","link":"","permalink":"http://example.com/2022/12/10/bash%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%20%E7%89%B9%E6%AE%8A%E5%8F%98%E9%87%8F/","excerpt":"","text":"特殊符号$()和`` 命令代换替换为命令输出（输出到stdout的内容）， 所有的shell支持使用反引号的方式进行命令替换， 命令替换可以嵌套，需要注意的是如果使用反引号的形式，在内部反引用前必须使用反斜杠转义 Current_Folder=$(cd `dirname $0`; pwd) $ nproc 1 $ make -j $(nproc) #即make -j 1 $ echo $(date) #即echo 2021年 11月 04日 星期四 21:41:54 CST 2021年 11月 04日 星期四 21:41:54 CST $ date 2021年 11月 04日 星期四 21:41:56 CST $(()) 算术代换 匹配符 说明 $(()) 例如 echo $((4 + 6)) 特殊变量$#expands to the number of arguments (positional parameters) i.e. $1, $2 ... passed to the script in question or the shell in case of argument directly passed to the shell e.g. in bash -c &#39;...&#39; ..... $1, $2 …arguments (positional parameters) passed to the script in question or the shell in case of argument directly passed to the shell e.g. in bash -c &#39;...&#39; ..... $0, $1, $2 …就是对应给shell的命令，以whitespace分隔， 所以$1, $2 … argument， $0 exe name","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"SSE编译flag","slug":"SSE编译flag","date":"2022-12-10T14:21:00.585Z","updated":"2022-12-10T14:21:15.047Z","comments":true,"path":"2022/12/10/SSE编译flag/","link":"","permalink":"http://example.com/2022/12/10/SSE%E7%BC%96%E8%AF%91flag/","excerpt":"","text":"gcc或g++编译：SSE2不用给flag##include &lt;immintrin.h&gt; 给flag -march=native","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"}],"tags":[{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"operf -t thread举例","slug":"operf-t-thread举例","date":"2022-12-09T14:55:43.000Z","updated":"2023-03-21T02:37:56.000Z","comments":true,"path":"2022/12/09/operf-t-thread举例/","link":"","permalink":"http://example.com/2022/12/09/operf-t-thread%E4%B8%BE%E4%BE%8B/","excerpt":"","text":"命令 profile程序（-t则将把每个线程分开统计并分别输出，-k指定内核调试文件，这样会得到内核的调用信息） sudo operf -t -k /usr/lib/debug/lib/modules/$(uname -r)/vmlinux ./main 根据得到的采集数据输出结果 opreport -o symbols.txt -l callgraph若要输出函数callgraph信息（这样每个函数就不仅仅是一行，而是它的调用栈），则都加上–callgraph选项 profile程序–callgraph或-g sudo operf --callgraph -t -k /usr/lib/debug/lib/modules/$(uname -r)/vmlinux ./main 根据得到的采集数据输出结果–callgraph或-c opreport --callgraph -o symbols.txt -l 输出的含义：https://oprofile.sourceforge.io/doc/opreport.html输出的每一个entry(一个entry通过----和其他entry分开)，含义：没有缩进的函数是我们关心的函数，其上的函数是直接调用关心函数的函数（有时会出现不是直接调用关心函数的函数，这是因为这些采样发生在直接调用关心函数的函数刚开始的时候，此时函数栈还没有搭好，误以为是这个函数的caller https://oprofile.sourceforge.io/doc/interpreting-callgraph.html），其下的函数是关心函数直接调用的函数（其中有一个[self]行，这是关心函数去除调用callee以外的时间） 输出输出的symbols.txt例如：三个线程每个线程分开统计，下面的%每一列是一个线程（每个%列求和是100），是按第一%列进行降序排序的 附：测试程序main.cpp#include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;algorithm&gt; #include &lt;vector&gt; using namespace std; mutex stdout_mut; // return first element int sort_work(int sz) &#123; std::vector&lt;int&gt; arr(sz); for (int i = 0; i &lt; sz; ++i) arr[i] = rand(); sort(arr.begin(), arr.end()); return arr[0]; &#125; void compute1() &#123; int re = sort_work(100000); lock_guard&lt;mutex&gt; lk(stdout_mut); cout &lt;&lt; pthread_self() &lt;&lt; &#39; &#39; &lt;&lt; re &lt;&lt; endl; &#125; void compute2() &#123; int re = sort_work(99999); lock_guard&lt;mutex&gt; lk(stdout_mut); cout &lt;&lt; pthread_self() &lt;&lt; &#39; &#39; &lt;&lt; re &lt;&lt; endl; &#125; int main() &#123; srand(time(0)); thread th1(compute1); th1.join(); thread th2(compute1); th2.join(); lock_guard&lt;mutex&gt; lk(stdout_mut); cout &lt;&lt; &quot;main thread: &quot; &lt;&lt; pthread_self() &lt;&lt; endl; return 0; &#125; makefileTARGET=main main:$&#123;TARGET&#125;.cpp makefile g++ -std=c++11 -g -Wall -rdynamic -pthread -o main $&#123;TARGET&#125;.cpp clean:main rm -rf main","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"tool","slug":"tool","permalink":"http://example.com/tags/tool/"}],"author":"zhiqiuyuan"},{"title":"linux性能监测工具学习计划","slug":"linux性能监测工具学习计划","date":"2022-12-09T14:52:38.000Z","updated":"2023-01-03T01:29:04.000Z","comments":true,"path":"2022/12/09/linux性能监测工具学习计划/","link":"","permalink":"http://example.com/2022/12/09/linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%B5%8B%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/","excerpt":"","text":"学这个！Linux Performance (brendangregg.com)","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"社交网络复习","slug":"社交网络复习","date":"2022-12-09T11:36:23.000Z","updated":"2022-12-29T14:53:29.000Z","comments":true,"path":"2022/12/09/社交网络复习/","link":"","permalink":"http://example.com/2022/12/09/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"未看但是可能要看： 2.4 分支限界算法中：多项式近似算法，page 35 2.4 KT index，page 63 1.1 图的基本概念、类型 1.2 幂律分布、图的测度参数、随机图 2.1 顶点及边的中心性计算 n为全图顶点数目 无向图的度中心性：顶点的度（可以通过除以最大可能值n-1来标准化度数） 2.2 可达性&amp;最短路径 Dijkstra算法： 直到所有顶点都加入集合S A*算法： 直到所有顶点都加入集合S 其中g(n)的计算：传递计算 2.3 稠密子图搜索定义和算法 k-core定义 算法 degree(u)&gt;degree(v)：即看在order中在v（当前顶点）右边的v邻居 算法举例：page 34-50 k-truss定义 算法 举例：page 54-63 k-clique定义 原始算法 举例：page 69-79 算法KCLIST 举例：page 82-86（如果看不懂，建议先看简单算法的举例） 比较 2.4 图关键字搜索r-clique 分支限界算法 举例：page 20-33 k-NK搜索二跳标签索引 举例和应用：线性扫描L(v1)和L(v3) k-Nk查询定义 前向搜索(FS) 其中“查找dist(q,vi)”通过查二跳标签索引L(q)和L(vi)得到 二跳标签后向索引根据二跳标签索引L构建LB： 前向后向搜索(FBS) 举例： 2.5 图结构差异性搜索基于连通分量的结构差异性是一个顶点的性质 基于核心的结构差异性是一个顶点的性质 问题 CC-TopK Core-TopK CC-TopK的基于度的简单方法bound 算法 举例： 2.6 图划分标签更新过程： 两个扩展：（当多个标签具有相同的最高频率，不再是随机选一个） 定义： 3.1 社区检测 COPRA重叠社区发现算法COPRA 算法 举例 解： 对于每个顶点： 删除标签：系数&gt;&#x3D;1&#x2F;2的标签保留；若所有标签都系数&lt;1&#x2F;2，则保留其中系数最高的标签；若有多个系数相同的这种标签，则随机保留其中一个； 对于保留的标签，进行系数归一化（所有标签系数之和为1） 传播：对于每个顶点，对于其邻居中的每个标签L，扫描它的所有邻居将该标签的系数求和，再除以邻居数目，得到L的系数 以此类推，见作业答案 3.2 异常检测评测指标 精确率P，召回率R F-measure（是P和R的一个平均数） ROC 曲线（TPR（即召回率）：样本中的正例有多少被预测正确了；FPR：样本中的负例有多少被预测正确了） SpotLight 算法图模型 每个Gt是一个有向二部图 算法 如何提取spotlight草图v(G)：先选取k个查询子图（分别对应v(G)坐标的k个维度），然后计算每个维度（对应查询子图的边权之和） 举例： 3.3 频繁子图挖掘定义 子图的支持度：（在输入的多个图中的）出现次数 一个图中出现（不管多少次），计一次 举例： Apriori算法 AGM 基于Apriori算法的频繁子图挖掘算法图编码 合并两个含有k个顶点（且共有一个k-1个顶点的子图）的图：如果用编码 算法 3.5 图概要 无损图表示 ”超节点映射“：记录每个超节点代表原图中的哪些点 （超点连接的）存储开销 贪婪算法 算法 举例s(x,y)计算举例 page42和page45 算法举例 page41-48","categories":[{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"github+hexo+volantis主题搭建博客","slug":"github-hexo-volantis主题搭建博客","date":"2022-12-08T15:31:20.000Z","updated":"2023-01-01T11:21:17.000Z","comments":true,"path":"2022/12/08/github-hexo-volantis主题搭建博客/","link":"","permalink":"http://example.com/2022/12/08/github-hexo-volantis%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"参考：GitHub Pages + Hexo搭建个人博客网站，史上最全教程 搭建创建github仓库新建public仓库，命名为&lt;用户名&gt;.github.io 仓库settings中pages项启用github pages（默认是启用了的） 本地hexo 安装 Hexo npm install -g hexo-cli 验证是否安装成功：查看版本 hexo -v 创建一个项目 hexo-blog hexo init hexo-blog # 将在当前目录下创建一个名为hexo-blog的目录，这个目录后面称作&lt;博客目录&gt; 更换主题：以volantis主题为例 在&lt;博客目录&gt;下： 下载主题源码，以后就可以魔改了 git clone https://github.com/volantis-x/hexo-theme-volantis.git themes/volantis 修改&lt;博客目录&gt;目录下的_config.yml： theme: volantis 关联github仓库配置好后，执行hexo g -d可以直接发布到github： 安装hexo-deployer-git npm install hexo-deployer-git --save 修改根目录下的 _config.yml，配置 GitHub 相关信息 deploy: type: git repo: https://github.com/yaorongke/yaorongke.github.io.git branch: main token: ghp_3KakcaPHerunNRyMerofcFd9pblU282FSbsY 其中 token 为 GitHub 的 Personal access tokens(settings - developer settings- Personal access tokens) [可选]volantis主题优化参考：Volantis volantis主题提供非常友好的配置方式：将&lt;博客目录&gt;/themes/volantis/_config.yml复制到&lt;博客目录&gt;下，命名为_config.volantis.yml，然后对这个yml文件进行配置即可（此配置文件的优先级高于_config.yml） 搜索 标题和内容搜索简直是支持成为好用博客的最重要因素了！ 这里以使用hexo search为例 enable： 在&lt;博客目录&gt;下运行下述，安装支持： npm i hexo-generator-json-content 配置_config.volantis.yml： search: enable: true service: hexo # hexo, algolia, meilisearch 其他配置：修改_config.volantis.yml中的search下面的配置即可 暗黑模式在顶部导航栏新增dark&#x2F;light mode切换按钮： _config.volantis.yml： navbar: ... menu: ... - name: 暗黑模式 icon: fa-solid fa-moon toggle: darkmode 文章分类和标签页面 分类页面 Create file if not exists: source/categories/index.md --- layout: category index: true title: 所有分类 --- 标签页面 Create file if not exists: source/tags/index.md --- layout: tag index: true title: 所有标签 --- 文章给分类和标签给文章写了分类和标签之后会自动在首页、分类页面、标签页面形成对应内容 分类 多级分类：分类B是分类A的子类 --- categories: [分类A, 分类B] --- 并列分类：分类A和B是并列分类 --- categories: - [分类A] - [分类B] --- 多级+并列分类 --- categories: - [分类A, 分类B] - [分类C, 分类D] --- 标签 --- tags: - tag1 - tag2 --- 其他页面见页面配置 - Volantis，比如“关于页面”、“友链页面”等 评论以giscus为例 _config.volantis.yml： comments: ... service: giscus ... giscus: # 以下配置按照 yml 格式增删填写即可 # repo: xxx/xxx # repo-id: xxx # category: xxx # category-id: xxx # mapping: &quot;pathname&quot; # reactions-enabled: &quot;1&quot; # emit-metadata: &quot;0&quot; # lang: &quot;zh-CN&quot; # 以上配置按照 yml 格式增删填写即可 上述comments/giscus下方的配置填啥： 进入giscus，按Repository这里说的配置你的github仓库（每一步不会的就戳蓝色链接进去，有手把手步骤） 配置github仓库完成后，回到giscus，从Repository开始填写你的信息：主要填一下你的Repository，接下来的通常用默认勾选的就可以 然后下方Enable giscus处就会出现给你的配置信息，对着填即可 引用自己上传的素材等指的是在yml文件中引用（文章中引用的格式见下文）上传到source目录下，然后在yml文件中可以用/路径来引用比如引用图片source/img/test.jpg是用/img/test.jpg 侧边栏配置https://volantis.js.org/v5/theme-settings/#%E4%BE%A7%E8%BE%B9%E6%A0%8F%E9%85%8D%E7%BD%AE 搭建后维护写文章参考页面配置 - Volantis [可选]引用图片 配置：修改&lt;博客目录&gt;目录下的_config.yml：打开这个配置是为了在生成文章的时候生成一个同名的资源目录用于存放图片文件等 post_asset_folder: true 语法：在文章中引用这个目录中的图片的方式：（举例：cute.jpg在这个同名目录下）（用markdown语法引用图片![]()有时会失效，推荐下述） &#123;% asset_img cute.jpg cute_sirotan %&#125; &#123;% asset_img cute.jpg %&#125; 引用网图： ![img_name](https://xxx.com/xx.jpg) ![](https://xxx.com/xx.jpg) 新建文章hexo new &quot;&lt;post_name&gt;&quot; this will generate .md and folder under /source/_post folder specify path --path,-pbash hexo new &quot;hello_title&quot; --path writing/hello this will create source/_posts/writing/hello.md file with the following front matter:&#96;&#96;&#96;markdowntitle: hello_titledate: 2019-04-04 23:51:44The `--path` option is not documented, but it is listed when using `hexo help new`. #### 删除文章 来自[How do I delete a post in hexo - Stack Overflow](https://stackoverflow.com/questions/27894210/how-do-i-delete-a-post-in-hexo) There is no command to delete a post on Hexo, but follow this steps : 1. Delete the post under `source/_post` folder 2. Run `hexo clean` to delete the database (`db.json`) and `assets` folder 3. Run `hexo generate`to generate the new blog without your deleted post 4. Run `hexo deploy` to deploy your blog #### [给文章分类and加标签](# 文章给分类和标签) #### 文章置顶 ```markdown --- pin: true --- 设置文章作者Volantis 支持多个作者在一个站点发布文章，其他作者信息需要写在数据文件中，例如：blog/source/_data/author.yml Jon: name: Jon Snow avatar: https://cn.bing.com/th?id=AMMS_fc8f99fd41ebd737a71c4e13806db9a0&amp;w=110&amp;h=110&amp;c=7&amp;rs=1&amp;qlt=80&amp;pcl=f9f9f9&amp;cdv=1&amp;dpr=2&amp;pid=16.1 url: https://gameofthrones.fandom.com/wiki/Jon_Snow Dany: name: Daenerys Targaryen avatar: https://tse1-mm.cn.bing.net/th?id=OIP.Yax4wLzIFbcBVUa_RsKywQHaLH&amp;w=80&amp;h=80&amp;c=8&amp;rs=1&amp;qlt=90&amp;dpr=2&amp;pid=3.1&amp;rm=2 url: https://gameofthrones.fandom.com/wiki/Daenerys_Targaryen 在文章中设置作者： --- title: Jon Snow | Game of Thrones Wiki | Fandom author: Jon --- 自定义文章模板修改&lt;博客顶层目录&gt;/scaffolds/post.md即可 volantis主题支持的文章中的标签https://castiele.gitee.io/2020/10/23/volantis-article/ 写文章后发布到博客在&lt;博客目录&gt;下： 每次内容更新之后：g生成文件，-ddeploy，如果完成[关联github](# 关联github仓库)则执行这行还会推送到github上 hexo g -d 当github上反应不是很及时时，可以本地启动查看内容 hexo s 可以在http://localhost:4000访问 halo文章导入hexohalo管理后台的系统-小工具 hexo高级_posts目录下文章分级管理以“按年月日”分级管理为例 效果： _posts └─2022 └─12 └─10 ├─blog1 ├─blog2 ... ... ... ... 配置&lt;博客目录&gt;下的_config.yml： new_post_name: :year/:month/:day/:title.md 这样hexo new &lt;blog_name&gt;就会自动创建目录（如果不存在的话）_posts/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;/，并在该目录下生成&lt;blog_name&gt;.md和&lt;blog_name&gt;空目录 文章网页链接配置default配置文章的网页链接会在文章标题前加上/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;/，这是因为在_config.yml中设置了的缘故，如果希望网页链接没有日期前缀而只是文章标题，则可以配置_config.yml如下： permalink: :name/","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}],"author":"zhiqiuyuan"},{"title":"rust learning source link","slug":"rust学习资源链接","date":"2022-12-07T15:50:58.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/07/rust学习资源链接/","link":"","permalink":"http://example.com/2022/12/07/rust%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E9%93%BE%E6%8E%A5/","excerpt":"","text":"入门学习：rust语言圣经 https://course.rs/first-try/editor.html","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"cargo","slug":"cargo","date":"2022-12-07T15:49:46.000Z","updated":"2022-12-29T14:56:26.000Z","comments":true,"path":"2022/12/07/cargo/","link":"","permalink":"http://example.com/2022/12/07/cargo/","excerpt":"","text":"cargo run 编译运行cargo run 首先对项目进行编译，然后再运行默认是debug模式，在这种模式下，代码的编译速度会非常快，运行速度就慢了. 原因是，在 debug 模式下，Rust 编译器不会做任何的优化高性能：cargo run --release cargo check 检查能否通过编译cargo check快速的检查一下代码能否编译通过。因此该命令速度会非常快，能节省大量的编译时间。","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"tool","slug":"rust/tool","permalink":"http://example.com/categories/rust/tool/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"数据库概念-transaction","slug":"数据库概念","date":"2022-11-22T11:31:44.010Z","updated":"2022-12-10T13:55:09.094Z","comments":true,"path":"2022/11/22/数据库概念/","link":"","permalink":"http://example.com/2022/11/22/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5/","excerpt":"","text":"A transaction is a logical, atomic unit of work that contains one or more SQL statements. A transaction groups SQL statements so that they are either all committed, which means they are applied to the database, or all rolled back, which means they are undone from the database.","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"bash条件判断if 字符串 整数","slug":"bash条件判断if 字符串 整数","date":"2022-11-13T03:36:54.137Z","updated":"2022-12-10T13:56:01.128Z","comments":true,"path":"2022/11/13/bash条件判断if 字符串 整数/","link":"","permalink":"http://example.com/2022/11/13/bash%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%ADif%20%E5%AD%97%E7%AC%A6%E4%B8%B2%20%E6%95%B4%E6%95%B0/","excerpt":"","text":"https://ryanstutorials.net/bash-scripting-tutorial/bash-if-statements.php 1.整数比较 -eq 等于,如:if [ “$a” -eq “$b” ]-ne 不等于,如:if [ “$a” -ne “$b” ]-gt 大于,如:if [ “$a” -gt “$b” ]-ge 大于等于,如:if [ “$a” -ge “$b” ]-lt 小于,如:if [ “$a” -lt “$b” ]-le 小于等于,如:if [ “$a” -le “$b” ]&lt; 小于(需要双括号),如:((“$a” &lt; “$b”))&lt;&#x3D; 小于等于(需要双括号),如:((“$a” &lt;&#x3D; “$b”)) 大于(需要双括号),如:((“$a” &gt; “$b”))&#x3D; 大于等于(需要双括号),如:((“$a” &gt;&#x3D; “$b”)) folder&#x3D;”目标文件夹的路径” if [ ! -d “$folder” ]; then mkdir -p “$folder” echo “文件夹已创建！”else echo “文件夹已经存在！”fi","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"调试奇怪bug","slug":"调试奇怪bug","date":"2022-11-08T07:26:44.976Z","updated":"2022-12-10T14:16:58.648Z","comments":true,"path":"2022/11/08/调试奇怪bug/","link":"","permalink":"http://example.com/2022/11/08/%E8%B0%83%E8%AF%95%E5%A5%87%E6%80%AAbug/","excerpt":"","text":"valgrind 这个厉害！比如其中的memcheck工具，跑一遍告诉你哪里越界访问了！yyds！ gdb细粒度跟踪（这个超级牛啊） 可以不断确定要在哪里打断点，然后r，带着已经打的断点重新观察 经验malloc abort 或者 delete报错（说二次释放可是其实没有）heap is corrupt：被程序写了不该写的地方，比如在数组&#x2F;vector长度后面写东西 std::vector&lt;VertexIdType&gt; new_vps(problem_num*2); //... for(...) new_vps[pos++] = vps[2 * i]; // 如果这里越界写，可能就会把heap搞坏 //下面这里可能就会abort VertexIdType *ranges = new VertexIdType[batch_num * 2]; 这个通常可以通过检查所有new来的原始数组的写入 是否有越界来找原因，通常这个“所有数组”是 “在delete abort发生的数组 之前new申请的数组”（这些数组都在堆上，如果这些数组写越界了，把后面申请的数组也写了，由于俩数组可能元素类型不一样，所以会出现heap crupt的问题）（说通常是因为，堆分配不一定是后面分配的地址在前面分配的后面，不过数组本身确实是连续内存） 或者是内存不够 delete or delete[]Type* p = new Type;如果是delete[] p，会把p当做数组首地址去释放，这个数组的长度undefined，如果不是1的话会释放多次且是释放数组首地址+sizeof(数组元素)的地址 奇怪的段错误比如某个向量奇怪的段错误：gdb检查下这个向量的entry（尤其头尾），看下是否有被写入junk（比如一些很大的数字）如果被写入junk了，那么很可能是在“这个向量一切正常”的地方-“这个向量异常”的地方之间、写入的某个数组或向量等越界了注意，数组和向量越界都不会有内置的告警！！！ future wait用future wait框架写的，里面会生成个线程来跑你的异步程序，注意你的程序中可能部分异常不会有提示而是直接安静退出！调试奇妙的程序终止时建议把future框架暂时去掉，让你的程序不是在future生成的线程里面跑","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"windows查看文件被啥进程占用 资源监视器","slug":"windows查看文件被啥进程占用 资源监视器","date":"2022-10-25T01:20:00.939Z","updated":"2022-12-10T13:59:33.613Z","comments":true,"path":"2022/10/25/windows查看文件被啥进程占用 资源监视器/","link":"","permalink":"http://example.com/2022/10/25/windows%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E8%A2%AB%E5%95%A5%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%20%E8%B5%84%E6%BA%90%E7%9B%91%E8%A7%86%E5%99%A8/","excerpt":"","text":"（按windows键然后输入任务管理器）任务管理器-（上方横栏）性能-（下方）打开资源监视器或者直接搜资源监视器-（下方）搜索句柄 输入完整路径，得占用其的PID","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"文件被explore.exe占用无法通过文件资源管理器重命名","slug":"文件被exploreexe占用无法通过文件资源管理器重命名","date":"2022-10-25T01:15:50.419Z","updated":"2022-12-10T14:01:13.317Z","comments":true,"path":"2022/10/25/文件被exploreexe占用无法通过文件资源管理器重命名/","link":"","permalink":"http://example.com/2022/10/25/%E6%96%87%E4%BB%B6%E8%A2%ABexploreexe%E5%8D%A0%E7%94%A8%E6%97%A0%E6%B3%95%E9%80%9A%E8%BF%87%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D/","excerpt":"","text":"explore.exe是文件资源管理器的进程，所以得通过命令行来重命名 先关掉文件资源管理器，然后通过git bash用mv重命名（不推荐powershell的ren等，貌似有问题，总提示找不到）","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"embedding matrix","slug":"embedding matrix","date":"2022-10-20T08:40:09.797Z","updated":"2022-12-10T14:02:45.089Z","comments":true,"path":"2022/10/20/embedding matrix/","link":"","permalink":"http://example.com/2022/10/20/embedding%20matrix/","excerpt":"","text":"embedding matrix：多列，每列是一个单词对应的特征向量 这个矩阵*one_hot向量（n个单词则是n维向量，只有一个1）得到这个向量表示的单词的特征向量 或者对于一个变量，其值域为D，是离散的，其中有|D|个不同取值，则embedding matrix：多列，每列是一个取值对应的特征向量 或者不通过矩阵乘法的方式得到某值对应的特征向量，而是通过哈希表的方式，值-&gt;对应特征向量，则视图是 多行，每行是一个取值对应的特征向量","categories":[{"name":"ML","slug":"ML","permalink":"http://example.com/categories/ML/"},{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"i.i.d. 独立同分布","slug":"iid 独立同分布","date":"2022-10-20T07:31:15.640Z","updated":"2022-12-10T14:03:44.723Z","comments":true,"path":"2022/10/20/iid 独立同分布/","link":"","permalink":"http://example.com/2022/10/20/iid%20%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83/","excerpt":"","text":"i.i.d.独立同分布 (Independent and identically distributed random variables)一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立","categories":[{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"}],"tags":[{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 2021VLDB NeuroCard_one cardinality estimator for all tables","slug":"论文笔记 2021VLDB NeuroCard_one cardinality estimator for all tables","date":"2022-10-20T02:29:49.877Z","updated":"2022-12-10T14:31:20.584Z","comments":true,"path":"2022/10/20/论文笔记 2021VLDB NeuroCard_one cardinality estimator for all tables/","link":"","permalink":"http://example.com/2022/10/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202021VLDB%20NeuroCard_one%20cardinality%20estimator%20for%20all%20tables/","excerpt":"","text":"codehttps://github.com/neurocard problem problem related 名词解释cardinity即解的大小（解包含多个tuple（有多个tuple都是解），解的大小是tuple的数量） 前置知识AR模型即用采样的方法得到条件概率 AR 结构： Conor Durkan and Charlie Nash. 2019. Autoregressive Energy Machines. InProceedings of the 36th International Conference on Machine Learning (Proceedingsof Machine Learning Research), Kamalika Chaudhuri and Ruslan Salakhutdinov(Eds.), Vol. 97. PMLR, Long Beach, California, USA, 1735–1744 Naru是AR模型形式化query inference阶段： model总体T是ARmodel中的“给定一个T”的T 我们的目标：构建一个输入为所有表格的所有列的模型 模型结构： 采集样本（作为训练数据）从full join中选取tuple采样的目标： 算法框架： [step1]得到join_key列step1：Computing join counts(别人提出) 得到采样的概率对一个表格进行采样：这个表由很多tuple组成，每个tuple有一个采样它的概率，这个阶段就是给每个表格的每个tuple计算这个概率 [step2]得到join_key列step2：采样 举例 join中null部分的处理 [step3]得到join key列之后把内容列补全 外加：full join中总行数 comment：采集多个样本可以并行（因为独立同分布） factorization（处理训练数据：将采样得到行转换成特征向量） 名词解释：embeding matrix 每个tuple的每一列在这一步之后都对应1~多个特征向量了： 这样处理的话，对于列的filter条件可以如何处理：","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2020VLDB Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning","slug":"论文笔记 2020VLDB Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning","date":"2022-10-20T01:49:14.075Z","updated":"2022-12-10T14:31:11.131Z","comments":true,"path":"2022/10/20/论文笔记 2020VLDB Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning/","link":"","permalink":"http://example.com/2022/10/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202020VLDB%20Buffer%20Pool%20Aware%20Query%20Scheduling%20via%20Deep%20Reinforcement%20Learning/","excerpt":"","text":"名词解释 问题 模型总图 输入在内存中cache了哪些block 每个query要请求哪些block 形式化 实验效果","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"vmstat 系统内存监控","slug":"vmstat 系统内存监控","date":"2022-10-19T01:17:46.629Z","updated":"2022-12-10T14:07:03.136Z","comments":true,"path":"2022/10/19/vmstat 系统内存监控/","link":"","permalink":"http://example.com/2022/10/19/vmstat%20%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7/","excerpt":"","text":"https://www.cnblogs.com/sjli-blog/p/15076966.html vmstat的常规用法：vmstat interval times即每隔interval秒采样一次，共采样times次，如果省略times,则一直采集数据，直到用户手动停止为止。 [yuanzhiqiu@graph vertex_disjoint_path]$ vmstat 1 2 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 5759288 15041652 128 162632320 3 6 16 14 0 0 1 0 98 0 0 4 0 5759288 15040160 128 162632352 0 0 0 27 27335 54270 1 1 97 0 0 第一行显示了系统自启动以来的平均值，第二行开始显示现在正在发生的情况，接下来的行会显示每5秒间隔发生了什么，每一列的含义在头部，如下所示： ▪ procs：r这一列显示了多少进程在等待cpu，b列显示多少进程正在不可中断的休眠（等待IO）。 ▪ memory：swapd列显示了多少块被换出了磁盘（页面交换），剩下的列显示了多少块是空闲的（未被使用），多少块正在被用作缓冲区，以及多少正在被用作操作系统的缓存。 ▪ swap：显示交换活动：每秒有多少块正在被换入（从磁盘）和换出（到磁盘）。 ▪ io：显示了多少块从块设备读取（bi）和写出（bo）,通常反映了硬盘I&#x2F;O。 ▪ system：显示每秒中断(in)和上下文切换（cs）的数量。 ▪ cpu：显示所有的cpu时间花费在各类操作的百分比，包括执行用户代码（非内核），执行系统代码（内核），空闲以及等待IO。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"内存泄漏检测工具valgrind","slug":"内存泄漏检测工具valgrind","date":"2022-10-19T01:09:57.699Z","updated":"2022-12-10T14:07:26.796Z","comments":true,"path":"2022/10/19/内存泄漏检测工具valgrind/","link":"","permalink":"http://example.com/2022/10/19/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7valgrind/","excerpt":"","text":"原理和简介Valgrind follows each allocation in your program and tracks it to see if it is returned properly, continue to be referenced or is lost in space, which is a ‘memory leak’. And as any leak, given enough time you will drown, in this case require more and more memory, until either you program is eating up your whole computer, or you get out of memory. 常用 memcheck--tool=memcheck是默认选项 valgrind --leak-check=yes YourRunCommand valgrind --leak-check=full YourRunCommand https://tutorialadda.com/gdb/what-is-valgrind-and-how-to-debug-memory-related-issue-using-valgrind#:~:text=Valgrind%20is%20a%20debugging%20tool%20used%20for%20memory,to%20optimize%20memory%20uses%20during%20running%20the%20program. 其他工具：多线程竞争halgrind，缓存misscachegrind配合gdbgdb可以停在valgrind的error处，此时你可以通过gdb来观察现场https://www.responsive.se/thomas/2013/09/20/debugging-memory-leaks-with-valgrind-and-gdb/","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"excel OFFSET函数","slug":"excel OFFSET函数","date":"2022-10-16T08:05:12.186Z","updated":"2022-12-10T14:08:00.995Z","comments":true,"path":"2022/10/16/excel OFFSET函数/","link":"","permalink":"http://example.com/2022/10/16/excel%20OFFSET%E5%87%BD%E6%95%B0/","excerpt":"","text":"OFFSET(reference, rows, cols, [height], [width])excel的索引从1开始前三个参数指定左上角，height和width指定这个区域的大小（height：行数，width：列数）ROW()获取当前行索引 如下表示求区域（A3单元格为区域左上角，区域高是ROW()-4行，宽是1列）的均方差（&#x3D;SQRT(VAR(…))） =STDEV(OFFSET(A3,0,0,ROW()-4,1)) 这个公式放在A14，则是求图中数字(A3:A12)的方差","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"linux函数运行时间监控 oprofile 用opref替代opcontrol","slug":"linux函数运行时间监控 oprofile 用opref替代opcontrol","date":"2022-10-14T08:43:34.911Z","updated":"2022-12-10T14:08:23.474Z","comments":true,"path":"2022/10/14/linux函数运行时间监控 oprofile 用opref替代opcontrol/","link":"","permalink":"http://example.com/2022/10/14/linux%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4%E7%9B%91%E6%8E%A7%20oprofile%20%E7%94%A8opref%E6%9B%BF%E4%BB%A3opcontrol/","excerpt":"","text":"oprofile的Q&amp;A：https://oprofile.sourceforge.io/faq/ 先operfSYNOPSIS operf [ options ] [ --system-wide | --pid &lt;pid&gt; | [ command [ args ] ] ] One (and only one) of either command , --pid or --system-wide is required. desOperf is an OProfile tool that can be used in place of opcontrol for profiling. Operf uses the Linux Performance Events Subsystem, and hence, does not require the use of the opcon‐ trol daemon – in fact, operf and opcontrol usage are mutually exclusive. By default, operf uses &#x2F;oprofile_data as the session-dir and stores profiling data there. You can change this by way of the –session-dir option. The usual post-profiling analysis tools such as opreport(1) and opannotate(1) can be used to generate profile reports. The post-processing analysis tools will search for samples in &#x2F;oprofile_data first. If that directory does not exist, the post-process‐ ing tools use the standard session-dir of &#x2F;var&#x2F;lib&#x2F;oprofile. Statistics, such as total samples received and lost samples, are written to the operf.log file that can be found in the &#x2F;samples directory. options指定监控对象command[args] 这部分和你普通运行程序时的命令一样 The command or application to be profiled. args are the input arguments that the command or application requires. One (and only one) of either command , --pid or --system-wide is required.--pid / -p PID This option enables operf to profile a running application. PID should be the process ID of the process you wish to profile. When finished profiling (e.g., when the profiled process ends), press Ctrl-c to stop operf. If you run operf –pid as a background job (i.e., with the &amp;), you must stop it in a controlled manner in order for it to process the profile data it has collected. Use kill -SIGINT for this purpose. 其他选项--vmlinux / k vmlinux_path 不带这个参数的话不会统计内核的symbols Why do the profile tools fail to open the vmlinux kernel image ?Probably because you have accidentally specified the vmlinuz not vmlinux file. If you don’t have a vmlinux file, most Linux distributions provide a kernel debuginfo package that includes it. Otherwise, you need to recompile your kernel from source. If you’re not interested in kernel samples, then don’t use the –vmlinux option (and for legacy profiling, use opcontrol –no-vmlinux). A vmlinux file that matches the running kernel that has symbol and/or debuginfo. Kernel samples will be attributed to this binary, allowing post-processing tools (like opreport) to attribute samples to the appropriate kernel symbols. --callgraph / -g This option enables the callgraph to be saved during profiling. NOTE: The full callchain is recorded, so there is no depth limit. --separate-thread / -t This option categorizes samples by thread group ID (tgid) and thread ID (tid). The ‘–separate-thread’ option is useful for seeing per-thread samples in multi- threaded applications. When used in conjunction with the ‘–system-wide’ option, the ‘–separate-thread’ option is also useful for seeing per-process (i.e., per- thread group) samples for the case where multiple processes are executing the same program during a profiling run. --separate-cpu / -c This option categorizes samples by cpu. --session-dir / -d path This option specifies the session path to hold the sample data. If not specified, the data is saved in the oprofile_data directory on the current path --lazy-conversion / -l Use this option to reduce the overhead of operf during profiling. Normally, profile data received from the kernel is converted to OProfile format during profiling time. This is typically not an issue when profiling a single application. But when using the –system-wide option, this on-the-fly conversion process can cause noticeable overhead, particularly on busy multi-processor systems. The –lazy-con‐ version option directs operf to wait until profiling is completed to do the conver‐ sion of profile data. opreport 输出解释 https://oprofile.sourceforge.io/doc/opreport.html opgprof-p不给的话默认是当前目录下的oprofile_data目录，-o不给的话默认生成gmon.out，可以作为gprof的输入 opgprof -o &lt;output_file&gt; -p &lt;oprofile_data_path&gt; 举例先收集统计数据，在当前目录下运行（-g希望能够输出call graph） sudo operf -g ./main -m msbfs -g test_graph.txt -o . -p vertex_pairs.txt 在当前目录下oprofile_data得到数据（此目录可以备份起来，之后还可以基于此目录生成各种分析文件），然后输出分析结果，在当前目录下运行（如果operf是command指定监控对象的，则用opreport不需要指定command） 将所有符号的统计结果（按占用cpu周期的降序）symbols.txt中，还有调用图 opreport -o symbols.txt -l opreport -o call_graph.txt -c opreport -l中输出的image name列中，no-vmlinux表示the time spent by the linux kernel，the application binary itself 在这里的名字就是可执行文件的名字，比如main，xxx.so是time spent in the shared libraries your application uses 同时profile内核举例获取vmlinux文件安装kernel debuginfo centos: https://iwmj.wordpress.com/2018/09/15/how-to-download-and-install-debuginfo-packages-for-centos/ Firstly, get the target packages from http://debuginfo.centos.org through wget&#x2F;curl # cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) # this means your system is centos 7, which determines download address wget http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-common-x86_64-$(uname -r).rpm wget http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-$(uname -r).rpm Then install them yum install kernel-debuginfo-common-x86_64-$(uname -r).rpm yum install kernel-debuginfo-$(uname -r).rpm 然后会得到/usr/lib/debug/lib/modules/$(uname -r)/vmlinux，这个可以-k传递给opref extract-vmlinux脚本解压vmlinuz operf报告解压得到的文件invalid https://blog.packagecloud.io/how-to-extract-and-disassmble-a-linux-kernel-image-vmlinuz/ centos： 获取解压脚本sudo yum install kernel-devel-$(uname -r) You will be able to find the extract-linux script at &#x2F;usr&#x2F;src&#x2F;kernels&#x2F;$(uname -r)&#x2F;scripts&#x2F;extract-vmlinux 解压： A good first step is to create a temporary directory and copy the kernel image to it: mkdir ~/tmp/kernel-extract sudo cp /boot/vmlinuz-$(uname -r) ~/tmp/kernel-extract/ Now, run the extract-vmlinux script to extract the image. cd ~/tmp/kernel-extract/ sudo &lt;path_to_extract-vmlinux&gt; vmlinuz-$(uname -r) &gt; vmlinux 比如&#x2F;usr&#x2F;src&#x2F;kernels&#x2F;$(uname -r)&#x2F;scripts&#x2F;extract-vmlinux operf 加上-k指定vmlinux file的路径 sudo operf -k /tmp/kernel-extract/vmlinux-$(uname -r) ./main -m msbfs -g test_graph.txt -o . -p vertex_pairs.txt 适用应用 多线程可 cpu占用型的可 太小的程序统计的不完全","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux监控函数调用时间 gprof gcov","slug":"linux监控函数调用时间 gprof gcov","date":"2022-09-30T03:07:57.441Z","updated":"2022-12-10T14:09:02.870Z","comments":true,"path":"2022/09/30/linux监控函数调用时间 gprof gcov/","link":"","permalink":"http://example.com/2022/09/30/linux%E7%9B%91%E6%8E%A7%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%97%B6%E9%97%B4%20gprof%20gcov/","excerpt":"","text":"https://blog.csdn.net/yuyin86/article/details/6671472 gprof[每个函数的调用时间] 仅单线程、用户态gprof的基本用法：1． 使用 -pg 选项编译和链接你的应用程序 ，在gcc编译程序的时候，加上-pg选项，如果是大项目，就在makefile里面修改编译选项，-pg放在那里都行。例如： gcc -pg -o test test.c 2． 执行你的应用程序使之生成供gprof 分析的数据，运行刚才的程序： ./test input.txt output.txt 这样就生成了一个gmon.out文件，该文件就包含了profiling的数据。3. gprof ./test gmon.out 会输出分析结果到标准输出./test不用传上面运行传入的参数这里可以给gprof传参数，man gprof 不加参数输出的是所有函数的累计执行时间，剔除了children的执行时间；加上-F等参数还会输出call graph（每个函数谁调用它它调用谁以及时间以及被当前函数调用次数在总被调用次数的占比，并且按照self+children总时间降序，相当好的一张表）gprof -FTask1 ./test gmon.out 仅为函数Task1以及其孩子生成call graph gprof举例先编译参数加上-pg编译产生可执行文件 g++ -std=c++11 -g -pg main.cpp -o main 然后正常运行 ./main -m msbfs -g test_graph.txt -o . -p vertex_pairs.txt 然后会在运行的当前目录下生成gmon.out文件分析此文件输出分析结果。此文件可以备份起来，之后还可以基于此文件以及对应的可执行文件生成各种分析文件这会输出各函数的调用时间（降序，去除孩子的执行时间） gprof ./main gmon.out 这除了上述还会输出callgraph（每个函数的执行时间（包括孩子的执行时间），以及孩子的执行时间）传入-F的过滤似乎无效，但是会出发输出callgraph gprof -FComputeTask ./main gmon.out gcov[每行执行时间]https://blog.csdn.net/qq_32534441/article/details/90645316","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux查看cache大小","slug":"linux查看cache大小","date":"2022-09-30T01:48:38.367Z","updated":"2022-12-10T14:09:22.141Z","comments":true,"path":"2022/09/30/linux查看cache大小/","link":"","permalink":"http://example.com/2022/09/30/linux%E6%9F%A5%E7%9C%8Bcache%E5%A4%A7%E5%B0%8F/","excerpt":"","text":"getconf显示的大小数据单位为byte所有CACHE相关的参数 getconf -a | grep CACHE cache line大小 getconf -a | grep CACHE_LINESIZE Intel的一般是64字节： LEVEL1_ICACHE_LINESIZE 64 LEVEL1_DCACHE_LINESIZE 64 LEVEL2_CACHE_LINESIZE 64 LEVEL3_CACHE_LINESIZE 64 LEVEL4_CACHE_LINESIZE 0","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"模板类static成员静态数据成员","slug":"模板类static成员静态数据成员","date":"2022-09-28T02:02:06.209Z","updated":"2022-12-10T14:30:53.375Z","comments":true,"path":"2022/09/28/模板类static成员静态数据成员/","link":"","permalink":"http://example.com/2022/09/28/%E6%A8%A1%E6%9D%BF%E7%B1%BBstatic%E6%88%90%E5%91%98%E9%9D%99%E6%80%81%E6%95%B0%E6%8D%AE%E6%88%90%E5%91%98/","excerpt":"","text":"https://blog.csdn.net/zhizhengguan/article/details/116108271 语法1：定义在.h.h文件： template &lt;typename T&gt; class the_class&#123; static int id; &#125;; template &lt;typename T&gt; int the_class&lt;T&gt;::id = 0; 编译链接为模板类static成员分配的地址 这个取决于链接器，有些版本的链接器不支持此特殊处理，会报错，那么用语法2 由于定义在头文件中，如果多个.cpp文件包含了此头文件会导致有多个定义的问题，情况比如：call1.cpp #include &lt;iostream&gt; #include &quot;the_class.h&quot; void call1()&#123; the_class&lt;int&gt; c; std::cout &lt;&lt; c.id &lt;&lt; &quot;\\n&quot;; &#125;; call2.cpp #include &lt;iostream&gt; #include &quot;the_class.h&quot; void call2()&#123; the_class&lt;int&gt; c; std::cout &lt;&lt; c.id &lt;&lt; &quot;\\n&quot;; &#125;; main.cpp #include &lt;string&gt; #include &lt;iostream&gt; void call1(); void call2(); int main()&#123; call1(); call2(); return 0; &#125; call1.cpp和call2.cpp定义的call1()和call2()两个函数都生成了类模板the_class的实例the_class，编译器会分别在编译两个代码文件所生成的目标文件中，为其静态成员变量the_class&lt;int&gt;::id分配内存地址。而按照类静态成员的概念，所有类实例应该共享同一套静态成员存储空间。在链接时，链接器将随机选择一个目标中的空间作为最终存储空间，从而使不同目标文件中的多个等价目标实例共享同一套静态成员空间。 语法2：定义在.cpp和模板类成员函数定义和申明分离的写法类似，要在.cpp文件中写对模板类的实例化申明 .h文件： template &lt;typename T&gt; class the_class&#123; static int id; &#125;; .cpp文件： #include &quot;the_class.h&quot; template class the_class&lt;int&gt;; template class the_class&lt;long long&gt;; template &lt;typename T&gt; int the_class&lt;T&gt;::id = 0;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"vscode调试c++查看变量的二进制表示","slug":"vscode调试c++查看变量的二进制表示","date":"2022-09-27T14:04:59.926Z","updated":"2022-12-10T14:16:30.043Z","comments":true,"path":"2022/09/27/vscode调试c++查看变量的二进制表示/","link":"","permalink":"http://example.com/2022/09/27/vscode%E8%B0%83%E8%AF%95c++%E6%9F%A5%E7%9C%8B%E5%8F%98%E9%87%8F%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%A1%A8%E7%A4%BA/","excerpt":"","text":"方法一：watch窗口加expression后缀expression[,suffix]无后缀：十进值,x或,h：十六进制,o：八进制,b：二进制（低地址在右边）比如：undone.reg,b（reg是undone的private成员，也可以监控） 方法二：gdb内存查看命令xF5启动调试在断点处停住后，可以在debug console中通过-exec前缀执行gdb的命令比如内存查看指令x（gdbx命令详解 https://blog.csdn.net/allenlinrui/article/details/5964046）x/tb中数字为1表示显示一个单元，t表示以二进制格式显示，b表示一个单元是一个字节下述为查看undone.reg的首字节（reg是undone类型的private成员，也可以查看） -exec x/tb &amp;undone.reg 二进制显示时低地址在右边 -exec x/tb &amp;cross.reg 0x7ffff72d7bc8: 00000001 # 1是最低位bit","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"unorder_map插入键 值调用默认构造函数","slug":"unorder_map插入键 值调用默认构造函数","date":"2022-09-26T09:04:03.916Z","updated":"2022-12-10T14:17:44.149Z","comments":true,"path":"2022/09/26/unorder_map插入键 值调用默认构造函数/","link":"","permalink":"http://example.com/2022/09/26/unorder_map%E6%8F%92%E5%85%A5%E9%94%AE%20%E5%80%BC%E8%B0%83%E7%94%A8%E9%BB%98%E8%AE%A4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/","excerpt":"","text":"判断是否有某键，不用count而是用find，因为如果存在某键的话，count会返回键的所有个数，也就是会遍历所有，而不是找到了就返回 []向Fr中插入键n，值调用默认构造函数 if (Fr.find(n) == Fr.end()) &#123; Fr[n]; &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"模板定义和声明分离方法","slug":"模板定义和声明分离方法","date":"2022-09-26T07:19:03.072Z","updated":"2022-12-10T14:18:17.941Z","comments":true,"path":"2022/09/26/模板定义和声明分离方法/","link":"","permalink":"http://example.com/2022/09/26/%E6%A8%A1%E6%9D%BF%E5%AE%9A%E4%B9%89%E5%92%8C%E5%A3%B0%E6%98%8E%E5%88%86%E7%A6%BB%E6%96%B9%E6%B3%95/","excerpt":"","text":"调用可以和定义或申明不在一起 不分离申明和定义都放在.h文件中函数模板 template &lt;typename T&gt; void testprint(T i) &#123; std::cout &lt;&lt; i &lt;&lt; std::endl; &#125; 类模板 template &lt;typename T&gt; class A &#123; T data; void func()&#123; //definition &#125; &#125;; 分离需要在.cpp文件中添加实例化申明 函数模板.h template &lt;typename T&gt; void testprint(T i); .cpp template void testprint&lt;int&gt;(T i); 这里 template &lt;typename T&gt; void testprint(T i) &#123; std::cout &lt;&lt; i &lt;&lt; std::endl; &#125; 类模板.h template &lt;typename T&gt; class A &#123; T data; void func(); &#125;; .cpp template class A&lt;int&gt;; 这里 template &lt;typename T&gt; void A&lt;T&gt;::func()&#123; //definition &#125; 结论 可以不分离就不分离了，实在要分离，如果 有很多模板函数的目标扩展类都是一样的话，可以把它们写成一个模板类的成员函数，这样在cpp文件中写实例化申明的时候只要对类写就可以，而不用对每个函数都写","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"SSE指令速查链接","slug":"SSE指令速查链接","date":"2022-09-23T08:56:48.260Z","updated":"2022-12-10T14:20:15.508Z","comments":true,"path":"2022/09/23/SSE指令速查链接/","link":"","permalink":"http://example.com/2022/09/23/SSE%E6%8C%87%E4%BB%A4%E9%80%9F%E6%9F%A5%E9%93%BE%E6%8E%A5/","excerpt":"","text":"指令速查中文部分（从这里猜测用什么关键词去下面的官方文档中搜）https://packagewjx.github.io/2018/11/12/sse-note/官方（这个超级好，搜索迅速，给了描述、实现指令、头文件、对应指令集标准等）https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"}],"tags":[{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"cpp对齐","slug":"cpp对齐","date":"2022-09-22T06:54:42.540Z","updated":"2022-12-10T14:27:34.092Z","comments":true,"path":"2022/09/22/cpp对齐/","link":"","permalink":"http://example.com/2022/09/22/cpp%E5%AF%B9%E9%BD%90/","excerpt":"","text":"栈：alignas specifier (since C++11) alignas specifier (since C++11) - cppreference.com Specifies the alignment requirement of a type or an object. Syntaxalignas( expression ) \\1) expression must be an integral constant expression that evaluates to zero, or to a valid value for an alignment or extended alignment. describeThe object or the type declared by such a declaration will have its alignment requirement equal to the strictest (largest) non-zero expression of all alignas specifiers used in the declaration, unless it would weaken the natural alignment of the type. If the strictest (largest) alignas on a declaration is weaker than the alignment it would have without any alignas specifiers (that is, weaker than its natural alignment or weaker than alignas on another declaration of the same object or type), the program is ill-formed: struct alignas(8) S &#123;&#125;; struct alignas(1) U &#123; S s; &#125;; // error: alignment of U would have been 8 without alignas(1) Invalid non-zero alignments, such as alignas(3) are ill-formed. Valid non-zero alignments that are weaker than another alignas on the same declaration are ignored. alignas(0) is always ignored. 堆：posix_memalignint posix_memalign(void **__memptr, size_t __alignment, size_t __size) Allocate memory of SIZE bytes with an alignment of ALIGNMENT, return a pointer to the allocated memory in memptr Upon successful completion(return 0), the value pointed to by memptr shall be a multiple of alignment. 举例new(visitLists[a]) Bitset[subgraphSize]();在visitLists[a]这个地址开始处的内存处，构造一个类型为Bitset[subgraphSize]的object std::array&lt;Bitset*,2&gt; visitLists; for(int a=0; a&lt;2; a++) &#123; //分配内存 const auto ret=posix_memalign(reinterpret_cast&lt;void**&gt;(&amp;(visitLists[a])),64,sizeof(Bitset)*subgraphSize); if(unlikely(ret!=0)) &#123; //告诉编译器ret!=0很可能为假 //#define unlikely(x) __builtin_expect(!!(x), 0) throw -1; &#125; //构造 new(visitLists[a]) Bitset[subgraphSize](); //create an object of type `Bitset[subgraphSize]`, through calling () constructor, //directly into storage at memory address `visitLists[a]`. &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"cpp new placement new","slug":"cpp new placement new","date":"2022-09-22T03:12:45.839Z","updated":"2022-12-10T14:26:09.970Z","comments":true,"path":"2022/09/22/cpp new placement new/","link":"","permalink":"http://example.com/2022/09/22/cpp%20new%20placement%20new/","excerpt":"","text":"new expression - cppreference.com Creates and initializes objects with dynamic storage duration, that is, objects whose lifetime is not necessarily limited by the scope in which they were created. Syntax::(optional) new ( type ) initializer(optional) (1) ::(optional) new new-type initializer(optional) (2) ::(optional) new (placement-params) ( type ) initializer(optional) (3) ::(optional) new (placement-params) new-type initializer(optional) (4) \\1) Attempts to create an object of type, denoted by the type-id type, which may be array type, and may include a placeholder type specifier (since C++11), or include a class template name whose argument is to be deduced by class template argument deduction (since C++17). \\2) Same as (1), but new-type cannot include parentheses: new int(*[10])(); // error: parsed as (new int) (*[10]) () new (int (*[10])()); // okay: allocates an array of 10 pointers to functions new int + 1; // okay: parsed as (new int) + 1, increments a pointer returned by new int new int * 1; // error: parsed as (new int*) (1) \\3) Same as (1), but provides additional arguments to the allocation function, see placement new. \\4) Same as (2), but provides additional arguments to the allocation function. placement newIf placement-params are provided, they are passed to the allocation function as additional arguments. Such allocation functions are known as “placement new”, after the standard allocation function void* operator new(std::size_t, void*), which simply returns its second argument unchanged. This is used to construct objects in allocated storage: // within any block scope... &#123; // Statically allocate the storage with automatic storage duration // which is large enough for any object of type `T`. alignas(T) unsigned char buf[sizeof(T)]; T* tptr = new(buf) T; // Construct a `T` object, placing it directly into your // pre-allocated storage at memory address `buf`. tptr-&gt;~T(); // You must **manually** call the object&#39;s destructor // if its side effects is depended by the program. &#125; // Leaving this block scope automatically deallocates `buf`. c++17的一些说明本文未记录 举例new(visitLists[a]) Bitset[subgraphSize]();在visitLists[a]这个地址开始处的内存处，构造一个类型为Bitset[subgraphSize]的object std::array&lt;Bitset*,2&gt; visitLists; for(int a=0; a&lt;2; a++) &#123; //分配内存 //int posix_memalign(void **__memptr, size_t __alignment, size_t __size) //Allocate memory of SIZE bytes with an alignment of ALIGNMENT, return a pointer to the allocated memory in memptr //Upon successful completion(return 0), the value pointed to by memptr shall be a multiple of alignment. const auto ret=posix_memalign(reinterpret_cast&lt;void**&gt;(&amp;(visitLists[a])),64,sizeof(Bitset)*subgraphSize); if(unlikely(ret!=0)) &#123; //告诉编译器ret!=0很可能为假 //#define unlikely(x) __builtin_expect(!!(x), 0) throw -1; &#125; //构造 new(visitLists[a]) Bitset[subgraphSize](); //create an object of type `Bitset[subgraphSize]`, through calling () constructor, //directly into storage at memory address `visitLists[a]`. &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"mmap munmap","slug":"mmap munmap","date":"2022-09-21T10:45:34.349Z","updated":"2022-12-10T14:27:06.735Z","comments":true,"path":"2022/09/21/mmap munmap/","link":"","permalink":"http://example.com/2022/09/21/mmap%20munmap/","excerpt":"","text":"Memory-mapped fileA memory-mapped file is a segment of virtual memory[1] that has been assigned a direct byte-for-byte correlation with some portion of a file or file-like resource. This resource is typically a file that is physically present on disk, but can also be a device, shared memory object, or other resource that the operating system can reference through a file descriptor. Once present, this correlation between the file and the memory space permits applications to treat the mapped portion as if it were primary memory. BenefitsThe benefit of memory mapping a file is increasing I&#x2F;O performance, especially when used on large files. For small files, memory-mapped files can result in a waste of slack space[7] as memory maps are always aligned to the page size, which is mostly 4 KiB. Therefore, a 5 KiB file will allocate 8 KiB and thus 3 KiB are wasted. Accessing memory mapped files is faster than using direct read and write operations for two reasons. Firstly, a system call is orders of magnitude slower than a simple change to a program’s local memory. Secondly, in most operating systems the memory region mapped actually is the kernel’s page cache (file cache), meaning that no copies need to be created in user space. Certain application-level memory-mapped file operations also perform better than their physical file counterparts. Applications can access and update data in the file directly and in-place, as opposed to seeking from the start of the file or rewriting the entire edited contents to a temporary location. Since the memory-mapped file is handled internally in pages, linear file access (as seen, for example, in flat file data storage or configuration files) requires disk access only when a new page boundary is crossed, and can write larger sections of the file to disk in a single operation. A possible benefit of memory-mapped files is a “lazy loading“, thus using small amounts of RAM even for a very large file. Trying to load the entire contents of a file that is significantly larger than the amount of memory available can cause severe thrashing as the operating system reads from disk into memory and simultaneously writes pages from memory back to disk. Memory-mapping may not only bypass the page file completely, but also allow smaller page-sized sections to be loaded as data is being edited, similarly to demand paging used for programs. The memory mapping process is handled by the virtual memory manager, which is the same subsystem responsible for dealing with the page file. Memory mapped files are loaded into memory one entire page at a time. The page size is selected by the operating system for maximum performance. Since page file management is one of the most critical elements of a virtual memory system, loading page sized sections of a file into physical memory is typically a very highly optimized system function.[8] DrawbacksThe major reason to choose memory mapped file I&#x2F;O is performance. Nevertheless, there can be tradeoffs. The standard I&#x2F;O approach is costly due to system call overhead and memory copying. The memory-mapped approach has its cost in minor page faults—when a block of data is loaded in page cache, but is not yet mapped into the process’s virtual memory space. In some circumstances, memory mapped file I&#x2F;O can be substantially slower than standard file I&#x2F;O.[10] Another drawback of memory-mapped files relates to a given architecture’s address space: a file larger than the addressable space can have only portions mapped at a time, complicating reading it. For example, a 32-bit architecture such as Intel’s IA-32 can only directly address 4 GiB or smaller portions of files. An even smaller amount of addressable space is available to individual programs—typically in the range of 2 to 3 GiB, depending on the operating system kernel. This drawback however is virtually eliminated on modern 64-bit architecture. mmap also tends to be less scalable than standard means of file I&#x2F;O, since many operating systems, including Linux, has a cap on the number of cores handling page faults. Extremely fast devices, such as modern NVM Express SSDs, are capable of making the overhead a real concern.[11] I&#x2F;O errors on the underlying file (e.g. its removable drive is unplugged or optical media is ejected, disk full when writing, etc.) while accessing its mapped memory are reported to the application as the SIGSEGV&#x2F;SIGBUS signals on POSIX, and the EXECUTE_IN_PAGE_ERROR structured exception on Windows. All code accessing mapped memory must be prepared to handle these errors, which don’t normally occur when accessing memory. Only hardware architectures with an MMU can support memory-mapped files. On architectures without an MMU, the operating system can copy the entire file into memory when the request to map it is made, but this is extremely wasteful and slow if only a little bit of the file will be accessed, and can only work for files that will fit in available memory. Common usesPerhaps the most common use for a memory-mapped file is the process loader in most modern operating systems (including Microsoft Windows and Unix-like systems.) When a process is started, the operating system uses a memory mapped file to bring the executable file, along with any loadable modules, into memory for execution. Most memory-mapping systems use a technique called demand paging, where the file is loaded into physical memory in subsets (one page each), and only when that page is actually referenced.[12] In the specific case of executable files, this permits the OS to selectively load only those portions of a process image that actually need to execute. Another common use for memory-mapped files is to share memory between multiple processes. In modern protected mode operating systems, processes are generally not permitted to access memory space that is allocated for use by another process. (A program’s attempt to do so causes invalid page faults or segmentation violations.) There are a number of techniques available to safely share memory, and memory-mapped file I&#x2F;O is one of the most popular. Two or more applications can simultaneously map a single physical file into memory and access this memory. For example, the Microsoft Windows operating system provides a mechanism for applications to memory-map a shared segment of the system’s page file itself and share data via this section. mmap munmaphttps://man7.org/linux/man-pages/man2/mmap.2.html SYNOPSIS#include &lt;sys/mman.h&gt; void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length); mmap: DESCRIPTIONmmap() creates a new mapping in the virtual address space of thecalling process. The starting address(virtual address) for the new mapping isspecified in addr. The length argument specifies** the length ofthe mapping** (which must be greater than 0). If addr is NULL, then the kernel chooses the (page-aligned)address(virtual address) at which to create the mapping; this is the most portablemethod of creating a new mapping. If addr is not NULL, then thekernel takes it as a hint about where to place the mapping; onLinux, the kernel will pick a nearby page boundary (but alwaysabove or equal to the value specified by&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;mmap_min_addr) and attempt to create the mappingthere. If another mapping already exists there, the kernel picksa new address that may or may not depend on the hint. Theaddress of the new mapping is returned as the result of the call. The contents of a file mapping (as opposed to an anonymousmapping; see MAP_ANONYMOUS below), are initialized using lengthbytes starting at offset offset in the file (or other object)referred to by the file descriptor fd. offset must be a multipleof the page size as returned by sysconf(_SC_PAGE_SIZE). After the mmap() call has returned, the file descriptor, fd, canbe closed immediately without invalidating the mapping. The prot argument describes the desired memory protection of themapping (and must not conflict with the open mode of the file).It is either PROT_NONE or the bitwise OR of one or more of thefollowing flags: PROT_EXECPages may be executed. PROT_READPages may be read. PROT_WRITEPages may be written. PROT_NONEPages may not be accessed. mmap: The flags argumentThe flags argument determines whether updates to the mapping arevisible to other processes mapping the same region, and whetherupdates are carried through to the underlying file. Thisbehavior is determined by including exactly one of the followingvalues in flags: MAP_SHAREDShare this mapping. Updates to the mapping are visible toother processes mapping the same region, and (in the caseof file-backed mappings) are carried through to theunderlying file. (To precisely control when updates arecarried through to the underlying file requires the use ofmsync(2).) MAP_SHARED_VALIDATE (since Linux 4.15)This flag provides the same behavior as MAP_SHARED exceptthat MAP_SHARED mappings ignore unknown flags in flags.By contrast, when creating a mapping usingMAP_SHARED_VALIDATE, the kernel verifies all passed flagsare known and fails the mapping with the error EOPNOTSUPPfor unknown flags. This mapping type is also required tobe able to use some mapping flags (e.g., MAP_SYNC). MAP_PRIVATECreate a private copy-on-write mapping. Updates to themapping are not visible to other processes mapping thesame file, and are not carried through to the underlyingfile. It is unspecified whether changes made to the fileafter the mmap() call are visible in the mapped region. munmapThe munmap() system call deletes the mappings for the specifiedaddress range, and causes further references to addresses withinthe range to generate invalid memory references. The region isalso automatically unmapped when the process is terminated. Onthe other hand, closing the file descriptor does not unmap theregion. The address addr must be a multiple of the page size (but lengthneed not be). All pages containing a part of the indicated rangeare unmapped, and subsequent references to these pages willgenerate SIGSEGV. It is not an error if the indicated range doesnot contain any mapped pages. Does mmap copy data to the memory?c - Does mmap really copy data to the memory? - Stack Overflow The only thing the mmap function really does is change some kernel data structures, and possibly the page table. It doesn’t actually put anything into physical memory at all. After you call mmap, the allocated region probably doesn’t even point to physical memory: accessing it will cause a page fault. This kind of page fault is transparently handled by the kernel mmap() vs. reading blocks using mmap() versus reading in blocks via C++’s fstream library compare A call to mmap has more overhead than read (just like epoll has more overhead than poll, which has more overhead than read). Changing virtual memory mappings is a quite expensive operation on some processors for the same reasons that switching between different processes is expensive. The IO system can already use the disk cache, so if you read a file, you’ll hit the cache or miss it no matter what method you use. However, Memory maps are generally faster for random access, especially if your access patterns are sparse and unpredictable. Memory maps allow you to keep using pages from the cache until you are done. This means that if you use a file heavily for a long period of time, then close it and reopen it, the pages will still be cached. With read, your file may have been flushed from the cache ages ago. This does not apply if you use a file and immediately discard it. (If you try to mlock pages just to keep them in cache, you are trying to outsmart the disk cache and this kind of foolery rarely helps system performance). Reading a file directly is very simple and fast. The discussion of mmap&#x2F;read reminds me of two other performance discussions: Some Java programmers were shocked to discover that nonblocking I/O is often slower than blocking I/O, which made perfect sense if you know that nonblocking I/O requires making more syscalls. Some other network programmers were shocked to learn that epoll is often slower than poll, which makes perfect sense if you know that managing epoll requires making more syscalls. ConclusionUse memory maps if you access data randomly, keep it around for a long time, or if you know you can share it with other processes (MAP_SHARED isn’t very interesting if there is no actual sharing). Read files normally if you access data sequentially or discard it after reading. And if either method makes your program less complex, do that. For many real world cases there’s no sure way to show one is faster without testing your actual application and NOT a benchmark. When should I use mmap for file access? POSIX environments provide at least two ways of accessing files. There’s the standard system calls open(), read(), write(), and friends, but there’s also the option of using mmap() to map the file into virtual memory. When is it preferable to use one over the other? benefit and when to usemmap is great if you have multiple processes accessing data in a read only fashion from the same file. mmap allows all those processes to share the same physical memory pages, saving a lot of memory. mmap also allows the operating system to optimize paging operations. For example, consider two programs; program A which reads in a 1MB file into a buffer creating with malloc, and program B which mmaps the 1MB file into memory. If the operating system has to swap part of A‘s memory out, it must write the contents of the buffer to swap before it can reuse the memory. In B‘s case any unmodified mmap‘d pages can be reused immediately because the OS knows how to restore them from the existing file they were mmap‘d from. (The OS can detect which pages are unmodified by initially marking writable mmap‘d pages as read only and catching seg faults, similar to Copy on Write strategy). mmap is also useful for inter process communication. You can mmap a file as read &#x2F; write in the processes that need to communicate and then use synchronization primitives in the mmap&#39;d region (this is what the MAP_HASSEMAPHORE flag is for). awkwardnessOne place mmap can be awkward is if you need to work with very large files on a 32 bit machine. This is because mmap has to find a contiguous block of addresses in your process’s address space that is large enough to fit the entire range of the file being mapped. This can become a problem if your address space becomes fragmented, where you might have 2 GB of address space free, but no individual range of it can fit a 1 GB file mapping. In this case you may have to map the file in smaller chunks than you would like to make it fit. Another potential awkwardness with mmap as a replacement for read &#x2F; write is that you have to start your mapping on offsets of the page size. If you just want to get some data at offset X you will need to fixup that offset so it’s compatible with mmap. And finally, read &#x2F; write are the only way you can work with some types of files. mmap can’t be used on things like pipes and ttys.","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"c++ data types __m128i","slug":"c++ data types __m128i","date":"2022-09-21T08:35:50.997Z","updated":"2022-12-10T14:32:06.952Z","comments":true,"path":"2022/09/21/c++ data types __m128i/","link":"","permalink":"http://example.com/2022/09/21/c++%20data%20types%20__m128i/","excerpt":"","text":"__m128i__m128i | Microsoft Learn The __m128i data type, for use with the Streaming SIMD Extensions 2 (SSE2) instructions intrinsics, is defined in &lt;emmintrin.h&gt;. eg: /usr/local/gcc-9.3.0/lib/gcc/x86_64-pc-linux-gnu/9.3.0/include/emmintrin.h // data_types__m128i.cpp #include &lt;emmintrin.h&gt; int main() &#123; __m128i x; &#125; RemarksUsing variables of type __m128i will cause the compiler to generate the SSE2 movdqa instruction. This instruction does not cause a fault on Pentium III processors but will result in silent failure, with possible side effects caused by whatever instructions movdqa translates into on Pentium III processors. You should not access the __m128i fields directly. You can, however, see these types in the debugger. A variable of type __m128i maps to the XMM[0-7] registers. Variables of type __m128i are automatically aligned on 16-byte boundaries. The __m128i data type is not supported on ARM processors.","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 2014SC Scalable and high performance betweenness centrality on the gpu","slug":"论文笔记 2014SC Scalable and high performance betweenness centrality on the gpu","date":"2022-09-17T09:27:09.726Z","updated":"2022-12-10T14:32:18.066Z","comments":true,"path":"2022/09/17/论文笔记 2014SC Scalable and high performance betweenness centrality on the gpu/","link":"","permalink":"http://example.com/2022/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202014SC%20Scalable%20and%20high%20performance%20betweenness%20centrality%20on%20the%20gpu/","excerpt":"","text":"一些定义和知识betweenness中心性 比较不同图的BC：（(n-1)(n-2)是除了v之外所有不同点对的数目，且含方向） 求BC的著名算法 [7] U. Brandes, “A Faster Algorithm for Betweenness Centrality,” Journalof Mathematical Sociology, vol. 25, pp. 163–177, 2001. 上述的GPU版本Jia [23] Y. Jia, V. Lu, J. Hoberock, M. Garland, and J. C. Hart, “Edge v. NodeParallelism for Graph Centrality Metrics,” GPU Computing Gems, vol. 2,pp. 15–30, 2011. 问题：不需要在这层inspect的点边或者边也inspect了，因为是给每个点&#x2F;边一个thread （需要记录前驱是因为我们需要知道路径是否经过xx点，因此完整路径是要记录的） GPU-FAN（虽然但是，这个显然就是上面的改了一点点，还更菜） [34] Z. Shi and B. Zhang, “Fast Network Centrality Analysis using GPUs,”BMC bioinformatics, vol. 12, no. 1, p. 149, 2011 前驱记录 算法变量（perblock的block指CUDA术语中的thread block） S和ends记录每层的顶点，类似CSR的结构 1 初始化 2 计算所有点对间最短路径数目 目前本文还没有提出新的东西","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 B类2002ESA External-memory breadth-first search with sublinear IO","slug":"论文笔记 B类2002ESA External memory breadth","date":"2022-09-17T08:03:06.650Z","updated":"2022-12-10T14:33:14.693Z","comments":true,"path":"2022/09/17/论文笔记 B类2002ESA External memory breadth/","link":"","permalink":"http://example.com/2022/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20B%E7%B1%BB2002ESA%20External%20memory%20breadth/","excerpt":"","text":"related workexternal BFS 算法1 预处理 非随机划分 回顾：欧拉图： 2 和[1999 SODA]几乎一样的BFS（只是多了个有序文件放最近用到的邻接表） 不一样的地方：维护一个有序的文件H用于获取邻接表：（H有序：H中存放的内容是边entry，有序按边entry字典序） 如何获取L(t-1)的邻居：","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 1999SODA IO-complexity of graph algorithms","slug":"论文笔记 1999SODA IOcomplexity of graph algorithms","date":"2022-09-17T03:25:31.428Z","updated":"2022-12-10T14:33:45.435Z","comments":true,"path":"2022/09/17/论文笔记 1999SODA IOcomplexity of graph algorithms/","link":"","permalink":"http://example.com/2022/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%201999SODA%20IOcomplexity%20of%20graph%20algorithms/","excerpt":"","text":"尚未全部阅读 parallel disk model（对于BFS没啥大用）模型 BD(j-1)定位红色框（trackj前有j-1个track（红框），每个track有BD个records）；B(k-1)在红框中定位蓝框（红框中，diskk前有k-1个block（蓝框），每个block有B个records）；i在蓝框中定位record IO compute BFS一个性质level(t-1)邻居的并集得到初始level(t)，此level(t)中要去除的已经visited（入队）的顶点，只可能在level(t-1)∪level(t-2)中 证明（by me）：如果初始level(t)中有level(t-3)中的顶点，则说明level(t-1)中有顶点有邻居在level(t-3)（因为level(t)是level(t-1)邻居的并集），而如果level(t-1)中有顶点有邻居在level(t-3)，则该顶点应该在处理level(t-3)的时候被入队到下一个level，即应该属于level(t-2)，这与该顶点属于level(t-1)矛盾证明（by [2002 ESA] External-memory breadth-first search with sublinear I&#x2F;O）： 算法","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2020VLDB Traversing Large Graphs on GPUs with Unified Memory","slug":"论文笔记 2020VLDB Traversing Large Graphs on GPUs with Unified Memory","date":"2022-09-16T02:27:01.163Z","updated":"2022-12-10T14:36:24.294Z","comments":true,"path":"2022/09/16/论文笔记 2020VLDB Traversing Large Graphs on GPUs with Unified Memory/","link":"","permalink":"http://example.com/2022/09/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202020VLDB%20Traversing%20Large%20Graphs%20on%20GPUs%20with%20Unified%20Memory/","excerpt":"","text":"问题 且cpu部分的存储貌似只是内存，没有考虑外存那些 在UVM settings下讨论（CUDA支持） related work本文作为对比对象的： 大图放多GPU或GPU和CPU GPU BFS external BFS：已计划 一些定义 UVM CSR和BFS 分析factors that impact performance(DATA ACCESS PATTERN)： Dependence on the Source Node Dependence on Graph Ordering Dependence on Directedness 问题形式化（貌似没有用） 理想的order： 1 HARMONIC LOCALITY ORDERING希望的从随机的顶点出发BFS，所以希望 这个在无向图中可以 计算 算法“精确” 代替上面的c(x) 计算中心性 给order 不是严格按照中心性降序作为order的原因以及设计： 近似 把上式展开，相同d的项放在一起，得到的和式，第一项对应和x距离为1的所有点，第二项对应和x距离为2的所有点…","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"An Overview of Semi-External Graph System","slug":"An Overview of Semi","date":"2022-09-15T06:56:54.995Z","updated":"2022-12-10T14:38:24.003Z","comments":true,"path":"2022/09/15/An Overview of Semi/","link":"","permalink":"http://example.com/2022/09/15/An%20Overview%20of%20Semi/","excerpt":"","text":"来自2022FAST Practicably Boosting the Processing Performance of BFS-like Algorithms on Semi-External Graph System via IO-Efficient Graph Ordering 存储 I&#x2F;O optimization techniques Pre-processing","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"db","slug":"graph/db","permalink":"http://example.com/categories/graph/db/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"conda环境切换","slug":"conda环境切换","date":"2022-09-14T12:53:22.653Z","updated":"2022-12-10T14:41:28.116Z","comments":true,"path":"2022/09/14/conda环境切换/","link":"","permalink":"http://example.com/2022/09/14/conda%E7%8E%AF%E5%A2%83%E5%88%87%E6%8D%A2/","excerpt":"","text":"装好miniconda之后有的conda命令（miniconda：相比起anaconda不会自带几千个包） conda activate &lt;env_name&gt; 比如conda activate basebase外的其他环境的存储目录在&lt;miniconda的安装目录&gt;/envs下（比如/home/yuanzhiqiu/miniconda3）","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"DNS error","slug":"DNS error","date":"2022-09-14T12:12:21.281Z","updated":"2022-12-10T14:41:56.393Z","comments":true,"path":"2022/09/14/DNS error/","link":"","permalink":"http://example.com/2022/09/14/DNS%20error/","excerpt":"","text":"https://stackoverflow.com/questions/9393409/ssh-could-not-resolve-hostname-github-com-name-or-service-not-known-fatal-th ssh: Could not resolve hostname github.com: Name or service not known fatal: The remote end hung up unexpectedly ubuntu上： ping github.com, if ping failed. it is DNS error. sudo vim /etc/resolv.conf, then add: nameserver 8.8.8.8 nameserver 8.8.4.4Or it can be a genuine network issue. Restart your network-manager using sudo service network-manager restart or fix it up","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2017FAST Graphene_Fine-Grained IO Management for Graph Computing","slug":"论文笔记 2017FAST Graphene_Fine Grained IO Management for Graph Computing","date":"2022-09-14T03:19:38.733Z","updated":"2022-12-10T14:42:31.256Z","comments":true,"path":"2022/09/14/论文笔记 2017FAST Graphene_Fine Grained IO Management for Graph Computing/","link":"","permalink":"http://example.com/2022/09/14/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202017FAST%20Graphene_Fine%20Grained%20IO%20Management%20for%20Graph%20Computing/","excerpt":"","text":"一些definition 1 Bitmap Based, Asynchronous IO1 store block size依据： 2 bitmap（这个） bitmap size: 举例：benefit: 3 Asynchronous IO upper bound for IO size(size for each IO transaction) 依据： IO context number： what is IO context: 2 Balancing Data and Workload1 图数据划分 2 处理 回顾：metadata放内存，graphdata放外存 详细和举例： 3 HugePage support大页可以降低TLB misses：因为TLB中line的内容是页表的entry","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2016SIGMOD iBFS_Concurrent Breadth-First Search on GPUs","slug":"论文笔记 2016SIGMOD iBFS_Concurrent Breadth First Search on GPUs","date":"2022-09-13T09:22:20.912Z","updated":"2022-12-10T14:43:03.652Z","comments":true,"path":"2022/09/13/论文笔记 2016SIGMOD iBFS_Concurrent Breadth First Search on GPUs/","link":"","permalink":"http://example.com/2022/09/13/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202016SIGMOD%20iBFS_Concurrent%20Breadth%20First%20Search%20on%20GPUs/","excerpt":"","text":"问题 code related workCPU-多BFS实例 MSBFS VLDB[26] Manuel Then, Moritz Kaufmann, Fernando Chirigati,Tuan-Anh Hoang-Vu, Kien Pham, Alfons Kemper,Thomas Neumann, and Huy T Vo. The more themerrier: Efficient multi-source graph traversal.Proceedings of the VLDB Endowment, 8(4), 2014. CCF-B [27] Ahmet Erdem Sarıyuce, Erik Saule, Kamer Kaya, and ¨Umit V ¸Cataly ¨ urek. Regularizing graph centrality ¨computations. Journal of Parallel and DistributedComputing, 2014. CCF-B IPDPS [28] Ahmet Erdem Sariyuce, Erik Saule, Kamer Kaya, andUmit V Catalyurek. Hardware&#x2F;software vectorizationfor closeness centrality on multi-&#x2F;many-corearchitectures. In International Parallel &amp; DistributedProcessing Symposium Workshops (IPDPSW), pages1386–1395. IEEE, 2014. GPU-多BFS实例 见上面[27] SC [35]Adam McLaughlin and David A Bader. Scalable andhigh performance betweenness centrality on the gpu.In International Conference for High PerformanceComputing, Networking, Storage and Analysis (SC),pages 572–583. IEEE, 2014 一些字母含义和取值 ideaexample中状态数组SA的图示说明 典型的BFS observation on shared frontiers 1 JOINT TRAVERSAL 和MSBFS类似+GPU设计 data structure generate JFQ implementation of JFQ example 2 GROUPBY 这个好（将BFS分组以最大化组内BFS的frontiers share）原理结论 结论的详细得出过程 speedup指相对于串行、分离地执行这个group中的BFS而言的加速比（串行时间&#x2F;此方案时间） idea规则对于两个BFS实例而言 q的选择： 规则应用方法 N be default &#x3D; 128 效果： 规则的直观解释： 3 GPU-BASED BITWISE OPERATIONS 和MSBFS类似+GPU设计idea数据结构 实现： expansion inspection Early Termination：This newly freed-up thread will then be scheduled to work on other frontiers. frontier generation","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2012PPoPP Scalable GPU Graph Traversal","slug":"论文笔记 2012PPoPP Scalable GPU Graph Traversal","date":"2022-09-10T09:58:42.602Z","updated":"2022-12-10T14:43:59.639Z","comments":true,"path":"2022/09/10/论文笔记 2012PPoPP Scalable GPU Graph Traversal/","link":"","permalink":"http://example.com/2022/09/10/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202012PPoPP%20Scalable%20GPU%20Graph%20Traversal/","excerpt":"","text":"details: High-Performance and Scalable GPU Graph Traversal我读的这篇详细的 BFS approach componentsContract-Expand Two-Phase gatheringCoarse-Grained, Warp-Based Gathering Fine-Grained, Scan-Based Gathering Scan+Warp+CTA Gathering 举例 filter(过滤已经visited的、vertex_frontier-&gt;edge_frontier)bitmask Warp Culling History Culling code Duane Merrill. 2011. Back40 computing: Fast and efficient software primitives for GPU computing.http://code.google.com/p/back40computing/这个现在被合并到 https://nvlabs.github.io/cub/","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"CUDA编程模型","slug":"CUDA编程模型","date":"2022-09-09T08:17:04.729Z","updated":"2022-12-10T14:45:20.431Z","comments":true,"path":"2022/09/09/CUDA编程模型/","link":"","permalink":"http://example.com/2022/09/09/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model overall thread hierarchy：将问题划分为线程块block Thread blocks are required to execute independently: It must be possible to execute them in any order, in parallel or in series. Threads within a block can cooperate by sharing data through some shared memory and by synchronizing their execution to coordinate memory accesses. thread num within one block: all threads of a block are expected to reside on the same processor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads. 16x16 (256 threads) is a common choice. cooperate: one can specify synchronization points in the kernel by calling the __syncthreads() intrinsic function; __syncthreads() acts as a barrier at which all threads in the block must wait before any is allowed to proceed. Shared Memory gives an example of using shared memory. In addition to __syncthreads(), the Cooperative Groups API provides a rich set of thread-synchronization primitives. For efficient cooperation, the shared memory is expected to be a low-latency memory near each processor core (much like an L1 cache) and __syncthreads() is expected to be lightweight. 下图：编程模型到硬件的映射 一个SM是一个multiprocessor，类似于一个处理器 block间并行独立因此： a compiled CUDA program can execute on any number of multiprocessors, and only the runtime system needs to know the physical multiprocessor count. program modelKernelsdefintion and call C++ functions defined using the __global__ declaration specifier calling with &lt;&lt;griddim, blockdim&gt;&gt; xxdim can be of type int or dim3 griddim: how the blocks are arranged&#x2F;indexed blockdim: how the threads in a block are arranged&#x2F;indexed elaboration and egs see [Thread Hierarchy](# Thread Hierarchy) when called, are executed N times in parallel by N different CUDA threads (N defined by &lt;&lt;griddim, blockdim&gt;&gt;). Each thread that executes the kernel is given a unique thread ID that is accessible within the kernel through built-in variables. “N defined by &lt;&lt;griddim, blockdim&gt;&gt;“ so a kernel can be executed by multiple equally-shaped thread blocks simple eg adds two vectors A and B of size N and stores the result into vector C: // Kernel definition __global__ void VecAdd(float* A, float* B, float* C) &#123; int i = threadIdx.x; C[i] = A[i] + B[i]; &#125; int main() &#123; ... // Kernel invocation with N threads VecAdd&lt;&lt;&lt;1, N&gt;&gt;&gt;(A, B, C); ... &#125; Thread Hierarchyindex built-in variable threadIdx is a 3-component vector, so that threads can be identified using a one-dimensional, two-dimensional, or three-dimensional thread index, forming a one-dimensional, two-dimensional, or three-dimensional block of threads（指的是 一个block内线程的编排，是block内的相对位置） threadIdx and thread ID： For a one-dimensional block, they are the same for a two-dimensional block of size *(Dx, Dy)*（size: in terms of thread num）, the thread ID of a thread of index (x, y) is (x + y Dx) for a three-dimensional block of size (Dx, Dy, Dz), the thread ID of a thread of index (x, y, z) is (x + y Dx + z Dx Dy). 一个问题的所有block的编排也采用类似的方式，built-in variable blockIdx 定位thread：blockIdx+blockDim定位哪个block，然后在block中threadIdx+threadDim定位哪个thread eg: structure-in-blockadds two matrices A and B of size NxN and stores the result into matrix C: // Kernel definition __global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]) &#123; int i = threadIdx.x; int j = threadIdx.y; C[i][j] = A[i][j] + B[i][j]; &#125; int main() &#123; ... // Kernel invocation with one block of N * N * 1 threads int numBlocks = 1; dim3 threadsPerBlock(N, N); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ... &#125; eg: both-structure-in-block-and-gridblocks are arranged in 2-dimention threads in a block are arranged in 2-dimention // Kernel definition __global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]) &#123; int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadIdx.y; if (i &lt; N &amp;&amp; j &lt; N) C[i][j] = A[i][j] + B[i][j]; &#125; int main() &#123; ... // Kernel invocation dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); // For simplicity, this example assumes that the number of threads per grid in each dimension is evenly divisible by the number of threads per block in that dimension MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ... &#125; Memory HierarchyCUDA threads may access data from multiple memory spaces during their execution. Each thread has private local memory. Each thread block has shared memory visible to all threads of the block and with the same lifetime as the block. All threads have access to the same global memory. There are also two additional read-only memory spaces accessible by all threads: the constant and texture memory spaces. The global, constant, and texture memory spaces are optimized for different memory usages (see Device Memory Accesses). The global, constant, and texture memory spaces are persistent across kernel launches by the same application. by me: 这样的memory层次划分是和硬件对应的 Heterogeneous Programming the CUDA programming model assumes that the CUDA threads execute on a physically separate device that operates as a coprocessor to the host running the C++ program. This is the case, for example, when the kernels execute on a GPU and the rest of the C++ program executes on a CPU. The CUDA programming model also assumes that both the host and the device maintain their own separate memory spaces in DRAM, referred to as host memory and device memory, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls to the CUDA runtime (described in Programming Interface). This includes device memory allocation and deallocation as well as data transfer between host and device memory. Unified Memory provides managed memory to bridge the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single, coherent memory image with a common address space. This capability enables oversubscription of device memory and can greatly simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device. See Unified Memory Programming for an introduction to Unified Memory.","categories":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/categories/GPU/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"}],"author":"zhiqiuyuan"},{"title":"GPU入门","slug":"GPU入门","date":"2022-09-06T09:26:37.248Z","updated":"2022-12-10T14:45:30.961Z","comments":true,"path":"2022/09/06/GPU入门/","link":"","permalink":"http://example.com/2022/09/06/GPU%E5%85%A5%E9%97%A8/","excerpt":"","text":"学习自：https://qiankunli.github.io/2021/08/18/gpu.htmlNVIDA官方手册：https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#abstract 整体感知 GPU 的整个处理过程是一个流式处理（Stream Processing）的过程，分支条件少（少用控制语句） 每个GPU核心（是个电路） 只有 取指令、指令译码、ALU 以及执行这些计算需要的寄存器和缓存 现代 CPU 里的晶体管变得越来越多，越来越复杂，其实已经不是用来实现“计算”这个核心功能，而是拿来实现处理乱序执行、进行分支预测，以及高速缓存部分。GPU把这些部分去除了the GPU can hide memory access latencies with computation, instead of relying on large data caches and complex flow control to avoid long memory access latencies, both of which are expensive in terms of transistors. 一个 GPU ：多个这样并行的 GPU 电路 内存访问（分离式架构）：（gpu作为外设可以访问cpu内存，但）cpu 和gpu 最擅长访问自己的内存 GPU 硬件架构 每个 GPU 都由一组 SM（流式多处理器Streaming Multiprocessor，核心Core） 构成； 线程调度器（Warp Scheduler）：线程束（Warp）是最基本的单元，每个线程束中包含 32 个并行的线程，它们使用不同的数据执行相同的命令，调度器会负责这些线程的调度； 访问存储单元（Load&#x2F;Store Queues）：在核心和内存之间快速传输数据； 特殊函数的计算单元（Special Functions Unit、SPU） 存储和缓存数据的寄存器文件（Register File） 共享内存（Shared Memory） 执行速度CUDA 核心在每个时钟周期都可以准确的执行一次整数或者浮点数的运算 CPU 与GPU 协作（分离式） 分离式： GPU 是一个外设，有驱动程序 MMIO: Memory-Mapped I&#x2F;O锁页：操作系统常用的操作，可以使硬件外设直接访问物理内存。”被锁定“的页面被os标记为不可被os 换出 驱动程序提供的接口： 一般的外设：输出数据地址 command_operation(输入数据地址) 这个意思是类似于函数申明：cpu控制向输入数据地址写数据，调用接口，等中断，然后从输出数据地址读数据 gpu：输出数据地址 command_operation(指令序列,输入数据地址) 典型工作流程: 应用层（cpu上执行）调用某个会调用GPU的API，如 OpenGL 或 CUDA OpenGL 或 CUDA 库，通过 UMD (User Mode Driver)，提交 workload 到 KMD (Kernel Mode Driver) Kernel Mode Driver 写 CSR MMIO，把它提交给 GPU 硬件 GPU 硬件开始工作… 完成后，DMA 到内存，发出中断给 CPU CPU 找到中断处理程序 —— Kernel Mode Driver 此前向 OS Kernel 注册过的 —— 调用它 中断处理程序找到是哪个 workload 被执行完毕了，…最终驱动唤醒相关的应用 CUDA(一种GPU驱动程序)编程 https://zhuanlan.zhihu.com/p/34587739nvida官方手册：https://developer.nvidia.com/zh-cn/blog/cuda-intro-cn/ 编程模型这些抽象提供了细粒度的数据并行和线程并行，嵌套在粗粒度的数据并行和任务并行中。它们指导程序员将问题划分为可以由++线程块++并行独立解决的粗略子问题，并将每个子问题划分为可以由++块内所有线程++并行协作解决的更精细的部分。 一个问题（grid）划分为多个线程块（block或者warp；gridDim个），线程块之间独立执行； 每个线程块有多个thread（blockDim个），每个线程块对应一个deviceFunction（kernel） 编程模型和硬件的关系 A cooperative thread array (or CTA) is a group of threads that will be co-located on the same multiprocessor（即比如此图中到同一个SM上的所有block的所有thread，它们属于一个CTA）each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order（指block之间的顺序？）, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors, and only the runtime system needs to know the physical multiprocessor count. 概念 在CUDA中：host指代CPU及其内存，而用device指代GPU及其内存 三类函数：函数类型 谁执行 谁调用global 设备端执行 可以从主机调用也可以从某些特定设备调用device 设备端执行 设备端调用 host 主机端执行 主机调用 device 函数和global函数因为需要在GPU上运行，因此不能调用常见的一些 C&#x2F;C++ 函数（因为这些函数没有对应的 GPU 实现） 典型的CUDA程序的执行流程如下：分配host内存，并进行数据初始化；分配device内存，并从host将数据拷贝到device上；调用CUDA的核函数在device上完成指定的运算；将device上的运算结果拷贝到host上；释放device和host上分配的内存。 编程举例一维数组加法x+y-&gt;z // __global__ 表示在device上执行，从host中调用 // 两个向量加法kernel，grid和block均为一维 // 每个thread的任务是“跨步”对位加法 __global__ void add(float* x, float * y, float* z, int n)&#123; // 获取全局索引：这个thread的indx，这是第几个thread int index = threadIdx.x + blockIdx.x * blockDim.x; // 步长：共有这么多thread int stride = blockDim.x * gridDim.x; for (int i = index; i &lt; n; i += stride)&#123; z[i] = x[i] + y[i]; &#125; &#125; int main()&#123; int N = 1 &lt;&lt; 20; int nBytes = N * sizeof(float); // 申请host内存 float *x, *y, *z; x = (float*)malloc(nBytes); y = (float*)malloc(nBytes); z = (float*)malloc(nBytes); // 初始化数据 for (int i = 0; i &lt; N; ++i)&#123; x[i] = 10.0; y[i] = 20.0; &#125; // 申请device内存 float *d_x, *d_y, *d_z; cudaMalloc((void**)&amp;d_x, nBytes); cudaMalloc((void**)&amp;d_y, nBytes); cudaMalloc((void**)&amp;d_z, nBytes); // 将host数据拷贝到device cudaMemcpy((void*)d_x, (void*)x, nBytes, cudaMemcpyHostToDevice); cudaMemcpy((void*)d_y, (void*)y, nBytes, cudaMemcpyHostToDevice); // 定义kernel的执行配置 dim3 blockSize(256); dim3 gridSize((N + blockSize.x - 1) / blockSize.x); // 执行kernel add &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(d_x, d_y, d_z, N); // 将device得到的结果拷贝到host cudaMemcpy((void*)z, (void*)d_z, nBytes, cudaMemcpyDeviceToHost); // 检查执行结果 float maxError = 0.0; for (int i = 0; i &lt; N; i++) maxError = fmax(maxError, fabs(z[i] - 30.0)); std::cout &lt;&lt; &quot;最大误差: &quot; &lt;&lt; maxError &lt;&lt; std::endl; // 释放device内存 cudaFree(d_x); cudaFree(d_y); cudaFree(d_z); // 释放host内存 free(x); free(y); free(z); return 0; &#125;","categories":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/categories/GPU/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"}],"author":"zhiqiuyuan"},{"title":"rockdb leveldb handbook链接","slug":"rockdb leveldb handbook链接","date":"2022-09-04T03:04:12.326Z","updated":"2022-12-10T14:47:04.623Z","comments":true,"path":"2022/09/04/rockdb leveldb handbook链接/","link":"","permalink":"http://example.com/2022/09/04/rockdb%20leveldb%20handbook%E9%93%BE%E6%8E%A5/","excerpt":"","text":"leveldb: https://leveldb-handbook.readthedocs.io/zh/latest/basic.htmlrocksdb: https://www.bookstack.cn/read/rocksdb-6.14-en/79f0ebf380de6ff5.md","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"}],"author":"zhiqiuyuan"},{"title":"leveldb SSTable sst文件 sst解析工具","slug":"leveldb SSTable sst文件 sst解析工具","date":"2022-09-04T02:45:23.278Z","updated":"2022-12-10T14:47:27.567Z","comments":true,"path":"2022/09/04/leveldb SSTable sst文件 sst解析工具/","link":"","permalink":"http://example.com/2022/09/04/leveldb%20SSTable%20sst%E6%96%87%E4%BB%B6%20sst%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7/","excerpt":"","text":"https://leveldb-handbook.readthedocs.io/zh/latest/sstable.html SStable文件格式物理结构 一个sstable文件按照固定大小进行块划分，默认每个块的大小为4KiB。 每个Block中，除了存储数据以外，还会存储两个额外的辅助字段： 压缩类型：说明了Block中存储的数据是否进行了数据压缩，若是，采用了哪种算法进行压缩。leveldb中默认采用Snappy算法进行压缩。 CRC校验码：校验范围包括数据以及压缩类型。 逻辑结构将一个sstable分为： data block: 用来存储key value数据对； filter block: 用来存储一些过滤器相关的数据（布隆过滤器），但是若用户不指定leveldb使用过滤器，leveldb在该block中不会存储任何内容； meta Index block: 用来存储filter block的索引信息（索引信息指在该sstable文件中的偏移量以及数据长度）； index block：index block中用来存储每个data block的索引信息； footer: 用来存储meta index block及index block的索引信息； 注意，1-4类型的区块，其物理结构都是如1.1节所示，每个区块都会有自己的压缩信息以及CRC校验码信息。 data block结构一个data block中的数据部分（不包括压缩类型、CRC校验码）按逻辑以下图进行划分： entry存储keyvalue数据key 由于sstable中所有的keyvalue对都是严格按序存储的，为了节省存储空间，leveldb并不会为每一对keyvalue对都存储完整的key值，而是存储与上一个key非共享的部分，避免了key重复内容的存储。 每间隔若干个keyvalue对，将为该条记录重新存储一个完整的key。重复该过程（默认间隔值为16），每个重新存储完整key的点称之为Restart point。 加速查找：由于每个Restart point存储的都是完整的key值，因此在sstable中进行数据查找时，可以首先利用restart point点的数据进行键值比较，以便于快速定位目标数据所在的区域；当确定目标数据所在区域时，再依次对区间内所有数据项逐项比较key值，进行细粒度地查找； entry格式每个entry的格式如下图所示： 与前一条记录key共享部分的长度； 与前一条记录key不共享部分的长度； value长度； 与前一条记录key非共享的内容； value内容； 举例restart_interval&#x3D;2entry one : key&#x3D;deck,value&#x3D;v1entry two : key&#x3D;dock,value&#x3D;v2entry three: key&#x3D;duck,value&#x3D;v3 三组entry按上图的格式进行存储。值得注意的是restart_interval为2，因此每隔两个entry都会有一条数据作为restart point点的数据项，存储完整key值。因此entry3存储了完整的key。 此外，第一个restart point为0（偏移量），第二个restart point为16，restart point共有两个，因此一个datablock数据段的末尾添加了下图所示的数据： 尾部数据记录了每一个restart point的值，以及所有restart point的个数。 SST dump tool编译sst_dump 参考https://shashangka.com/2020/06/26/rocksdb-administration-and-data-access-tool/ 在rocksdb源码顶层目录下 # generate cmake cache mkdir build cd build cmake .. 然后回到rocksdb源码顶层目录下 # config cmake and build cmake --build ./build --config Debug --target sst_dump # --build: specify where cmake cache locates 得到sst_dump在&lt;--build指定的目录&gt;/tools下 使用https://github.com/facebook/rocksdb/wiki/Administration-and-Data-Access-Tool Printing entries in SST file./sst_dump --file=/path/to/sst/000829.sst --command=scan --read_num=5 This command will print the first 5 keys in the SST file to the screen. the output may look like this &#39;Key1&#39; @ 5: 1 =&gt; Value1 &#39;Key2&#39; @ 2: 1 =&gt; Value2 &#39;Key3&#39; @ 4: 1 =&gt; Value3 &#39;Key4&#39; @ 3: 1 =&gt; Value4 &#39;Key5&#39; @ 1: 1 =&gt; Value5 The output can be interpreted like this &#39;&lt;key&gt;&#39; @ &lt;sequence number&gt;: &lt;type&gt; =&gt; &lt;value&gt; Please notice that if your key has non-ascii characters, it will be hard to print it on screen, in this case it’s a good idea to use --output_hex like this ./sst_dump --file=/path/to/sst/000829.sst --command=scan --read_num=5 --output_hex You can also specify where do you want to start reading from and where do you want to stop by using --from and --to like this ./sst_dump --file=/path/to/sst/000829.sst --command=scan --from=&quot;key2&quot; --to=&quot;key4&quot; You can pass --from and --to using hexadecimal as well by using --input_key_hex ./sst_dump --file=/path/to/sst/000829.sst --command=scan --from=&quot;0x6B657932&quot; --to=&quot;0x6B657934&quot; --input_key_hex C","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"}],"author":"zhiqiuyuan"},{"title":"跳跃列表","slug":"跳跃列表","date":"2022-09-04T01:44:28.314Z","updated":"2022-12-10T14:49:07.287Z","comments":true,"path":"2022/09/04/跳跃列表/","link":"","permalink":"http://example.com/2022/09/04/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8/","excerpt":"","text":"https://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8 概述 使得包含n个元素的有序序列的查找和插入操作的平均时间复杂度都是O(log n)，优于数组的O(n)复杂度 一个多层次的链表。与前一层（下面一层）链表元素的数量相比，每一层链表中的元素的数量更少。每一层是有序的 构造跳跃列表是按层建造的。底层是一个普通的有序链表。每个更高层都充当下面列表的“快速通道”，在第i层（下面的层）中的每个元素按某个固定的概率p（通常为1/2或1/4）出现在第i+1层（上面的层）中，直到当前层元素个数为1 每个元素平均出现在1/1-p个列表中，而最高层的元素（通常是在跳跃列表前端的一个特殊的头元素）在log&#123;1/p&#125;n个列表中出现。 查找在查找目标元素时，从顶层列表、头元素起步。算法沿着每层链表搜索，直至找到一个大于或等于目标的元素，或者到达当前层列表末尾。如果该元素等于目标元素，则表明该元素已被找到；如果该元素大于目标元素或已到达链表末尾，则退回到当前层的上一个元素，然后转入下一层进行搜索。举例见插入 每层链表中预期的查找步数最多为1/p，而层数为log&#123;1/p&#125;n，所以查找的总体步数为log&#123;p&#125;n/p，由于p是常数，查找操作总体的时间复杂度为O(logn)。而通过选择不同p值，就可以在查找代价和存储代价之间获取平衡。 插入和查找类似插入80 80&lt;&#x3D;30? 80&lt;&#x3D;30?no 80&lt;&#x3D;50? 80&lt;&#x3D;50?no 走到nil所以向下走80&lt;&#x3D;70? 80&lt;&#x3D;70?no 80&lt;&#x3D;90? 80&lt;&#x3D;90?yes, insert","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"leveldb底层概述和Files","slug":"leveldb底层概述和Files","date":"2022-09-04T01:16:33.962Z","updated":"2022-12-10T14:50:20.335Z","comments":true,"path":"2022/09/04/leveldb底层概述和Files/","link":"","permalink":"http://example.com/2022/09/04/leveldb%E5%BA%95%E5%B1%82%E6%A6%82%E8%BF%B0%E5%92%8CFiles/","excerpt":"","text":"https://leveldb-handbook.readthedocs.io/zh/latest/basic.htmlhttps://github.com/google/leveldb/blob/main/doc/impl.md leveldb架构 leveldb写流程概述 将所有的写操作写到日志文件（log文件）中 将内容写入到内存中 先memtable，等到其存储内容的容量达到阈值时（默认为4MB），便将其转换成一个不可修改的memtable，与此同时创建一个新的memtable，供用户继续进行读写操作。 当一个immutable memtable被创建时，leveldb的后台压缩进程便会将利用其中的内容，创建一个sstable，持久化到磁盘文件中。 memtable 其中数据按用户定义的排序方法排序之后按序存储 跳表实现，这种数据结构绝大多数操作的时间复杂度为O(log n) immutable memtable和memtable的结构定义完全一样 写入磁盘 compaction 虽然每个memetable中所有的数据都是按序排列的，但是当多个memetable数据持久化到磁盘后，对应的不同的sstable之间是存在交集的（比如两个table中都出现了某条kv pair），在读操作时，需要对所有的sstable文件进行遍历，严重影响了读取效率。因此leveldb后台会“定期“整合这些sstable文件，该过程也称为compaction。 随着compaction的进行，sstable文件在逻辑上被分成若干层，由内存数据直接dump出来的文件称为level 0层文件，后期整合而成的文件为level i 层文件 manifest版本版本定义 一个版本中主要记录了 每一层中所有文件的元数据，元数据包括（1）文件大小（2）最大key值（3）最小key值。 一些进行compaction的统计值，来控制compaction的进行 元数据结构举例（goleveldb，类型在名后面）// tFile holds basic information about a table. type tFile struct &#123; fd storage.FileDesc seekLeft int32 size int64 imin, imax internalKey &#125; 版本结构举例type version struct &#123; s *session // session - version levels []tFiles // file meta 每层文件的元数据 // 压缩信息 // Level that should be compacted next and its compaction score. // Score &lt; 1 means compaction is not strictly needed. These fields // are initialized by computeCompaction() cLevel int // next level cScore float64 // current score cSeek unsafe.Pointer closing bool ref int released bool &#125; 创建版本当每次compaction完成（或者换一种更容易理解的说法，当每次sstable文件有新增或者减少），leveldb都会创建一个新的version manifest文件记录版本更新(versionEdit) 每次leveldb启动时，都会创建一个新的Manifest文件 下图是一个manifest文件的示意图，其中包含了3条versionEdit记录，每条记录包括（1）新增哪些sst文件（2）删除哪些sst文件（3）当前compaction的下标（4）日志文件编号（5）操作seqNumber等信息。 通过这些信息，leveldb便可以在启动时，基于一个空的version，不断apply这些记录，最终得到一个上次运行结束时的版本信息。 current记载当前的manifest文件名 *.loglog files(WAL) LOG and LOG.oldInformational messages are printed to files named LOG and LOG.old","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"}],"author":"zhiqiuyuan"},{"title":"NebulaGraph存储","slug":"NebulaGraph存储","date":"2022-09-03T02:17:55.202Z","updated":"2022-12-10T14:50:50.396Z","comments":true,"path":"2022/09/03/NebulaGraph存储/","link":"","permalink":"http://example.com/2022/09/03/NebulaGraph%E5%AD%98%E5%82%A8/","excerpt":"","text":"架构 架构总览 - Nebula Graph Database 手册 (nebula-graph.com.cn) Meta 服务是由 nebula-metad 进程提供的，负责数据管理，例如 Schema 操作、集群管理和用户权限管理等。 所有 nebula-metad 进程构成了基于 Raft 协议的集群，其中一个进程是 leader，其他进程都是 follower。leader 是由多数派选举出来，只有 leader 能够对客户端或其他组件提供服务，其他 follower 作为候补，如果 leader 出现故障，会在所有 follower 中选举出新的 leader Graph 服务负责处理计算请求，由 nebula-graphd 进程提供。 Storage 服务负责存储数据，由 nebula-storaged 进程提供。 Storage 服务 Storage 服务 - Nebula Graph Database 手册 (nebula-graph.com.cn) Nebula Graph 使用 RocksDB 作为本地存储引擎，实现了自己的 KVStore Storage 写入流程 数据存储格式KV存储 key：点和边的信息 value：点和边的属性信息，将属性信息编码后按顺序存储 为了支持在线变更 Schema，在编码属性时，会加入对应的 Schema 版本信息 点 字段 说明 Type key 类型。长度为 1 字节。 PartID 数据分片编号。长度为 3 字节。此字段主要用于 Storage 负载均衡（balance）时方便根据前缀扫描整个分片的数据。 VertexID 点 ID。当点 ID 类型为 int 时，长度为 8 字节；当点 ID 类型为 string 时，长度为创建图空间时指定的fixed_string长度。 TagID 点关联的 Tag ID。长度为 4 字节。 SerializedValue 序列化的 value，用于保存点的属性信息。 边 字段 说明 Type key 类型。长度为 1 字节。 PartID 数据分片编号。长度为 3 字节。此字段主要用于 Storage 负载均衡（balance）时方便根据前缀扫描整个分片的数据。 VertexID 点 ID。前一个VertexID在出边里表示起始点 ID，在入边里表示目的点 ID；后一个VertexID出边里表示目的点 ID，在入边里表示起始点 ID。 Edge type 边的类型。大于 0 表示出边，小于 0 表示入边。长度为 4 字节。 Rank 用来处理两点之间有多个同类型边的情况。用户可以根据自己的需求进行设置，例如存放交易时间、交易流水号等。长度为 8 字节， PlaceHolder 预留字段。长度为 1 字节。 SerializedValue 序列化的 value，用于保存边的属性信息。 获取属性 由于属性的长度是固定的，查询时可以根据偏移量快速查询。在解码之前，需要先从 Meta 服务中查询具体的 Schema 信息（并缓存） 切边逻辑上的一条边对应着硬盘上的两个键值对： 起点 SrcVertex 通过边 EdgeA 连接目的点 DstVertex，形成路径(SrcVertex)-[EdgeA]-&gt;(DstVertex)，这两个点和一条边会以 6 个键值对（2(src)+2(dst)+2(edge)）的形式保存在存储层的两个不同分片，即 Partition x 和 Partition y 中 服务架构 Store Engine 层 Storage 服务的最底层，是一个单机版本地存储引擎，提供对本地数据的get、put、scan等操作。相关接口存储在KVStore.h和KVEngine.h文件 数据分片 数据量过大，单机存不下 -&gt; 将图元素切割，并存储在不同逻辑分片（Partition）上 分片 ID 和机器地址之间的映射是随机的，不能假定任何两个分片位于同一台机器上 分片算法 静态 Hash：对点 VID 进行取模操作（得到分片ID：pId = vid % numParts + 1），同一个点的所有 Tag、出边和入边信息都会存储到同一个分片 Raft What is Raft used for？ 分布式系统中，同一份数据通常会有多个副本，这样即使少数副本发生故障，系统仍可正常运行。这就需要一定的技术手段来保证多个副本之间的一致性。通过 保证集群所有节点 log 一致性 来保证。 每个分片的所有副本共同组成一个 Raft group，其中一个副本是 leader，其他副本是 follower 缓存Nebula Graph 自行实现了 Storage 缓存管理指 内存 中缓存外存的内容","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"db","slug":"graph/db","permalink":"http://example.com/categories/graph/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"Raft","slug":"Raft","date":"2022-09-03T02:17:27.443Z","updated":"2022-12-10T14:53:12.586Z","comments":true,"path":"2022/09/03/Raft/","link":"","permalink":"http://example.com/2022/09/03/Raft/","excerpt":"","text":"https://docs.nebula-graph.com.cn/3.2.0/1.introduction/3.nebula-graph-architecture/4.storage-service/#raft https://cloud.tencent.com/developer/article/1826594 简介 分布式系统中，同一份数据通常会有多个副本，这样即使少数副本发生故障，系统仍可正常运行。这就需要一定的技术手段来保证多个副本之间的一致性。 通过 保证集群所有节点log一致性 来保证 log一致性保证了即可保证多个副本之间的数据一致性 基本原理 赢得”超过半数”副本投票的（候选）副本成为 Leader，由 Leader 代表所有副本对外提供服务；其他 Follower 作为备份。 当该 Leader 出现异常后（通信故障、运维命令等），其余 Follower 进行新一轮选举，投票出一个新的 Leader。 Leader 和 Follower 之间通过心跳的方式相互探测是否存活，并以 Raft-wal 的方式写入硬盘，超过多个心跳仍无响应的副本会被认为发生故障。并以 Raft-wal 的方式写入硬盘 啥意思？写入探测结果？ 读写流程 对于客户端的每个写入请求，Leader 会将该写入以 Raft-wal 的方式，将该条同步给其他 Follower，并只有在“超过半数”副本都成功收到 Raft-wal 后，才会返回客户端该写入成功（即日志复制：所有 log 都必须交给 leader 节点处理，并由 leader 复制给其他节点）。 对于客户端的每个读取请求，都直接访问 Leader，而 Follower 并不参与读请求服务。","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"},{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"WAL Write Ahead Log预写日志","slug":"WAL Write Ahead Log预写日志","date":"2022-09-03T01:31:41.414Z","updated":"2022-12-10T14:53:44.033Z","comments":true,"path":"2022/09/03/WAL Write Ahead Log预写日志/","link":"","permalink":"http://example.com/2022/09/03/WAL%20Write%20Ahead%20Log%E9%A2%84%E5%86%99%E6%97%A5%E5%BF%97/","excerpt":"","text":"https://www.cnblogs.com/xuwc/p/14037750.html 在使用 WAL 的系统中，**所有的修改在提交之前都要先写入 log 文件中(写入log文件是写入永久存储)**。log 文件中通常包括 redo 和 undo 信息 使用 WAL 的数据库系统不会再每新增一条 WAL 日志就将其刷入数据库文件中，一般**积累一定的量然后批量写入(checkpoint)**，通常使用「页」为单位，这是磁盘的写入单位 一方面 WAL 中记录事务的更新内容，通过 WAL 将随机的脏页写入变成顺序的日志刷盘 另一方面，WAL 通过 buffer 的方式改单条磁盘刷入为缓冲批量刷盘 再者从 WAL 数据到最终数据的同步过程中可以采用并发同步的方式 这样极大提升数据库写入性能，因此，WAL 的写入能力决定了数据库整体性能的上限，尤其是在高并发时","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"powershell美化 powershell字体 powershell颜色","slug":"powershell美化字体颜色","date":"2022-09-02T07:09:19.755Z","updated":"2022-12-10T14:53:54.945Z","comments":true,"path":"2022/09/02/powershell美化字体颜色/","link":"","permalink":"http://example.com/2022/09/02/powershell%E7%BE%8E%E5%8C%96%E5%AD%97%E4%BD%93%E9%A2%9C%E8%89%B2/","excerpt":"","text":"设置颜色 安装colortoolscoop install colortool 预览主题 列出哪些主题 colortool -s 预览主题，比如OneHalfDark.itermcolors colortool OneHalfDark.itermcolors 设置主题（将方案同时应用于当前控制台和默认控制台）colortool -b OneHalfDark.itermcolors 附：colortool 的相关命令-c --current：打印当前应用方案的颜色表 -q --quiet：使用后不要打印颜色表 -e --errors：在控制台上报告方案分析错误 -d --defaults：仅将方案应用于注册表中的默认值 -b --both：将方案同时应用于当前控制台和默认控制台。 -x --xterm：使用VT序列设置颜色。用于设置WSL中的颜色。仅适用于Windows版本&gt;=17048。 -s --schemes：显示所有可用的方案 -l --location：显示schemes目录的完整路径 -v --version：显示版本号 -o --output&lt;filename&gt;：将当前颜色表输出到文件（以.ini格式） 设置字体 下载字体（https://blog.csdn.net/Z_YMing/article/details/103082807有`yahe mona&#96;字体下载连接） 安装字体 解压缩，右键ttf文件选择安装 修改注册表 powershell右键-属性-字体","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"graph schema","slug":"graph schema","date":"2022-09-02T02:34:14.281Z","updated":"2022-12-10T14:54:56.397Z","comments":true,"path":"2022/09/02/graph schema/","link":"","permalink":"http://example.com/2022/09/02/graph%20schema/","excerpt":"","text":"https://docs.tigergraph.com/gsql-ref/current/tutorials/gsql-101/ Every graph has a schema, or a model describing the types of vertices and edges that appear in a graph.（描述图中有哪些类型的点边，每种类型有哪些属性，以及点边类型之间有哪些关系） a graph showing a group of friends and when each of them met schema： the Friendship edge answers the question, “What type of entity is connected by friendship?” graph：","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"linux启动docker服务","slug":"linux启动docker服务","date":"2022-09-01T12:49:03.848Z","updated":"2022-12-10T14:55:08.817Z","comments":true,"path":"2022/09/01/linux启动docker服务/","link":"","permalink":"http://example.com/2022/09/01/linux%E5%90%AF%E5%8A%A8docker%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"安装和启动这个写很好：Install Docker Engine on Ubuntu 在上述教程install之后docker run hello-word之前可能需要启动docker后台服务：sudo service docker starthow would you know that the service name was docker： You can see them using service --status-all docker原理To generate this message, Docker took the following steps: The Docker client contacted the Docker daemon. The Docker daemon pulled the “hello-world” image from the Docker Hub.(amd64) The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. 配置 linux-postinstall boot自启动：On Debian and Ubuntu, the Docker service is configured to start on boot by default. 配置非root docker run","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"bash获取命令退出代码","slug":"bash获取命令退出代码","date":"2022-09-01T06:39:40.106Z","updated":"2022-12-10T14:55:51.510Z","comments":true,"path":"2022/09/01/bash获取命令退出代码/","link":"","permalink":"http://example.com/2022/09/01/bash%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E9%80%80%E5%87%BA%E4%BB%A3%E7%A0%81/","excerpt":"","text":"echo $?即输出上一条执行命令的退出码另外if command; then fi也是对command的退出码进行判断，如果为0则条件成立","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash超时kill","slug":"bash超时kill","date":"2022-09-01T03:05:21.939Z","updated":"2022-12-10T14:56:46.027Z","comments":true,"path":"2022/09/01/bash超时kill/","link":"","permalink":"http://example.com/2022/09/01/bash%E8%B6%85%E6%97%B6kill/","excerpt":"","text":"timeout 3 sleep 30 当 sleep 执行 3 秒的时候就会终止 包裹程序未超时，timeout传递退出代码（--preserve-status）（亲测似乎不加此选项也会保护退出代码） timeout --preserve-status 1m ping -c 5 Nostromo.local echo $? # 如果timeout包裹的程序超时，则返回值为124，否则为未超时程序的返回代码","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash遍历数组","slug":"bash遍历数组","date":"2022-09-01T03:03:35.605Z","updated":"2022-12-10T14:56:35.727Z","comments":true,"path":"2022/09/01/bash遍历数组/","link":"","permalink":"http://example.com/2022/09/01/bash%E9%81%8D%E5%8E%86%E6%95%B0%E7%BB%84/","excerpt":"","text":"无下标控制，类似range-for array=(hello word) for element in $array do echo $element done 下标：&#96;$","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash变量计数加一","slug":"bash变量计数加一","date":"2022-09-01T03:02:15.966Z","updated":"2022-12-10T14:56:25.514Z","comments":true,"path":"2022/09/01/bash变量计数加一/","link":"","permalink":"http://example.com/2022/09/01/bash%E5%8F%98%E9%87%8F%E8%AE%A1%E6%95%B0%E5%8A%A0%E4%B8%80/","excerpt":"","text":"i=1 # in loop body i=`expr $i + 1`","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash获取命令输出内容 一维或多维","slug":"bash获取命令输出内容 一维或多维","date":"2022-09-01T02:44:00.490Z","updated":"2022-12-10T14:57:19.481Z","comments":true,"path":"2022/09/01/bash获取命令输出内容 一维或多维/","link":"","permalink":"http://example.com/2022/09/01/bash%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E8%BE%93%E5%87%BA%E5%86%85%E5%AE%B9%20%E4%B8%80%E7%BB%B4%E6%88%96%E5%A4%9A%E7%BB%B4/","excerpt":"","text":"一维 line=`cat syntest.sh | wc -l` echo $line 多维：返回数组 fnames=`ls testcase/functional | grep .sy` for fname in $&#123;fnames[@]&#125; do echo $fname done","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash条件判断命令执行返回值","slug":"bash条件判断命令执行返回值","date":"2022-09-01T02:41:36.175Z","updated":"2022-12-10T14:57:35.187Z","comments":true,"path":"2022/09/01/bash条件判断命令执行返回值/","link":"","permalink":"http://example.com/2022/09/01/bash%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E8%BF%94%E5%9B%9E%E5%80%BC/","excerpt":"","text":"if diff test.sh syntest.sh &gt; tmpout; then # diff比较如果相同则返回0，则会if条件成立走上面的分支 echo &quot;same.&quot; else echo &quot;different.&quot; fi rm -rf tmpout","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"gcc生成32位x86和arm汇编并运行","slug":"gcc生成32位x86和arm汇编并运行","date":"2022-09-01T01:36:43.763Z","updated":"2022-12-10T14:58:35.438Z","comments":true,"path":"2022/09/01/gcc生成32位x86和arm汇编并运行/","link":"","permalink":"http://example.com/2022/09/01/gcc%E7%94%9F%E6%88%9032%E4%BD%8Dx86%E5%92%8Carm%E6%B1%87%E7%BC%96%E5%B9%B6%E8%BF%90%E8%A1%8C/","excerpt":"","text":"main.c测试内容 #include &lt;stdio.h&gt; int main() &#123; printf(&quot;hello\\n&quot;); return 0; &#125; ubuntu装环境sudo apt update sudo apt install build-essential sudo apt install gcc-multilib sudo apt install -y flex sudo apt install -y bison sudo apt install -y qemu sudo apt install -y qemu-system sudo apt install -y qemu-user sudo apt-get install gcc-arm-linux-gnueabi x86 32位生成汇编x86 ATT 32位main. c -&gt; x86_32.s gcc -O0 -o x86_32.s -S -masm=att -m32 -fno-exceptions -fno-asynchronous-unwind-tables -fno-builtin -fno-pie main.c 这个需要gcc−multilib正确装好（因为需要32位的lib） 运行生成可执行文件 32位 gcc -m32 x86_32.s -o x86_32 qemu运行 qemu-i386 ./x86_32 或者./x86_32，会隐式调用qemu arm 32位生成汇编arm-linux-gnueabi-gcc -o arm.s -S -O0 main.c -fno-asynchronous-unwind-tables 运行生成可执行文件 arm-linux-gnueabi-gcc arm.s -o arm -static qemu运行 qemu-arm ./arm 或者./arm，会隐式调用qemu","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"gcc","slug":"c/gcc","permalink":"http://example.com/categories/c/gcc/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 GraphChi_Large-Scale Graph Computation on Just a PC","slug":"论文笔记 GraphChi_Large Scale Graph Computation on Just a PC","date":"2022-08-31T11:29:24.796Z","updated":"2022-12-10T14:59:01.325Z","comments":true,"path":"2022/08/31/论文笔记 GraphChi_Large Scale Graph Computation on Just a PC/","link":"","permalink":"http://example.com/2022/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20GraphChi_Large%20Scale%20Graph%20Computation%20on%20Just%20a%20PC/","excerpt":"","text":"GraphChi: Large-Scale Graph Computation on Just a PC | USENIX2012 OSDI Parallel Sliding Windows (PSW) 关键：以interval为单元的BSP(Bulk-Synchronous Parallel)；设计存储layout，使得获取一个interval中所有顶点的邻居只需要 顺序 访问全图磁盘存储 一次 回忆阅读推荐：3.6 Analysis of the I&#x2F;O Costs PSW processing a interval1. load subgraph For each interval, we associate a shard, which stores all the edges that have destination in the interval. Edges are stored in the order of their source（看下图的shard1中的src列，顶点是in order的） Intervals are chosen to balance the number of edges in each shard 且interval的划分就是对顶点1-&gt;|V|这个长区间进行划分（从而在前面的interval中的顶点id小于后面的interval中的顶点id） requires only P sequential disk reads to process each interval 【问题】可是就按照邻接表（出邻居）随机存储所有顶点的邻居的话，想要获取一个顶点集合的所有出边和入边，对于磁盘的访问也是可以只要P sequential disk reads的呀？【解答】是的，但是邻接表是对于每个顶点获取一次邻居都需要P sequential disk reads，而这个方法是对于一个interval中所有顶点获取邻居只需要P sequential disk reads 2. Parallel Updates executes the user-defined update-function for each vertex( in this interval) in parallel vertices that have edges with both end-points in the same interval are flagged as critical, and are updated in sequential order 3. write back把subgraph中有更新的edge value写回，文章中没有提出新的idea，只是分析了一下写回对于磁盘的访问 例子 remark graph traversals or vertex queries are not efficient in the model, because loading the neighborhood of a single vertex requires scanning a complete memory-shard.","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"wsl WSL 拒绝访问 Access is denied","slug":"wsl WSL 拒绝访问 Access is denied","date":"2022-08-21T15:27:28.822Z","updated":"2022-12-10T14:59:11.699Z","comments":true,"path":"2022/08/21/wsl WSL 拒绝访问 Access is denied/","link":"","permalink":"http://example.com/2022/08/21/wsl%20WSL%20%E6%8B%92%E7%BB%9D%E8%AE%BF%E9%97%AE%20Access%20is%20denied/","excerpt":"","text":"计算机重新启动后，Windows 10 上新安装的 Ubuntu 子系统向我展示了Access is denied.Press any key to continue… 解决有关解决方案，请参阅 github 问题答案。https://github.com/microsoft/WSL/issues/4920#issuecomment-658808564 当 WSL 自动关闭并且您需要使用管理员权限重新启动它时，就会发生这种情况。以管理员身份打开 Powershell&#x2F;CMD 并运行wsl. WSL 将启动，您可以关闭窗口。现在可以正常使用 WSL。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"lsof 查看资源被进程占用情况","slug":"lsof 查看资源被进程占用情况","date":"2022-08-16T02:27:01.989Z","updated":"2022-12-10T15:01:03.177Z","comments":true,"path":"2022/08/16/lsof 查看资源被进程占用情况/","link":"","permalink":"http://example.com/2022/08/16/lsof%20%E6%9F%A5%E7%9C%8B%E8%B5%84%E6%BA%90%E8%A2%AB%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/","excerpt":"","text":"打开文件的进程定位到打开的进程 lsof &lt;file&gt; $ lsof /opt/mysql/data/5690/mysql-error.log COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME mysqld 12858 actiontech-universe 1w REG 253,1 6345 20083533 /opt/mysql/data/5690/mysql-error.log mysqld 12858 actiontech-universe 2w REG 253,1 6345 20083533 /opt/mysql/data/5690/mysql-error.log 端口占用lsof 查看端口占用语法格式： lsof -i lsof -i:端口号 查看服务器 8000 端口的占用情况： $ lsof -i:8000 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nodejs 26993 root 10u IPv4 37999514 0t0 TCP *:8000 (LISTEN) 可以看到 8000 端口已经被轻 nodejs 服务占用。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"cmake","slug":"cmake","date":"2022-08-16T02:23:54.603Z","updated":"2022-12-10T15:01:14.482Z","comments":true,"path":"2022/08/16/cmake/","link":"","permalink":"http://example.com/2022/08/16/cmake/","excerpt":"","text":"cmake https://www.jianshu.com/p/cdd6e56c2422 指定编译标准CXX标准set(CMAKE_CXX_STANDARD 14) # c++14 PROJECT基本用法：指定工程名称（完成路径赋值） # 顶层CMakeLists.txt cmake_minimum_required (VERSION 3.10.2) project (mytest) 指定当前的工程名称为mytest。实际上在调用project命令指定当前工程名字的同时，cmake内部会为如下变量赋值： PROJECT_NAME：将当前工程的名称赋值给PROJECT_NAME，对于本例子，就是$&#123;PROJECT_NAME&#125;=mytest。 PROJECT_SOURCE_DIR：当前工程的源码路径。 &lt;PROJECT-NAME&gt;_SOURCE_DIR：指定工程的源码路径，这个变量和PROJECT_SOURCE_DIR的区别就是，&lt;PROJECT-NAME&gt;_SOURCE_DIR跟具体的工程名字关联起来，若&lt;PROJECT-NAME&gt;就是当前工程，则该变量和PROJECT_SOURCE_DIR相等。 PROJECT_BINARY_DIR：当前工程的二进制路径。 &lt;PROJECT-NAME&gt;_BINARY_DIR：指定工程的二进制路径，这个变量和PROJECT_BINARY_DIR的区别就是，&lt;PROJECT-NAME&gt;_BINARY_DIR跟具体的工程名字关联起来，若&lt;PROJECT-NAME&gt;就是当前工程，则该变量和PROJECT_BINARY_DIR相等。 CMAKE_PROJECT_NAME：顶层工程的名称。例如当前调用的CMakeLists.txt位于顶层目录（可以理解为使用cmake命令首次调用的那个CMakeLists.txt），那么工程名还会赋值给CMAKE_PROJECT_NAME。 变量cmake变量定义的方式有两种：隐式定义和显式定义。 隐式定义前面举了一个隐式定义的例子，就是PROJECT指令，他会隐式的定义_BINARY_DIR和_SOURCE_DIR两个变量。 显示定义显式定义的例子我们前面也提到了,使用 SET 指令,就可以构建一个自定义变量了。比如: s(HELLO_SRC main.c) 就可以通过${HELLO_SRC}来引用这个自定义变量(main.c)了. 举例 设置编译参数，指定拿哪些文件build： cmake_minimum_required( VERSION 2.8 ) project(disjoint_path) set(CMAKE_CXX_STANDARD 11) # 设置编译参数 set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11 -g -Wall -rdynamic -pthread&quot;) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) include_directories($&#123;PROJECT_SOURCE_DIR&#125;) include_directories($&#123;PROJECT_BINARY_DIR&#125;) # set self-define var set(MAIN_FILE_LIST # 目录结构：这些文件都和CMakeLists.txt在项目顶层目录下，同级 main.cpp TwoConnected.cpp TwoConnected.h Graph.cpp Graph.h config.h ) # add_executable add_executable(main $&#123;MAIN_FILE_LIST&#125;) 如何编译： # 项目顶层目录下 mkdir build &amp; cd build cmake .. make main 链接库和链接参数： cmake_minimum_required(VERSION 3.15) project(rdb_example) set(CMAKE_CXX_STANDARD 14) set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11 -g -Wall -rdynamic -pthread&quot;) add_executable(simple_rdb_eg simple_adjlist.cpp) # 目录结构：simple_adjlist.cpp和CMakeLists.txt在项目顶层目录下，同级 target_link_libraries(simple_rdb_eg librocksdb.a -lpthread -llz4 -lsnappy -lbz2 -lzstd -ldl libz.so) #librocksdb.a已经设置$PATH可以通过环境变量$PATH找到 make simple_rdb_eg编译","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"make","slug":"make","date":"2022-08-16T02:22:53.426Z","updated":"2022-12-10T15:01:23.055Z","comments":true,"path":"2022/08/16/make/","link":"","permalink":"http://example.com/2022/08/16/make/","excerpt":"","text":"make http://www.ruanyifeng.com/blog/2015/02/make.html 代码变成可执行文件，叫做编译（compile）；先编译这个，还是先编译那个（即编译的安排），叫做构建（build）。Make是最常用的构建工具，主要用于C语言的项目。但是实际上 ，任何只要某个文件有变化，就要重新构建的项目，都可以用Make构建。 重构的标准”目标”是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新（前置文件的last-modification时间戳比目标的时间戳新），”目标”就需要重新构建。 Makefile指明的命令是如何在shell中执行的每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。 var-lost: export foo=bar echo &quot;foo=[$$foo]&quot; 上面代码执行后（make var-lost），取不到foo的值。因为两行命令在两个不同的进程执行。 一个解决办法是将两行命令写在一行，中间用分号分隔。 var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; 另一个解决办法是在换行符前加反斜杠转义。 var-kept: export foo=bar; \\ echo &quot;foo=[$$foo]&quot; 最后一个方法是加上.ONESHELL:命令。 .ONESHELL: var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; Makefile语法规则：t: p1 p2 “p1 p2”称为前置条件 伪目标除了文件名，目标还可以是某个操作的名字，这称为”伪目标”（phony target） 可以明确声明clean是”伪目标”，申明以后，When it is time to consider such a target, make will run its recipe unconditionally, regardless of whether a file with that name exists or what its last-modification time is 写法如下： .PHONY clean clean: rm *.o 默认目标make的默认目标是第一个目标 设置默认目标： .DEFAULT_GOAL := main #设置main为默认目标 main: #不过话说默认目标习惯上最好命名为default啦 @ echo default target 一般规则make会首先寻找普通的生成规则，如果没找到，就尝试用一般规则 %.gas : %.c Makefile $(CC1) -o $*.gas $*.c %.nas : %.gas Makefile $(GAS2NASK) $*.gas $*.nas 比如makefile中没有main.gas的“菜单”，会尝试用下面这样来生成main.gas： main.gas : main.c Makefile $(CC1) -o main.gas main.c 回声正常情况下，make会打印每条命令（，然后再执行），这就叫做回声（echoing） 在命令的前面加上@，就可以关闭该行的回声（即执行该行之前不打印该行）。 变量Makefile 允许使用等号自定义变量。 txt = Hello World test: @echo $(txt) 上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中。 调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。 test: @echo $$HOME 有时，变量的值可能指向另一个变量。 v1 = $(v2) 上面代码中，变量 v1 的值是另一个变量 v2。这时会产生一个问题，v1 的值到底在定义时扩展（静态扩展），还是在运行时扩展（动态扩展）？如果 v2 的值是动态的，这两种扩展方式的结果可能会差异很大。 为了解决类似问题，Makefile一共提供了四个赋值运算符 （&#x3D;、:&#x3D;、？&#x3D;、+&#x3D;），它们的区别请看StackOverflow。 VARIABLE = value ### 在执行时扩展，允许递归扩展。 VARIABLE := value ### 在定义时扩展。 VARIABLE ?= value ### 只有在该变量为空时才设置值。 VARIABLE += value ### 将值追加到变量的尾端。 内置变量（Implicit Variables）Make命令提供一系列内置变量，比如，**$(CC) 指向当前使用的编译器，$(MAKE) 指向当前使用的Make工具**。这主要是为了跨平台的兼容性，详细的内置变量清单见手册。 output: $(CC) -o output input.c 自动变量（Automatic Variables）Make命令还提供一些自动变量，它们的值与当前规则有关。主要有以下几个。 （1）$@ $@指代当前目标，就是Make命令当前构建的那个目标。比如，make foo的 $@ 就指代foo。 a.txt b.txt: touch $@ 等同于下面的写法。 a.txt: touch a.txt b.txt: touch b.txt （2）$&lt; $&lt; 指代第一个前置条件。比如，规则为 t: p1 p2，那么$&lt; 就指代p1。 a.txt: b.txt c.txt cp $&lt; $@ 等同于下面的写法。 a.txt: b.txt c.txt cp b.txt a.txt （3）$? $? 指代比目标更新的所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，其中 p2 的时间戳比 t 新，$?就指代p2。 （4）$^ $^ 指代所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，那么 $^ 就指代 p1 p2 。 （5）$* $ 指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，$ 就表示 f1。 （6）$(@D) 和 $(@F) $(@D) 和 $(@F) 分别指向 $@ 的目录名和文件名。比如，$@是 src&#x2F;input.c，那么$(@D) 的值为 src ，$(@F) 的值为 input.c。 （7）$(&lt;D) 和 $(&lt;F) $(&lt;D) 和 $(&lt;F) 分别指向 $&lt; 的目录名和文件名。 所有的自动变量清单，请看手册。下面是自动变量的一个例子。 dest/%.txt: src/%.txt @[ -d dest ] || mkdir dest cp $&lt; $@ 上面代码将 src 目录下的 txt 文件，拷贝到 dest 目录下。首先判断 dest 目录是否存在，如果不存在就新建，然后，$&lt; 指代前置文件（src&#x2F;%.txt）， $@ 指代目标文件（dest&#x2F;%.txt）。 判断和循环Makefile使用 Bash 语法，完成判断和循环。 ifeq ($(CC),gcc) libs=$(libs_for_gcc) else libs=$(normal_libs) endif 上面代码判断当前编译器是否 gcc ，然后指定不同的库文件。 LIST = one two three all: for i in $(LIST); do \\ echo $$i; \\ done ## 等同于 all: for i in one two three; do \\ echo $i; \\ done 上面代码的运行结果。 one two three 函数Makefile 还可以使用函数，格式如下。 $(function arguments) ## 或者 $&#123;function arguments&#125; Makefile提供了许多内置函数，可供调用。下面是几个常用的内置函数。 （1）shell 函数 shell 函数用来执行 shell 命令 srcfiles := $(shell echo src/&#123;00..99&#125;.txt) （2）wildcard 函数 wildcard 函数用来在 Makefile 中，替换 Bash 的通配符。 srcfiles := $(wildcard src/*.txt) （3）替换函数 替换函数的写法是：变量名 + 冒号 + 替换规则。 min: $(OUTPUT:.js=.min.js) 上面代码的意思是，将变量OUTPUT中的 .js 全部替换成 .min.js 。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2014VLDB The More the Merrier Efficient Multi-Source Graph Traversal","slug":"论文笔记 2014VLDB The More the Merrier Efficient Multi Source Graph Traversal","date":"2022-08-13T08:36:44.519Z","updated":"2022-12-10T15:02:10.116Z","comments":true,"path":"2022/08/13/论文笔记 2014VLDB The More the Merrier Efficient Multi Source Graph Traversal/","link":"","permalink":"http://example.com/2022/08/13/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202014VLDB%20The%20More%20the%20Merrier%20Efficient%20Multi%20Source%20Graph%20Traversal/","excerpt":"","text":"MSBFSThe More the Merrier: Efficient Multi-Source Graph TraversalVLDB 2014 基准 bit op ANP（这个） tuningcache line heuristic maximum sharing way of grouping BFSs reason:","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"有sudo的ubuntu安装指定版本gcc","slug":"有sudo的ubuntu安装指定版本gcc","date":"2022-08-11T09:20:17.946Z","updated":"2022-12-10T15:02:42.614Z","comments":true,"path":"2022/08/11/有sudo的ubuntu安装指定版本gcc/","link":"","permalink":"http://example.com/2022/08/11/%E6%9C%89sudo%E7%9A%84ubuntu%E5%AE%89%E8%A3%85%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%ACgcc/","excerpt":"","text":"https://blog.csdn.net/qq_29007291/article/details/84953671","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"win10开机自动执行命令 后台运行","slug":"win10开机自动执行命令 后台运行","date":"2022-08-11T04:57:04.841Z","updated":"2022-12-10T15:02:53.840Z","comments":true,"path":"2022/08/11/win10开机自动执行命令 后台运行/","link":"","permalink":"http://example.com/2022/08/11/win10%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%20%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/","excerpt":"","text":"打开startup文件夹：win+R键入shell:startup回车，打开的文件夹即是 在这个文件夹中放xx.bat脚本或者应用xx.exe（或它们的快捷方式），即会开机执行它们 这样执行.bat文件是在前台执行，且会有一个黑框，消除黑框的方法： https://codeantenna.com/a/3gznir1890 在startup文件夹中放xx.vbs文件来代替原先的bat文件（或它们的快捷方式），文件内容为 Set ws = CreateObject(&quot;Wscript.Shell&quot;) ws.run &quot;cmd /c H:\\myBlog\\start_personal_blog.bat&quot;,vbhide 其中H:\\myBlog\\start_personal_blog.bat为希望后台运行隐藏黑框的命令","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"vscode配置c++项目 include路径等","slug":"vscode配置c++项目 include路径等","date":"2022-08-11T03:58:44.361Z","updated":"2022-12-10T15:03:16.612Z","comments":true,"path":"2022/08/11/vscode配置c++项目 include路径等/","link":"","permalink":"http://example.com/2022/08/11/vscode%E9%85%8D%E7%BD%AEc++%E9%A1%B9%E7%9B%AE%20include%E8%B7%AF%E5%BE%84%E7%AD%89/","excerpt":"","text":"装c++环境gcc和g++都要以ubuntu为例 sudo apt-get instal gcc sudo apt-get instal g++ #没装会报错找不到比如iostream头文件 配置vscode https://blog.csdn.net/jinking01/article/details/106186575 装c/c++、c++ IntelliSense插件version1.70开始c++ IntelliSense没了，合并到c/c++了 include path关键是 配置c++ IntelliSense插件：这个插件会帮你解决所有include path的问题ctrl+shift+P打开Command Palette,运行C/C++: Edit configurations... 生成c_cpp_properties.json debug配置F5会生成launch.json，然后配置这个文件有些时候不会，则在项目顶层目录的.vscode目录下新建launch.json，打开此文件在编辑界面右下角会出现add configuration...按钮，点击然后选择c/c++(gdb): Launch，然后填写launch.json内容即可program指明调试的可执行文件路径，args指定传递给可执行文件program的参数，比如： &#123; // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;/home/yuanzhiqiu/external_multi_bfs/vertex_disjoint_path/build/main&quot;, &quot;args&quot;: [ &quot;-n&quot;, &quot;2&quot;, &quot;-b&quot;, &quot;128&quot;, &quot;-m&quot;, &quot;msbfs&quot;, &quot;-g&quot;, &quot;/home/yuanzhiqiu/test_dataset/disjoint_test.txt&quot;, //disjoint_test split_vertex_test &quot;-p&quot;, &quot;/home/yuanzhiqiu/vertex_pairs/disjoint_test.txt&quot;, &quot;-o&quot;, &quot;.&quot;, ], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125;, &#123; &quot;description&quot;: &quot;Set Disassembly Flavor to Intel&quot;, &quot;text&quot;: &quot;-gdb-set disassembly-flavor intel&quot;, &quot;ignoreFailures&quot;: true &#125; ] &#125; ] &#125; 启动调试如何调试：自己编译，然后F5唤起调试","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"linux服务器间文件传送 .tar.gz文件压缩和解压","slug":"linux服务器间文件传送 targz文件压缩和解压","date":"2022-08-11T01:46:09.175Z","updated":"2022-12-10T15:04:36.515Z","comments":true,"path":"2022/08/11/linux服务器间文件传送 targz文件压缩和解压/","link":"","permalink":"http://example.com/2022/08/11/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%97%B4%E6%96%87%E4%BB%B6%E4%BC%A0%E9%80%81%20targz%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9%E5%92%8C%E8%A7%A3%E5%8E%8B/","excerpt":"","text":"旧服务器备份：把~&#x2F;.halo压缩 tar -zvcf ~/.halo.tar.gz ~/.halo # 得到~/.halo.tar.gz 移到新服务器中在旧服务器上运行 scp ~/.halo.tar.gz &lt;新服务器用户名&gt;@&lt;新服务器ip地址&gt;:~/.halo.tar.gz #scp即secure copy，是用来进行远程文件拷贝的。数据传输使用 ssh，并且和ssh 使用相同的认证方式，提供相同的安全保证 scp在服务器之间文件传送 https://www.xiebruce.top/578.html scp也可以直接目录拷贝，scp -r递归拷贝，但是亲测感觉压缩之后传输快一点 新服务器中解压在~&#x2F;目录下 tar -zvxf .halo.tar.gz","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"解决应用商店Microsoft store打不开 代码0x80131500","slug":"解决应用商店Microsoft store打不开 代码0x80131500","date":"2022-08-11T01:10:13.261Z","updated":"2022-12-10T15:04:56.258Z","comments":true,"path":"2022/08/11/解决应用商店Microsoft store打不开 代码0x80131500/","link":"","permalink":"http://example.com/2022/08/11/%E8%A7%A3%E5%86%B3%E5%BA%94%E7%94%A8%E5%95%86%E5%BA%97Microsoft%20store%E6%89%93%E4%B8%8D%E5%BC%80%20%E4%BB%A3%E7%A0%810x80131500/","excerpt":"","text":"解决方法：https://zhuanlan.zhihu.com/p/116654088事后还原：勾选 TLS 1.0，取消勾选TLS 1.2","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"linux文件打开系统调用 追加写覆盖写","slug":"linux文件打开系统调用 追加写覆盖写","date":"2022-08-10T07:48:23.457Z","updated":"2022-12-10T15:05:10.118Z","comments":true,"path":"2022/08/10/linux文件打开系统调用 追加写覆盖写/","link":"","permalink":"http://example.com/2022/08/10/linux%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%20%E8%BF%BD%E5%8A%A0%E5%86%99%E8%A6%86%E7%9B%96%E5%86%99/","excerpt":"","text":"man page: https://man7.org/linux/man-pages/man2/open.2.html const char* file = &quot;test_file.txt&quot;; int pfd = open(file, O_WRONLY | O_CREAT | O_APPEND, 0777); O_WRONLY：只写O_CREAT：如果不存在则创建O_APPEND：追加写0777：所有组给全部权限 int pfd = open(file, O_WRONLY | O_CREAT | O_TRUNC, 0777); O_TRUNC：覆盖写","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"RDF三元组数据转schema图","slug":"RDF三元组数据转schema图","date":"2022-08-06T06:48:24.168Z","updated":"2022-12-10T15:05:41.429Z","comments":true,"path":"2022/08/06/RDF三元组数据转schema图/","link":"","permalink":"http://example.com/2022/08/06/RDF%E4%B8%89%E5%85%83%E7%BB%84%E6%95%B0%E6%8D%AE%E8%BD%ACschema%E5%9B%BE/","excerpt":"","text":"schema：反映顶点label之间的关系，以及Label会有哪些常量类型用G6 &lt;id&gt; &lt;label&gt; &lt;vertex label&gt;. &lt;id&gt; &lt;edge label&gt; &lt;id&gt;. &lt;id&gt; &lt;vertex property&gt; literal. 不可以拖拽http://graphviz.herokuapp.com/?token=eeb362635d6b026b24d7b012b3ba6ee7想尝试https://github.com/magjac/graphviz-visual-editor 加箭头https://g6.antv.vision/zh/docs/manual/middle/elements/edges/arrow可以拖拽https://g6.antv.vision/zh/examples/net/forceDirected#basicForceDirected graphvizdigraph ClassDiagram &#123; #//////////////////////////////// Introduction \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ /* This graph is meant as a starting point to help you create UML Class Diagrams by providing a preset for edges and nodes. To use it, you need to take the folowing steps: - Copy and paste (or &quot;save as&quot;) this graph into a new file - Rename the relevant labels (anything with the word &quot;Example&quot; in it). - Add nodes (inside subgraphs when needed) - Add connections for the nodes Make sure you place your connections under the right headers, otherwise the decoration won&#39;t match the UML specifications. For each module you should use a separate subgraph. Make sure the name of your subgraph starts with `cluster_` If you don&#39;t like the colors, the easiest way to ammend this is by changing the defined colorscheme (currently &quot;pastel13&quot;) in the &quot;General Styles&quot; section to any other 3-scheme. All available colorschemes can be found at http://www.graphviz.org/doc/info/colors.html#brewer */ #/////////////////////////////// General Styles \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ graph [ label = &quot;Example \\n Class Diagram&quot; labelloc = t //dpi = 200 ranksep=0.65 nodesep=0.40 rankdir=BT bgcolor=&quot;#FFFFDD&quot; style=&quot;dotted, filled&quot; fillcolor=&quot;#FFFFFF&quot; ] edge [arrowhead=empty] //空心箭头 =none则无箭头 node [ labeljust=&quot;l&quot; colorscheme=&quot;pastel13&quot; style=filled fillcolor=3 shape=record ] #/////////////////////////////////// subgraph \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ //可以添加很多子图 subgraph schema &#123; //label = &quot;Example \\n subgraph Diagram&quot; //子图标题 //nodes alarm [label=&quot;&#123;alarm|arriveTime&#125;&quot;] lip [label=&quot;&#123;lip|slotnum&#125;&quot;] &#125; &#123; //edges lip -&gt; alarm [label=&quot;like&quot;] lip -&gt; alarm [label=&quot;happen&quot;] &#125; &#125;//ClassDiagram","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}]},{"title":"生成树","slug":"生成树","date":"2022-08-06T03:38:52.959Z","updated":"2022-12-10T15:06:25.394Z","comments":true,"path":"2022/08/06/生成树/","link":"","permalink":"http://example.com/2022/08/06/%E7%94%9F%E6%88%90%E6%A0%91/","excerpt":"","text":"生成树最大生成树的性质","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[]},{"title":"MIT 6.S081 Operating System Engineering 资源汇总","slug":"MIT 6S081 Operating System Engineering 资源汇总","date":"2022-08-06T01:19:50.111Z","updated":"2022-12-10T15:07:09.849Z","comments":true,"path":"2022/08/06/MIT 6S081 Operating System Engineering 资源汇总/","link":"","permalink":"http://example.com/2022/08/06/MIT%206S081%20Operating%20System%20Engineering%20%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/","excerpt":"","text":"https://csdiy.wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/MIT6.S081/ 课程资源课程网站：https://pdos.csail.mit.edu/6.828/2021/schedule.html课程视频：https://www.youtube.com/watch?v=L6YqHxYHa7A，每节课的链接详见课程网站 B站 https://www.bilibili.com/video/BV19k4y1C7kA/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=b980455be8f7254fee312ed56a30137b课程视频翻译文档：https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/课程教材：https://pdos.csail.mit.edu/6.828/2021/xv6/book-riscv-rev2.pdf课程作业：https://pdos.csail.mit.edu/6.828/2021/schedule.html，11个lab，具体要求详见课程网站 xv6 补充资源见https://csdiy.wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/MIT6.S081/ 一些可以参考的博客见https://csdiy.wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/MIT6.S081/","categories":[{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"},{"name":"os","slug":"course/os","permalink":"http://example.com/categories/course/os/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 multi-terminal network flows","slug":"论文笔记 multiterminal network flows","date":"2022-08-05T08:26:54.181Z","updated":"2022-12-10T15:07:39.429Z","comments":true,"path":"2022/08/05/论文笔记 multiterminal network flows/","link":"","permalink":"http://example.com/2022/08/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20multiterminal%20network%20flows/","excerpt":"","text":"定义bij：顶点Ni到顶点Nj间边Bij的容量fij：顶点Ni到顶点Nj的最大流流量F是fij构成的方阵 贡献判定一个F是否能在某些网络拓扑中达到 判定算法：求fij；然后在构造最大生成树时检查是否违反这个 (1)可以自然推出：&gt;&#x3D;i-p任意“路径”（注意路径上“相邻”两点不需要有边相连）的minflow 证明过程中提出：以fij作为边Bij的权重构造一棵最大生成树，对于任意一条不在该树上的边ip，i到p的最大流 等于 该树上i到p（唯一）的路径的minflow condense graph构造（注意(A,A’)是最小割） 性质（ordinary nodes是指在A中（A中是因为A‘中的顶点在condense graph中已经被收缩成一个点了）、非Ni的顶点） n-1次最大流求解就求出全图所有点对之间的最大流不断做划分顶点的事，然后 证明中提出的一个性质： 这个性质应用到最终划分所得树上，以及根据划分过程，得到最终树的性质：关键是这个性质使得可以n-1代替n(n-1)&#x2F;2、进行合并：最终树的边既是cut又是maxflow，cut则两点间maxflow&lt;&#x3D;min(树上路径)，maxflow则两点间maxflow&gt;&#x3D;min(树上路径)，因此两点间maxflow&#x3D;&#x3D;min(树上路径) 划分过程原文描述完思路之后还有一个详细例子 证明阅读lemma1证明","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"disjoint-path-max-flow problem","slug":"disjoint path max flow problem","date":"2022-08-04T09:29:36.158Z","updated":"2022-12-10T15:10:20.912Z","comments":true,"path":"2022/08/04/disjoint path max flow problem/","link":"","permalink":"http://example.com/2022/08/04/disjoint%20path%20max%20flow%20problem/","excerpt":"","text":"defintions unit network单位网络：每个顶点要么只有一条出边且容量为1，要么只有一条入边且容量为1 unit capacity network单位容量网络：所有边容量&#x3D;1 reductions of problem versionundirected-&gt;directed https://stackoverflow.com/questions/29741691/maximum-flow-in-the-undirected-graph 正确性： - for max-flow：It can be easily proven that in such conversion, flow only propagates through one of the two edges and always one of them is not used max flow: directed-&gt;undirected Faster Energy Maximization for Faster Maximum Flow方法： 证明： directed vertex disjoint -&gt; directed edge disjoint general relationship between max-flow and disjointedge-disjoint -&gt; max-flow对于单位容量、整数流的网络，augment paths after adjustment are edge-disjoint：edge-disjoint来自于 边容量都是1，流是{0,1}流 最大流最小割定理 这个定理可以看出，最大流的大小取决于网络拓扑（因为等于最小s-t割的容量） 定义 augment path for f in G：s-t path in Gf Gf：残余网络，G上流上f得到的：对于流f流过的边(u,v)，正向边(u,v)的容量为c(u,v)-f(u,v)，反向边(v,u)的容量为f(u,v) s-t cut：顶点集的划分 proof 因此证明只需要 在对f没有augment path时，找到一个s-t cut满足这个iff后面的特征即可，下面找这个s-t cut if then是因为 没有augment path for f，则没有s-t path in Gf，所以Ef中一些边不存在 2 disjoint path第一条augment path的选择， 正确性定理的(2)-&gt;(1)：对于f没有augment path -&gt; f是G中最大流因此 对于最大流&gt;&#x3D;2的单位容量、整数流网络，随意选择第一条augment path，都一定可以找到第二条augment path 因为 如果选择某条augment path作为第一条之后找不到其他augment path了，则根据“对于f没有augment path -&gt; f是G中最大流”有此时的flow就是最大流，但此时的流量只有1，这与流最大&gt;&#x3D;2矛盾，所以一定可以找到第二条augment path (2)-&gt;(1) proof框架（详细见下方proof）：如果对f不存在augment path，则存在s-t cut满足c(S,T)&#x3D;|f|（注意这个是全局的而不是局部的！），则f是最大流 效率（时间复杂度） 随意选择第一条augment path都一定可以找到第二条augment path的话，则考虑怎样选取进行求解的速度最快 如何选取第一条和第二条augment path，使得效率最高？","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 Faster Energy Maximization for Faster Maximum Flow","slug":"论文笔记 Faster Energy Maximization for Faster Maximum Flow","date":"2022-08-04T07:57:51.764Z","updated":"2022-12-10T15:10:41.949Z","comments":true,"path":"2022/08/04/论文笔记 Faster Energy Maximization for Faster Maximum Flow/","link":"","permalink":"http://example.com/2022/08/04/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20Faster%20Energy%20Maximization%20for%20Faster%20Maximum%20Flow/","excerpt":"","text":"思考目前没有看完，刚看完central path的定义，在看norm的定义，浏览了下算法overall，似乎文章主要目标在max-flow的max，augment path的步骤文章中是直接说执行这个步骤，即这个步骤和往昔的max-flow算法是一样的，而++max-flow的disjoint是cancel flow提供的++，通过augment path步骤构造路径，而我们只需要两条augment path即可，这样似乎没有必要阅读全文：是否值得继续阅读取决于一个问题：即第一条augment path的选择是否会影响能否找到两条以及找到两条的效率： 如果存在两条edge-disjoint，则若利用cancel flow，是否对于任意的第一条augment path，都可以找到第二条augment path（从而修正一下得到两条edge-disjoint）？ 如果是的话，是否 对于第一条aygment path的选择，其可以对于整体找两条augment path有效率提升？ 解决的问题最大流：其中BT*f&#x3D;tX即（BT*f即得到一个n维向量，表示每个顶点的净流量（出-入））满足flow conservation，所有顶点除了st都入流&#x3D;出流，即净流&#x3D;0，s是出，t是入，且s出量&#x3D;t入量 V是标量，V的梯度（下三角）是m维向量（V对于每条边求偏导） 无向图 Preliminaries定义d-flow即满足顶点净流量&#x3D;&#x3D;dv ab-flow即满足flow conservation energy和electrical d-flow 能量回忆物理：电功率i^2*relectrical d-flow即满足顶点净流量&#x3D;&#x3D;dv、minimize能量的 maximum flow problem Laplacian of the graph G with resistances r n*n矩阵，Lij&#x3D;0，如果顶点ij之间没有边相连；&#x3D;负的 ij间边电阻的倒数之和，如果顶点ij之间有边相连 B矩阵：对于每条边（即B的每行）只有两个端点（即B的每行只有两列非零，1和-1）；B矩阵的每一列（即每个顶点的），表示对应顶点的出边入边情况 推导思考：B转置*R-1得到的是：n*m矩阵，是B转置每一列都分别乘 该列对应的边的电阻的倒数再乘以B，对于目标矩阵n*n的每个格子ij，思考：顶点i和j 的入边出边记录 对位相乘再相加 -&gt; 对于每条边，这条边要么在顶点ij之间，要么不在，在的话对位相乘结果是”-1”(-1*1&#x2F;r)，不在的话则至少有一边是0，则对位相乘结果是0 R-1*B，得到：m*n矩阵，是B矩阵每一行（每条边）都乘以对应边的电阻的倒数可以看出求出φ就可以求出f帽 提出的定义central path为了转换优化问题，观察到在最优时： 因此定义central path（满足V(f)最小时点(f,t,y)在central path上）： 以及定义描述离central path距离的measurement： 先定义电阻 再定义measurement： 也定义描述最大流距离“流最大”的measurement： 算法overall","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[]},{"title":"图拉普拉斯","slug":"图拉普拉斯","date":"2022-08-04T06:41:06.661Z","updated":"2022-12-10T15:11:15.993Z","comments":true,"path":"2022/08/04/图拉普拉斯/","link":"","permalink":"http://example.com/2022/08/04/%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF/","excerpt":"","text":"学习自 https://zhuanlan.zhihu.com/p/484348911 定义梯度 拉普拉斯算子 图拉普拉斯公式给定一个有n个顶点的图G&#x3D;(V,E)，其拉普拉斯矩阵被定义为L&#x3D;D-A，D其中为图的度矩阵，A为图的邻接矩阵。 推导 (4) 拉普拉斯矩阵中的第i行反应了第i个节点在对其他所有节点产生扰动时所产生的增益累积。图拉普拉斯反映了当我们在节点i上施加一个势，这个势以哪个方向能够多顺畅的流向其他节点。","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"多对数函数polylogarithmic","slug":"多对数函数polylogarithmic","date":"2022-08-04T03:03:20.000Z","updated":"2022-12-10T15:11:31.346Z","comments":true,"path":"2022/08/04/多对数函数polylogarithmic/","link":"","permalink":"http://example.com/2022/08/04/%E5%A4%9A%E5%AF%B9%E6%95%B0%E5%87%BD%E6%95%B0polylogarithmic/","excerpt":"","text":"https://zh.wikipedia.org/zh-cn/%E5%A4%9A%E5%B0%8D%E6%95%B8%E5%87%BD%E6%95%B8","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"},{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"c重定向stdout然后恢复stdout 文件权限编码 chmod","slug":"c重定向stdout然后恢复stdout 文件权限编码 chmod","date":"2022-07-29T02:25:17.309Z","updated":"2022-12-10T15:12:07.055Z","comments":true,"path":"2022/07/29/c重定向stdout然后恢复stdout 文件权限编码 chmod/","link":"","permalink":"http://example.com/2022/07/29/c%E9%87%8D%E5%AE%9A%E5%90%91stdout%E7%84%B6%E5%90%8E%E6%81%A2%E5%A4%8Dstdout%20%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%BC%96%E7%A0%81%20chmod/","excerpt":"","text":"重定向https://stackoverflow.com/questions/47719965/how-to-redirect-stdout-to-a-file-and-then-restore-stdout-back 举例#include &lt;iostream&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; using namespace std; int main() &#123; /*redirect stdout to file*/ int pfd = open(&quot;file&quot;, O_WRONLY | O_CREAT, 0777); // now pfd is descriptor to &quot;file&quot; int saved = dup(1); // now 1 and saved both are descriptor to STDOUT // int dup2(int oldfd, int newfd); dup2(pfd, 1); // would close descriptor 1 first, then now 1 and pfd both are descriptor to &quot;file&quot;(pfd previously pointed to) close(pfd); // close descriptor pfd cout &lt;&lt; &quot;This goes into file&quot; &lt;&lt; endl; // fflush(stdout); // NOTE that endl or fflush(stdout) after printf is necessary to flush content in buffer into file /*restore stdout*/ dup2(saved, 1); // would close descriptor 1 first, then now 1 and saved both are descriptor to STDOUT(saved previously pointed to) close(saved); // close descriptor saved cout &lt;&lt; &quot;This goes into console&quot; &lt;&lt; endl; return 0; &#125; RAII异常处理时c++编译器保证会（按顺序）调用所有对象的析构函数，因此把重定向和恢复操作封装到类中会异常安全 上面举例那种，如果在重定向之后、恢复之前程序abort了，则不会进行stdout恢复 全局一个实例#include &lt;iostream&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; using namespace std; // implement redirect stdout in class: exception safety // destructors of all objects are ensured to be called when exception occurs(ensured by compiler) // redirect stdout to file when constructing instance, restore when destructing // NOTE: only one success instance is allowed class RedirectStdout &#123; int saved; int redirected_success; static int success_instance_count; public: int is_success() &#123; return redirected_success; &#125; // redirect stdout to file RedirectStdout(const char *file) &#123; if (success_instance_count == 1) &#123; cout &lt;&lt; &quot;only one success instance is allowed!&quot; &lt;&lt; endl; redirected_success = 0; return; &#125; // TODO: check these syscall&#39;s return value // now 1 is descriptor to STDOUT int pfd = open(file, O_WRONLY | O_CREAT, 0777); // now pfd is descriptor to &quot;bin/.gconsole_tmp_out&quot; saved = dup(1); // now 1 and saved both are descriptor to STDOUT // int dup2(int oldfd, int newfd); dup2(pfd, 1); // would close descriptor 1 first, then now 1 and pfd both are descriptor to &quot;bin/.gconsole_tmp_out&quot;(pfd previously pointed to) close(pfd); // close descriptor pfd redirected_success = 1; ++success_instance_count; &#125; // fflush and restore stdout ~RedirectStdout() &#123; if (redirected_success) &#123; --success_instance_count; // TODO: check these syscall&#39;s return value fflush(stdout); // NOTE that flush the buffer is necessary to indeed push content into file dup2(saved, 1); // would close descriptor 1 first, then now 1 and saved both are descriptor to STDOUT(saved previously pointed to) close(saved); // close descriptor saved&#125; &#125; &#125; &#125;; int RedirectStdout::success_instance_count = 0; // init to 0 int main() &#123; &#123; RedirectStdout ins1(&quot;1&quot;); // success, stdout is redirected to file&quot;1&quot; cout &lt;&lt; ins1.is_success() &lt;&lt; endl; // success, print to file&quot;1&quot; cout &lt;&lt; &quot;This goes into file&quot; &lt;&lt; endl; // print to file&quot;1&quot; RedirectStdout ins2(&quot;2&quot;); // fail, fail msg print to file&quot;1&quot; cout &lt;&lt; ins2.is_success() &lt;&lt; endl; // print to file&quot;1&quot; RedirectStdout ins3(&quot;3&quot;); // fail, fail msg print to file&quot;1&quot; cout &lt;&lt; ins3.is_success() &lt;&lt; endl; // print to file&quot;1&quot; &#125; // destruct: restore stdout cout &lt;&lt; &quot;This goes into console&quot; &lt;&lt; endl; return 0; &#125; 栈式重定向#include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;stack&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; using namespace std; template &lt;typename T&gt; void print_stk(stack&lt;T&gt; arr) &#123; cout &lt;&lt; &quot;[sz:&quot; &lt;&lt; arr.size() &lt;&lt; &quot;] &quot;; while (arr.empty() == 0) &#123; cout &lt;&lt; arr.top() &lt;&lt; &quot; &quot;; arr.pop(); &#125; cout &lt;&lt; endl; &#125; // if &lt;des&gt; is descriptor to &lt;file&gt;, then we call &lt;des&gt;&#39;s refer is &lt;file&gt; // construct: redirect descriptor 1&#39;s refer ori_file to file(constructor&#39;s param)(and push ori_file to static stk top) // destruct: restore descriptor 1&#39;s refer to stk top(and pop stk) // static stk design ensures when there&#39;s no RedirectStdout instance, descriptor 1&#39;s refer is stdout class RedirectStdout &#123; public: static stack&lt;int&gt; ori_file_stk; /* redirect descriptor 1&#39;s refer ori_file to file(and push ori_file to static stk top) */ // append: if set, then open file with |O_APPEND RedirectStdout(const char *file, int append = 0) &#123; // TODO: check these syscall&#39;s return value // now 1 is descriptor to ori_file(if stk is empty, ori_file is STDOUT; else ori_file is stk.top()) int pfd; if (append) &#123; pfd = open(file, O_WRONLY | O_CREAT | O_APPEND, 0777); &#125; else &#123; pfd = open(file, O_WRONLY | O_CREAT | O_TRUNC, 0777); &#125; // now pfd is descriptor to file int saved = dup(1); // now 1 and saved both are descriptor to ori_file(1 previously refer to) // int dup2(int oldfd, int newfd); dup2(pfd, 1); // would close descriptor 1 first, then now 1 and pfd both are descriptor to file(pfd previously refer to) close(pfd); // close descriptor pfd ori_file_stk.push(saved); // now saved(stk.top()) is descriptor to ori_file, 1 is descriptor to file &#125; /* fflush and restore descriptor 1&#39;s refer to stk top(and pop stk) */ ~RedirectStdout() &#123; // TODO: check these syscall&#39;s return value fflush(stdout); // NOTE that flush the buffer is necessary to indeed push content into file int saved = ori_file_stk.top(); ori_file_stk.pop(); dup2(saved, 1); // would close descriptor 1 first, then now 1 and saved both are descriptor to &quot;saved previously refer to&quot; close(saved); // close descriptor saved // now only 1 is descriptor to &quot;saved previously refer to&quot; &#125; &#125;; stack&lt;int&gt; RedirectStdout::ori_file_stk; int main() &#123; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in console: &#123;&#125; // now 1 refer to STDOUT &#123; RedirectStdout ins1(&quot;ins1&quot;); // now 1 refer to &quot;ins1&quot; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in ins1: &#123;des_to_STDOUT&#125; &#123; RedirectStdout ins2(&quot;ins2&quot;); // now 1 refer to &quot;ins2&quot; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in ins2: &#123;des_to_ins1,des_to_STDOUT&#125; &#125; // ins2 destruct: now 1 refer to &quot;ins1&quot; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in ins1: &#123;des_to_STDOUT&#125; &#125; // ins1 destruct: now 1 refer to STDOUT print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in console: &#123;&#125; return 0; &#125; 文件权限编码 chmod https://digitalfortress.tech/php/difference-file-mode-0777-vs-777/ 如何编码 对于posix接口： parameter you pass to mkdir() is interpreted as decimal if it isn’t preceded by a 0 如果前面有0则是被当作16进制数翻译 因此777 and 0777有区别： 0777 (octal) == binary 0b 111 111 111 == permissions rwxrwxrwx (== decimal 511) 777 (decimal) == binary 0b 1 100 001 001 == permissions sr----x--x (== octal 1411) 对于chmod chmod interprets all numeric arguments as octal，则777 and 0777无区别 一个计算器：https://chmodcommand.com/ dup dup2 https://man7.org/linux/man-pages/man2/dup.2.html dup, dup2, dup3 - duplicate a file descriptor #include &lt;unistd.h&gt; int dup(int oldfd); int dup2(int oldfd, int newfd); dup The dup() system call ++allocates a new file descriptor++ that ++refers to the same open file++ description as the descriptor oldfd. The new file descriptor number is guaranteed to be the lowest-numbered file descriptor that was unused in the calling process. After a successful return, the old and new file descriptors may be used interchangeably（毕竟它们指向相同的文件）.Since the two file descriptors refer to the same open file description, they share file offset and file status flags;（for example, if the file offset is modified by using lseek(2) on one of the file descriptors, the offset is also changed for the other file descriptor.） The two file descriptors do NOT share file descriptor flags (the close-on-exec flag). The close-on-exec flag (FD_CLOEXEC; see fcntl(2)) for the duplicate descriptor is off. dup2++the file descriptor newfd++ is adjusted so that it now ++refers to the same open file description as oldfd.++ If the file descriptor newfd was previously open, it is closedbefore being reused; the close is performed silently (i.e., anyerrors during the close are not reported by dup2()). returnOn success, these system calls return the new file descriptor.On error, -1 is returned, and errno is set to indicate the error.","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"c函数宏定义函数可变参数","slug":"c函数宏定义函数可变参数","date":"2022-07-28T04:33:23.438Z","updated":"2022-12-10T15:13:29.527Z","comments":true,"path":"2022/07/28/c函数宏定义函数可变参数/","link":"","permalink":"http://example.com/2022/07/28/c%E5%87%BD%E6%95%B0%E5%AE%8F%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/","excerpt":"","text":"宏定义函数https://gcc.gnu.org/onlinedocs/gcc-7.3.0/gcc.pdf搜索__VA_ARGS__ #define debug(format, ...) fprintf (stderr, format, __VA_ARGS__) Here ... is a variable argument. In the invocation of such a macro, it represents the zero or more tokens until the closing parenthesis that ends the invocation, including anycommas. This set of tokens replaces the identifier __VA_ARGS__ in the macro body whereverit appears. See the CPP manual for more information. c函数https://blog.csdn.net/qq_16628781/article/details/72717008","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"linux c隐藏输入 termios.h","slug":"linux c隐藏输入 termiosh","date":"2022-07-27T08:27:11.661Z","updated":"2022-12-10T15:13:23.096Z","comments":true,"path":"2022/07/27/linux c隐藏输入 termiosh/","link":"","permalink":"http://example.com/2022/07/27/linux%20c%E9%9A%90%E8%97%8F%E8%BE%93%E5%85%A5%20termiosh/","excerpt":"","text":"参考教程https://terminalroot.com/how-to-hide-input-via-cli-with-cpp/?ref=morioh.com&amp;utm_source=morioh.com man信息#include &lt;termios.h&gt;https://pubs.opengroup.org/onlinepubs/7908799/xsh/termios.h.html 举例#include &lt;iostream&gt; #include &lt;termios.h&gt; #include &lt;unistd.h&gt; /* https://man7.org/linux/man-pages/man0/termios.h.0p.html The &lt;termios.h&gt; header shall contain the definitions used by the terminal I/O interfaces (see Chapter 11, General Terminal Interface for the structures and names defined).*/ using namespace std; int main() &#123; string pswd; string stdpswd = &quot;1234&quot;; // set attribute of stdin: hide input pswd termios oldt; tcgetattr(STDIN_FILENO, &amp;oldt); termios newt = oldt; newt.c_lflag &amp;= ~ECHO; // ECHO bit: Enables echo. If this flag is set, characters are echoed as they are received. tcsetattr(STDIN_FILENO, TCSANOW, &amp;newt); // TCSANOW: Change attributes immediately. while (1) &#123; cout &lt;&lt; &quot;Enter password: &quot;; char c; while ((c = getchar()) != EOF &amp;&amp; c != &#39;\\n&#39; &amp;&amp; c != &#39;\\r&#39;) &#123; pswd.push_back(c); &#125; if (feof(stdin)) &#123; cout &lt;&lt; &quot;End of stdin!&quot; &lt;&lt; endl; return 0; &#125; cout &lt;&lt; endl; if (pswd == stdpswd) &#123; break; &#125; pswd.clear(); cout &lt;&lt; &quot;Wrong password.&quot; &lt;&lt; endl; &#125; // recover attribute tcsetattr(STDIN_FILENO, TCSANOW, &amp;oldt); cout &lt;&lt; pswd &lt;&lt; endl; return 0; &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"GNU readline","slug":"GNU readline","date":"2022-07-27T01:49:47.895Z","updated":"2022-12-10T15:13:47.398Z","comments":true,"path":"2022/07/27/GNU readline/","link":"","permalink":"http://example.com/2022/07/27/GNU%20readline/","excerpt":"","text":"自动补全，添加历史https://blog.51cto.com/u_3078781/3287204 自定义换行符https://www.igiftidea.com/article/12962763210.html 官方文档https://web.mit.edu/gnu/doc/html/rlman_2.html 快捷键使用（该库支持的）https://flyyang.me/2017/05/03/GNU-Readline-%E8%AE%A9%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%BE%91%E5%80%8D%E9%80%9F%E6%8F%90%E5%8D%87/","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"git配置","slug":"git配置","date":"2022-07-26T06:20:26.123Z","updated":"2022-12-10T15:13:57.455Z","comments":true,"path":"2022/07/26/git配置/","link":"","permalink":"http://example.com/2022/07/26/git%E9%85%8D%E7%BD%AE/","excerpt":"","text":"写得非常好的官方文档 https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%88%9D%E6%AC%A1%E8%BF%90%E8%A1%8C-Git-%E5%89%8D%E7%9A%84%E9%85%8D%E7%BD%AE 设置当前git仓库提交的用户名和邮箱git config user.name yuanzhiqiu git config user.email zhiqiuyuan@qq.com 检查是否设置成功 git config user.name git config user.email 设置之后则在当前仓库commit的用户名和邮箱即是你设置的这个（这是优先级最高的配置，覆盖比如全局的配置） 查看所有git配置git config --list","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python3调用c++","slug":"python3调用c++","date":"2022-07-25T08:30:57.293Z","updated":"2022-12-10T15:14:32.151Z","comments":true,"path":"2022/07/25/python3调用c++/","link":"","permalink":"http://example.com/2022/07/25/python3%E8%B0%83%E7%94%A8c++/","excerpt":"","text":"https://blog.csdn.net/springlustre/article/details/101177282","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"language","slug":"python/language","permalink":"http://example.com/categories/python/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"linux源码编译安装gcc并添加环境变量","slug":"linux源码编译安装gcc并添加环境变量","date":"2022-07-22T02:00:48.489Z","updated":"2022-12-10T15:15:05.031Z","comments":true,"path":"2022/07/22/linux源码编译安装gcc并添加环境变量/","link":"","permalink":"http://example.com/2022/07/22/linux%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85gcc%E5%B9%B6%E6%B7%BB%E5%8A%A0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"本例中，下载源码到$HOME/built/目录下，安装到$HOME/local/gcc-9.4.0目录下 1. 获取源码在预计放源码的目录下，比如$HOME/built/ wget -c http://ftp.gnu.org/gnu/gcc/gcc-9.4.0/gcc-9.4.0.tar.gz tar -zxvf gcc-9.4.0.tar.gz cd gcc-9.4.0 2. 下载依赖gcc源码中提供了可执行文件./contrib/download_prerequisites来干这个事情，./contrib/download_prerequisites --help可以查看使用方法 ./contrib/download_prerequisites # 下载到当前目录下 3. 编译创建和源码目录同级的编译目录gcc-build-9.4.0（创建之后gcc-build-9.4.0和gcc-9.4.0源码目录是同级目录，本例中及都在$HOME/built/下），在其中执行configure # 目前在gcc-9.4.0源码目录下 mkdir ../gcc-build-9.4.0 # 进入编译目录 cd ../gcc-build-9.4.0 ../gcc-9.4.0/configure --prefix=$HOME/local/gcc-9.4.0 --enable-checking=release --enable-languages=c,c++ --disable-multilib # prefix指定你想要安装到的目录 make -j &amp;&amp; make install 然后源码压缩包和源码目录以及编译目录就可以删除了 2.5 在编译之前要确保安装了texinfo检查下makeinfo这个命令有没有，没有则是没有安装https://iq.opengenus.org/makeinfo-command-not-found/ 源码编译安装方法： download sourcewget -c http://ftp.gnu.org/gnu/texinfo/texinfo-7.0.tar.gz Unzip the download source code of teXinfo:tar -xvf texinfo-7.0.tar.gzcd texinfo-7.0 Build and install teXinfo:.&#x2F;configure –prefix&#x3D;$HOME&#x2F;local&#x2F;texinfo-7.0make -j &amp;&amp; make install With this, teXinfo will be installed in $HOME&#x2F;local&#x2F;texinfo-7.0然后源码压缩包和源码目录就可以删除了 add env variable在~/.bashrc（$HOME/.bashrc）中添加 export PATH=$PATH:$HOME/local/texinfo-7.0/bin 4. 配置环境变量在~/.bashrc（$HOME/.bashrc）中添加 export PATH=$HOME/local/gcc-9.4.0/bin:$HOME/local/gcc-9.4.0/lib64:$PATH export LD_LIBRARY_PATH=$HOME/local/gcc-9.4.0/lib64:$HOME/local/gcc-9.4.0/lib:$LD_LIBRARY_PATH export LD_PRELOAD=$HOME/local/gcc-9.4.0/lib64/libstdc++.so.6:$LD_PRELOAD # export LD_PRELOAD=$HOME/local/gcc-9.4.0/lib64/libstdc++.so.6 之前博客里是这么写的，我感觉应该是拼接在前面，而不是覆盖，所以改成了上面那样 使得在当前shell生效则可以执行： source ~/.bashrc cmake不生效 指定指定版本gcc给cmake命令-D指明变量值： cmake -D CMAKE_C_COMPILER=$HOME/local/gcc-9.3.0/bin/gcc -D CMAKE_CXX_COMPILER=$HOME/local/gcc-9.3.0/bin/g++ .. 修改CMakeLists.txt定义俩变量似乎没有效果： SET(CMAKE_C_COMPILER $HOME/local/gcc-9.3.0/bin/gcc) SET(CMAKE_CXX_COMPILER $HOME/local/gcc-9.3.0/bin/g++)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"linux源码编译安装boost库1.56版本","slug":"linux源码编译安装boost库156版本","date":"2022-07-21T05:46:42.173Z","updated":"2022-12-10T15:15:18.668Z","comments":true,"path":"2022/07/21/linux源码编译安装boost库156版本/","link":"","permalink":"http://example.com/2022/07/21/linux%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost%E5%BA%93156%E7%89%88%E6%9C%AC/","excerpt":"","text":"1. 获取源码wget -c --no-check-certificate http://sourceforge.net/projects/boost/files/boost/1.56.0/boost_1_56_0.tar.gz #下载源码 tar -xzvf boost_1_56_0.tar.gz #解压源码 cd boost_1_56_0 #进入源码目录 2. 修改bootstrap.sh中的prefix把bootstrap.sh中的 PREFIX=/usr/local 修改为 PREFIX=/home/yuanzhiqiu/.local/usr/local #你希望安装在的目录 3. b2指定prefix./bootstrap.sh ./b2 --prefix=/home/yuanzhiqiu/.local/usr/local/ ./b2 --prefix=/home/yuanzhiqiu/.local/usr/local/ install 可以./b2 --help查看b2的使用方法 4. 修改动态链接库和头文件路径（添加环境变量）安装成功后， 修改动态链接库路径：假设 boost 的动态链接库在/prefix/lib路径下（prefix即上文的在bootstrap.sh中指定的PREFIX和给b2传入的--prefix，与上文一致的举例则为home/yuanzhiqiu/.local/usr/local）：在~/.bashrc中添加如下内容： export LD_LIBRARY_PATH=/prefix/lib:$LD_LIBRARY_PATH 举例： export LD_LIBRARY_PATH=/home/yuanzhiqiu/.local/usr/local/lib:$LD_LIBRARY_PATH 修改头文件路径：假设 boost 的头文件在/prefix/include路径下，则需要执行以下命令： export CPATH=/prefix/include:$CPATH 举例： export CPATH=/home/yuanzhiqiu/.local/usr/local/include:$CPATH","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"c++并发编程实践2ed：4.3 限时等待","slug":"c++并发编程实践2ed：43 限时等待","date":"2022-07-16T13:27:10.498Z","updated":"2022-12-10T15:15:58.142Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：43 限时等待/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A43%20%E9%99%90%E6%97%B6%E7%AD%89%E5%BE%85/","excerpt":"","text":"4.3 限时等待阻塞调用会将线程挂起一段(不确定的)时间，直到相应的事件发生。通常情况下，这样的方式很不错，但是在一些情况下，需要限定线程等待的时间。可以发送一些类似“我还存活”的信息，无论是对交互式用户，或是其他进程，亦或当用户放弃等待，也可以按下“取消”键终止等待。 这里介绍两种指定超时方式：一种是“时间段”，另一种是“时间点”。第一种方式，需要指定一段时间(例如，30毫秒)。第二种方式，就是指定一个时间点(例如，世界标准时间[UTC]17:30:15.045987023，2011年11月30日)。多数等待函数提供变量，对两种超时方式进行处理。处理持续时间的变量以_for作为后缀，处理绝对时间的变量以_until作为后缀。 所以，std::condition_variable的两个成员函数wait_for()和wait_until()成员函数分别有两个重载，这两个重载都与wait()成员函数的重载相关——其中一个只是等待信号触发，或超期，亦或伪唤醒，并且醒来时会使用谓词检查锁，并且只有在校验为true时才会返回(这时条件变量的条件达成)，或直接超时。 观察使用超时函数的细节前，我们来检查一下在C++中指定时间的方式，就从“时钟”开始吧！ 4.3.1 时钟 std::chrono对于C++标准库来说，时钟就是时间信息源。并且，时钟是一个类，提供了四种不同的信息： 当前时间 时间类型 时钟节拍 稳定时钟 当前时间可以通过静态成员函数now()从获取。例如，**std::chrono::system_clock::now()会返回系统的当前时间。特定的时间点可以通过time_point**的typedef成员来指定，所以some_clock::now()的类型就是some_clock::time_point。 时钟节拍被指定为1&#x2F;x(x在不同硬件上有不同的值)秒，这是由时间周期所决定——一个时钟一秒有25个节拍，因此一个周期为std::ratio&lt;1, 25&gt;，当一个时钟的时钟节拍每2.5秒一次，周期就可以表示为std::ratio&lt;5, 2&gt;。当时钟节拍在运行时获取时，可以使用给定的应用程序运行多次，用执行的平均时间求出，其中最短的时间可能就是时钟节拍，或者是写在手册当中，这就不保证在给定应用中观察到的节拍周期与指定的时钟周期是否相匹配。 当时钟节拍均匀分布(无论是否与周期匹配)，并且不可修改，这种时钟就称为稳定时钟。is_steady静态数据成员为true时，也表明这个时钟就是稳定的。通常情况下，因为std::chrono::system_clock可调，所以是不稳定的。这可调可能造成首次调用now()返回的时间要早于上次调用now()所返回的时间，这就违反了节拍频率的均匀分布。稳定闹钟对于计算超时很重要，所以C++标准库提供一个稳定时钟std::chrono::steady_clock。C++标准库提供的其他时钟可表示为std::chrono::system_clock，代表了系统时钟的“实际时间”，并且提供了函数，可将时间点转化为time_t类型的值。std::chrono::high_resolution_clock 可能是标准库中提供的具有最小节拍周期(因此具有最高的精度)的时钟。它实际上是typedef的另一种时钟，这些时钟和与时间相关的工具，都在**&lt;chrono&gt;库**头文件中定义。 我们先看一下时间段是怎么表示的。 4.3.2 时间段 std::chrono时间部分最简单的就是时间段，std::chrono::duration&lt;&gt;函数模板能够对时间段进行处理(线程库使用到的所有C++时间处理工具，都在std::chrono命名空间内)。第一个模板参数是一个类型表示(比如，int，long或double)，第二个模板参数是定制部分，表示每一个单元所用秒数。例如，当几分钟的时间要存在short类型中时，可以写成std::chrono::duration&lt;short, std::ratio&lt;60, 1&gt;&gt;(60s累加1次)，因为60秒是才是1分钟，所以第二个参数写成std::ratio&lt;60, 1&gt;。当需要将毫秒级计数存在double类型中时，可以写成std::chrono::duration&lt;double, std::ratio&lt;1, 1000&gt;&gt;(1s累加1000次)，因为1秒等于1000毫秒。 标准库在std::chrono命名空间内为时间段变量提供一系列预定义类型：**nanoseconds[纳秒] , microseconds[微秒] , milliseconds[毫秒] , seconds[秒] , minutes[分]和hours[时]**。比如，你要在一个合适的单元表示一段超过500年的时延，预定义类型可充分利用了大整型，来表示所要表示的时间类型。当然，这里也定义了一些国际单位制(SI, [法]le Système international d’unités)分数，可从std::atto(10^(-18))到std::exa(10^(18))(题外话：当你的平台支持128位整型)，也可以指定自定义时延类型。例如：std::duration&lt;double, std::centi&gt;，就可以使用一个double类型的变量表示1&#x2F;100。 方便起见，C++14中**std::chrono_literals命名空间中有许多预定义的后缀操作符**用来表示时长。下面的代码就是使用硬编码的方式赋予变量具体的时长： using namespace std::chrono_literals; auto one_day=24h; auto half_an_hour=30min; auto max_time_between_messages=30ms; 使用整型字面符时，15ns和std::chrono::nanoseconds(15)就是等价的。不过，当使用浮点字面量时，且未指明表示类型时，数值上会对浮点时长进行适当的缩放。因此，2.5min会被表示为std::chrono::duration&lt;some-floating-point-type,std::ratio&lt;60,1&gt;&gt;。如果非常关心所选的浮点类型表示的范围或精度，就需要构造相应的对象来保证表示范围或精度，而不是去苛求字面值来对范围或精度进行表达。 当不要求截断值（即会舍入）的情况下(时转换成秒是没问题，但是秒转换成时就不行)时间段的转换是隐式的，显示转换可以由**std::chrono::duration_cast&lt;&gt;**来完成。 std::chrono::milliseconds ms(54802); std::chrono::seconds s= std::chrono::duration_cast&lt;std::chrono::seconds&gt;(ms); 这里的结果就是截断的，而不是进行了舍入，所以s最后的值为54。 时间值支持四则运算，所以能够对两个时间段进行加减，或者是对一个时间段乘除一个常数(模板的第一个参数)来获得一个新时间段变量。例如，5seconds(1)与seconds(5)或minutes(1)-seconds(55)是一样。在时间段中可以通过count()成员函数获得单位时间的数量。例如，*std::chrono::milliseconds(1234).count()就是1234**。 基于时间段的等待可由std::chrono::duration&lt;&gt;来完成。例如：等待future状态变为就绪需要35毫秒： std::future&lt;int&gt; f=std::async(some_task); if(f.wait_for(std::chrono::milliseconds(35))==std::future_status::ready) do_something_with(f.get()); 等待函数会返回状态值，表示是等待是超时，还是继续等待。等待future时，超时时会返回std::future_status::timeout。当future状态改变，则会返回std::future_status::ready。当与future相关的任务延迟了，则会返回std::future_status::deferred。基于时间段的等待使用稳定时钟来计时，所以这里的35毫秒不受任何影响。当然，系统调度的不确定性和不同操作系统的时钟精度意味着：线程调用和返回的实际时间间隔可能要比35毫秒长。 现在，来看看“时间点”如何工作。 4.3.3 时间点时间点可用**std::chrono::time_point&lt;&gt;来表示，第一个参数用来指定使用的时钟，第二个函数参数用来表示时间单位**(特化的std::chrono::duration&lt;&gt;)。时间点就是时间戳，而时间戳是时钟的基本属性，不可以直接查询，其在C++标准中已经指定。通常，UNIX时间戳表示1970年1月1日 00:00。时钟可能共享一个时间戳，或具有独立的时间戳。当两个时钟共享一个时间戳时，其中一个time_point类型可以与另一个时钟类型中的time_point相关联。虽然不知道UNIX时间戳的具体值，但可以通过对指定time_point类型使用time_since_epoch()来获取时间戳，该成员函数会返回一个数值，这个数值是指定时间点与UNIX时间戳的时间间隔。 例如，指定一个时间点std::chrono::time_point&lt;std::chrono::system_clock, std::chrono::minutes&gt;，这就与系统时钟有关，且实际中的一分钟与系统时钟精度应该不相同(通常差几秒)。 可以通过对std::chrono::time_point&lt;&gt;实例进行加&#x2F;减，来获得一个新的时间点，所以std::chrono::hight_resolution_clock::now() + std::chrono::nanoseconds(500)将得到500纳秒后的时间，这对于计算绝对时间来说非常方便。 也可以减去一个时间点(二者需要共享同一个时钟)，结果是两个时间点的时间差。这对于代码块的计时是很有用的，例如： auto start=std::chrono::high_resolution_clock::now(); do_something(); auto stop=std::chrono::high_resolution_clock::now(); std::cout&lt;&lt;&quot;do_something() took &quot; &lt;&lt;std::chrono::duration&lt;double,std::chrono::seconds&gt;(stop-start).count() &lt;&lt;&quot; seconds&quot;&lt;&lt;std::endl; std::chrono::time_point&lt;&gt;的时钟参数不仅能够指定UNIX时间戳。当等待函数(绝对时间超时)传递时间点时，时间点参数就可以用来测量时间。当时钟变更时，会产生严重的后果，因为等待轨迹随着时钟的改变而改变，并且直到调用now()成员函数时，才能返回一个超过超时时间的值。 后缀为_unitl的(等待函数的)变量会使用时间点。通常是使用时钟的::now()(程序中一个固定的时间点)作为偏移，虽然时间点与系统时钟有关，可以使用std::chrono::system_clock::to_time_point()静态成员函数，对时间点进行操作。 代码4.11 等待条件变量满足条件——有超时功能 #include &lt;condition_variable&gt; #include &lt;mutex&gt; #include &lt;chrono&gt; std::condition_variable cv; bool done; std::mutex m; bool wait_loop() &#123; auto const timeout= std::chrono::steady_clock::now()+ std::chrono::milliseconds(500); std::unique_lock&lt;std::mutex&gt; lk(m); while(!done) &#123; if(cv.wait_until(lk,timeout)==std::cv_status::timeout) break; &#125; return done; &#125; 当没有什么可以等待时，可在一定时限中等待条件变量。这种方式中，循环的整体长度有限。4.1.1节中当使用条件变量时，就使用了循环，这是为了处理假唤醒。当循环中使用wait_for()时，可能在等待了足够长的时间后结束等待(在假唤醒之前)，且下一次等待又开始了。这可能重复很多次，出现无限等待的情况。 至此，有关时间点的基本知识已经了解差不多了。现在，让我们来了解一下如何在函数中使用超时。 4.3.4 使用超时使用超时的最简单方式，就是对特定线程添加延迟处理。当线程无所事事时，就不会占用其他线程的处理时间。4.1节中的例子，循环检查“done”标志，两个处理函数分别是**std::this_thread::sleep_for()和std::this_thread::sleep_until()**。它们的工作就像一个简单的闹钟：当线程因为指定时长而进入睡眠时，可使用sleep_for()唤醒，可指定休眠的时间点，之后可使用sleep_until唤醒。sleep_for()的使用和4.1节一样，有些事必须在指定时间内完成，所以耗时就很敏感。另一方面，sleep_until()允许在某个特定时间点将调度线程唤醒。可能在晚间备份或在早上6:00打印工资条时使用，亦或挂起线程直到下一帧刷新时进行视频播放。 当然，休眠只是超时处理的一种形式，超时可以配合条件变量和future一起使用。超时甚至可以在获取互斥锁时(当互斥量支持超时时)使用。std::mutex和std::recursive_mutex都不支持超时，而std::timed_mutex和std::recursive_timed_mutex支持超时。这两种类型也有try_lock_for()和try_lock_until()成员函数，可以在一段时期内尝试获取锁，或在指定时间点前获取互斥锁。表4.1展示了C++标准库中支持超时的函数。参数列表为“延时”(duration)必须是std::duration&lt;&gt;的实例，并且列出为时间点(time_point)必须是std::time_point&lt;&gt;的实例。 表4.1 可接受超时的函数 类型/命名空间 函数 返回值 std::this_thread 命名空间 sleep_for(duration) N/A sleep_until(time_point) std::condition_variable 或 std::condition_variable_any wait_for(lock, duration) std::cv_status::time_out 或 std::cv_status::no_timeout wait_until(lock, time_point) wait_for(lock, duration, predicate) bool —— 当唤醒时，返回谓词的结果 wait_until(lock, duration, predicate) std::timed_mutex 或 std::recursive_timed_mutex try_lock_for(duration) bool —— 获取锁时返回true，否则返回fasle try_lock_until(time_point) std::unique_lock&lt;TimedLockable&gt; unique_lock(lockable, duration) N/A —— 对新构建的对象调用owns_lock(); unique_lock(lockable, time_point) 当获取锁时返回true，否则返回false try_lock_for(duration) bool —— 当获取锁时返回true，否则返回false try_lock_until(time_point) std::future&lt;ValueType&gt;或std::shared_future&lt;ValueType&gt; wait_for(duration) 当等待超时，返回std::future_status::timeout wait_until(time_point) 当期望值准备就绪时，返回std::future_status::ready 当期望值持有一个为启动的延迟函数，返回std::future_status::deferred 现在，我们讨论过的机制有：条件变量、future、promise，还有打包任务。是时候从更高的角度去看待这些机制，以及如何使用这些机制简化线程的同步操作。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：4.2 使用future","slug":"c++并发编程实践2ed：42 使用future","date":"2022-07-16T13:25:51.790Z","updated":"2022-12-10T15:16:10.360Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：42 使用future/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A42%20%E4%BD%BF%E7%94%A8future/","excerpt":"","text":"4.2 使用futurestd::future &#96;头文件 std::future&lt;&gt; 可移动不可拷贝（构造函数和赋值重载操作符） An asynchronous operation (created via std::async, std::packaged_task, or std::promise) can provide a std::future object to the creator of that asynchronous operation. The creator of the asynchronous operation can then use a variety of methods to query, wait for, or extract a value from the std::future. These methods may block if the asynchronous operation has not yet provided a value. When the asynchronous operation is ready to send a result to the creator, it can do so by modifying shared state (e.g. std::promise::set_value) that is linked to the creator’s std::future. 假设你要乘飞机去国外度假，当到达机场办理完各种登机手续后，还需要等待机场广播通知登机。这段时间内，你可能会在候机室里面找一些事情来打发时间，比如：读书，上网，或者来一杯咖啡。不过，你就在等待一件事情：机场广播通知登机。 C++标准库将这种事件称为future。当线程需要等待特定事件时，某种程度上来说就需要知道期望的结果。之后，线程会周期性(较短的周期)的等待或检查事件是否触发(检查信息板)，检查期间也会执行其他任务(品尝昂贵的咖啡)。另外，等待任务期间也可以先执行另外的任务，直到对应的任务触发，而后等待future的状态会变为就绪状态。future可能是和数据相关(比如，登机口编号)，也可能不是。当事件发生时(状态为就绪)，这个future就不能重置了。 C++标准库中有两种future，声明在**&lt;future&gt;头文件**中: unique future(std::future&lt;&gt;)和shared futures(std::shared_future&lt;&gt;)，与了std::unique_ptr和std::shared_ptr非常类似。std::future只能与指定事件相关联，而std::shared_future就能关联多个事件。后者的实现中，所有实例会在同时变为就绪状态，并且可以访问与事件相关的数据。这种关联与模板有关，比如std::unique_ptr 和std::shared_ptr的模板参数就是相关的数据类型。与数据无关处的，可以使用std::future&lt;void&gt;与std::shared_future&lt;void&gt;的特化模板。虽然，我倾向于线程通讯，但future对象本身并不提供同步访问。当多个线程需要访问一个独立future对象时，必须使用互斥量或类似同步机制进行保护。不过，当多个线程对一个std::shared_future&lt;&gt;副本进行访问，即使同一个异步结果，也不需要同步future。 并行技术规范将这两个模板类在std::experimental命名空间中进行了扩展：std::experimental::future&lt;&gt;和std::experimental::shared_future&lt;&gt; 。这个命名空间是为了将其与std命名空间中的模板类进行区分，实验命名空间中为这两个模板类添加了更多的功能。尤其是std::experimental中的内容与代码质量无关(我希望这里也会有较高质量的实现)，需要强调的是这个命名空间提供的都不是标准类和函数，这个命名空间中类和函数的语法和语义，很可能与纳入C++标准(也就是std命名空间)后有所不同。如果想要使用这两个试验性的模板类，需要包含&lt;experimental/future&gt;头文件。 最简单的事件，就是在后台运行的计算操作。第2章中已经清楚了std::thread 执行的任务不能有返回值，不过这个问题能使用future进行解决。 4.2.1 后台任务的返回值 std::async std::async 模板函数 构造函数：（六个，两种） async( Function&amp;&amp; f, Args&amp;&amp;… args ); async( std::launch policy, Function&amp;&amp; f, Args&amp;&amp;… args ); 概述：runs the function f asynchronously (potentially in a separate thread which might be a part of a thread pool) and returns a std::future that will eventually hold the result of that function call. policy： std::launch::async：executes the callable object f on a new thread of execution (with all thread-locals initialized) as if spawned by std::thread(std::forward(f), std::forward(args)…), except that if the function f returns a value or throws an exception, it is stored in the shared state accessible through the std::future that async returns to the caller. If the deferred flag is set (i.e. (policy &amp; std::launch::deferred) !&#x3D; 0)：converts f and args... the same way as by std::thread constructor, but does not spawn a new thread of execution. Instead, lazy evaluation is performed: the first call to a non-timed wait function on the std::future that async returned to the caller will cause the copy of f to be invoked (as an rvalue) with the copies of args... (also passed as rvalues) in the current thread（对这个std::future调用non-timed wait function的线程） (which does not have to be the thread that originally called std::async). The result or exception is placed in the shared state associated with the future and only then it is made ready. All further accesses to the same std::future will return the result immediately. If more than one flag is set, it is implementation-defined which policy is selected. For the default (both the std::launch::async and std::launch::deferred flags are set in policy), standard recommends (but doesn’t require) utilizing available concurrency, and deferring any additional tasks. 关于其中std::future的析构： If the std::future obtained from std::async is not moved from or bound to a reference, the destructor of the std::future will block at the end of the full expression until the asynchronous operation completes, essentially making code such as the following synchronous: std::async(std::launch::async, []&#123; f(); &#125;); // temporary&#39;s dtor waits for f() std::async(std::launch::async, []&#123; g(); &#125;); // does not start until f() completes 假设有一个需要长时间的运算，需要计算出一个有效值，但并不迫切需要这个值。你可以启动新线程来执行这个计算，你需要计算的结果，而std::thread并不提供直接接收返回值的机制。这里就需要**std::async函数模板(也是在头文件&lt;future&gt;**)。 当不着急让任务结果时，可以使用**std::async启动一个异步任务。与std::thread对象等待的方式不同，std::async会返回一个std::future对象，这个对象持有最终计算出来的结果。当需要这个值时，只需要调用这个对象的get()成员函数，就会阻塞（调用）线程直到future为就绪为止**，并返回计算结果。 代码4.6 std::future从异步任务中获取返回值 #include &lt;future&gt; #include &lt;iostream&gt; int find_the_answer_to_ltuae(); void do_other_stuff(); int main() &#123; std::future&lt;int&gt; the_answer=std::async(find_the_answer_to_ltuae); do_other_stuff(); std::cout&lt;&lt;&quot;The answer is &quot;&lt;&lt;the_answer.get()&lt;&lt;std::endl; &#125; 与std::thread方式一样，std::async允许通过添加额外的调用参数，向函数传递额外的参数。第一个参数是指向成员函数的指针，第二个参数提供这个函数成员类的具体对象(是通过指针，也可以包装在std::ref中)，剩余的参数可作为函数的参数传入。否则，第二个和随后的参数将作为函数的参数，或作为指定可调用对象的第一个参数。和std::thread一样，当参数为右值时，拷贝操作将使用移动的方式转移原始数据，就可以使用“只移动”类型作为函数对象和参数。 代码4.7 使用std::async向函数传递参数 #include &lt;string&gt; #include &lt;future&gt; struct X &#123; void foo(int,std::string const&amp;); std::string bar(std::string const&amp;); &#125;; X x; auto f1=std::async(&amp;X::foo,&amp;x,42,&quot;hello&quot;); // 调用p-&gt;foo(42, &quot;hello&quot;)，p是指向x的指针 auto f2=std::async(&amp;X::bar,x,&quot;goodbye&quot;); // 调用tmpx.bar(&quot;goodbye&quot;)， tmpx是x的拷贝副本 struct Y &#123; double operator()(double); &#125;; Y y; auto f3=std::async(Y(),3.141); // 调用tmpy(3.141)，tmpy通过Y的移动构造函数得到 auto f4=std::async(std::ref(y),2.718); // 调用y(2.718) X baz(X&amp;); std::async(baz,std::ref(x)); // 调用baz(x) class move_only &#123; public: move_only(); move_only(move_only&amp;&amp;) move_only(move_only const&amp;) = delete; move_only&amp; operator=(move_only&amp;&amp;); move_only&amp; operator=(move_only const&amp;) = delete; void operator()(); &#125;; auto f5=std::async(move_only()); // 调用tmp()，tmp是通过std::move(move_only())构造得到 future的等待取决于std::async是否启动一个线程，或是否有任务在进行同步。大多数情况下，也可以在函数调用之前向std::async传递一个额外参数，这个参数的类型是std::launch，还可以是std::launch::defered，表明函数调用延迟到wait()或get()函数调用时才执行，**std::launch::async表明函数必须在独立线程上执行，std::launch::deferred | std::launch::async表明实现可以选择这两种方式的一种**（“ If more than one flag is set, it is implementation-defined which policy is selected.”）。最后一个选项（std::launch::deferred | std::launch::async）是默认的，当函数调用延迟，就可能不会再运行了。如下所示： auto f6=std::async(std::launch::async,Y(),1.2); // 在新线程上执行 auto f7=std::async(std::launch::deferred,baz,std::ref(x)); // 在wait()或get()调用时执行 auto f8=std::async( std::launch::deferred | std::launch::async, baz,std::ref(x)); // 实现选择执行方式 auto f9=std::async(baz,std::ref(x)); f7.wait(); // 调用延迟函数 本章的后续小节和第8章中，会再次看到这段程序，使用std::async会将算法分割到各个任务中，这样程序就能并发了。不过，这不是让std::future与任务实例相关联的唯一方式，也可以将任务包装入std::packaged_task&lt;&gt;中，或通过编写代码的方式，使用std::promise&lt;&gt;模板显式设置值。与std::promise&lt;&gt;相比，std::packaged_task&lt;&gt;具有更高的抽象，所以我们从“高抽象”模板说起。 4.2.2 future与任务关联 std::packaged_task std::packaged_task&lt;&gt; 可移动不可拷贝 概述：The class template std::packaged_task wraps any Callable target (function, lambda expression, bind expression, or another function object) so that it can be invoked asynchronously. Its return value or exception thrown is stored in a shared state which can be accessed through std::future objects. (args)重载函数：Calls the stored task with args as the arguments（在调用这个重载函数的线程中执行）. The return value of the task or any exceptions thrown are stored in the shared state. The shared state is made ready and any threads waiting for this are unblocked. std::packaged_task&lt;&gt;会将future与函数或可调用对象进行绑定。当调用std::packaged_task&lt;&gt;对象时，就会调用相关函数或可调用对象，（并且返回值作为异步结果存储在std::future中）当future状态为就绪时，会存储返回值。这可以用在构建线程池(可见第9章)或其他任务的管理中，比如：在任务所在线程上运行其他任务，或将它们串行运行在一个特殊的后台线程上。当粒度较大的操作被分解为独立的子任务时，每个子任务都可以包含在std::packaged_task&lt;&gt;实例中，之后将实例传递到任务调度器或线程池中。对任务细节进行抽象，调度器仅处理std::packaged_task&lt;&gt;实例，而非处理单独的函数。 std::packaged_task&lt;&gt;的模板参数是一个函数签名，比如void()就是一个没有参数也没有返回值的函数，或int(std::string&amp;, double*)就是有一个非const引用的std::string参数和一个指向double类型的指针参数，并且返回类型是int。构造std::packaged_task&lt;&gt;实例时，就必须传入函数或可调用对象。这个函数或可调用的对象，需要能接收指定的参数和返回(可转换为指定返回类型的)值。类型可以不完全匹配，因为这里类型可以隐式转换，可以用int类型参数和返回float类型的函数，来构建std::packaged_task&lt;double(double)&gt;实例。 函数签名的返回类型可以用来标识从get_future()返回的std::future&lt;&gt;的类型，而函数签名的参数列表，可用来指定packaged_task的函数调用操作符。例如，模板偏特化std::packaged_task&lt;std::string(std::vector&lt;char&gt;*,int)&gt;会在下面的代码中使用到。 代码4.8 std::packaged_task&lt;&gt;的偏特化 template&lt;&gt; class packaged_task&lt;std::string(std::vector&lt;char&gt;*,int)&gt; &#123; public: template&lt;typename Callable&gt; explicit packaged_task(Callable&amp;&amp; f); std::future&lt;std::string&gt; get_future(); void operator()(std::vector&lt;char&gt;*,int); &#125;; std::packaged_task是个可调用对象，可以封装在std::function对象中，从而作为线程函数传递到std::thread对象中，或作为可调用对象传递到另一个函数中或直接调用。当std::packaged_task作为函数调用时，实参将由函数调用操作符传递至底层函数，并且返回值作为异步结果存储在std::future中，并且**可通过get_future()获取(获取future对象)**。因此可以用std::packaged_task对任务进行打包，并适时的取回future。当异步任务需要返回值时，可以等待future状态变为“就绪”。 线程间传递任务 很多图形架构需要特定的线程去更新界面，所以当线程对界面更新时，需要发出一条信息给正确的线程，让相应的线程来做界面更新。std::packaged_task提供了这种功能，且不需要发送一条自定义信息给图形界面线程。 代码4.9 使用std::packaged_task执行一个图形界面线程 #include &lt;deque&gt; #include &lt;mutex&gt; #include &lt;future&gt; #include &lt;thread&gt; #include &lt;utility&gt; std::mutex m; std::deque&lt;std::packaged_task&lt;void()&gt; &gt; tasks; bool gui_shutdown_message_received(); void get_and_process_gui_message(); void gui_thread() // 1 &#123; //没有关闭gui的情况下，不断尝试从队首取任务 while(!gui_shutdown_message_received()) // 2 &#123; get_and_process_gui_message(); // 3 std::packaged_task&lt;void()&gt; task; &#123; //这里设置一个scope的目的是std::lock_guard&lt;std::mutex&gt;对象离开作用域时析构解锁 std::lock_guard&lt;std::mutex&gt; lk(m); if(tasks.empty()) // 4 continue; //对于while循环的continue task=std::move(tasks.front()); // 5 调用std::packaged_task&lt;void()&gt;的移动赋值重载函数 tasks.pop_front(); &#125; task(); // 6 &#125; &#125; std::thread gui_bg_thread(gui_thread); //将任务传入队列 template&lt;typename Func&gt; std::future&lt;void&gt; post_task_for_gui_thread(Func f) &#123; std::packaged_task&lt;void()&gt; task(f); // 7 std::future&lt;void&gt; res=task.get_future(); // 8 std::lock_guard&lt;std::mutex&gt; lk(m); tasks.push_back(std::move(task)); // 9 return res; // 10 &#125; 代码十分简单：图形界面线程①循环直到收到一条关闭图形界面的信息后关闭界面②。关闭界面前，进行轮询界面消息处理③，例如：用户点击和执行在队列中的任务。当队列中没有任务④时，循环将继续。除非能在队列中提取出一个任务⑤，释放队列上的锁，并且执行任务⑥。这里future与任务相关，当任务执行完时，其状态会置为“就绪”。 将任务传入队列：提供的函数⑦可以提供一个打包好的任务，通过这个任务⑧调用get_future()成员函数获取future对象，并且在任务推入列表⑨之前，future将返回调用函数⑩。 例子中使用std::packaged_task&lt;void()&gt;创建任务，其中包含了一个无参数无返回值的函数或可调用对象(如果当这个调用有返回值时，返回值会被丢弃)。这可能是最简单的任务，std::packaged_task也可以用于复杂的情况——通过指定不同的函数签名作为模板参数，不仅可以改变其返回类型(因此该类型的数据会存在期望相关的状态中)，也可以改变函数操作符的参数类型。这个例子可以简单的扩展成允许任务运行在图形界面线程上，并且接受传参，还可以通过std::future获取返回值。 这些任务能作为简单的函数调用来表达吗？还有，任务的结果能从很多地方得到吗？这些问题可以使用第三种方法创建future来解决：使用std::promise对值进行显示设置。 4.2.3 使用std::promise std::promise 可移动不可拷贝 A promise may do three things with the shared state（那个与这个promise对象相关联的std::future）: make ready: the promise stores the result or the exception in the shared state. Marks the state ready and unblocks any thread waiting on a future associated with the shared state. release: the promise gives up its reference to the shared state. If this was the last such reference, the shared state is destroyed. Unless this was a shared state created by std::async which is not yet ready, this operation does not block. abandon: the promise stores the exception of type std::future_error with error code std::future_errc::broken_promise, makes the shared state ready, and then releases it. The promise is the “push” end of the promise-future communication channel: the operation that stores a value in the shared state synchronizes-with (as defined in std::memory_order) the successful return from any function that is waiting on the shared state (such as std::future::get). Concurrent access to the same shared state may conflict otherwise: for example multiple callers of std::shared_future::get must either all be read-only or provide external synchronization. 当需要处理很多网络连接时，会使用不同线程尝试连接每个接口，能使网络尽早联通。不幸的是，随着连接数量的增长，这种方式变的越来越不合适。因为大量的线程会消耗大量的系统资源，还有可能造成线程上下文频繁切换(当线程数量超出硬件可接受的并发数时)，这都会对性能有影响。最极端的例子：线程会将系统资源消耗殆尽，系统连接网络的能力会变的极差。因此通过少数线程处理网络连接，每个线程同时处理多个连接，对需要处理大量网络连接的应用而言，这是一种比较普遍的做法。 当线程处理多个连接事件，来自不同的端口连接的数据包基本上以乱序方式进行处理。同样的，数据包也将以乱序的方式进入队列。很多情况下，一些应用不是等待数据成功的发送，就是等待(新的)指定网络接口数据的接收成功。 std::promise&lt;T&gt;提供设定值的方式(类型为T)，这个类型会和后面看到的std::future&lt;T&gt;对象相关联。std::promise/std::future对提供一种机制：future可以阻塞等待线程，提供数据的线程可以使用promise对相关值进行设置，并将future的状态置为“就绪”。 可以通过给定的**std::promise的get_future()成员函数来获取与之相关的std::future对象，与std::packaged_task的用法类似。当promise设置完毕(使用set_value()成员函数)时，对应的future状态就变为“就绪”，并且可用于检索已存储的值。当设置值之前销毁std::promise，将会存储一个异常**。在4.2.4节中，会详细描述异常是如何传送到线程的。 代码4.10中是单线程处理多接口的实现，这个例子中，可以使用一对std::promise&lt;bool&gt;/std::future&lt;bool&gt;找出传出成功的数据块，与future相关的只是简单的“成功&#x2F;失败”标识。对于传入包，与future相关的数据就是数据包的有效负载。 代码4.10 使用promise解决单线程多连接问题 #include &lt;future&gt; void process_connections(connection_set&amp; connections) &#123; while(!done(connections)) // 1 &#123; //依次的检查每个连接 for(connection_iterator // 2 connection=connections.begin(),end=connections.end(); connection!=end; ++connection) &#123; if(connection-&gt;has_incoming_data()) // 3 &#123; data_packet data=connection-&gt;incoming(); std::promise&lt;payload_type&gt;&amp; p= connection-&gt;get_promise(data.id); // 4 获取引用 p.set_value(data.payload); //set_value &#125; if(connection-&gt;has_outgoing_data()) // 5 &#123; outgoing_packet data= connection-&gt;top_of_outgoing_queue(); connection-&gt;send(data.payload); data.promise.set_value(true); // 6 表明传输成功 set_value &#125; &#125; &#125; &#125; process_connections()中(直到done()返回true①为止)每一次循环，都会依次的检查每个连接②，检索是否有数据③或正在发送已入队的传出数据⑤。假设输入数据包是具有ID和有效负载的(有实际的数在其中)，一个ID映射到一个std::promise(可能是在相关容器中进行的依次查找)④，并且值是在包的有效负载中。传出包是在传出队列中检索，从接口直接发送出去。当发送完成，传出数据相关的promise将置为true，来表明传输成功⑥。是否能映射到实际网络协议上，取决于所用协议。 上面的代码不理会异常，一切工作都会很好的执行，但有悖常理。有时候磁盘满载，有时候会找不到东西，有时候网络会断，还有时候数据库会崩溃。当需要某个操作的结果时，就需要在对应的线程上执行这个操作，因为代码可以通过异常来报告错误。不过，这会对使用std::packaged_task或std::promise带来一些不必要的限制。因此，C++标准库提供了一种在以上情况下清理异常的方法，并且允许将异常存储为相关结果的一部分。 4.2.4 将异常存与future中看完下面的代码段，思考一下：当你传递-1到square_root()中时，它将抛出一个异常，并且你想让调用者看到这个异常： double square_root(double x) &#123; if(x&lt;0) &#123; throw std::out_of_range(&quot;x&lt;0&quot;); &#125; return sqrt(x); &#125; 假设调用square_root()函数不是当前线程， double y=square_root(-1); 将调用改为异步调用： std::future&lt;double&gt; f=std::async(square_root,-1); double y=f.get(); 当y获得函数调用的结果，线程调用f.get()时，就能再看到异常了。 函数作为**std::async的一部分时，当调用抛出一个异常时，这个异常就会存储到future中，之后future的状态置为“就绪”，之后调用get()会抛出已存储的异常**(注意：标准级别没有指定重新抛出的这个异常是原始的异常对象，还是一个拷贝。不同的编译器和库将会在这方面做出不同的选择)。将函数打包入std::packaged_task任务包后，当任务调用时，同样的事情也会发生。打包函数抛出一个异常，这个异常将存储在future中，在get()调用时会再次抛出。 当然，通过函数的显式调用，std::promise也能提供同样的功能。当存入的是异常而非数值时，就需要调用set_exception()成员函数，而非set_value()。这通常是用在一个catch块中，并作为算法的一部分。为了捕获异常，这里使用异常填充promise： extern std::promise&lt;double&gt; some_promise; try &#123; some_promise.set_value(calculate_value()); &#125; catch(...) &#123; some_promise.set_exception(std::current_exception()); //set_exception &#125; 这里使用std::current_exception()来检索抛出的异常，可用std::copy_exception()作为替代方案，std::copy_exception()会直接存储新的异常而不抛出： some_promise.set_exception(std::copy_exception(std::logic_error(&quot;foo &quot;))); 这比使用try&#x2F;catch块更加清晰，当异常类型已知，就应该优先使用。不是因为代码实现简单，而是给编译器提供了极大的优化空间。 另一种向future中存储异常的方式，在没有调用promise上的任何设置函数前，或正在调用包装好的任务时，销毁与std::promise或std::packaged_task相关的future对象。任何情况下，当future的状态还不是“就绪”时，调用std::promise或std::packaged_task的析构函数，将会存储一个与std::future_errc::broken_promise错误状态相关的std::future_error异常。通过创建一个future，可以构造一个promise为其提供值或异常，也可以通过销毁值和异常源，去违背promise。这种情况下，编译器没有在future中存储任何东西，线程可能会永远的等下去。 现在，例子中都在用std::future，不过std::future也有局限性。很多线程在等待的时候，只有一个线程能获取结果。当多个线程等待相同事件的结果时，就需要使用std::shared_future来替代std::future了。 4.2.5 多个线程的等待 std::shared_future std::shared_future 可拷贝 虽然std::future可以处理所有在线程间数据转移的同步，但是调用某一特殊 std::future对象的成员函数，就会让这个线程的数据和其他线程的数据不同步。多线程在没有额外同步的情况下，访问独立std::future对象时，就会有数据竞争和未定义行为。因为std::future独享同步结果，并且通过调用get()函数，一次性的获取数据，这就让并发访问变的毫无意义。 如果并行代码没办法让多个线程等待同一个事件，std::shared_future可以帮你解决这个问题。因为**std::future是只移动的，所以其所有权可以在不同的实例中互相传递，但只有一个实例可以获得特定的同步结果，而std::shared_future实例是可拷贝的**，所以多个对象可以引用同一关联期望值的结果。 每一个std::shared_future的独立对象上，成员函数调用返回的结果还是不同步的，所以为了在多个线程访问一个独立对象时避免数据竞争，必须使用锁来对访问进行保护。优先使用的办法：为了替代只有一个拷贝对象的情况，可以让每个线程都拥有自己对应的拷贝对象。这样，当每个线程都通过自己拥有的std::shared_future对象获取结果，那么多个线程访问共享同步结果就是安全的。可见图4.1。 图4.1 使用多个std::shared_future对象来避免数据竞争 可能会使用std::shared_future的场景，例如：实现类似于复杂的电子表格的并行执行，每一个单元格有唯一终值，这个终值可能由其他单元格中的数据通过公式计算得到。公式计算得到的结果依赖于其他单元格，然后可以使用std::shared_future对象引用第一个单元格的数据。当每个单元格内的所有公式并行执行后，任务会以期望的方式完成工作。不过，当其中有计算需要依赖其他单元格的值时就会阻塞，直到依赖单元格的数据准备就绪。这可以让系统在最大程度上使用硬件并发。 std::shared_future的实例同步std::future实例的状态。当std::future对象没有与其他对象共享同步状态所有权，那么所有权必须使用std::move将所有权传递到std::shared_future，其默认构造函数如下： std::promise&lt;int&gt; p; std::future&lt;int&gt; f(p.get_future()); //把p内部的future转移给f，即f现在是p内部的future assert(f.valid()); // 1 期望值 f 是合法的 std::shared_future&lt;int&gt; sf(std::move(f)); //移动语义的std::shared_future&lt;int&gt;的构造函数 assert(!f.valid()); // 2 期望值 f 现在是不合法的 assert(sf.valid()); // 3 sf 现在是合法的 期望值f开始是合法的①，因为引用的是promise p的同步状态，但是在转移sf的状态后，f就不合法了②，而sf就是合法的了③。 如其他可移动对象一样，转移所有权是对右值的隐式操作，所以可以通过std::promise对象的成员函数get_future()的返回值，直接构造一个std::shared_future对象，例如： std::promise&lt;std::string&gt; p; std::shared_future&lt;std::string&gt; sf(p.get_future()); // 1 隐式转移所有权 调用std::shared_future&lt;std::string&gt;移动语义的构造函数 转移所有权是隐式的，用右值构造std::shared_future&lt;&gt;，得到std::future&lt;std::string&gt;类型的实例①。 std::future的这种特性，可促进std::shared_future的使用，容器可以自动的对类型进行推断，从而初始化该类型的变量(详见附录A，A.6节)。**std::future有一个share()成员函数，可用来创建新的std::shared_future ，并且可以直接转移future的所有权**。这样也就能保存很多类型，并且使得代码易于修改： std::promise&lt; std::map&lt; SomeIndexType, SomeDataType, SomeComparator, SomeAllocator&gt;::iterator&gt; p; auto sf=p.get_future().share(); 这个例子中，sf的类型推导为std::shared_future&lt;std::map&lt;SomeIndexType, SomeDataType, SomeComparator, SomeAllocator&gt;::iterator&gt;，还真的长。当比较器或分配器有所改动，只需要对promise的类型进行修改即可。future的类型会自动与promise的修改进行匹配。 有时需要限定等待事件的时间，不论是因为时间上有硬性规定(一段指定的代码需要在某段时间内完成)，还是因为在事件没有很快的触发，或是有工作需要特定线程来完成，为了处理这种情况，需要等待函数能对超时进行指定。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：4.1 等待事件或条件","slug":"c++并发编程实践2ed：41 等待事件或条件","date":"2022-07-16T13:24:25.763Z","updated":"2022-12-10T15:16:25.384Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：41 等待事件或条件/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A41%20%E7%AD%89%E5%BE%85%E4%BA%8B%E4%BB%B6%E6%88%96%E6%9D%A1%E4%BB%B6/","excerpt":"","text":"4.1 等待事件或条件假设你正在一辆在夜间运行的火车上，在夜间如何在正确的站点下车呢？有一种方法是整晚都要醒着，每停一站都能知道，这样就不会错过你要到达的站点，但会很疲倦。另外，可以看一下时间表，估计一下火车到达目的地的时间，然后在一个稍早的时间点上设置闹铃，然后安心的睡会。这个方法听起来也很不错，也没有错过你要下车的站点，但是当火车晚点时，就要被过早的叫醒了。当然，闹钟的电池也可能会没电了，并导致你睡过站。理想的方式是，无论是早或晚，只要当火车到站的时候，有人或其他东西能把你叫醒就好了。 这和线程有什么关系呢？当一个线程等待另一个线程完成时，可以持续的检查共享数据标志(用于做保护工作的互斥量)，直到另一线程完成工作时对这个标识进行重置。不过，这种方式会消耗线程的执行时间检查标识，并且当互斥量上锁后，其他线程就没有办法获取锁，就会持续等待。因为对等待线程资源的限制，并且在任务完成时阻碍对标识的设置。类似于保持清醒状态和列车驾驶员聊了一晚上：驾驶员不得不缓慢驾驶，因为你分散了他的注意力，所以火车需要更长的时间，才能到站。同样，等待的线程会等待更长的时间，也会消耗更多的系统资源。 另外，在等待线程在检查间隙，使用std::this_thread::sleep_for()进行周期性的间歇(详见4.3节)： bool flag; std::mutex m; void wait_for_flag() &#123; std::unique_lock&lt;std::mutex&gt; lk(m); while(!flag) &#123; lk.unlock(); // 1 解锁互斥量 // 所以另外的线程就有机会获取锁并设置标识 std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 2 休眠100ms lk.lock(); // 3 再锁互斥量 &#125; &#125; 循环中，休眠前②函数对互斥量进行解锁①，并且在休眠结束后再对互斥量上锁，所以另外的线程就有机会获取锁并设置标识。 这个实现就进步很多，当线程休眠时没有浪费执行时间，但很难确定正确的休眠时间。太短的休眠和没有一样，都会浪费执行时间。太长的休眠时间，可能会让任务等待时间过久。休眠时间过长比较少见，这会影响到程序的行为，在高节奏的游戏中，就意味着丢帧或错过了一个时间片。 第三个选择(也是优先选择的)，使用C++标准库提供的工具去等待事件的发生。通过另一线程触发等待事件的机制是最基本的唤醒方式(例如：流水线上存在额外的任务时)，这种机制就称为“条件变量”。从概念上来说，条件变量会与多个事件或其他条件相关，并且一个或多个线程会等待条件的达成。当某些线程被终止时，为了唤醒等待线程(允许等待线程继续执行)，终止线程将会向等待着的线程广播“条件达成”的信息。 4.1.1 等待条件达成C++标准库对条件变量有两套实现：**std::condition_variable和std::condition_variable_any，这两个实现都包含在&lt;condition_variable&gt;头文件**的声明中。两者都需要与互斥量一起才能工作(互斥量是为了同步)，前者仅能与std::mutex一起工作，而后者可以和合适的互斥量一起工作，从而加上了_any的后缀。因为** std::condition_variable_any更加通用，不过在性能和系统资源的使用方面会有更多的开销**，所以通常会将std::condition_variable作为首选类型。当对灵活性有要求时，才会考虑std::condition_variable_any。 所以，使用std::condition_variable去处理之前提到的情况——当有数据需要处理时，如何唤醒休眠中的线程？以下代码展示了使用条件变量唤醒线程的方式。 代码4.1 使用std::condition_variable处理数据等待 std::mutex mut; // 所有线程只有这一个互斥量，这个互斥量用于对data_queue的互斥访问 std::queue&lt;data_chunk&gt; data_queue; // 1 std::condition_variable data_cond; // 条件变量，用来通知data准备好的事件 void data_preparation_thread() &#123; while(more_data_to_prepare()) &#123; data_chunk const data=prepare_data(); std::lock_guard&lt;std::mutex&gt; lk(mut); // lock 对mut上锁 data_queue.push(data); // 2 data_cond.notify_one(); // 3 对等待的线程(如果有等待线程)进行通知 // unlock &#125; &#125; void data_processing_thread() &#123; while(true) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); // 4 对mut上锁 data_cond.wait( // 传递一个锁和一个Lambda表达式作为等待的条件 lk,[]&#123;return !data_queue.empty();&#125;); // 5 data_chunk data=data_queue.front(); data_queue.pop(); lk.unlock(); // 6 process(data); if(is_last_chunk(data)) break; &#125; &#125; 首先，队列中中有两个线程，两个线程之间会对数据进行传递①。数据准备好时，使用std::lock_guard锁定队列，将准备好的数据压入队列②之后，线程会对队列中的数据上锁，并调用std::condition_variable的notify_one()成员函数，对等待的线程(如果有等待线程)进行通知③。 另外的一个线程正在处理数据，线程首先对互斥量上锁(这里使用std::unique_lock要比std::lock_guard④更加合适)。之后会调用std::condition_variable的成员函数wait()，**传递一个锁和一个Lambda表达式(作为等待的条件**⑤)。Lambda函数是C++11添加的新特性，可以让一个匿名函数作为其他表达式的一部分，并且非常合适作为标准函数的谓词。例子中，简单的Lambda函数[]&#123;return !data_queue.empty();&#125;会去检查data_queue是否为空，当data_queue不为空，就说明数据已经准备好了。附录A的A.5节有Lambda函数更多的信息。 wait()会去检查这些条件(通过Lambda函数)，当条件满足(Lambda函数返回true)时返回。如果条件不满足(Lambda函数返回false)，wait()将解锁互斥量，并且将线程(处理数据的线程)置于阻塞或等待状态（放到这个条件变量相关的等待线程队列中）。当准备数据的线程调用notify_one()通知条件变量时，（**从等待在这个条件变量上的所有线程中选一个来唤醒，比如这个处理数据的线程）处理数据的线程从睡眠中苏醒，重新获取互斥锁，并且再次进行条件检查。在条件满足的情况下，从wait()返回并继续持有锁。当条件不满足时，线程将对互斥量解锁，并重新等待**。这就是为什么用std::unique_lock而不使用std::lock_guard的原因——等待中的线程必须在等待期间解锁互斥量，并对互斥量再次上锁，而std::lock_guard没有这么灵活。如果互斥量在线程休眠期间保持锁住状态，准备数据的线程将无法锁住互斥量，也无法添加数据到队列中。同样，等待线程也永远不会知道条件何时满足。 代码4.1使用了简单的Lambda函数用于等待⑤(用于检查队列何时不为空)，不过任意的函数和可调用对象都可以传入wait()。当写好函数做为检查条件时，不一定非要放在一个Lambda表达式中，也可以直接将这个函数传入wait()。调用wait()的过程中，在互斥量锁定时，可能会去检查条件变量若干次，当提供测试条件的函数返回true就会立即返回。当等待线程重新获取互斥量并检查条件变量时，并非直接响应另一个线程的通知，就是所谓的伪唤醒(spurious wakeup)。因为任何伪唤醒的数量和频率都是不确定的，所以不建议使用有副作用的函数做条件检查。 本质上， std::condition_variable::wait是“忙碌-等待”的优化。下面用简单的循环实现了一个“忙碌-等待”： template&lt;typename Predicate&gt; void minimal_wait(std::unique_lock&lt;std::mutex&gt;&amp; lk, Predicate pred)&#123; while(!pred())&#123; lk.unlock(); lk.lock(); &#125; &#125; 为wait()准备一个最小化实现，只需要notify_one()或notify_all()。 std::unique_lock的灵活性，不仅适用于对wait()的调用，还可以用于待处理的数据⑥。处理数据可能是耗时的操作，并且长时间持有锁是个糟糕的主意。 **使用队列在多个线程中转移数据(如代码4.1)**很常见。做得好的话，同步操作可以在队列内部完成，这样同步问题和条件竞争出现的概率也会降低。鉴于这些好处，需要从代码4.1中提取出一个通用线程安全的队列。 4.1.2 构建线程安全队列设计通用队列时，就要花时间想想，哪些操作需要添加到队列实现中去，就如之前在3.2.3节看到的线程安全的栈。可以看一下C++标准库提供的实现，找找灵感。std::queue&lt;&gt;容器的接口展示如下： 代码4.2 std::queue接口 template &lt;class T, class Container = std::deque&lt;T&gt; &gt; class queue &#123; public: explicit queue(const Container&amp;); explicit queue(Container&amp;&amp; = Container()); template &lt;class Alloc&gt; explicit queue(const Alloc&amp;); template &lt;class Alloc&gt; queue(const Container&amp;, const Alloc&amp;); template &lt;class Alloc&gt; queue(Container&amp;&amp;, const Alloc&amp;); template &lt;class Alloc&gt; queue(queue&amp;&amp;, const Alloc&amp;); void swap(queue&amp; q); bool empty() const; size_type size() const; T&amp; front(); const T&amp; front() const; T&amp; back(); const T&amp; back() const; void push(const T&amp; x); void push(T&amp;&amp; x); void pop(); template &lt;class... Args&gt; void emplace(Args&amp;&amp;... args); &#125;; 忽略构造、赋值以及交换操作，剩下了三组操作： 对整个队列的状态进行查询(empty()和size()) 查询在队列中的各个元素(front()和back()) 修改队列的操作(push(), pop()和emplace()) 和3.2.3中的栈一样，也会遇到接口上的条件竞争。因此，需要将front()和pop()合并成一个函数调用，就像之前在栈实现时合并top()和pop()一样。与代码4.1不同的是，当队列在多个线程中传递数据时，接收线程通常需要等待数据的压入。这里提供pop()函数的两个变种：try_pop()和wait_and_pop()。 try_pop() ，尝试从队列中弹出数据，即使没有值可检索，也会直接返回。立即返回 wait_and_pop()，将会等待有值可检索的时候才返回。 当使用之前栈的方式来实现队列，接口可能会是下面这样： 代码4.3 线程安全队列的接口 #include &lt;memory&gt; // 为了使用std::shared_ptr template&lt;typename T&gt; class threadsafe_queue &#123; public: threadsafe_queue(); threadsafe_queue(const threadsafe_queue&amp;); threadsafe_queue&amp; operator=( const threadsafe_queue&amp;) = delete; // 不允许简单的赋值 void push(T new_value); bool try_pop(T&amp; value); // 1 在引用变量中返回检索值 std::shared_ptr&lt;T&gt; try_pop(); // 2 返回检索值 void wait_and_pop(T&amp; value); std::shared_ptr&lt;T&gt; wait_and_pop(); bool empty() const; &#125;; 就像之前的栈，裁剪了很多构造函数，并禁止简单赋值。需要提供两个版本的try_pop()和wait_for_pop()。第一个重载的try_pop()①在引用变量中存储着检索值，可以用来返回队列中值的状态。当检索到一个变量时，将返回true，否则返回false(详见A.2节)。第二个重载②就不行了，因为它是用来直接返回检索值的，当没有值可检索时，这个函数返回NULL。 那么问题来了，如何将以上这些和代码4.1相关联呢？从之前的代码中提取push()和wait_and_pop()，如以下代码所示。 代码4.4 从代码4.1中提取push()和wait_and_pop() #include &lt;queue&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; template&lt;typename T&gt; class threadsafe_queue &#123; private: std::mutex mut; std::queue&lt;T&gt; data_queue; std::condition_variable data_cond; public: void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); //lock mut data_queue.push(new_value); data_cond.notify_one(); //notify_one //unlock mut &#125; void wait_and_pop(T&amp; value) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); //lock mut // wait for condition and notify data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); // 执行到这里时检查条件是否满足，如果不满足就释放锁，并被挂起到data_cond相关的等待队列中（当前线程），直到有线程对data_cond调用notify，则会从data_cond相关的等待队列中选择一个线程被唤醒：这个线程先获取锁，然后检查条件是否满足，如果满足则这个线程会从wait()返回继续执行后面的，如果不满足则释放锁，并挂起到data_cond相关的等待队列中 value=data_queue.front(); data_queue.pop(); //unlock mut &#125; &#125;; threadsafe_queue&lt;data_chunk&gt; data_queue; // 1 void data_preparation_thread() &#123; while(more_data_to_prepare()) &#123; data_chunk const data=prepare_data(); data_queue.push(data); // 2 &#125; &#125; void data_processing_thread() &#123; while(true) &#123; data_chunk data; data_queue.wait_and_pop(data); // 3 process(data); if(is_last_chunk(data)) break; &#125; &#125; 线程队列中有互斥量和条件变量，所以独立的变量就不需要了①，并且push()不需要外部同步②。当然，wait_and_pop()还要兼顾条件变量的等待③。 另一个wait_and_pop()的重载写起来就很琐碎，剩下的函数就像从代码3.5实现的栈中粘过来一样。 代码4.5 使用条件变量的线程安全队列(完整版) #include &lt;queue&gt; #include &lt;memory&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; template&lt;typename T&gt; class threadsafe_queue &#123; private: mutable std::mutex mut; // 1 互斥量必须是可变的 std::queue&lt;T&gt; data_queue; std::condition_variable data_cond; public: threadsafe_queue() &#123;&#125; threadsafe_queue(threadsafe_queue const&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lk(other.mut); // lock other.mut // 这个对象还在构造中，因此不用担心其他线程会来通过这个对象访问其中的队列数据，因此不用对mut上锁 data_queue=other.data_queue; // unlock other.mut &#125; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut data_queue.push(new_value); data_cond.notify_one(); // data_cond.notify // unlock mut &#125; void wait_and_pop(T&amp; value) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); // lock mut (unique_lock 因为wait要能够unlock和lock锁) data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); // wait on data_cond value=data_queue.front(); data_queue.pop(); // unlock mut &#125; std::shared_ptr&lt;T&gt; wait_and_pop() &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); // lock mut (unique_lock) data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); // wait on data_cond std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front())); data_queue.pop(); return res; // unlock mut &#125; bool try_pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut if(data_queue.empty()) return false; // unlock mut value=data_queue.front(); data_queue.pop(); return true; // unlock mut &#125; std::shared_ptr&lt;T&gt; try_pop() &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut if(data_queue.empty()) return std::shared_ptr&lt;T&gt;(); // unlock mut std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front())); data_queue.pop(); return res; // unlock mut &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut return data_queue.empty(); // unlock mut &#125; &#125;; empty()是一个const成员函数，并且传入拷贝构造函数的other形参是一个const引用（这个引用不可变，不是说指向的对象不可变）。因为其他线程可能有非const引用对象，并调用变种成员函数，所以这里有必要对互斥量上锁。又因为锁住互斥量是个可变操作，所以互斥量成员必须为mutable①才能在empty()和拷贝构造函数中进行上锁。 条件变量在多个线程等待同一个事件时也很有用。当线程用来分解工作负载，并且只有一个线程可以对通知做出反应时，与代码4.1中结构完全相同。当数据准备完成时，调用notify_one()将会唤醒一个正在wait()的线程，检查条件和wait()函数的返回状态(因为仅是向data_queue添加了一个数据项)。 这里不保证线程一定会被通知到，即使只有一个等待线程收到通知，其他处理线程也有可能因为在处理数据，而忽略了这个通知。 另一种可能是，很多线程等待同一事件。对于通知，都需要做出回应。这会发生在共享数据初始化的时候，当处理线程使用同一数据时，就要等待数据被初始化，或等待共享数据的更新，比如：周期性初始化(periodic reinitialization)。这些情况下，线程准备好数据时，就会通过条件变量调用notify_all()，而非调用notify_one()。顾名思义，这就是全部线程在都去执行wait()(检查他们等待的条件是否满足)的原因。 当条件为true时，等待线程只等待一次，就不会再等待条件变量了，所以尤其是在等待一组可用的数据块时，一个条件变量并非同步操作最好的选择。 接下来就来了解一下future，对于条件变量的补足。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：3.3 保护共享数据的方式","slug":"c++并发编程实践2ed：33 保护共享数据的方式","date":"2022-07-16T13:22:56.918Z","updated":"2022-12-10T15:16:37.146Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：33 保护共享数据的方式/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A33%20%E4%BF%9D%E6%8A%A4%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F/","excerpt":"","text":"3.3 保护共享数据的方式互斥量是一种通用的机制，但其并非保护共享数据的唯一方式。有很多方式可以在特定情况下，对共享数据提供合适的保护。 一个特别极端的情况就是，共享数据在并发访问和初始化时(都需要保护)，需要进行隐式同步。这可能是因为数据作为只读方式创建，所以没有同步问题，或者因为必要的保护作为对数据操作的一部分。任何情况下，数据初始化后锁住一个互斥量，纯粹是为了保护其初始化过程，并且会给性能带来不必要的影响。 出于以上的原因，C++标准提供了一种纯粹保护共享数据初始化过程的机制。 3.3.1 保护共享数据的初始化过程假设有一个共享源，构建代价很昂贵，它可能会打开一个数据库连接或分配出很多的内存。 以下两种初始化方式可能存在竞争条件问题： 延迟初始化延迟初始化(Lazy initialization)在单线程代码很常见——每一个操作都需要先对源进行检查，为了了解数据是否被初始化，然后在其使用前决定，数据是否需要初始化： std::shared_ptr&lt;some_resource&gt; resource_ptr; void foo() &#123; if(!resource_ptr) &#123; resource_ptr.reset(new some_resource); // 1 &#125; resource_ptr-&gt;do_something(); &#125; 转为多线程代码时，只有①处需要保护，这样共享数据对于并发访问就是安全的。但是下面天真的转换会使得线程资源产生不必要的序列化，为了确定数据源已经初始化，每个线程必须等待互斥量。 代码3.11 使用延迟初始化(线程安全)的过程 std::shared_ptr&lt;some_resource&gt; resource_ptr; std::mutex resource_mutex; void foo() &#123; std::unique_lock&lt;std::mutex&gt; lk(resource_mutex); // 所有线程在此序列化 if(!resource_ptr) &#123; resource_ptr.reset(new some_resource); // 只有初始化过程需要保护 &#125; lk.unlock(); resource_ptr-&gt;do_something(); &#125; 这段代码相当常见了，也足够表现出没必要的线程化问题，很多人能想出更好的一些的办法来做这件事，包括声名狼藉的“双重检查锁模式”： void undefined_behaviour_with_double_checked_locking() &#123; if(!resource_ptr) // 1 &#123; std::lock_guard&lt;std::mutex&gt; lk(resource_mutex); if(!resource_ptr) // 2 &#123; resource_ptr.reset(new some_resource); // 3 &#125; &#125; resource_ptr-&gt;do_something(); // 4 &#125; 指针第一次读取数据不需要获取锁①，并且只有在指针为空时才需要获取锁。然后，当获取锁之后，会再检查一次指针② (这就是双重检查的部分)，避免另一线程在第一次检查后再做初始化，并且让当前线程获取锁。 这个模式为什么声名狼藉呢？因为有潜在的条件竞争。未被锁保护的读取操作①没有与其他线程里被锁保护的写入操作③进行同步（*举例？没想出来*），因此就会产生条件竞争，这个条件竞争不仅覆盖指针本身，还会影响到其指向的对象；即使一个线程知道另一个线程完成对指针进行写入，它可能没有看到新创建的some_resource实例，然后调用do_something()④后，得到不正确的结果。这个例子是在一种典型的条件竞争——数据竞争，C++标准中指定为“未定义行为”，这种竞争是可以避免的。阅读第5章时，那里有更多对内存模型的讨论，也包括数据竞争的构成。(译者注：著名的《C++和双重检查锁定模式(DCLP)的风险》可以作为补充材料供大家参考 英文版 中文版) C++标准委员会也认为条件竞争的处理很重要，所以C++标准库提供了std::once_flag和std::call_once来处理这种情况。比起锁住互斥量并显式的检查指针，每个线程只需要使用std::call_once就可以，在std::call_once的结束时，就能安全的知晓指针已经被其他的线程初始化了。使用std::call_once比显式使用互斥量消耗的资源更少，特别是当初始化完成后。下面的例子展示了与代码3.11中的同样的操作，这里使用了std::call_once。这种情况下，初始化通过调用函数完成，这样的操作使用类中的函数操作符来实现同样很简单。如同大多数在标准库中的函数一样，或作为函数被调用，或作为参数被传递，std::call_once可以和任何函数或可调用对象一起使用。 使用std::call_once延迟初始化(线程安全) std::shared_ptr&lt;some_resource&gt; resource_ptr; std::once_flag resource_flag; // 1 void init_resource() &#123; resource_ptr.reset(new some_resource); &#125; void foo() &#123; std::call_once(resource_flag,init_resource); // 可以完整的进行一次初始化 resource_ptr-&gt;do_something(); &#125; 这个例子中，std::once_flag①和初始化好的数据都是命名空间区域的对象，但std::call_once()可仅作为延迟初始化的类型成员，如同下面的例子一样： 代码3.12 使用std::call_once作为类成员的延迟初始化(线程安全) class X &#123; private: connection_info connection_details; connection_handle connection; std::once_flag connection_init_flag; void open_connection() &#123; connection=connection_manager.open(connection_details); &#125; public: X(connection_info const&amp; connection_details_): connection_details(connection_details_) &#123;&#125; void send_data(data_packet const&amp; data) // 1 &#123; std::call_once(connection_init_flag,&amp;X::open_connection,this); // 2 connection.send_data(data); &#125; data_packet receive_data() // 3 &#123; std::call_once(connection_init_flag,&amp;X::open_connection,this); // 2 return connection.receive_data(); &#125; &#125;; 例子中第一次调用send_data()①或receive_data()③的线程完成初始化过程。使用成员函数open_connection()去初始化数据，也需要将this指针传进去。和标准库中的函数一样，接受可调用对象，比如std::thread的构造函数和std::bind()，通过向std::call_once()②传递一个额外的参数来完成这个操作。 值得注意的是，**std::mutex和std::once_flag的实例不能拷贝和移动**，需要通过显式定义相应的成员函数，对这些类成员进行操作。 static类型的局部变量 c++11编译器会阻止这种竞争还有一种初始化过程中潜存着条件竞争：其中一个局部变量为static类型（static类型的变量会存放在进程地址空间的data区，这个区是为一个进程的多个线程所共享的），这种变量的在声明后就已经完成初始化。对于多线程调用的函数，这就意味着这里有条件竞争——抢着去定义这个变量。很多在不支持C++11标准的编译器上，在实践过程中，这样的条件竞争是确实存在的，因为在多线程中，每个线程都认为他们是第一个初始化这个变量线程，或一个线程对变量进行初始化，而另外一个线程要使用这个变量时，初始化过程还没完成。在C++11标准中，这些问题都被解决了：初始化及定义完全在一个线程中发生，并且没有其他线程可在初始化完成前对其进行处理，条件竞争终止于初始化阶段，这样比在之后再去处理好的多。在只需要一个全局实例情况下，这里提供一个std::call_once的替代方案 class my_class; my_class&amp; get_my_class_instance() &#123; static my_class instance; // 线程安全的初始化过程 return instance; &#125; 多线程可以安全的调用get_my_class_instance()①函数，不用为数据竞争而担心。 对于很少有更新的数据结构来说，只在初始化时保护数据。大多数情况下，这种数据结构是只读的，并且多线程对其并发的读取也是很愉快的，不过一旦数据结构需要更新就会产生竞争。 3.3.2 保护不常更新的数据结构 读者-作者锁c++17试想为了将域名解析为其相关IP地址，在缓存中的存放了一张DNS入口表。通常，给定DNS数目在很长的时间内保持不变。虽然，用户访问不同网站时，新的入口可能会被添加到表中，但是这些数据可能在其生命周期内保持不变。所以定期检查缓存中入口的有效性就变的十分重要。但也需要一次更新，也许这次更新只是对一些细节做了改动。 虽然更新频度很低，但也有可能发生，并且当缓存多个线程访问时，这个缓存就需要保护更新时状态的状态，也是为了确保每个线程读到都是有效数据。 没有使用专用数据结构时，这种方式是符合预期的，并为并发更新和读取进行了特别设计(更多的例子在第6和第7章中介绍)。这样的更新要求线程独占数据结构的访问权，直到更新操作完成。当完成更新时，数据结构对于并发多线程的访问又会是安全的。使用std::mutex来保护数据结构，感觉有些反应过度(因为在没有发生修改时，它将削减并发读取数据的可能性)。这里需要另一种不同的互斥量，这种互斥量常被称为“读者-作者锁”，因为其允许两种不同的使用方式：一个“作者”线程独占访问和共享访问，让多个“读者”线程并发访问。 C++17标准库提供了两种非常好的互斥量——**std::shared_mutex和std::shared_timed_mutex。C++14只提供了std::shared_timed_mutex，并且在C++11中并未提供任何互斥量类型。如果还在用支持C++14标准之前的编译器，可以使用Boost库中的互斥量。std::shared_mutex和std::shared_timed_mutex的不同点在于，std::shared_timed_mutex支持更多的操作方式(参考4.3节)，std::shared_mutex有更高的性能优势**，但支持的操作较少。 第8章中会看到，这种锁的也不能包治百病，其性能依赖于参与其中的处理器数量，同样也与读者和作者线程的负载有关。为了确保增加复杂度后还能获得性能收益，目标系统上的代码性能就很重要。 比起使用std::mutex实例进行同步，不如使用std::shared_mutex来做同步。 对于更新操作，可以使用**std::lock_guard&lt;std::shared_mutex&gt;和std::unique_lock&lt;std::shared_mutex&gt;上锁**。作为std::mutex的替代方案，与std::mutex所做的一样，这就能保证更新线程的独占访问。 那些无需修改数据结构的线程，可以使用**std::shared_lock&lt;std::shared_mutex&gt;获取访问权。这种RAII类型模板是在C++14中的新特性，这与使用std::unique_lock一样，除了多线程可以同时获取同一个std::shared_mutex的共享锁。唯一的限制：当有线程拥有共享锁时，尝试获取独占锁的线程会被阻塞，直到所有其他线程放弃锁。当任一线程拥有一个独占锁时，其他线程就无法获得共享锁或独占锁**，直到第一个线程放弃其拥有的锁。 如同之前描述的那样，下面的代码清单展示了一个简单的DNS缓存，使用std::map持有缓存数据，使用std::shared_mutex进行保护。 代码3.13 **使用std::shared_mutex**对数据结构进行保护 #include &lt;map&gt; #include &lt;string&gt; #include &lt;mutex&gt; #include &lt;shared_mutex&gt; class dns_entry; class dns_cache &#123; std::map&lt;std::string,dns_entry&gt; entries; mutable std::shared_mutex entry_mutex; // std::shared_mutex public: dns_entry find_entry(std::string const&amp; domain) const &#123; std::shared_lock&lt;std::shared_mutex&gt; lk(entry_mutex); // 1 读者，shared_lock std::map&lt;std::string,dns_entry&gt;::const_iterator const it= entries.find(domain); return (it==entries.end())?dns_entry():it-&gt;second; &#125; void update_or_add_entry(std::string const&amp; domain, dns_entry const&amp; dns_details) &#123; std::lock_guard&lt;std::shared_mutex&gt; lk(entry_mutex); // 2 写者，lock_guard entries[domain]=dns_details; &#125; &#125;; 代码3.13中，find_entry()使用std::shared_lock&lt;&gt;来保护共享和只读权限①。这就使得多线程可以同时调用find_entry()，且不会出错。另一方面，update_or_add_entry()使用std::lock_guard&lt;&gt;实例，当表格需要更新时②，为其提供独占访问权限。update_or_add_entry()函数调用时，独占锁会阻止其他线程对数据结构进行修改，并且阻止线程调用find_entry()。 3.3.3 嵌套锁线程对已经获取的std::mutex(已经上锁)再次上锁是错误的，尝试这样做会导致未定义行为。在某些情况下，一个线程会尝试在释放一个互斥量前多次获取。因此，C++标准库提供了**std::recursive_mutex类。除了可以在同一线程的单个实例上多次上锁，其他功能与std::mutex相同。其他线程对互斥量上锁前，当前线程必须释放拥有的所有锁**，所以如果你调用lock()三次，也必须调用unlock()三次。正确使用std::lock_guard&lt;std::recursive_mutex&gt;和std::unique_lock&lt;std::recursive_mutex&gt;可以帮你处理这些问题。 使用嵌套锁时，要对代码设计进行改动。嵌套锁一般用在可并发访问的类上，所以使用互斥量保护其成员数据。每个公共成员函数都会对互斥量上锁，然后完成对应的操作后再解锁互斥量。不过，有时成员函数会调用另一个成员函数，这种情况下，第二个成员函数也会试图锁住互斥量，这就会导致未定义行为的发生。“变通的”解决方案会将互斥量转为嵌套锁，第二个成员函数就能成功的进行上锁，并且函数能继续执行。 但是这种方式过于草率和不合理，所以不推荐这样的使用方式。特别是，对应类的不变量通常会被破坏。这意味着，当不变量被破坏时，第二个成员函数还需要继续执行。一个比较好的方式是，从中提取出一个函数作为类的私有成员，**这个私有成员函数不会对互斥量进行上锁(调用前必须获得锁)**。然后，需要仔细考虑一下，这种情况调用新函数时数据的状态。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：3.2 使用互斥量","slug":"c++并发编程实践2ed：32 使用互斥量","date":"2022-07-16T13:19:19.631Z","updated":"2022-12-10T15:16:46.157Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：32 使用互斥量/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A32%20%E4%BD%BF%E7%94%A8%E4%BA%92%E6%96%A5%E9%87%8F/","excerpt":"","text":"竞争条件一个来源：指令级并发 std::lock_guard和std::unique_lock对象，都是为构造它们时传入的第一个参数提供锁服务的，这两种类型的对象**拥有的资源是对 构造函数传递给他们的第一个参数这个资源 的关联，以及如果他们拥有的这个资源上了锁的话，上的这把锁（这把锁其实是那个资源类内部实现的）也是**（移动语义即转移这俩给别的对象） 资源类有lock() unlock() try_lock()成员函数 lock_guard：std::lock_guard&lt;std::mutex&gt; guard(some_mutex); 则guard对象提供对std::mutex类型的实例some_mutex提供锁保护，具体而言是在构造guard对象后就对some_mutex上锁（会构造一把锁然后上锁），guard析构时释放锁 如果传入**第二个参数std::adopt_lock**则告诉guard使用some_mutex上面已经加的锁，并且将该锁的管理交给guard unique_lock：std::unique_lock&lt;std::mutex&gt; ulock(some_mutex); 则ulock对象提供对std::mutex类型的实例some_mutex提供锁保护，具体而言是在构造ulock对象后就对some_mutex上锁，ulock析构时释放锁（如果ulock相关联的资源some_mutex有锁的话） 如果传入**第二个参数std::adopt_lock**则告诉ulock使用some_mutex上面已经加的锁，而不用另外构建锁（如果没有传入第二个参数，则在ulock构造函数中会构造对some_mutex的锁然后上锁），并且将该锁的管理交给ulock 如果传入**第二个参数std::defer_lock**则ulock与资源some_mutex相关联，但是不新构造对some_mutex的锁也不上锁 ulock有**成员函数lock()和unlock()和try_lock()**来在std::unique_lock类型对象构造后销毁前进行锁申请和锁释放（这个lock_guard类型没有，也因为要实现这个，unique_lock类型比lock_guard类型占用内存更大（比如一些对于锁状态记录的标志），开销也更多一点（比如一些对于锁状态的检查）） 3.2 使用互斥量你肯定不想让共享数据陷入条件竞争，或是出现破坏不变量的情况。将所有访问共享数据的代码标记为互斥是否是一种更好的办法呢？这样，任何一个线程在执行时，其他线程就必须进行等待。除非该线程在修改共享数据，否则任何线程都不可能会看到不变量的中间状态。 访问共享数据前，将数据锁住，在访问结束后，再将数据解锁。线程库需要保证，当线程使用互斥量锁住共享数据时，其他的线程都必须等到之前那个线程对数据进行解锁后，才能进行访问数据。 互斥量是C++保护数据最通用的机制，但也需要编排代码来保护数据的正确性(见3.2.2节)，并避免接口间的条件竞争(见3.2.3节)也非常重要。不过，互斥量也会造成死锁(见3.2.4节)，或对数据保护的太多(或太少)(见3.2.8节)。 3.2.1 互斥量通过实例化**std::mutex创建互斥量实例，成员函数lock()可对互斥量上锁，unlock()为解锁。不过，不推荐直接去调用成员函数，调用成员函数就意味着，必须在每个函数出口都要去调用unlock()(包括异常的情况)。C++标准库为互斥量提供了RAII模板类std::lock_guard，在构造时（对互斥量上锁**）就能提供已锁的互斥量，并在析构时进行解锁，从而保证了互斥量能被正确解锁。下面的代码中，展示了如何在多线程应用中，使用std::mutex构造的std::lock_guard实例，对列表进行访问保护。(std::mutex和std::lock_guard都在**&lt;mutex&gt;头文件**中声明。) 代码3.1 使用互斥量保护列表 不是 直接锁住要控制为互斥访问的资源some_list，而是锁住some_mutex，这个互斥量对于所有竞争线程只有一个，因此一个线程占有some_mutex时，其他线程无法占有，而对于some_list的操作一定在some_mutex被锁住之后到被解锁之前，由此提供对some_list的互斥访问 #include &lt;list&gt; #include &lt;mutex&gt; #include &lt;algorithm&gt; std::list&lt;int&gt; some_list; // 1 std::mutex some_mutex; // 2 void add_to_list(int new_value) &#123; std::lock_guard&lt;std::mutex&gt; guard(some_mutex); // 3 构造时对some_mutex上锁 some_list.push_back(new_value); // guard析构时对some_mutex解锁 &#125; bool list_contains(int value_to_find) &#123; std::lock_guard&lt;std::mutex&gt; guard(some_mutex); // 4 构造时对some_mutex上锁 return std::find(some_list.begin(),some_list.end(),value_to_find) != some_list.end(); // guard析构时对some_mutex解锁 &#125; 代码3.1中有一个全局变量①，这个全局变量被一个全局的互斥量保护②。add_to_list()③和list_contains()④函数中使用std::lock_guard&lt;std::mutex&gt;，使得这两个函数中对数据的访问是互斥的：list_contains()不可能看到正在被add_to_list()修改的列表。 C++17中添加了一个新特性，称为模板类参数推导，类似std::lock_guard这样简单的模板类型，其模板参数列表可以省略。③和④的代码可以简化成： std::lock_guard guard(some_mutex); 具体的模板参数类型推导则交给C++17的编译器完成。3.2.4节中，会介绍C++17中的一种加强版数据保护机制——std::scoped_lock，所以在C++17的环境下，上面的这行代码也可以写成： std::scoped_lock guard(some_mutex); 为了让代码更加清晰，并且兼容只支持C++11标准的编译器，我会继续使用std::lock_guard，并在代码中写明模板参数的类型。 某些情况下使用全局变量没问题，但大多数情况下，互斥量通常会与需要保护的数据放在同一类中，而不是定义成全局变量。这是面向对象设计的准则：将其放在一个类中，就可让他们联系在一起，也可对类的功能进行封装，并进行数据保护。这种情况下，函数add_to_list和list_contains可以作为这个类的成员函数。互斥量和需要保护的数据，在类中都定义为private成员，这会让代码更清晰，并且方便了解什么时候对互斥量上锁。所有成员函数都会在调用时对数据上锁，结束时对数据解锁，这就保证了访问时数据不变量的状态稳定。 当然，也不是总能那么理想：当其中一个成员函数返回的是保护数据的指针或引用时，也会破坏数据。具有访问能力的指针或引用可以访问(并可能修改)保护数据，而不会被互斥锁限制。这就需要对接口谨慎设计，要确保互斥量能锁住数据访问，并且不留后门。 3.2.2 保护共享数据使用互斥量来保护数据，并不是在每一个成员函数中加入一个std::lock_guard对象那么简单。一个指针或引用，也会让这种保护形同虚设。不过，检查指针或引用很容易，只要没有成员函数通过返回值或者输出参数的形式，向其调用者返回指向受保护数据的指针或引用，数据就是安全的。确保成员函数不会传出指针或引用的同时，检查成员函数是否通过指针或引用的方式来调用也是很重要的(尤其是这个操作不在你的控制下时)。函数可能没在互斥量保护的区域内存储指针或引用，这样就很危险。更危险的是：将保护数据作为一个运行时参数，如同下面代码中所示。 代码3.2 无意中传递了保护数据的引用 class some_data &#123; int a; std::string b; public: void do_something(); &#125;; class data_wrapper &#123; private: some_data data; std::mutex m; public: template&lt;typename Function&gt; void process_data(Function func) &#123; std::lock_guard&lt;std::mutex&gt; l(m); func(data); // 1 传递“保护”数据给用户函数 &#125; &#125;; some_data* unprotected; void malicious_function(some_data&amp; protected_data) &#123; unprotected=&amp;protected_data; &#125; data_wrapper x; void foo() &#123; x.process_data(malicious_function); // 2 传递一个恶意函数 unprotected-&gt;do_something(); // 3 在无保护的情况下访问保护数据 &#125; 例子中process_data看起来没有问题，std::lock_guard对数据做了很好的保护，但调用用户提供的函数func①，就意味着foo能够绕过保护机制将函数malicious_function传递进去②，可以在没有锁定互斥量的情况下调用do_something()。 这段代码的问题在于根本没有保护，只是将所有可访问的数据结构代码标记为互斥。函数foo()中调用unprotected-&gt;do_something()的代码未能被标记为互斥。这种情况下，C++无法提供任何帮助，只能由开发者使用正确的互斥锁来保护数据。从乐观的角度上看，还是有方法的：**切勿将受保护数据的指针或引用传递到互斥锁作用域之外**。 虽然，这是使用互斥量保护共享数据时常犯的错误，但绝不仅仅是一个潜在的陷阱。下一节中，即便是使用了互斥量对数据进行保护，条件竞争可能依旧存在。 3.2.3 接口间的条件竞争问题使用了互斥量或其他机制保护了共享数据，就不必再为条件竞争所担忧吗？并不是，依旧需要确定数据是否受到了保护。回想之前双链表的例子，为了能让线程安全地删除一个节点，需要确保防止对这三个节点(待删除的节点及其前后相邻的节点)的并发访问。如果只对指向每个节点的指针进行访问保护，那就和没有使用互斥量一样，条件竞争仍会发生——除了指针，整个数据结构和整个删除操作需要保护。这种情况下最简单的解决方案就是使用互斥量来保护整个链表，如代码3.1所示。 尽管链表的个别操作是安全的，但依旧可能遇到条件竞争。例如，构建一个类似于std::stack的栈(代码3.3)，除了构造函数和swap()以外，需要对std::stack提供五个操作：push()一个新元素进栈，pop()一个元素出栈，top()查看栈顶元素，empty()判断栈是否是空栈，size()了解栈中有多少个元素。即使修改了top()，返回一个拷贝而非引用(即遵循了3.2.2节的准则)，这个接口仍存在条件竞争。这个问题不仅存在于互斥量实现接口中，在无锁实现接口中，也会产生条件竞争。这是接口的问题，与实现方式无关。 代码3.3 std::stack容器的实现 template&lt;typename T,typename Container=std::deque&lt;T&gt; &gt; class stack &#123; public: explicit stack(const Container&amp;); explicit stack(Container&amp;&amp; = Container()); template &lt;class Alloc&gt; explicit stack(const Alloc&amp;); template &lt;class Alloc&gt; stack(const Container&amp;, const Alloc&amp;); template &lt;class Alloc&gt; stack(Container&amp;&amp;, const Alloc&amp;); template &lt;class Alloc&gt; stack(stack&amp;&amp;, const Alloc&amp;); bool empty() const; size_t size() const; T&amp; top(); T const&amp; top() const; void push(T const&amp;); void push(T&amp;&amp;); void pop(); void swap(stack&amp;&amp;); template &lt;class... Args&gt; void emplace(Args&amp;&amp;... args); // C++14的新特性 &#125;; 虽然empty()和size()可能在返回时是正确的，但结果不可靠。当返回后，其他线程就可以自由地访问栈，并且可能push()多个新元素到栈中，也可能pop()一些已在栈中的元素。这样的话，之前从empty()和size()得到的数值就有问题了。 非共享的栈对象，如果栈非空，使用empty()检查再调用top()访问栈顶部的元素是安全的。如下代码所示： stack&lt;int&gt; s; if (! s.empty())&#123; // 1 int const value = s.top(); // 2 s.pop(); // 3 do_something(value); &#125; 不仅在单线程代码中安全，而且在空堆栈上调用top()是未定义的行为也符合预期。对于共享的栈对象，这样的调用顺序就不再安全，因为**在调用empty()①和调用top()②之间，可能有来自另一个线程的pop()调用并删除了最后一个元素**。这是一个经典的条件竞争，使用互斥量对栈内部数据进行保护，但依旧不能阻止条件竞争的发生，这就是接口固有的问题。 怎么解决呢？问题发生在接口设计上，所以解决的方法就是变更接口设计。怎么改？这个简单的例子中调用top()时，发现栈已经是空，就抛出异常。这能直接解决这个问题，但这是一个笨拙的解决方案，这样的话，即使empty()返回false的情况下，也需要进行异常捕获。本质上，这会让empty()成为一个多余函数。 仔细的观察之前的代码段，在调用top()②和pop()③之间会发现另一个潜在的条件竞争。假设两个线程运行着前面的代码，并且都引用同一个栈对象。当为性能而使用线程时，多个线程在不同的数据上执行相同的操作很正常，并且共享栈可以将工作进行分摊。假设，一开始栈中只有两个元素，这时任一线程上的empty()和top()都存在竞争，只需要考虑可能的执行顺序即可。 内部互斥量保护栈时，只有一个线程可以调用栈的成员函数，所以调用可以很好地交错，并且do_something()是可以并发运行的。在表3.1中，展示一种可能的执行顺序。 表3.1 一种可能执行顺序 Thread A Thread B if (!s.empty); if(!s.empty); int const value &#x3D; s.top(); int const value &#x3D; s.top(); s.pop(); do_something(value); s.pop(); do_something(value); 当线程运行时，调用两次top()，没修改栈，所以每个线程能得到同样的值。不仅是这样，调用top()的过程中(两次)，都没有调用pop()函数。这样，在其中一个值再读取的时候，虽然不会出现“写后读”的情况，但其值已处理了两次。这种条件竞争，比未定义的empty()&#x2F;top()竞争更加严重。虽然结果依赖于do_something()的结果，但因为看起来没有任何错误，就会让这个Bug更难定位。 这就需要接口设计上有较大的改动，提议之一就是使用同一互斥量来保护top()和pop()。Tom Cargill[1]指出当拷贝构造函数在栈中抛出一个异常，这样的处理方式就会有问题。在Herb Sutter[2]看来，这个问题可以从“异常安全”的角度完美解决，不过潜在的条件竞争，可能会组成一些新的组合。 说一些大家没有意识到的问题：假设有一个stack&lt;vector&lt;int&gt;&gt;，vector是一个动态容器，当拷贝一个vector，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败，所以vector的拷贝构造函数可能会抛出一个std::bad_alloc异常。当vector中存有大量元素时，这种情况发生的可能性更大。当pop()函数返回“弹出值”时(也就是从栈中将这个值移除)，会有一个潜在的问题：这个值返回到调用函数的时候，栈才被改变（比如元素计数）。但拷贝数据的时候，调用函数抛出一个异常会怎么样？ 如果真的发生了，要弹出的数据将会丢失，它的确从栈上移出了，但是拷贝失败了！std::stack的设计人员将这个操作分为两部分：先获取顶部元素(top())，然后从栈中移除(pop())。这样，在不能安全的将元素拷贝出去的情况下，栈中的这个数据还依旧存在，没有丢失。当问题是堆空间不足，应用可能会释放一些内存，然后再进行尝试。 不幸的是，这样的分割却制造了本想避免的条件竞争。幸运的是，我们还有的别的选项，但使用每个选项都有相应的代价。 选项1： 传入一个引用 选项1的意思：修改pop函数的接口设计为 通过引用参数返回栈顶元素 第一个选项是将变量的引用作为参数，传入pop()函数中获取“弹出值”： std::vector&lt;int&gt; result; some_stack.pop(result); 这种方式还不错，缺点也很明显：需要构造出一个栈中类型的实例，用于接收目标值。对于一些类型，这样做是不现实的，因为临时构造一个实例，从时间和资源的角度上来看都不划算。对于其他的类型，这样也不总行得通，因为构造函数需要的参数，在这个阶段不一定可用。最后，需要可赋值的存储类型，这是一个重大限制：即使支持移动构造，甚至是拷贝构造(从而允许返回一个值)，很多用户自定义类型可能都不支持赋值操作。 选项2：无异常抛出的拷贝构造函数或移动构造函数 选项2的意思：使用有返回值的pop接口设计（删除栈顶元素，返回栈顶元素）（这样的接口设计可以解决“top()和无返回值和引用参数的pop()的接口设计”产生的竞争条件问题（一个线程调用top之后，在其调用pop之前，可能其他线程删除了栈顶）），则同时要求 栈中元素类型 有无异常抛出的拷贝构造函数或移动构造函数，这样在pop返回值的时候，不会因为在构造返回值的过程中（通过拷贝构造函数或移动构造函数进行的）抛出异常，而导致已经删除了栈顶元素却无法获取栈顶元素即栈顶元素丢失的情况 对于有返回值的pop()函数来说，只有“异常安全”方面的担忧(当返回值时可以抛出一个异常)。很多类型都有拷贝构造函数，它们不会抛出异常，并且随着新标准中对“右值引用”的支持(详见附录A，A.1节)，很多类型都将会有一个移动构造函数，即使他们和拷贝构造函数做着相同的事情，也不会抛出异常。一个有用的选项可以限制对线程安全栈的使用，并且能让栈安全的返回所需的值，而不抛出异常。 虽然安全，但非可靠。尽管能在编译时可使用std::is_nothrow_copy_constructible和std::is_nothrow_move_constructible，让拷贝或移动构造函数不抛出异常，但是这种方式的局限性太强。用户自定义的类型中，会有不抛出异常的拷贝构造函数或移动构造函数的类型， 那些有抛出异常的拷贝构造函数，但没有移动构造函数的类型往往更多(这种情况会随着人们习惯于C++11中的右值引用而有所改变)。如果这些类型不能存储在线程安全的栈中，那将是多么的不幸。 选项3：返回指向弹出值的指针第三个选择是返回一个指向弹出元素的指针，而不是直接返回值。指针的优势是自由拷贝，并且不会产生异常，这样就能避免Cargill提到的异常问题了。缺点就是返回指针需要对对象的内存分配进行管理，对于简单数据类型(比如:int)，内存管理的开销要远大于直接返回值。对于这个方案，使用std::shared_ptr是个不错的选择，不仅能避免内存泄露(因为当对象中指针销毁时，对象也会被销毁)，而且标准库能够完全控制内存分配方案，就不需要new和delete操作。这种优化是很重要的：因为堆栈中的每个对象，都需要用new进行独立的内存分配，相较于非线程安全版本，这个方案的开销相当大。 选项4：“选项1 + 选项2”或 “选项1 + 选项3”对于通用的代码来说，灵活性不应忽视。当已经选择了选项2或3时，再去选择1也是很容易的。这些选项提供给用户，让用户自己选择最合适，最经济的方案。 举例例：定义线程安全的堆栈 代码3.4中是一个接口没有条件竞争的堆栈类定义，它实现了选项1和选项3：重载了pop()，使用局部引用去存储弹出值，并返回std::shared_ptr&lt;&gt;对象。它有一个简单的接口，只有两个函数：push()和pop(); 代码3.4 线程安全的堆栈类定义(概述) #include &lt;exception&gt; #include &lt;memory&gt; // For std::shared_ptr&lt;&gt; struct empty_stack: std::exception &#123; const char* what() const throw(); &#125;; template&lt;typename T&gt; class threadsafe_stack &#123; public: threadsafe_stack(); threadsafe_stack(const threadsafe_stack&amp;); threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; // 1 赋值操作被删除 void push(T new_value); std::shared_ptr&lt;T&gt; pop(); void pop(T&amp; value); bool empty() const; &#125;; 削减接口可以获得最大程度的安全,甚至限制对栈的一些操作。栈是不能直接赋值的，因为赋值操作已经删除了①(详见附录A，A.2节)，并且这里没有swap()函数。当栈为空时，pop()函数会抛出一个empty_stack异常，所以在empty()函数被调用后，其他部件还能正常工作。如选项3描述的那样，使用std::shared_ptr可以避免内存分配管理的问题，并避免多次使用new和delete操作。堆栈中的五个操作，现在就剩下三个：push(), pop()和empty()(这里empty()都有些多余)。简化接口更有利于数据控制，可以保证互斥量将操作完全锁住。下面的代码展示了一个简单的实现——封装std::stack&lt;&gt;的线程安全堆栈。 代码3.5 扩充(线程安全)堆栈 #include &lt;exception&gt; #include &lt;memory&gt; #include &lt;mutex&gt; #include &lt;stack&gt; struct empty_stack: std::exception &#123; const char* what() const throw() &#123; return &quot;empty stack!&quot;; &#125;; &#125;; template&lt;typename T&gt; class threadsafe_stack &#123; private: std::stack&lt;T&gt; data; mutable std::mutex m; public: threadsafe_stack() : data(std::stack&lt;T&gt;())&#123;&#125; threadsafe_stack(const threadsafe_stack&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lock(other.m); data = other.data; // 1 在构造函数体中的执行拷贝 &#125; threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); data.push(new_value); &#125; std::shared_ptr&lt;T&gt; pop() &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否为空 std::shared_ptr&lt;T&gt; const res(std::make_shared&lt;T&gt;(data.top())); // 在修改堆栈前，分配出返回值 data.pop(); return res; &#125; void pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); value=data.top(); data.pop(); &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lock(m); return data.empty(); &#125; &#125;; 堆栈可以拷贝——拷贝构造函数对互斥量上锁，再拷贝堆栈。构造函数体中①的拷贝使用互斥量来确保复制结果的正确性，这样的方式比成员初始化列表好。 之前对top()和pop()函数的讨论中，因为锁的粒度太小，恶性条件竞争已经出现，需要保护的操作并未全覆盖到。不过，锁的颗粒度过大同样会有问题。还有一个问题，一个全局互斥量要去保护全部共享数据，在一个系统中存在有大量的共享数据时，线程可以强制运行，甚至可以访问不同位置的数据，抵消了并发带来的性能提升。第一版为多处理器系统设计Linux内核中，就使用了一个全局内核锁。这个锁能正常工作，但在双核处理系统的上的性能要比两个单核系统的性能差很多，四核系统就更不能提了。太多请求去竞争占用内核，使得依赖于处理器运行的线程没有办法很好的工作。随后修正的Linux内核加入了一个细粒度锁方案，因为少了很多内核竞争，这时四核处理系统的性能就和单核处理的四倍差不多了。 使用多个互斥量保护所有的数据，细粒度锁也有问题。如前所述，当增大互斥量覆盖数据的粒度时，只需要锁住一个互斥量。但这种方案并非放之四海皆准，互斥量保护一个独立类的实例，锁的状态的下一个阶段，不是离开锁定区域将锁定区域还给用户，就是有独立的互斥量去保护这个类的全部实例，两种方式都不怎么好。 一个给定操作需要两个或两个以上的互斥量时，另一个潜在的问题将出现：死锁。与条件竞争完全相反——不同的两个线程会互相等待，从而什么都没做。 3.2.4 死锁：问题描述及解决方案试想有一个玩具，这个玩具由两部分组成，必须拿到这两个部分，才能够玩。例如玩具鼓，需要鼓锤和鼓才能玩。有两个小孩，他们都很喜欢玩这个玩具。当其中一个孩子拿到了鼓和鼓锤时，那就可以尽情的玩耍了。当另一孩子想要玩，他就得等待另一孩子玩完才行。再试想，鼓和鼓锤被放在不同的玩具箱里，并且两个孩子在同一时间里都想要去敲鼓。之后，他们就去玩具箱里面找这个鼓。其中一个找到了鼓，并且另外一个找到了鼓锤。现在问题就来了，除非其中一个孩子决定让另一个先玩，他可以把自己的那部分给另外一个孩子。但当他们都紧握着自己所有的部分，那么这个鼓谁都没法玩。 现在没有孩子去争抢玩具，但线程有对锁的竞争：一对线程需要对他们所有的互斥量做一些操作，其中每个线程都有一个互斥量，且等待另一个解锁。因为他们都在等待对方释放互斥量，没有线程能工作。这种情况就是死锁，它的问题就是由两个或两个以上的互斥量进行锁定。 避免死锁的一般建议，就是让两个互斥量以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。某些情况下是可以这样用，因为不同的互斥量用于不同的地方。不过，当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要避免并发修改数据，并确保每个实例上的互斥量都能锁住自己要保护的区域。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了！ 很幸运，C++标准库有办法解决这个问题，**std::lock()——可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)**。下面的程序代码中，就来看一下怎么在一个简单的交换操作中使用std::lock。 代码3.6 交换操作中使用std::lock()和std::lock_guard // 这里的std::lock()需要包含&lt;mutex&gt;头文件 class some_big_object; void swap(some_big_object&amp; lhs,some_big_object&amp; rhs); class X &#123; private: some_big_object some_detail; std::mutex m; public: X(some_big_object const&amp; sd):some_detail(sd)&#123;&#125; friend void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; std::lock(lhs.m,rhs.m); // 1 std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m,std::adopt_lock); // 2 std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m,std::adopt_lock); // 3 swap(lhs.some_detail,rhs.some_detail); &#125; &#125;; 首先检查参数，因为操作试图获取std::mutex对象上的锁，所以结果很难预料。(互斥量可以在同一线程上多次上锁，标准库中std::recursive_mutex提供这样的功能。详情见3.3.3节)。然后，调用std::lock()①锁住两个互斥量，并且创建两个std:lock_guard实例②③。 提供**std::adopt_lock参数除了表示std::lock_guard可获取锁之外，还将锁（std::lock对lhs.m,rhs.m已经上的锁）交由std::lock_guard管理，就不需要std::lock_guard再去构建新的锁**了。 这样，就能保证在大多数情况下【为啥说是大多数情况下？】，函数退出时互斥量能解锁(保护操作可能会抛出一个异常)，也允许使用一个简单的“return”作为返回。当使用std::lock去锁lhs.m或rhs.m时，可能会抛出异常，异常会传播到std::lock之外。当std::lock获取互斥锁时，并尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常而自动释放，所以**std::lock要么将两个锁都锁住，要不一个都不锁**。 C++17对这种情况提供了支持，std::scoped_lock&lt;&gt;是一种新的RAII模板类型，与 std::lock_guard&lt;&gt;的功能相同，这个新类型能接受不定数量的互斥量类型作为模板参数，以及相应的互斥量(数量和类型)作为构造参数。互斥量支持构造时上锁，与std::lock的用法相同，解锁在析构中进行。代码3.6中swap()操作可以重写如下： void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; std::scoped_lock guard(lhs.m,rhs.m); // 1 swap(lhs.some_detail,rhs.some_detail); &#125; 这里使用了C++17的另一个特性：自动推导模板参数。如果有支持C++17的编译器(就能使用std::scoped_lock了，因为其是C++17标准库中的一个工具)，C++17可以通过隐式参数模板类型推导机制， 通过传递的对形象类型来构造实例①。这行代码等价于下面全给参数的版本： std::scoped_lock&lt;std::mutex,std::mutex&gt; guard(lhs.m,rhs.m); std::scoped_lock的好处在于，可以将所有std::lock替换掉，从而减少错误的发生。 虽然std::lock(和std::scoped_lock&lt;&gt;)可以在这情况下(获取两个以上的锁)避免死锁，但它没办法帮助你获取其中一个锁。这需要依赖开发者的纪律性(译者：也就是经验)，来确保程序不会死锁。 死锁是多线程编程中令人相当头痛的问题，并且死锁经常是不可预见的，因为在大部分时间里，所有工作都能很好的完成。不过，一些相对简单的规则能帮助写出“无死锁”的代码。 3.2.5 避免死锁的进阶指导死锁通常是对锁的使用不当造成。无锁的情况下，仅需要两个线程std::thread对象互相调用join()就能产生死锁。这种情况下，没有线程可以继续运行，因为他们正在互相等待。这种情况很常见，一个线程会等待另一个线程，其他线程同时也会等待第一个线程结束，所以三个或更多线程的互相等待也会发生死锁。为了避免死锁，这里意见：不要谦让。以下提供一些个人建议。 避免嵌套锁第一个建议往往是最简单的：线程获得一个锁时，就别再去获取第二个。每个线程只持有一个锁，就不会产生死锁。**当需要获取多个锁，使用std::lock**来做这件事(对获取锁的操作上锁)，避免产生死锁。 避免在持有锁时调用外部代码第二个建议是次简单的：因为代码是外部提供的，所以没有办法确定外部要做什么。外部程序可能做任何事情，包括获取锁。在持有锁的情况下，如果用外部代码要获取一个锁，就会违反第一个指导意见，并造成死锁(有时这是无法避免的)。当写通用代码时(例如3.2.3中的栈)，每一个操作的参数类型，都是外部提供的定义，这就需要其他指导意见来帮助你了。 使用固定顺序获取锁当硬性要求获取两个或两个以上的锁，并且不能使用std::lock单独操作来获取它们时，最好在每个线程上，用固定的顺序获取它们(锁)。3.2.4节中提到，当需要获取两个互斥量时，需要以一定的顺序获取锁。一些情况下，这种方式相对简单。比如，3.2.3节中的栈——每个栈实例中都内置有互斥量，但是对数据成员存储的操作上，栈就需要调用外部代码。虽然，可以添加一些约束，对栈上存储的数据项不做任何操作，但对数据项的处理仅限于栈自身。这会让使用通用栈的难度有所增加，但是一个容器很少去访问另一个容器中存储的数据，即使发生了也会很显眼，所以这对于通用栈来说并不是一个特别重的负担。 其他情况下，这就没那么简单了(例如：3.2.4节中的交换操作)，这时可能同时锁住多个互斥量(有时不会发生)。3.1节中那个链表连接例子中，列表中的每个节点都会有一个互斥量保护。为了访问链表，线程必须获取感兴趣节点上的互斥锁。当一个线程删除一个节点，就必须获取三个节点上的互斥锁：将要删除的节点，两个邻接节点。为了遍历链表，线程必须保证在获取当前节点的互斥锁前提下，获得下一个节点的锁，要保证指向下一个节点的指针不会同时被修改。当下一个节点上的锁被获取，第一个节点的锁就可以释放了。 这种“手递手”的模式允许多个线程访问链表，为每一个访问的线程提供不同的节点。为了避免死锁，节点必须以固定的顺序上锁：如果两个线程试图用互为反向的顺序，在使用“手递手”遍历列表时，执行到链表中间部分时会发生死锁。当节点A和B在列表中相邻，当前线程可能会同时尝试获取A和B上的锁。另一个线程可能已经获取了节点B上的锁，并试图获取节点A上的锁——经典的死锁场景，如图3.2所示。 线程1 线程2 锁住主入口的互斥量 读取头结点指针 锁住头结点互斥量 解锁主入口互斥量 锁住主入口互斥量 读取head-&gt;next指针 锁住尾结点互斥量 锁住next结点的互斥量 读取tail-&gt;prev指针 读取next-&gt;next指针 解锁尾结点的互斥量 … … 锁住A结点的互斥量 锁住C结点的互斥量 读取A-&gt;next指针(也就是B结点) 读取C-&gt;next指针(也就是B结点) 锁住B结点互斥量 阻塞，尝试锁住B结点的互斥量 解锁C结点互斥量 读取B-&gt;prev指针(也就是A结点) 阻塞，尝试锁住A结点的互斥量 死锁！ 图3.2 不同线程以相反顺序访问列表所造成的死锁 当A、C节点中间的B节点删除时，有线程在已获取A和C上的锁后，还要获取B节点上的锁时，就可能发生死锁。线程可能会试图先锁住A节点或C节点(根据遍历的方向)，但是发现无法获得B上的锁，因为执行删除任务的线程，已经获取了B上的锁。 这里提供一种避免死锁的方式，定义遍历的顺序，一个线程必须先锁住A才能获取B的锁，在锁住B之后才能获取C的锁。这将消除死锁，不允许反向遍历链表。类似的约定常用于建立其他的数据结构。 使用层次锁结构虽然，定义锁的顺序是一种特殊情况，但层次锁的意义在于，在运行时会约定是否进行检查。这个建议需要对应用进行分层，并且识别在给定层上所有互斥量。当代码试图对互斥量上锁，而低层已持有该层锁时，不允许锁定。可以通过每个互斥量对应的层数，以及每个线程使用的互斥量，在运行时检查锁定操作是否可以进行。下面的代码列表中，展示两个线程如何使用进行分层互斥的。 代码3.7 使用层次锁来避免死锁 hierarchical_mutex high_level_mutex(10000); // 1 hierarchical_mutex low_level_mutex(5000); // 2 hierarchical_mutex other_mutex(6000); // 3 int do_low_level_stuff(); int low_level_func() &#123; std::lock_guard&lt;hierarchical_mutex&gt; lk(low_level_mutex); // 4 return do_low_level_stuff(); &#125; void high_level_stuff(int some_param); void high_level_func() &#123; std::lock_guard&lt;hierarchical_mutex&gt; lk(high_level_mutex); // 6 high_level_stuff(low_level_func()); // 5 &#125; void thread_a() // 7 &#123; high_level_func(); &#125; void do_other_stuff(); void other_stuff() &#123; high_level_func(); // 10 do_other_stuff(); &#125; void thread_b() // 8 在运行时会失败 &#123; std::lock_guard&lt;hierarchical_mutex&gt; lk(other_mutex); // 9 other_stuff(); &#125; 这段代码有三个hierarchical_mutex实例(①，②和③)，其通过逐渐递减的层级进行构造。根据已经定义好的机制，如将一个hierarchical_mutex实例进行上锁，那么只能获取更低层级实例上的锁，这就会对代码进行一些限制。 假设do_low_level_stuff不会对任何互斥量进行上锁，low_level_func为层级最低的函数，并且会对low_level_mutex④进行上锁。high_level_func调用low_level_func⑤的同时，也持有high_level_mutex⑥上的锁，这也没什么问题，因为high_level_mutex(①：10000)要比low_level_mutex(②：5000)更高级。 thread_a()⑦遵守规则，所以运行没问题。 另一方面，thread_b()⑧无视规则，因此在运行时会失败。 首先，thread_b锁住了other_mutex⑨，这个互斥量的层级值只有6000③。这就意味着，中层级的数据已被保护。当other_stuff()调用high_level_func()⑧时，就违反了层级结构：high_level_func()试图获取high_level_mutex，这个互斥量的层级值是10000，要比当前层级值6000大很多。因此hierarchical_mutex将会产生一个错误，可能会是抛出一个异常或直接终止程序。层级互斥量不可能死锁，因为互斥量本身会严格遵循约定进行上锁。当多个互斥量在是在同一级上时，不能同时持有多个锁，所以“手递手”的方案需要每个互斥量在一条链上，并且每个互斥量都比前一个有更低的层级值，这在某些情况下无法实现。 例子也展示了std::lock_guard&lt;&gt;模板与用户自定义的互斥量类型如何一起使用。虽然hierarchical_mutex不是C++标准的一部分，但是写起来很容易，代码3.8中有一个简单的实现。尽管它是一个用户定义类型，可用于std::lock_guard&lt;&gt;模板中，为了满足互斥量操作，其有三个成员函数：lock(), unlock() 和 try_lock()。try_lock()使用起来很简单：当互斥量上的锁被一个线程持有，它将返回false，而不是等待调用的线程，直到能够获取互斥量上的锁为止；如果互斥量上的锁没有被持有，则获取锁并返回true。std::lock()的内部实现中，try_lock()作为避免死锁算法的一部分。 代码3.8 简单的层级互斥量实现 class hierarchical_mutex &#123; std::mutex internal_mutex; unsigned long const hierarchy_value; //这个锁的层级，构造函数中传入进行设定 unsigned long previous_hierarchy_value; //当前线程获得这把锁前获取的上一把锁的层级（这个应该是thread_local的吗？不需要，这把锁一个时刻只能被一个线程占有，这把锁的上一把锁是well-defined的，即只有一个或者没有，这把锁不会出现有多把上一把锁的情况） static thread_local unsigned long this_thread_hierarchy_value; // 1 当前线程的层级（可以获取的锁必须层级&lt;=这个级别） //检查当前线程的层级是否不低于这把锁的层级，不低于的话当前线程才允许获取这把锁 void check_for_hierarchy_violation() &#123; if(this_thread_hierarchy_value &lt;= hierarchy_value) // 2 &#123; throw std::logic_error(&quot;mutex hierarchy violated&quot;); &#125; &#125; void update_hierarchy_value() &#123; previous_hierarchy_value=this_thread_hierarchy_value; // 3 记录当前线程在获取这把锁之前的层级 this_thread_hierarchy_value=hierarchy_value; //更新当前线程的层级为这把锁的层级（其实是更新为std::min(this_thread_hierarchy_value, hierarchy_value)，不过能够执行更新函数一定有hierarchy_value&lt;=this_thread_hierarchy_value，所以这个直接赋值即可，一定是向下或不变地更新当前线程的层级） &#125; public: //构造函数，设定这个锁的层级 explicit hierarchical_mutex(unsigned long value): hierarchy_value(value), previous_hierarchy_value(0) &#123;&#125; void lock() &#123; check_for_hierarchy_violation(); internal_mutex.lock(); // 4 update_hierarchy_value(); // 5 &#125; void unlock() &#123; //当前线程的层级!=这把锁的层级，说明当前线程在获取这把锁之后获取了其他的锁（必须是层级低于这把锁的），而其他锁尚未解锁，或者当前线程尚未获取这把锁 if(this_thread_hierarchy_value!=hierarchy_value) throw std::logic_error(&quot;mutex hierarchy violated&quot;); // 9 this_thread_hierarchy_value=previous_hierarchy_value; // 6 释放这把锁，更新当前线程的层级为它获得的上一把锁的层级 internal_mutex.unlock(); &#125; bool try_lock() &#123; check_for_hierarchy_violation(); if(!internal_mutex.try_lock()) // 7 return false; //对internal_mutex lock了，更新层级 update_hierarchy_value(); return true; &#125; &#125;; thread_local unsigned long hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX); // 8 在构造函数中指定这把锁的层级（所以我们可以创建多个同层次的不同锁） 这里重点是使用了thread_local的值来代表当前线程的层级值：this_thread_hierarchy_value①，初始化为最大值⑧，所以最初所有线程都能被锁住。因为声明中有thread_local，所以每个线程都有其副本，这样线程中变量状态完全独立，当从另一个线程进行读取时，变量的状态也完全独立。 所以，线程第一次锁住一个hierarchical_mutex时，this_thread_hierarchy_value的值是ULONG_MAX。由于其本身的性质，这个值会大于其他任何值，所以通过了check_for_hierarchy_vilation()②的检查。这种检查下，lock()代表内部互斥锁已锁住④。一旦成功锁住，就可以更新层级值了⑤。 当持有第一个锁的同时，还锁住了另一个hierarchical_mutex，this_thread_hierarchy_value的值将会显示第一个互斥量的层级值。第二个互斥量的层级值必须小于已持有互斥量，检查函数②才能通过。 现在，最重要的是为当前线程赋予之前的层级值，可以调用unlock()⑥对层级值进行保存。否则，就锁不住任何互斥量(第二个互斥量的层级数高于第一个互斥量)，即使线程没有持有任何锁。因为保存了之前的层级值，只有当持有internal_mutex③，且在解锁内部互斥量⑥之前存储它的层级值时，需要内部互斥量对hierarchical_mutex实例进行保护，才能安全的将hierarchical_mutex存储。为了避免无序解锁造成层次混乱，不是解锁最近上锁的那个互斥量，就需要抛出异常⑨。其他机制也能做到这点，但目前这是最简单的。 try_lock()与lock()的功能相似，除了在调用internal_mutex的try_lock()⑦失败时，不能持有对应锁，所以不必更新层级值，并直接返回false。 虽然是运行时检测，但无时间依赖性——不必去等待构成死锁的条件出现。同时，设计过程需要拆分应用，互斥量在这种情况下可以消除死锁的可能性。这样的练习很有必要去做一下，即使你之后没有去做，代码也会在运行时检查。 超越锁的延伸扩展死锁不仅仅会发生在锁之间，也会发生在同步构造中(可能会产生一个等待循环)，这也需要有指导意见，例如：获取嵌套锁，等待一个持有锁的线程，都是很糟糕的决定(因为线程为了能继续运行可能需要获取对应的锁)。如果去等待一个线程结束，应该确定这个线程的层级，这样一个线程只需要等待比其层级低的线程结束即可。用一个简单的办法便可确定，添加的线程是否在同一函数中启动，如同在3.1.2节和3.3节中描述的那样。 代码已能规避死锁，std::lock()和std::lock_guard可组成简单的锁，并覆盖大多数情况，但有时需要更多的灵活性，可以使用标准库提供的std::unique_lock模板。如 std::lock_guard，这是一个参数化的互斥量模板类，它提供很多RAII类型锁用来管理std::lock_guard类型，可以让代码更加灵活。 3.2.6 std::unique_lock——灵活的锁std::unqiue_lock使用起来更为自由，**std::unique_lock实例不会总与互斥量的数据类型相关，使用起来要比std:lock_guard更加灵活。首先，可将std::adopt_lock作为第二个参数传入构造函数，对互斥量进行管理（意思是这传入这个参数之后，就不是用std::unqiue_lock内部申请的锁，不是由std::unqiue_lock类来进行锁管理，而是由用户代码进行锁管理）。也可以将std::defer_lock作为第二个参数传递进去，表明互斥量应保持解锁状态（构造对象的时候不是直接上锁）。这样就可以让std::unique_lock对象(不是互斥量)的lock()所获取，或传递std::unique_lock对象到std::lock()中。代码3.6可以轻易的转换为代码3.9，使用std::unique_lock和std::defer_lock①，而非std::lock_guard和std::adopt_lock。代码长度相同，几乎等价，唯一不同的就是：std::unique_lock会占用比较多的空间，并且比std::lock_guard稍慢一些**。保证灵活性要付出代价，这个代价就是允许std::unique_lock实例不带互斥量：信息已存储，且已更新。 代码3.9 交换操作中std::lock()和std::unique_lock的使用 class some_big_object; void swap(some_big_object&amp; lhs,some_big_object&amp; rhs); class X &#123; private: some_big_object some_detail; std::mutex m; public: X(some_big_object const&amp; sd):some_detail(sd)&#123;&#125; friend void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; //unique_lock的模板参数类型为 其上锁的类型（对什么上锁，比如这里是对std::mutex类型的实例上锁，这个类型与构造函数传入的第一个参数的类型一致） std::unique_lock&lt;std::mutex&gt; lock_a(lhs.m,std::defer_lock); // 1 std::unique_lock&lt;std::mutex&gt; lock_b(rhs.m,std::defer_lock); // 1 std::defer_lock 留下未上锁的互斥量 std::lock(lock_a,lock_b); // 2 互斥量在这里上锁 swap(lhs.some_detail,rhs.some_detail); &#125; &#125;; 代码3.9中，因为**std::unique_lock支持lock(), try_lock()和unlock()成员函数，所以能将std::unique_lock对象传递到std::lock()②。这些同名成员函数在低层做着实际的工作，并且仅更新std::unique_lock实例中的标志，来确定该实例是否拥有特定的互斥量，这个标志是为了确保unlock()在析构函数中正确调用。如果实例拥有互斥量，那么析构函数必须调用unlock()。但当实例中没有互斥量时，析构函数就不能去调用unlock()，这个标志可以通过owns_lock()成员变量进行查询**。除非想将std::unique_lock的所有权进行转让，最好使用C++17中提供的std::scoped_lock(详见3.2.4节)。 如期望的那样，这个标志存储在了某个地方。因此，std::unique_lock实例的体积通常要比std::lock_guard实例大，当使用std::unique_lock替代std::lock_guard，会对标志进行更新或检查，就会有一些轻微的性能惩罚。当std::lock_guard已经能够满足需求时，建议继续使用。当需要更加灵活的锁时，最好选择std::unique_lock，因为它更适合于你的任务。我们已经看到一个递延锁的例子，另外一种情况是锁的所有权从一个域转到另一个域。 3.2.7 不同域中互斥量的传递std::unique_lock实例没有与自身相关的互斥量，互斥量的所有权可以通过移动操作，在不同的实例中进行传递。某些情况下，这种转移是自动发生的，例如：当函数返回一个实例。另一种情况下，需要显式的调用std::move()来执行移动操作。本质上来说，需要依赖于源值是否是左值——一个实际的值或是引用——或一个右值——一个临时类型。当源值是一个右值，为了避免转移所有权过程出错，就必须显式移动成左值。**std::unique_lock是可移动，但不可赋值**的类型。 一种使用可能是允许函数去锁住一个互斥量，并且将所有权移到调用者上，所以调用者可以在这个锁保护的范围内执行额外的动作。 下面的程序片段展示了：函数get_lock()锁住了互斥量，然后准备数据，返回锁的调用函数。 std::unique_lock&lt;std::mutex&gt; get_lock() &#123; extern std::mutex some_mutex; std::unique_lock&lt;std::mutex&gt; lk(some_mutex); //构造函数没有传入第二个参数，则是构造函数中就对互斥量std::mutex some_mutex上锁 prepare_data(); return lk; // 1 编译器会调用移动构造函数来构造返回值（一个临时的类型为std::unique_lock&lt;std::mutex&gt;的变量） &#125; void process_data() &#123; std::unique_lock&lt;std::mutex&gt; lk(get_lock()); // 2 get_lock()返回临时对象，然后lk的构造是调用移动构造函数，把get_lock()返回的临时对象关联的锁移动给lk do_something(); &#125; lk在函数中被声明为自动变量，它不需要调用std::move()，可以直接返回①(编译器负责调用移动构造函数)。process_data()函数直接转移std::unique_lock实例的所有权②，调用do_something()可使用的正确数据(数据没有受到其他线程的修改)。 通常这种模式会用于已锁的互斥量，其依赖于当前程序的状态，或依赖于传入返回类型为std::unique_lock的函数(或以参数返回)。这样不会直接返回锁，不过网关类的数据成员可用来确认，是否已经对保护数据的访问权限进行上锁。这种情况下，所有的访问都必须通过网关类：当你想要访问数据，需要获取网关类的实例(如同前面的例子，通过调用get_lock()之类函数)来获取锁。之后就可以通过网关类的成员函数对数据进行访问，完成访问时可以销毁这个网关类对象，将锁进行释放，让别的线程来访问保护数据。这样的一个网关类可能是可移动的(所以可以从函数进行返回)，这种情况下锁对象的数据必须可移动。 std::unique_lock的灵活性同样也允许实例在销毁之前放弃拥有的锁。可以使用unlock()来做这件事，如同一个互斥量：std::unique_lock的成员函数提供类似于锁定和解锁的功能。std::unique_lock实例有在销毁前释放锁的能力，当没有必要在持有锁的时候，可以在特定的代码分支对锁进行选择性释放。这对于应用的性能来说非常重要，因为持有锁的时间增加会导致性能下降，其他线程会等待这个锁的释放，避免超越操作。 3.2.8 锁的粒度3.2.3节中，已经对锁的粒度有所了解：锁的粒度是一个华而不实的术语(hand-waving term)，用来描述通过一个锁保护着的数据量大小。一个细粒度锁(a fine-grained lock)能够保护较小的数据量，一个粗粒度锁(a coarse-grained lock)能够保护较多的数据量。粒度对于锁来说很重要，为了保护对应的数据，保证锁有能力保护这些数据也很重要。 在超市等待结账的时候，正在结账的顾客突然意识到忘了拿蔓越莓酱，然后离开柜台去拿，并让其他的人都等待他回来。或者当收银员，准备收钱时，顾客才去翻钱包拿钱，这样的情况都会让等待的顾客很无奈。当每个人都检查了自己要拿的东西，且能随时为拿到的商品进行支付时，每件事都会进行得很顺利。 道理同样适用于线程：如果很多线程正在等待同一个资源(等待收银员对自己拿到的商品进行清点)，当有线程持有锁的时间过长，这就会增加等待的时间(别等到结账的时候，才想起来蔓越莓酱没拿)。可能的情况下，锁住互斥量的同时只能对共享数据进行访问，试图对锁外数据进行处理。特别是做一些费时的动作，比如：对文件的输入&#x2F;输出操作进行上锁。文件输入&#x2F;输出通常要比从内存中读或写同样长度的数据慢成百上千倍，所以除非锁已经打算去保护对文件的访问，要么执行输入&#x2F;输出操作将会将延迟其他线程执行的时间，这没有必要(因为文件锁阻塞住了很多操作)，这样多线程带来的性能效益会被抵消。 std::unique_lock在这种情况下工作正常，调用unlock()时，代码不需要再访问共享数据。当再次需要对共享数据进行访问时，再调用lock()就可以了。 void get_and_process_data() &#123; std::unique_lock&lt;std::mutex&gt; my_lock(the_mutex); //std::unique_lock对象与对the_mutex的锁相关联，或者说这个std::unique_lock对象提供对the_mutex实例的锁服务 some_class data_to_process=get_next_data_chunk(); my_lock.unlock(); // 1 不要让锁住的互斥量越过process()函数的调用 result_type result=process(data_to_process); my_lock.lock(); // 2 为了写入数据，对互斥量再次上锁 write_result(data_to_process,result); &#125; 不需要让锁住的互斥量越过对process()函数的调用，所以可以在函数调用①前对互斥量进行手动解锁，之后对其再次上锁②。 这表示只有一个互斥量保护整个数据结构时的情况，不仅会有更多对锁的竞争，也会增加持锁的时长。较多的操作步骤需要获取同一个互斥量上的锁，所以持有锁的时间会更长。成本上的双重打击也算是为了向细粒度锁转移提供了激励和可能。 如同上面的例子，锁不仅是能 锁住合适粒度的数据，还要控制锁的持有时间，以及哪些操作在执行的同时能够拥有锁。一般情况下，尽可能将持有锁的时间缩减到最小。 代码3.6和3.9中，交换操作需要锁住两个互斥量，其明确要求并发访问两个对象。假设用来做比较的是一个简单的数据类型(比如：int类型)，将会有什么不同么？int的拷贝很廉价，所以可以进行数据复制，并且每个比较的对象都持有该对象的锁，在比较之后进行数据拷贝。在最短时间内持有每个互斥量，并且不会在持有一个锁的同时再去获取另一个。下面的代码中展示了这样情景中的Y类，并且展示了一个相等比较运算符的等价实现。 代码3.10 比较操作符中一次锁住一个互斥量 class Y &#123; private: int some_detail; mutable std::mutex m; int get_detail() const &#123; std::lock_guard&lt;std::mutex&gt; lock_a(m); // 1 return some_detail; &#125; public: Y(int sd):some_detail(sd)&#123;&#125; friend bool operator==(Y const&amp; lhs, Y const&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return true; int const lhs_value=lhs.get_detail(); // 2 int const rhs_value=rhs.get_detail(); // 3 return lhs_value==rhs_value; // 4 &#125; &#125;; 例子中，比较操作符首先通过调用get_detail()成员函数检索要比较的值②③，函数在索引时被锁保护着①。比较操作符会在之后比较索引出来的值④。注意：虽然锁只持有一次的操作能减少锁持有的时间(这样能消除死锁的可能性)，但这里有一个微妙的语义操作同时对两个锁住的值进行比较。 代码3.10中，当操作符返回true时，就意味着在这个时间点上的lhs.some_detail与另一个时间点的rhs.some_detail相同。这两个值在读取之后，可能会以任意方式修改。两个值会在②和③处进行交换，这样就会失去了比较的意义。比较可能会返回true，表明这两个值是相等的，实际上这两个值相等的情况可能就发生在一瞬间。这样的变化必须要小心，语义操作是无法改变比较方式的：当持有锁的时间没有达到整个操作时间，就会让自己处于条件竞争的状态。 有时可能找不到一个合适的粒度级别，因为并不是所有对数据结构的访问都需要同一级的保护。这个例子中，就需要寻找一个合适的机制，去替换std::mutex。 [1] Tom Cargill, “Exception Handling: A False Sense of Security,” in C++ Report 6, no. 9 (November–December 1994). Also available at http://www.informit.com/content/images/020163371x/supplements/Exception_Handling_Article.html. [2] Herb Sutter, Exceptional C++: 47 Engineering Puzzles, Programming Problems, and Solutions (Addison Wesley Pro-fessional, 1999).","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.5 线程标识","slug":"c++并发编程实践2ed：25 线程标识","date":"2022-07-16T13:17:37.923Z","updated":"2022-12-10T15:17:02.975Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：25 线程标识/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A25%20%E7%BA%BF%E7%A8%8B%E6%A0%87%E8%AF%86/","excerpt":"","text":"2.5 线程标识线程标识为**std::thread::id类型，可以通过两种方式进行检索。第一种，可以通过调用std::thread对象**的成员函数get_id()来直接获取。如果std::thread对象没有与任何执行线程相关联，get_id()将返回std::thread::type默认构造值，这个值表示“无线程”。第二种，**当前线程中调用std::this_thread::get_id()**(这个函数定义在&lt;thread&gt;头文件中)也可以获得线程标识。 std::thread::id对象可以自由的拷贝和对比，因为标识符可以复用。如果两个对象的std::thread::id相等，那就是同一个线程，或者都“无线程”。如果不等，那么就代表了两个不同线程，或者一个有线程，另一没有线程。 C++线程库不会限制你去检查线程标识是否一样，std::thread::id类型对象提供了相当丰富的对比操作。比如，为不同的值进行排序。这意味着开发者可以将其当做为容器的键值做排序，或做其他比较。按默认顺序比较不同的std::thread::id：当a&lt;b，b&lt;c时，得a&lt;c，等等。标准库也提供std::hash&lt;std::thread::id&gt;容器，std::thread::id也可以作为无序容器的键值。 std::thread::id实例常用作检测线程是否需要进行一些操作。比如：当用线程来分割一项工作(如代码2.9)，主线程可能要做一些与其他线程不同的工作，启动其他线程前，可以通过std::this_thread::get_id()得到自己的线程ID。每个线程都要检查一下，其拥有的线程ID是否与初始线程的ID相同。 std::thread::id master_thread; void some_core_part_of_algorithm() &#123; if(std::this_thread::get_id()==master_thread) &#123; do_master_thread_work(); &#125; do_common_work(); &#125; 另外，当前线程的std::thread::id将存储到数据结构中。之后这个结构体对当前线程的ID与存储的线程ID做对比，来决定操作是“允许”，还是“需要”(permitted&#x2F;required)。 同样，作为线程和本地存储不适配的替代方案，线程ID在容器中可作为键值。例如，容器可以存储其掌控下每个线程的信息，或在多个线程中互传信息。 std::thread::id可以作为线程的通用标识符，当标识符只与语义相关(比如，数组的索引)时，就需要这个方案了。也可以使用输出流(std::cout)来记录一个std::thread::id对象的值。 std::cout&lt;&lt;std::this_thread::get_id(); 具体的输出结果是严格依赖于具体实现的，C++标准的要求就是保证ID相同的线程必须有相同的输出。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.4 确定线程数量","slug":"c++并发编程实践2ed：24 确定线程数量","date":"2022-07-16T13:16:43.074Z","updated":"2022-12-10T15:17:13.000Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：24 确定线程数量/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A24%20%E7%A1%AE%E5%AE%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E9%87%8F/","excerpt":"","text":"2.4 确定线程数量std::thread::hardware_concurrency()在新版C++中非常有用，其会返回并发线程的数量。例如，多核系统中，返回值可以是CPU核芯的数量。返回值也仅仅是一个标识，当无法获取时，函数返回0。 代码2.9实现了并行版的std::accumulate。代码将整体工作拆分成小任务，交给每个线程去做，并设置最小任务数，避免产生太多的线程，程序会在操作数量为0时抛出异常。比如，std::thread无法启动线程，就会抛出异常。 代码2.9 并行版的std::accumulate template&lt;typename Iterator,typename T&gt; struct accumulate_block &#123; void operator()(Iterator first,Iterator last,T&amp; result) &#123; result=std::accumulate(first,last,result); &#125; &#125;; template&lt;typename Iterator,typename T&gt; T parallel_accumulate(Iterator first,Iterator last,T init) &#123; unsigned long const length=std::distance(first,last); if(!length) // 1 return init; unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; // 2 unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= // 3 std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); unsigned long const block_size=length/num_threads; // 4 std::vector&lt;T&gt; results(num_threads); std::vector&lt;std::thread&gt; threads(num_threads-1); // 5 Iterator block_start=first; for(unsigned long i=0; i &lt; (num_threads-1); ++i) &#123; Iterator block_end=block_start; std::advance(block_end,block_size); // 6 threads[i]=std::thread( // 7 accumulate_block&lt;Iterator,T&gt;(), block_start,block_end,std::ref(results[i])); block_start=block_end; // 8 &#125; //最终块可能没有block_size个元素，其end用last accumulate_block&lt;Iterator,T&gt;()( block_start,last,results[num_threads-1]); // 9 for (auto&amp; entry : threads) entry.join(); // 10 return std::accumulate(results.begin(),results.end(),init); // 11 &#125; 函数看起来很长，但不复杂。如果输入的范围为空①，就会得到init的值。如果范围内的元素多于一个时，需要用范围内元素的总数量除以线程(块)中最小任务数，从而确定启动线程的最大数量②。 因为上下文频繁切换会降低线程的性能，所以计算量的最大值和硬件支持线程数，较小的值为启动线程的数量③。std::thread::hardware_concurrency()返回0时，可以选择一个合适的数字。在本例中，我选择了”2”。 每个线程中处理的元素数量，是范围中元素的总量除以线程的个数得出的④，分配是否得当会在后面讨论。 现在，确定了线程个数，创建一个std::vector&lt;T&gt;容器存放中间结果，并为线程创建一个std::vector&lt;std::thread&gt;容器⑤。因为**在启动之前已经有了一个线程(主线程)**，所以启动的线程数必须比num_threads少1。 使用循环来启动线程：block_end迭代器指向当前块的末尾⑥，并启动一个新线程为当前块累加结果⑦。当迭代器指向当前块的末尾时，启动下一个块⑧。 启动所有线程后，⑨中的线程会处理最终块的结果。因为知道最终块是哪一个，所以最终块中有多少个元素就无所谓了。 累加最终块的结果后，可等待std::for_each⑩joint线程(如同在代码2.8中做的那样)，之后使用std::accumulate将所有结果进行累加⑪。 结束这个例子之前，需要明确：T类型的加法不满足结合律(比如，对于float型或double型，在进行加法操作时，系统很可能会做截断操作)，因为对范围中元素的分组，会导致parallel_accumulate得到的结果可能与std::accumulate的结果不同。同样的，这里对迭代器的要求更加严格：必须是前向迭代器。对于results容器，需要保证T有默认构造函数。可以需要根据算法本身的特性，选择不同的并行方式。算法并行会在第8章更加深入的进行讨论，并在第10章中会介绍C++17中支持的并行算法(其中std::reduce操作等价于这里的parallel_accumulate)。因为不能直接从一个线程中返回值，所以需要传递results容器的引用到线程中去。另一个办法，通过地址来获取线程执行的结果(第4章中，我们将使用future完成这种方案)。 当线程运行时，所有必要的信息都需要传入到线程中去，包括存储计算结果的位置。有时候可以传递一个标识数，例如代码2.8中的i。不过，需要标识的函数（的标识数参数）在调用栈的底层，同时其他线程也可调用该函数（这样其实本来只是想标识线程，但是现在由于设计了标识数这个参数，每次谁调用这个函数都会在栈上有这个参数占的内存），那么标识数就会变成累赘。好消息是在设计C++的线程库时，就有预见了这种情况，实现中给每个线程附加了唯一标识符。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.2 传递参数","slug":"c++并发编程实践2ed：22 传递参数","date":"2022-07-16T13:12:10.634Z","updated":"2022-12-10T15:17:24.687Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：22 传递参数/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A22%20%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0/","excerpt":"","text":"2.2 传递参数：std::thread构造函数规则如代码2.4所示，向可调用对象或函数传递参数很简单，只需要将这些参数作为 std::thread构造函数的附加参数即可。需要注意的是，这些参数会**拷贝至新线程的内存空间中(同临时变量一样)。即使函数中的参数是引用的形式**，拷贝操作也会执行。 事实上，以附加参数传入的参数，其在线程函数中的类型只能是值传递或者const引用传递（const引用可以是因为可以const引用右值），否则会编译错误 cppreference thread() noexcept; (1) (since C++11) thread( thread&amp;&amp; other ) noexcept; 移动构造函数，1.参数类型thread&amp;&amp;右值引用类型暗示实现是移动语义（即浅拷贝+源指针置空） 2.noexcept则一旦在其上下文中抛出异常，异常处理机制将直接调用std::terminate() (2) (since C++11) template&lt; class Function, class… Args &gt; explicit thread( Function&amp;&amp; f, Args&amp;&amp;… args ); 构造函数 (3) (since C++11) thread( const thread&amp; ) &#x3D; delete; 拷贝构造函数，不允许编译器生成 (4) (since C++11) Constructs new thread object. \\1) Creates new thread object which does not represent a thread. \\2) Move constructor. Constructs the thread object to represent the thread of execution that was represented by other. After this call other no longer represents a thread of execution. \\3) Creates new std::thread object and associates it with a thread of execution. The new thread of execution starts executing &#x2F;*INVOKE*&#x2F;(std::move(f_copy), std::move(args_copy)…), where &#x2F;*INVOKE*&#x2F; performs the *INVOKE* operation specified in Callable f_copy is an object of type std::decay::type and constructed from std::forward(f), and 如果Function类型为左值引用类型，则f_copy为左值，否则f_copy类型为右值 args_copy... are objects of types std::decay::type… and constructed from std::forward(args)…. Constructions of these objects are executed in the context of the caller, so that any exceptions thrown during evaluation and copying&#x2F;moving of the arguments are thrown in the current thread, without starting the new thread. The program is ill-formed if any construction or the *INVOKE* operation is invalid. This constructor does not participate in overload resolution if std::decay::type is the same type as thread. The completion of the invocation of the constructor synchronizes-with (as defined in std::memory_order) the beginning of the invocation of the copy of f on the new thread of execution. \\4) The copy constructor is deleted; threads are not copyable. No two std::thread objects may represent the same thread of execution. 来看一个例子： void f(int i, std::string const&amp; s); std::thread t(f, 3, &quot;hello&quot;); 替换隐式转换为显示转换代码创建了一个调用f(3, “hello”)的线程。注意，函数f需要一个std::string对象作为第二个参数，但这里使用的是字符串的字面值，也就是char const *类型，线程的上下文完成字面值向std::string的转化。需要特别注意，指向动态变量的指针作为参数的情况，代码如下： void f(int i,std::string const&amp; s); void oops(int some_param) &#123; char buffer[1024]; // 1 sprintf(buffer, &quot;%i&quot;,some_param); std::thread t(f,3,buffer); // 2 t.detach(); &#125; buffer①是一个指针变量，指向局部变量，然后此局部变量通过buffer传递到新线程中②。此时，函数oops可能会在buffer转换成std::string之前结束，从而导致未定义的行为。因为，**无法保证隐式转换的操作和std::thread构造函数的拷贝操作的顺序，有可能std::thread的构造函数拷贝的是转换前的变量(buffer指针)。解决方案就是在传递到std::thread构造函数之前，就将字面值转化为std::string**： void f(int i,std::string const&amp; s); void not_oops(int some_param) &#123; char buffer[1024]; sprintf(buffer,&quot;%i&quot;,some_param); std::thread t(f,3,std::string(buffer)); // 使用std::string，避免悬空指针 t.detach(); &#125; 相反的情形(期望传递一个非常量引用，但复制了整个对象)倒是不会出现，因为会出现编译错误。比如，尝试使用线程更新引用传递的数据结构： void update_data_for_widget(widget_id w,widget_data&amp; data); // 1 void oops_again(widget_id w) &#123; widget_data data; std::thread t(update_data_for_widget,w,data); // 2 display_status(); t.join(); process_widget_data(data); &#125; 虽然update_data_for_widget①的第二个参数期待传入一个引用，但std::thread的构造函数②并不知晓，构造函数无视函数参数类型，盲目地拷贝已提供的变量。不过，内部代码会将拷贝的参数以右值的方式进行传递，这是为了那些只支持移动的类型，而后会尝试以右值为实参调用update_data_for_widget。但因为函数期望的是一个非常量引用作为参数(而非右值)，所以会在编译时出错。 使用std::ref传递引用 std::ref和std::cref事实上是模板函数，返回值是一个std::reference_wrapper对象（该对象有一个数据成员：一个指针），而std::reference_wrapper虽然是一个对象，可是他却能展现出和普通引用类似的效果 对于熟悉std::bind的开发者来说，问题的解决办法很简单：可以使用std::ref将参数转换成引用的形式。因此可将线程的调用改为以下形式： std::thread t(update_data_for_widget,w,std::ref(data)); 这样仍然是发生拷贝，拷贝的std::reference_wrapper对象，这个对象满足函数引用参数类型的要求 这样update_data_for_widget就会收到data的引用，而非data的拷贝副本，这样代码就能顺利的通过编译了。 类的成员函数作为线程函数如果熟悉std::bind，就应该不会对以上述传参的语法感到陌生，因为std::thread构造函数和std::bind的操作在标准库中以相同的机制进行定义。比如，你也可以传递一个成员函数指针作为线程函数，并提供一个合适的对象指针作为第一个参数： class X &#123; public: void do_lengthy_work(); &#125;; X my_x; std::thread t(&amp;X::do_lengthy_work, &amp;my_x); // 1 这段代码中，新线程将会调用my_x.do_lengthy_work()，其中my_x的地址①作为对象指针提供给函数。也可以为成员函数提供参数：std::thread构造函数的第三个参数就是成员函数的第一个参数，以此类推(代码如下，译者自加)。 class X &#123; public: void do_lengthy_work(int); &#125;; X my_x; int num(0); std::thread t(&amp;X::do_lengthy_work, &amp;my_x, num); std::move传递只能移动不能拷贝的类型另一种有趣的情形是，提供的参数仅支持移动(move)，不能拷贝。&#96;&#96;std::unique_ptr&#96;是这种类型 使用移动操作可以将对象转换成函数可接受的实参类型，或满足函数返回值类型要求。 void process_big_object(std::unique_ptr&lt;big_object&gt;); std::unique_ptr&lt;big_object&gt; p(new big_object); p-&gt;prepare_data(42); std::thread t(process_big_object,std::move(p)); //std::move将左值p强制类型转换为右值引用类型 C++标准线程库中和std::unique_ptr在所属权上相似的类有好几种，std::thread为其中之一。虽然，std::thread不像std::unique_ptr能占有动态对象的所有权，但是它能占有其他资源：每个实例都负责管理一个线程。线程的所有权可以在多个std::thread实例中转移，这依赖于**std::thread实例的可移动且不可复制性**。不可复制性表示在某一时间点，一个std::thread实例只能关联一个执行线程。可移动性使得开发者可以自己决定，哪个实例拥有线程实际执行的所有权。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++11左右值引用 移动语义","slug":"c++11左右值引用 移动语义","date":"2022-07-16T13:11:07.413Z","updated":"2022-12-10T15:17:36.420Z","comments":true,"path":"2022/07/16/c++11左右值引用 移动语义/","link":"","permalink":"http://example.com/2022/07/16/c++11%E5%B7%A6%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89/","excerpt":"","text":"学习自一文读懂C++右值引用和std::move - 知乎 (zhihu.com)，原文真的写得超级好！ 该文文末还讲解了std::forward，暂时未学习 左右值引用左值引用左值引用类型为T&amp; 非const不可以指向右值 int a = 5; int &amp;ref_a = a; // 左值引用指向左值，编译通过 int &amp;ref_a = 5; // 左值引用指向了右值，会编译失败 const左值引用是可以指向右值的： const int &amp;ref_a = 5; // 编译通过 const左值引用不会修改指向值，因此可以指向右值 如std::vector的push_back： void push_back (const value_type&amp; val); 如果没有const，vec.push_back(5)这样的代码就无法编译通过了。 右值引用右值引用类型为T&amp;&amp; 可以指向右值，不能指向左值 可以修改右值 int &amp;&amp;ref_a_right = 5; // ok int a = 5; int &amp;&amp;ref_a_left = a; // 编译不过，右值引用不可以指向左值 ref_a_right = 6; // 右值引用的用途：可以修改右值 右值引用修改右值的实际实现：把右值提升为一个左值，并定义一个右值引用通过std::move指向该左值： int &amp;&amp;ref_a = 5; ref_a = 6; //等同于以下代码： int temp = 5;//只是这个是编译器给准备的一个存储实体，估计这个存储实体是在栈上，和int temp=5;一样是栈上的局部变量，只是我们没有这个变量的名字 int &amp;&amp;ref_a = std::move(temp); ref_a = 6; 右值引用有办法指向左值吗？ std::moveint a = 5; // a是个左值 int &amp;ref_a_left = a; // 左值引用指向左值 int &amp;&amp;ref_a_right = std::move(a); // 通过std::move将左值类型转化为右值，可以被右值引用指向 cout &lt;&lt; a; // 打印结果：5 在上边的代码里，看上去是左值a通过std::move移动到了右值ref_a_right中，那是不是a里边就没有值了？并不是，打印出a的值仍然是5。 std::move是一个非常有迷惑性的函数，不理解左右值概念的人们往往以为它能把一个变量里的内容移动到另一个变量，但事实上std::move没有做移动，唯一的功能是强制类型转换（把左值强制转化为右值），让右值引用可以指向左值。其实现等同于一个类型转换：**static_cast&lt;T&amp;&amp;&gt;(lvalue)**。 结论 从性能上讲，左右值引用没有区别，传参使用左右值引用都可以避免拷贝。 右值引用可以直接指向右值，也可以通过std::move指向左值；而左值引用只能指向左值(const左值引用也能指向右值)。 作为函数形参时，右值引用更灵活。虽然const左值引用也可以做到左右值都接受，但它无法修改，有一定局限性。 std::ref 使用举例见 c++并发编程实践：2.2 传递参数 用于函数接收参数类型为非const左值引用，但是只能拷贝传递的场景下（比如std::thread构造函数中通过附件参数来传参，这些参数都是通过值传递的方式传递的），来包装左值引用 std::ref和std::cref是模板函数，返回值是一个std::reference_wrapper对象（该对象有一个数据成员：一个指针），而std::reference_wrapper虽然是一个对象，可是他却能展现出和普通引用类似的效果 头文件#include 编译参数：-std=c++11 -pthread 其中-pthread 库需要 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;functional&gt; void func(int&amp; arg) &#123; std::cout&lt;&lt;arg&lt;&lt;std::endl; &#125; int main()&#123; int a; //想把a的引用传入func中，func作为新线程的线程函数 std::thread th(func, a); //编译器会报错 std::thread th(func, std::ref(a)); //也是值传递std::ref(a)，把std::ref(a)这个对象拷贝到新线程堆栈中（先准备参数，然后是返回地址，然后是旧的栈底指针，然后是栈底...），这个对象中有个指向a的指针 th.join();//等待子线程，因为子线程持有主线程生命周期中的局部变量的引用，所以为了防止未定义行未，主线程得比子线程晚结束 return 0; &#125; 常量引用可以绑定到右值 https://herbsutter.com/2008/01/01/gotw-88-a-candidate-for-the-most-important-const/ Normally, a temporary object lasts only until the end of the full expression in which it appears. However, C++ deliberately specifies that binding a temporary object to a reference to const on the stack lengthens the lifetime of the temporary ++to the lifetime of the reference itself++, and thus avoids what would otherwise be a common dangling-reference error Note this only applies to stack-based references. It doesn’t work for references that are members of objects 右值引用和std::move的应用场景 移动语义实现移动语义 移动语义理解举例class Array &#123; public: Array(int size) : size_(size) &#123; data = new int[size_]; &#125; // 深拷贝构造 Array(const Array&amp; temp_array) &#123; size_ = temp_array.size_; data_ = new int[size_]; for (int i = 0; i &lt; size_; i ++) &#123; data_[i] = temp_array.data_[i]; &#125; &#125; // 深拷贝赋值 Array&amp; operator=(const Array&amp; temp_array) &#123; delete[] data_; size_ = temp_array.size_; data_ = new int[size_]; for (int i = 0; i &lt; size_; i ++) &#123; data_[i] = temp_array.data_[i]; &#125; &#125; ~Array() &#123; delete[] data_; &#125; public: int *data_; int size_; &#125;; 该类的拷贝构造函数、赋值运算符重载函数已经通过使用左值引用传参来避免一次多余拷贝了，但是内部实现要深拷贝，无法避免。 这时，有人提出一个想法：是不是可以提供一个移动构造函数，把被拷贝者的数据移动过来，被拷贝者后边就不要了，这样就可以避免深拷贝了 如： class Array &#123; public: Array(int size) : size_(size) &#123; data = new int[size_]; &#125; // 深拷贝构造 Array(const Array&amp; temp_array) &#123; ... &#125; // 深拷贝赋值 Array&amp; operator=(const Array&amp; temp_array) &#123; ... &#125; // 移动构造函数，可以浅拷贝 Array(const Array&amp; temp_array, bool move) &#123; data_ = temp_array.data_; size_ = temp_array.size_; // 为防止temp_array析构时delete data，提前置空其data_ temp_array.data_ = nullptr; &#125; ~Array() &#123; delete [] data_; &#125; public: int *data_; int size_; &#125;; 这么做有2个问题： 不优雅，表示移动语义还需要一个额外的参数(或者其他方式)。 无法实现！temp_array是个const左值引用，无法被修改，所以temp_array.data_ = nullptr;这行会编译不过。当然函数参数可以改成非const：Array(Array&amp; temp_array, bool move)&#123;...&#125;，这样也有问题，由于左值引用不能接右值，Array a = Array(Array(), true);这种调用方式就没法用了。 可以发现左值引用真是用的很不爽，右值引用的出现解决了这个问题， 在STL的很多容器中，都实现了以右值引用为参数的移动构造函数和移动赋值重载函数，或者其他函数，最常见的如std::vector的push_back和emplace_back。STL的函数中，参数为左值引用意味着拷贝，为右值引用意味着移动（这是个设计上的“convention”） class Array &#123; public: ...... // 优雅 Array(Array&amp;&amp; temp_array) &#123; data_ = temp_array.data_; size_ = temp_array.size_; // 为防止temp_array析构时delete data，提前置空其data_ temp_array.data_ = nullptr; &#125; public: int *data_; int size_; &#125;; 如何使用： int main()&#123; Array a; // 做一些操作 ..... // 左值a，用std::move转化为右值 Array b(std::move(a)); // 这里a.data_是nullptr了，原来的a.data_被赋给b.data_ &#125; 移动语义理解 可以这样理解： 拷贝语义：深拷贝 移动语义：浅拷贝 + 把源指针赋值为空 拷贝语义和移动语义的实际应用：类的构造函数和赋值重载函数的实现 可移动不可拷贝：这种类的“拷贝”构造函数都是移动语义的，赋值重载函数都是移动语义的 实例：vector::push_backint main() &#123; std::string str1 = &quot;aacasxs&quot;; std::vector&lt;std::string&gt; vec; vec.push_back(str1); // 传统方法，copy vec.push_back(std::move(str1)); // 调用移动语义的push_back方法，避免拷贝，str1会失去原有值，变成空字符串 vec.push_back(&quot;axcsddcas&quot;); // 当然可以直接接右值 &#125; // std::vector方法定义 void push_back (const value_type&amp; val); void push_back (value_type&amp;&amp; val); 加个std::move会调用到移动语义函数，避免了深拷贝。 移动进函数中（函数参数移动构造）注意1.函数定义的参数类型 2.调用函数用std::move传参 typedef std::map&lt;unsigned, std::set&lt;unsigned&gt;&gt; PatternType; void print_mapContainer(const PatternType&amp;ptn); void func(PatternType ptn) // 函数参数类型 &#123; std::cout &lt;&lt; &quot;[in func:]&quot; &lt;&lt; std::endl; print_mapContainer(ptn); &#125; void test_move_semantics() &#123; PatternType ptn; for (int k = 0; k &lt; 3; ++k) for (int v = 0; v &lt; 2; ++v) ptn[k].insert(k + v); print_mapContainer(ptn); // ptn func(std::move(ptn)); // 函数调用传参 std::cout &lt;&lt; &quot;[after func call:]&quot; &lt;&lt; std::endl; print_mapContainer(ptn); // 空了 &#125; 只可移动类型还有些STL类是move-only的，比如unique_ptr，这种类只有移动构造函数，因此只能移动，不能拷贝: std::unique_ptr&lt;A&gt; ptr_a = std::make_unique&lt;A&gt;(); std::unique_ptr&lt;A&gt; ptr_b = std::move(ptr_a); // unique_ptr只有‘移动赋值重载函数‘，参数是&amp;&amp; ，只能接右值，因此必须用std::move转换类型 std::unique_ptr&lt;A&gt; ptr_b = ptr_a; // 编译不通过 建议除非设计不允许移动，STL类大都支持移动语义函数，即可移动的。 另外，编译器会默认在用户自定义的class和struct中生成移动语义函数，但前提是用户没有主动定义该类的拷贝语义函数。 因此，可移动对象在**&lt;需要拷贝且被拷贝者之后不再被需要&gt;的场景，建议使用std::move触发移动语义**，提升性能。 void func(const T&amp;);//参数类型const T&amp;暗示其实现为拷贝（深拷贝） void func(T&amp;&amp;);//参数类型T&amp;&amp;暗示其实现为移动（浅拷贝+把源指针赋值为空） moveable_objecta = moveable_objectb; //调用拷贝赋值重载函数 func(moveable_objectb); //调用参数类型为const T&amp;的func 改为： moveable_objecta = std::move(moveable_objectb); //调用移动赋值重载函数 func(std::move(moveable_objectb)); //调用参数类型为T&amp;&amp;的func std::forwardforward也是仅进行强制类型转换 std::forward(u)有两个参数：T与 u： 当T为左值引用类型时，u将被转换为T类型的左值； 否则u将被转换为T类型右值。 举个例子，有main，A，B三个函数，调用关系为：main-&gt;A-&gt;B，建议先看懂2.3节对左右值引用本身是左值还是右值的讨论再看这里： void B(int&amp;&amp; ref_r) &#123; ref_r = 1; &#125; // A、B的入参是右值引用 // 有名字的右值引用是左值，因此ref_r是左值 void A(int&amp;&amp; ref_r) &#123; B(ref_r); // 错误，B的入参是右值引用，需要接右值，ref_r是左值，编译失败 B(std::move(ref_r)); // ok，std::move把左值转为右值，编译通过 B(std::forward&lt;int&gt;(ref_r)); // ok，std::forward的T是int类型，属于条件b，因此会把ref_r转为右值 &#125; int main() &#123; int a = 5; A(std::move(a)); &#125; 例2： void change2(int&amp;&amp; ref_r) &#123; ref_r = 1; &#125; void change3(int&amp; ref_l) &#123; ref_l = 1; &#125; // change的入参是右值引用 // 有名字的右值引用是 左值，因此ref_r是左值 void change(int&amp;&amp; ref_r) &#123; change2(ref_r); // 错误，change2的入参是右值引用，需要接右值，ref_r是左值，编译失败 change2(std::move(ref_r)); // ok，std::move把左值转为右值，编译通过 change2(std::forward&lt;int &amp;&amp;&gt;(ref_r)); // ok，std::forward的T是右值引用类型(int &amp;&amp;)，符合条件b，因此u(ref_r)会被转换为右值，编译通过 change3(ref_r); // ok，change3的入参是左值引用，需要接左值，ref_r是左值，编译通过 change3(std::forward&lt;int &amp;&gt;(ref_r)); // ok，std::forward的T是左值引用类型(int &amp;)，符合条件a，因此u(ref_r)会被转换为左值，编译通过 // 可见，forward可以把值转换为左值或者右值 &#125; int main() &#123; int a = 5; change(std::move(a)); &#125; 上边的示例在日常编程中基本不会用到，std::forward最主要运于模版编程的参数转发中","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"c++11异常处理","slug":"c++11异常处理","date":"2022-07-16T13:10:25.309Z","updated":"2022-12-10T15:17:47.154Z","comments":true,"path":"2022/07/16/c++11异常处理/","link":"","permalink":"http://example.com/2022/07/16/c++11%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","excerpt":"","text":"学习自C++11异常处理 noexcept_木的情感的博客-CSDN博客_c++11 noexcept C++03 异常处理（throw）c++11也可以用 指定异常规格（语法）C++98中，在函数声明时，我们使用throw指定一个函数可以抛出异常的类型（异常规格（exception specification））。例如： class Ex &#123; public: double getVal(); void display() throw(); void setVal(int i) throw (char*, double); private: int m_val; &#125;;12345678 上述函数的声明指定了该函数可以抛出异常的类型：getVal() 可以抛出任何异常(默认)；display() 不可以抛出任何异常；setVal() 只可以抛出char* 和 double类型异常。 编译器为了遵守C++语言标准，在编译时，只检查部分函数的异常规格（不会递归检查函数内部调用的所有函数抛出的异常类型是否符合异常规格）。 // declaration extern void funAny(void); //May throw ANY exception. void check(void) throw (std::out_of_range); // May throw only std::out_of_range. // implementation void check(void) throw(std::out_of_range) &#123; funAny(); // Compiler does not check if funAny(), or one of its &#125; // subordinates, only throws std::out_of_range! 异常处理过程使用throw指定异常规格的话， 如果函数抛出异常： 异常处理机制会进行栈回退，寻找(一个或多个）catch语句。 此时，检测catch可以捕捉的类型，如果没有匹配的类型，**std::unexpected()**会被调用。 但是std::unexpected()本身也可能抛出异常。如果std::unexpected()抛出的异常对于当前的异常规格是有效的，异常传递和栈回退会像以前那样继续进行。 这意味着，如果使用throw， 编译器几乎没有机会做优化。事实上，编译器甚至会让代码变得更臃肿、庞大：（1）栈必须被保存在回退表中；（2）所有对象的析构函数必须被正确的调用（按照对象构建相反的顺序析构对象）；（3）编译器可能引入新的传播栅栏（propagation barriers）、引入新的异常表入口，使得异常处理的代码变得更庞大；（4）内联函数的异常规格（exception specification）可能无效的。 C++11新增（noexcept）语法void mightThrow(); // could throw any exceptions. void doesNotThrow() noexcept; // does not throw any exceptions 异常处理过程当使用noexcept时，如果在该函数的上下文中抛出异常，std::teminate()函数会被立即调用（终止整个进程）（std::teminate()也可能抛出异常，其是noexcept），而不是调用std::unexpected()；因此，在异常处理的过程中，编译器不会回退栈 比较noexcept和throw()下面两个函数声明的异常规格在语义上是相同的，都表示函数不抛出任何异常。 void old_style() throw(); void new_style() noexcept; 但是throw()的会栈回退，noexcept的不会，这为编译器的优化提供了更大的空间。 建议如果你知道你的函数绝对不会抛出任何异常，应该使用noexcept, 而不是throw().","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.1和2.3 thread生命周期","slug":"c++并发编程实践2ed：21和23 thread生命周期","date":"2022-07-16T13:08:25.394Z","updated":"2022-12-10T15:18:01.567Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：21和23 thread生命周期/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A21%E5%92%8C23%20thread%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"学习自 第25课 std::thread对象的析构 - 浅墨浓香 - 博客园 (cnblogs.com)和《c++并发编程实践第二版》2.1 一、线程创建std::thread th对象创建时，创建线程，这个线程是主线程的子线程，与主线程并发执行 语法 每个程序有一个执行 main() 函数的主线程，将函数添加为 std::thread 的参数即可创建另一个线程，两个线程并发运行 #include &lt;iostream&gt; #include &lt;thread&gt; void f() &#123; std::cout &lt;&lt; &quot;hello world&quot;; &#125; int main() &#123; std::thread t&#123;f&#125;; t.join(); // 等待新起的线程退出 &#125; std::thread 的参数也可以是函数对象或者 lambda #include &lt;iostream&gt; #include &lt;thread&gt; struct A &#123;//函数对象 void operator()() const &#123; std::cout &lt;&lt; 1; &#125; &#125;; int main() &#123; /*函数对象*/ A a; std::thread t1(a); // （对象申明）会调用 A 的拷贝构造函数 std::thread t2(A()); // （函数申明）most vexing parse，声明 名为 t2 、参数类型为 A 的 函数 std::thread t3&#123;A()&#125;; std::thread t4((A())); /*lambda*/ std::thread t5&#123;[] &#123; std::cout &lt;&lt; 1; &#125;&#125;; t1.join(); t3.join(); t4.join(); t5.join(); &#125; 二、td::thread对象的等待与分离下文中“底层线程”指std::thread对象关联的底层线程。比如创建std::thread th对象时创造的新线程为这个std::thread对象th的底层线程；而在执行th.detach()或th.join()之后，对象th将不与任何底层线程相关联 下文中“线程对象”指类型为std::thread的一个对象 （一）join和detach函数对线程对象执行join或detach之后，都会和底层线程断开联系，joinable()都会变成返回false。其中执行join之后会释放底层线程的内存（所以这显然要断开线程对象和底层线程的联系）；执行detach就是分离底层线程 ### 1. 线程等待&#x2F;联结：join() （1）等待子线程结束，调用线程处于阻塞模式。 （2）join()执行完成之后，底层线程id被设置为0，即joinable()变为false。同时会清理线程相关的存储部分， 这样 std::thread 对象将不再与底层线程有任何关联。这意味着，**只能对一个线程对象使用一次join()**。 ### 2. 线程分离：detach() （1）分离子线程，与当前线程的连接被断开，子线程成为后台线程，被C++运行时库接管。 std::thread 对象将不再与底层线程有任何关联。与join一样，detach也只能调用一次，当detach以后其joinable()为false。 （2）注意事项： ①如果不等待线程，就必须保证线程结束之前，可访问的数据是有效的。**特别是要注意线程函数是否还持有一些局部变量的指针或引用（这些局部变量所在作用域在线程函数返回前可能已经结束了）**。 悬空引用问题： #include &lt;iostream&gt; #include &lt;thread&gt; using namespace std; class FuncObject &#123; void do_something(int&amp; i) &#123; cout &lt;&lt;&quot;do something: &quot; &lt;&lt; i &lt;&lt; endl; &#125; public: int&amp; i; //注意：引用类型 FuncObject(int&amp; i) :i(i) &#123; &#125; //注意：引用类型 void operator()() &#123; for (unsigned int j = 0; j &lt; 1000; ++j) &#123; do_something(i); //可能出现悬空引用的问题。 &#125; &#125; &#125;; void oops() &#123; int localVar = 0; FuncObject fObj(localVar); //注意，fObj的成员i是引用局部变量localVar std::thread t1(fObj); t1.detach(); //主线程调用oops函数,可能出现oops函数执行完了，子线程还在运行的现象。它会去调用do_something，这时会访问到己经被释放的localVar变量，会出现未定义行为！如果这里改成join()则不会发生这种现象。因为主线程会等子线程执行完才退出oops &#125; int main() &#123; oops(); return 0; &#125; ②为防止上述的悬空指针和悬引用的问题，线程对象（std::thread对象）的生命期应尽量长于底层线程（std::thread对象创造时创造的线程）的生命期，或者将局部变量复制传入线程，而不是引用或指针 （3）应用场合 ①适合长时间运行的任务，如后台监视文件系统、对缓存进行清理、对数据结构进行优化等。 ②线程被用于“发送即不管”（fire and forget）的任务，任务完成情况线程并不关心，即安排好任务之后就不管。 （二）联结状态：线程对象的联结状态即std::thread对象是否与某个有效的底层线程关联，可用joinable()函数来判断，内部通过判断线程id是否为0来实现。一个std::thread对象只可能处于可联结或不可联结两种状态之一。 1. **不可联结**： 1. **己调用join或detach的std::thread对象**为不可联结状态。 2. **不带参构造的std::thread对象**为不可联结，因为底层线程还没创建。 3. **己移动的std::thread对象**为不可联结。因为该对象的底层线程id会被设置为0。 可联结：当线程可运行、己运行或处于阻塞时是可联结的 std::thread对象生命周期内的其他情况。注意，如果某个底层线程已经执行完任务，但是没有被join的话，该线程依然会被认为是一个活动的执行线程，该std::thread对象仍然处于joinable状态。 三、std::thread对象的析构（一）std::thread的析构 std::thread对象析构时，会先判断joinable()，如果可联结，则程序会直接被终止（std::thread对象的析构函数中会调用&#96;&#96;std::terminate&#96;函数）。 std::terminate 调用当前安装的 std::terminate_handler 。默认的 std::terminate_handler 调用 std::abort 这好像会终止进程 这意味std::thread对象从其它定义域出去的任何路径，都应为不可联结状态。也意味着创建thread对象以后，要在随后的某个地方显式地调用join或detach以便让std::thread处于不可联结状态。 （二）为什么析构函数中不隐式调用join或detach？ 如果设计成隐式join()：将导致调用线程一直等到子线程结束才返回。如果子线程正在运行一个耗时任务，这可能造成性能低下的问题，而且问题也不容易被发现。 如果设计成隐式detach()：由于detach会将切断std::thread对象与底层线程之间的关联，两个线程从此各自独立运行。如果线程函数是按引用（或指针）方式捕捉的变量，在调用线程退出作用域后这些变量会变为无效，这容易掩盖错误也将使调试更加困难。因此隐式detach，还不如join或者显式调用detach更直观和安全。 标准委员会认为，销毁一个joinable线程的后果是十分可怕的，因此他们通过terminate程序来禁止这种行为。为了避免销毁一个joinable的线程，就得由程序员自己来确保std::thread对象从其定义的作用域出去的任何路径，都处于不可联结状态，最常用的方法就是资源获取即初始化技术（RAII，Resource Acquisition Is Initialization）。 （三）利用RAII技术：保证从std::thread对象定义的作用域出去的任何路径，都处于不可联结状态异常抛出情况下如果主线程（创造std::thread对象的线程）运行后在执行join()之前抛出异常，这样就会跳过join()，即这种情况下主线程可能会比它join的线程先结束，因为它中止在异常抛出的处理中了，而没有走到join，这种情况下主线程在结束的时候析构std::thread对象时，该对象是joinable的，则整个进程会终止 因此，如果在无异常的情况下要使用join()，则需要**在异常处理中也调用join()**，从而避免生命周期的问题。 struct func &#123; int&amp; i; //注意这个是引用 func(int&amp; i_) : i(i_) &#123;&#125; //构造函数的参数是引用类型 void operator() () &#123; for (unsigned j=0 ; j&lt;1000000 ; ++j) &#123; do_something(i); // 1 潜在访问隐患：空引用 &#125; &#125; &#125;; void f() &#123; int some_local_state=0; func my_func(some_local_state); std::thread t(my_func); try &#123; do_something_in_current_thread(); &#125; catch(...) &#123; t.join(); // 1 throw; &#125; t.join(); // 2 &#125; 代码2.2中使用了try/catch块确保(子)线程退出后(主线程的f)函数才结束。当函数正常退出后，会执行到②处。当执行过程中抛出异常，程序会执行到①处。如果线程在函数之前结束——就要查看是否因为线程函数使用了局部变量的引用——而后再确定一下程序可能会退出的途径，无论正常与否，有一个简单的机制，可以解决这个问题。 RAII方案 1. 方案1：自定义的thread_guard类，并将std::thread对象传入其中，同时在构造时选择join或detach策略。当thread_guard对象析构时，会根据析构策略，**调用std::thread的join()或detach()**，确保在任何路径，线程对象都处于unjoinable状态。 2. 方案2：重新封装std::thread类（见下面的代码，类名为joining_thread），在**析构时隐式调用join()**。 #include &lt;iostream&gt; #include &lt;thread&gt; class thread_guard &#123; std::thread t; public: //构造函数 explicit thread_guard(std::thread t_): t(std::move(t_)) &#123;&#125; //析构函数 ~thread_guard() &#123; if(t.joinable()) &#123; t.join(); &#125; &#125; //拷贝语义函数删除 thread_guard(thread_guard const&amp;)=delete; thread_guard&amp; operator=(thread_guard const&amp;)=delete; &#125;; struct func; void f() &#123; int some_local_state=0; func my_func(some_local_state); std::thread t(my_func);//创建新线程 thread_guard g(std::move(t)); //调用thread_guard的构造函数，其中构造参数_t（_t是类型为std::thread的bian&#39;lian）会调用std::thread的移动构造函数（把底层线程所有权给_t），然后t(std::move(_t))也会调用std::thread的移动构造函数（把底层线程所有权给t） do_something_in_current_thread(); //主线程离开这里时，析构thread_guard g对象，调用其析构函数 &#125; 代码尚未阅读//使用RAII等待线程完成：joining_thread类的实现 class joining_thread &#123; std::thread thr; public: joining_thread() noexcept = default; //析构函数 ~joining_thread() &#123; if (joinable()) //对象析构造，会隐式调用join() &#123; join(); &#125; &#125; template&lt;typename Callable, typename... Args&gt; explicit joining_thread(Callable&amp;&amp; func, Args&amp;&amp; ...args): thr(std::forward&lt;Callable&gt;(func), std::forward&lt;Args&gt;(args)...) &#123; &#125; //类型转换构造函数 explicit joining_thread(std::thread t) noexcept : thr(std::move(t)) &#123; &#125; //移动操作 joining_thread(joining_thread&amp;&amp; other) noexcept : thr(std::move(other.thr)) &#123; &#125; joining_thread&amp; operator=(joining_thread&amp;&amp; other) noexcept &#123; if (joinable()) join(); //等待原线程执行完 thr = std::move(other.thr); //将新线程移动到thr中 return *this; &#125; joining_thread&amp; operator=(std::thread other) noexcept &#123; if (joinable()) join(); thr = std::move(other); return *this; &#125; bool joinable() const noexcept &#123; return thr.joinable(); &#125; void join() &#123; thr.join(); &#125; void detach() &#123; thr.detach(); &#125; void swap(joining_thread&amp; other) noexcept &#123; thr.swap(other.thr); &#125; std::thread::id get_id() const noexcept &#123; return thr.get_id(); &#125; std::thread&amp; asThread() noexcept //转化为std::thread对象 &#123; return thr; &#125; const std::thread&amp; asThread() const noexcept &#123; return thr; &#125; &#125;; void doWork(int i) &#123; cout &lt;&lt; i &lt;&lt; endl; &#125; int main() &#123; //3. 测试joining_thread类 std::vector&lt;joining_thread&gt; threads; //joining_thread析构时隐式调用join for (unsigned int i = 0; i &lt; 20; ++i) &#123; threads.push_back(joining_thread(doWork, i)); &#125; std::for_each(threads.begin(), threads.end(), std::mem_fn(&amp;joining_thread::join)); return 0; &#125; 四、std::thread的移动语义创建了两个执行线程，并在std::thread实例之间(t1，t2和t3)转移所有权： void some_function(); void some_other_function(); std::thread t1(some_function); // 1 std::thread t2=std::move(t1); // 2 std::move返回的右值类型触发调用 std::thread的移动赋值重载函数，这个移动语义函数实现底层线程的“所有权”从t1移动到t2 //此时t1无关联线程 t1=std::thread(some_other_function); // 3 临时std::thread对象启动了一个线程，临时对象是一个右值，因此触发调用 std::thread的移动赋值重载函数，将这个新触发的线程移动给t1 //现在t1和刚刚std::thread临时对象启动的线程相关联 std::thread t3; // 4 t3此时没有与任何线程进行关联 t3=std::move(t2); // 5 t1=std::move(t3); // 6 因为t1已经有了一个关联的线程，赋值操作将抛出异常，移动赋值重载函数是noexcept则异常处理机制将直接调用std::terminate() 函数返回std::thread对象： std::thread f() &#123; void some_function(); return std::thread(some_function); //构造返回值std::thread临时对象时是调用std::thread的移动构造函数 &#125; //这个编译器不会报错吗？试了一下不会 std::thread g() &#123; void some_other_function(int); std::thread t(some_other_function,42); return t; //构造返回值std::thread临时对象时是调用std::thread的移动构造函数 //return std::move(t);比较符合我的li &#125; std::thread实例作为参数进行传递： void f(std::thread t); void g() &#123; void some_function(); f(std::thread(some_function)); std::thread t(some_function); f(std::move(t)); &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++底层 c++STL源码","slug":"c++底层 c++STL源码","date":"2022-07-16T13:00:59.357Z","updated":"2022-12-10T15:18:15.739Z","comments":true,"path":"2022/07/16/c++底层 c++STL源码/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%BA%95%E5%B1%82%20c++STL%E6%BA%90%E7%A0%81/","excerpt":"","text":"用户内存分配和使用的规则（os知识）堆栈查看堆栈总大小每个进程允许的堆栈总大小在linux下可以用ulimit查看 stack size #查看软极限，单个进程的stack size限制 ulimit -a #或者ulimit -aS #查看硬极限，软极限的限制 ulimit -aH 堆栈地址增长方向x86机器上， 栈是向下增长的，即入栈是栈顶指针值变小 堆是向上增长的（这个其实无所谓，看操作系统分配堆内存的机制，会分配给哪些内存） 习惯性思考视图：向下方向是地址变小 使用堆or栈的权衡内存分配消耗： 在堆上创建对象需要追踪内存的可用区域。这个算法是由操作系统提供，通常不会是常量时间的。当内存出现大量碎片，或者几乎用到 100% 内存时，这个过程会变得更久。 与此相比，栈分配是常量时间的。 分配的大小： 栈的大小是固定的，并且远小于堆的大小。 所以，如果你需要分配很大的对象，或者很多很多小对象，一般而言，堆是更好的选择。如果你分配的对象大小超出栈的大小，通常会抛出一个异常。 局部变量栈分配的规则 （小端法）整形和浮点型：低有效位在低地址，视图是：首地址在“下面”，高位字节到低位字节是”向下走“ 比如四字节int型， int a=0x01 02 03 04; 位级表示为0x01 02 03 04的，首字节地址为addr，则内容： addr+3:0x01 addr+2:0x02 addr+1:0x03 addr:0x04 数组：数组下标小的在低地址，视图是：首地址在“下面”，idx(数组下标)++给数组赋值是不断“向上走” 比如char数组 char arr[4]=&#123;1,2,3,4&#125;; 首字节地址为addr，则内容： addr+3:4 addr+2:3 addr+1:2 addr:1 比如int数组 int arr[2]=&#123;0x12345678,0x12345678&#125;; 首字节地址为addr，则内容： addr+7:0x12 addr+6:0x34 addr+5:0x56 addr+4:0x78 addr+3:0x12 addr+2:0x34 addr+1:0x56 addr:0x78 即数组idx++视图是向上走，int元素高位字节到低位字节是向下走 举例： #include&lt;stdio.h&gt; int main() &#123; int i; int a[3]; for (i = 0;i &lt;= 11;++i)&#123; a[i] = 0; printf(&quot;%d\\n&quot;, a[i]); &#125; return 0; &#125; 对应的反汇编objdump -j .text -l -C -S a.out 局部变量i分配在%rbp-4处开始，局部变量数组a分配在%rbp-16处开始，所以其实a[4]是i，所以每次给a[4]&#x3D;0后即把i&#x3D;0，这样又重新i从0到4，然后又把i清零，死循环 0000000000400502 &lt;main&gt;: main(): /home/yuanzhiqiu/tools/c/main.c:3 #include&lt;stdio.h&gt; int main() &#123; 400502: 55 push %rbp 400503: 48 89 e5 mov %rsp,%rbp 400506: 48 83 ec 10 sub $0x10,%rsp /home/yuanzhiqiu/tools/c/main.c:6 int i; int a[3]; for (i = 0;i &lt;= 11;++i)&#123; 40050a: c7 45 fc 00 00 00 00 movl $0x0,-0x4(%rbp) #局部变量i分配在%rbp-4处开始 400511: eb 2b jmp 40053e &lt;main+0x3c&gt; /home/yuanzhiqiu/tools/c/main.c:7 (discriminator 3) a[i] = 0; 400513: 8b 45 fc mov -0x4(%rbp),%eax 400516: 48 98 cltq 400518: c7 44 85 f0 00 00 00 movl $0x0,-0x10(%rbp,%rax,4) #局部变量数组a分配在%rbp-16处开始 40051f: 00 /home/yuanzhiqiu/tools/c/main.c:8 (discriminator 3) printf(&quot;%d\\n&quot;, a[i]); 400520: 8b 45 fc mov -0x4(%rbp),%eax 400523: 48 98 cltq 400525: 8b 44 85 f0 mov -0x10(%rbp,%rax,4),%eax 400529: 89 c6 mov %eax,%esi 40052b: bf d4 05 40 00 mov $0x4005d4,%edi 400530: b8 00 00 00 00 mov $0x0,%eax 400535: e8 c6 fe ff ff callq 400400 &lt;printf@plt&gt; /home/yuanzhiqiu/tools/c/main.c:6 (discriminator 3) for (i = 0;i &lt;= 11;++i)&#123; 40053a: 83 45 fc 01 addl $0x1,-0x4(%rbp) /home/yuanzhiqiu/tools/c/main.c:6 (discriminator 1) 40053e: 83 7d fc 0b cmpl $0xb,-0x4(%rbp) 400542: 7e cf jle 400513 &lt;main+0x11&gt; /home/yuanzhiqiu/tools/c/main.c:10 &#125; return 0; 400544: b8 00 00 00 00 mov $0x0,%eax /home/yuanzhiqiu/tools/c/main.c:11 &#125; 400549: c9 leaveq 40054a: c3 retq 40054b: 0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) c++ new delete https://blog.csdn.net/hazir/article/details/21413833 可以通过反汇编找到相应的汇编代码 newnew 分配内存（堆），获得分配内存的起始地址，这里假设是 0x007da290。 是否会对分配的内存的内容进行修改（比如清空）取决于操作系统机制，通常不会改 在这一块分配的内存上对类对象进行初始化：调用相应的构造函数 返回新分配并构造好的对象的指针，这里 pA 就指向 0x007da290 这块内存，pA 的类型为类 A 对象的指针。 new [] 分配内存 对于数组每个元素的内存调用构造函数 （由于delete []时需要知道要析构和释放多少个元素）C++ 会在分配数组空间时多分配 4 个字节，用于保存数组的大小 deletedelete 调用pA 指向对象的析构函数 释放该对象的内存 释放内存是否会对被释放的内存的内容进行修改取决于操作系统机制，通常不会改 释放这些堆内存之后，操作系统可以把这些堆内存分配给这个进程别的地方了 delete [] 对每个元素调用析构函数（从数组对象指针前面的 4 个字节中取出数组大小，然后从传入的指针开始析构和释放这么多元素） 释放内存（传入的指针是对象指针-4） c++11 range-for Range-based for loop (since C++11) - cppreference.com https://blog.csdn.net/K346K346/article/details/57403750 语法for (range-declaration : range-expression) loop-statement 完整语法： attr(optional) for ( init-statement(optional) range-declaration : range-expression ) loop-statement 编译器生成的代码range-for语法将产生和下述等价的代码： &#123; auto &amp;&amp; __range = range-expression; for (auto __begin = begin_expr, __end = end_expr; __begin != __end; ++__begin) &#123; range-declaration = *__begin; loop_statement &#125; &#125; 其中begin_expr 与 end_expr 是迭代对象的迭代器，根据range-expression的类型，取值有：（1）数组：begin_expr 和 end_expr 分别等于__range和__range + bound；（2）STL 容器：__range.begin()和__range.end()（3）其他类型：begin(__range)和end(__range)。编译器将会通过参数类型找到合适的 begin 和 end 函数。 Temporary range expression If range-expression returns a temporary, its lifetime is extended until the end of the loop, as indicated by binding to the forwarding reference __range, but beware that the lifetime of any temporary within range-expression is not extended 注意到auto &amp;&amp; __range = range-expression在循环之前引用绑定range-expression，循环中是通过__range对迭代对象进行操作，因此如果range-expression返回的是临时对象，则： 不会每一轮循环都evaluate一次range-expression得到临时对象，而是循环开始前evaluate一次 临时对象的生命周期为整个循环，而不是当轮循环 c++ STLc++标准中规定，stl要优先考虑性能，为此，其他的容错性以及更多的功能都可以被舍弃掉 观察下面的STL类实现可以发现，没错，栈上的实体是大小在编译期间就可以确定的，所以可以放在栈上，可以增长的存储部分确实是放堆上的 vector https://segmentfault.com/a/1190000040103598 数据成员和数据结构规则 栈上对象：3个迭代器_First、_Last、_End： _First指向使用空间的头部，_Last指向使用空间大小（size）的尾部，_End指向使用空间容量（capacity）的尾部 堆上存储数据：上面迭代器_First和_End指向的内存范围 所以比如 class A{int x;}; vector&lt;vector&gt; vvs; vvs这个对象在栈上就三个指针，这三个指针指向堆中的数组，这个数组每个元素都是三个指针的vector对象，这个数组中每个元素的三个指针都指向堆中的一个元素为A的数组 源码stl_vector.h template&lt;typename _Tp, typename _Alloc&gt; struct _Vector_base &#123; typedef typename __gnu_cxx::__alloc_traits&lt;_Alloc&gt;::template rebind&lt;_Tp&gt;::other _Tp_alloc_type; typedef typename __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;::pointer pointer; struct _Vector_impl //栈上的实际存储：这三个数据成员 : public _Tp_alloc_type &#123; pointer _M_start;//容器开始位置 pointer _M_finish;//容器结束位置 pointer _M_end_of_storage;//容器所申请的动态内存最后一个位置的下一个位置 _Vector_impl() : _Tp_alloc_type(), _M_start(), _M_finish(), _M_end_of_storage() //默认构造函数，不进行堆内存申请 &#123; &#125; ... &#125;; public: typedef _Alloc allocator_type; ... _Vector_base() : _M_impl() &#123; &#125; _Vector_base(size_t __n) : _M_impl() &#123; _M_create_storage(__n); &#125; ... public: _Vector_impl _M_impl; pointer _M_allocate(size_t __n) &#123; typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr; return __n != 0 ? _Tr::allocate(_M_impl, __n) : pointer(); &#125; void _M_deallocate(pointer __p, size_t __n) &#123; typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr; if (__p) _Tr::deallocate(_M_impl, __p, __n); &#125; private: void _M_create_storage(size_t __n) &#123; this-&gt;_M_impl._M_start = this-&gt;_M_allocate(__n); this-&gt;_M_impl._M_finish = this-&gt;_M_impl._M_start; this-&gt;_M_impl._M_end_of_storage = this-&gt;_M_impl._M_start + __n; &#125; &#125;; 扩充机制：翻倍找空闲空间，拷贝规则vector是动态分配空间，随着元素的不断插入，它会按照自身的一套机制不断扩充自身的容量：按照容器现在容量的一倍进行增长。 vector容器分配的是一块连续的内存空间（堆上），每次容器的增长，并不是在原有连续的内存空间后再进行简单的叠加，而是重新申请一块更大的新内存，并把现有容器中的元素逐个复制过去，然后销毁旧的内存。这时原有指向旧内存空间的迭代器已经失效，所以当操作容器时，迭代器要及时更新 源码push_back void push_back(const value_type&amp; __x) &#123; if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) &#123; _Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish, __x); ++this-&gt;_M_impl._M_finish; &#125; else _M_realloc_insert(end(), __x); &#125; 其中_M_realloc_insert： #if __cplusplus &gt;= 201103L //c++11标准是在2011年3月份发布的，这个表示是c++11及以后 template&lt;typename _Tp, typename _Alloc&gt; template&lt;typename... _Args&gt; void vector&lt;_Tp, _Alloc&gt;:: _M_realloc_insert(iterator __position, _Args&amp;&amp;... __args) #else template&lt;typename _Tp, typename _Alloc&gt; void vector&lt;_Tp, _Alloc&gt;:: _M_realloc_insert(iterator __position, const _Tp&amp; __x) #endif &#123; //_M_check_len函数功能说明：若传入参数为1：只要没有超出stl规定的最大内存大小，每次返回当前容器大小的双倍，初次返回1 const size_type __len = _M_check_len(size_type(1), &quot;vector::_M_realloc_insert&quot;); const size_type __elems_before = __position - begin(); //_M_allocate函数功能说明：根据传入长度申请内存空间 pointer __new_start(this-&gt;_M_allocate(__len)); pointer __new_finish(__new_start); __try &#123; //把x写入相应的位置 _Alloc_traits::construct(this-&gt;_M_impl, __new_start + __elems_before, #if __cplusplus &gt;= 201103L std::forward&lt;_Args&gt;(__args)...); #else __x); #endif __new_finish = pointer(); //这里其实就是把原来数据拷贝到新的内存中来 __new_finish = std::__uninitialized_move_if_noexcept_a (this-&gt;_M_impl._M_start, __position.base(), __new_start, _M_get_Tp_allocator()); ++__new_finish; //这里为什么要再调用一次呢，是针对往vector中间插入元素的情况来的 __new_finish = std::__uninitialized_move_if_noexcept_a (__position.base(), this-&gt;_M_impl._M_finish, __new_finish, _M_get_Tp_allocator()); &#125; __catch(...) &#123; ...; &#125; //这里销毁原来的内存并给成员变量赋新值 std::_Destroy(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_finish, _M_get_Tp_allocator()); _M_deallocate(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_end_of_storage - this-&gt;_M_impl._M_start); this-&gt;_M_impl._M_start = __new_start; this-&gt;_M_impl._M_finish = __new_finish; this-&gt;_M_impl._M_end_of_storage = __new_start + __len; &#125;; 建议 所以如果对于一个空vector不断调用push_back，底层是先分配1个元素的内存，然后分配2个元素的内存（如果原来的起始地址开始没有足够大的连续内存，则要申请一块新内存，把原来的内容拷贝过去），4个元素，8个元素… 所以，如果能确定vector必定会被使用且有数据时，我们应该在声明的时候指定元素个数，避免最开始的时候多次申请动态内存消耗资源，进而影响性能 具体接口底层 上面数据结构和规则的应用+一些线性表简单实现 规律： 扩充机制：push_back、resize（大小增大的调用）、insert（capacity不够的调用） 释放内存：只有析构函数（和c++11及以后的shrink_to_fit）可以主动释放内存，否则只有是扩充的时候发现首地址连续内存不够大，然后换一块会释放原先的内存，其他比如clear\\erase\\resize等都不会释放内存 具体接口： insert：（不够会扩充）把插入位置后面的元素向后移动（拷贝），然后把待插入元素插入到相应的位置 resize：如果是截断的调用，只是对截断后面的元素调用析构函数，不会有内存分配的变化，也不会释放内存 clear：对于所有元素调用析构函数，不会有内存分配的变化，也不会释放内存 delete和erase：会析构被删除元素，会通过拷贝元素来保持连续内存，不会有内存分配的变化，也不会释放内存 swap：交换三个指针 c++11c++11以后vector中增加了一些什么内容呢，我们来看看： 对于迭代器，增加cbegin系列函数，返回常量迭代器，就是只读迭代器； 增加了移动构造函数和移动赋值函数，这一点基本上标准库里面所有类型都增加了； 增加公共成员函数shrink_to_fit，允许释放未使用的内存； 增加公共成员函数emplace和emplace_back，它支持在指定位置原味构造元素，因为它们是以右值引用的方式传递参数，所以它们相比于push_back这一类的函数，少了一个拷贝的动作 释放vector所有元素存储内存 swap vector&lt;int&gt;().swap(v); //想释放v的 v这个vector的三个指针和一个空vector的三个指针进行交换，然后由于这个空vector因为是一个临时变量，它在这行代码结束以后，会自动调用vector的析构函数释放动态内存空间 c++11以后：shrink_to_fit 先调用clear函数，这样所有元素都变成未使用了； 然后调用shrink_to_fit函数把未使用的部分内存释放掉 list数据结构：双向链表有头结点 节点的定义如下： template&lt;typename T,...&gt; struct __List_node&#123; //... __list_node&lt;T&gt;* prev; __list_node&lt;T&gt;* next; T myval; //... &#125; deque STL deque源码实现及分析_FishBear_move_on的博客-CSDN博客 数据结构：首地址数组+多个数组deque 的元素不一定是相邻存储的：典型实现是 多个单独分配的固定大小的相邻元素数组（数组大小：例如 64 位 libstdc++ 上为对象大小的 8 倍空间； 64 位 libc++ 上为对象大小的16 倍或 4096 字节的较大者） 有一个元素的 deque ：也必须为其分配至少一个内存数组 一个数组存储这些空间的首地址（STL中称为map，其中元素称为node） 这表示下标访问必须进行二次指针解引用，与之相比 vector 的下标访问只需要进行一次；迭代器++的时候，可能要换数组，vector只需要迭代器++，而deque还需要从map数组中读取下一个数组的首地址 数据成员迭代器：三个T*指针（指向当前数组），一个T**指针（指向map数组中当前所在数组对应的首地址节点） template &lt;class T, class Ref, class Ptr, size_t buff_size&gt; struct __deque_iterator&#123; typedef __deque_iterator&lt;T, T&amp;, T*, buff_size&gt; iterator; typedef __deque_iterator&lt;T, const T&amp;, const T*, buff_size&gt; const_iterator; static size_t buffer_size() &#123;return __deque_buf_size(buff_size, sizeof(T)); &#125; typedef T value_type; typedef size_t size_type; typedef ptrdiff_t difference_type; typedef T** map_pointer; typedef __deque_iterator self; // 保持与容器的联结 T* cur; // 此迭代器所指之缓冲区中的现行元素 T* first; // 此迭代器所指之缓冲区的头 T* last; // 此迭代器所指之缓冲区的尾（含备用空间） //由于，指针肯会遇到缓冲区边缘，因此需要跳到下一个缓冲区 //于是需要指向map回去下一个缓冲区地址 map_pointer node; // 指向管控中心 &#125; deque类： 栈：两个迭代器（每个迭代器4个指针，即8个指针），一个T**指针（map数组首地址），一个map_size 堆：map数组+多个数组 template&lt;typename T, size_t buff_size = 0&gt; class deque&#123; public: typedef T value_type; typedef T&amp; reference; typedef T* pointer; typedef __deque_iterator&lt;T, T&amp;, T*, buff_size&gt; iterator; typedef size_t size_type; typedef ptrdiff_t difference_type; protected: typedef pointer* map_pointer; // 实际的数据存储，分配器 typedef allocator&lt;value_type&gt; dataAllocator; // map指针分配器 typedef allocator&lt;pointer&gt; mapAllocator; private: //数据成员 iterator start; iterator finish; map_pointer map; size_type map_size; &#125; 扩充机制：新增固定大小数组，无拷贝一旦有必要在deque的前端或尾端增加新空间（当当前数组填满最后一个元素，且当前数组是第一个或者最后一个数组时），便配置一段定量连续空间，串接在整个deque的头端或尾端，不需要复制当前的元素到新内存位置 举例： 初始 push_back0 1 2 push_back3 push_front99 具体接口 deque源码4(deque元素操作:pop_back、pop_front、clear、erase、insert） - ybf&amp;yyj - 博客园 (cnblogs.com) pop 如果不是当前数组最后一个元素，则只是析构这个待删除元素，正确移动迭代器； 如果是最后一个元素，则会释放当前数组，并正确移动迭代器 pop_back void pop_back()&#123; if(finish.cur!=finish.first)&#123; //最后缓冲区至少有一个元素 --finish.cur; //调整指针，相当于排除了最后元素 pop_front这里是++ destory(finish.cur); //将最后元素构析 &#125; else //最后缓冲区没有任何元素 pop_back_aux(); //这里将进行缓冲区的释放工作 &#125; //只有当finish.cur==finish.first时才会被调用 template &lt;class T,class Alloc,size_t BufSize&gt; void deque&lt;T,Alloc,BufSize&gt;::pop_back_aux()&#123; deallocate_node(finish.first); //释放最后一个缓冲区 finish.set_node(finish.node-1); //调整finish的状态，使指向上一个缓冲区的最后一个元素 finish.cur=finish.last-1; destory(finish.cur); //将该元素析构 &#125; clear 存储数组：保留一个存储数组不释放（但是都析构），其余存储数组全部析构和释放 map数组：不释放不析构，只是finish和start迭代器置为相等 template &lt;class T,class Alloc,size_t BufSize&gt; void deque&lt;T,Alloc,BufSize&gt;::clear()&#123; //以下针对头尾以外的每一个缓冲区 for(map_pointer node=start.node+1;node&lt;finish.node;++node)&#123; //将缓冲区内的所有元素析构 destory(*node,*node+buff_size()); //释放缓冲区内存 data_allocator::deallocate(*node,buff_size()); &#125; if(start.node!=finish.node)&#123; //至少有头尾两个缓冲区 destory(start.cur,start.last); //将头缓冲区的目前所有元素析构 destory(finish.first,finish.cur); //将尾缓冲区的目前所有元素析构 //以下释放尾缓冲区，注意，头缓冲区保留 data_allocator::deallocate(finish.first,buffer_size()); &#125; else //只有一个缓冲区 destory(start.cur,finish.cur); //将此唯一缓冲区内所有元素析构，并保留缓冲区 finish=start; //调整状态 &#125; erase和insert 一个存储数组内部需要保持连续存储，因此会有拷贝（待删除元素或者待插入元素哪边元素少就拷贝哪边）（数组定长比较短，就16或者8） //清除pos所指向的元素，pos为清除点 iterator erase(iterator pos)&#123; iterator next=pos; ++next; difference_type index=pos-start; //清除点之前的元素个数 if(index&lt;(size()&gt;&gt;1))&#123; //如果清除点之前的元素比较少 copy_backward(start,pos,next); //就移动清除点之前的元素 pop_front(); //移动完毕，清除最前一个元素 &#125; else&#123; //清除点之后的元素比较少 copy(next,finish,pos); //就移动清除点之后的元素 pop_back(); //移动完毕，清除最后一个元素 &#125; return start+index; &#125; queue和stack：默认底层deque queue和stack底层默认是由deque实现 (multi)map,(multi)set map源码：libstdc++: map.h Source File (gnu.org) 数据结构：红黑树unordered_(multi)map,unordered_(multi)set C++ STL无序容器底层实现原理（深度剖析） (biancheng.net) 数据结构：开链哈希表所有无序容器的底层实现：用“开链法”解决数据存储位置发生冲突的哈希表：（图中Pi 表示存储的各个键值对） 一整块连续的存储空间：存储各个链表的头指针，STL 标准库通常选用 vector。 各个链表的节点：各键值对 在 C++ STL 标准库中，将图 1 中的各个链表称为桶（bucket），每个桶都有自己的编号（从 0 开始）。 所以如果是用vector来存储链表头指针， unordered_map栈上对象应该有个vector对象，这个对象有三个指针 然后比如· class A{int x;}; unordered_map&lt;int, vector&gt; int2vector; int2vector这个对象在栈上有三个指针，这三个指针指向堆中的数组，这个数组每个元素是链表头指针，链表中每个元素至少是“键+三个指针的vector对象+下一个元素的地址”，其中每个指针都指向堆中的一个元素为A的数组 插入新键值当有新键值对存储到无序容器中时，整个存储过程分为如下几步： 将该键值对中键的值带入设计好的哈希函数，会得到一个哈希值（一个整数，用 H 表示）； 将 H 和无序容器拥有桶的数量 n 做取模运算（即 H % n），该结果即表示应将此键值对存储到的桶的编号； 建立一个新节点存储此键值对，同时将该节点链接到相应编号的桶上。 增加桶数重新哈希无序容器中，负载因子的计算方法为： 负载因子 = 容器存储的总键值对 / 桶数 默认情况下，无序容器的最大负载因子为 1.0。如果操作无序容器过程中，使得最大负载因子超过了默认值，则容器会自动增加桶数（翻倍式（8、16、32、…）增加（这个翻倍式增长可能是因为链表头指针时是用vector存储的自然导致的）），并重新进行哈希，以此来减小负载因子的值。需要注意的是，此过程会导致容器迭代器失效，但指向单个键值对的引用或者指针仍然有效。 所以，我们在操作无序容器过程中，键值对的存储顺序有时会“莫名”的发生变动。 管理哈希表的成员方法 成员方法 功能 bucket_count() 返回当前容器底层存储键值对时，使用桶的数量。 比如unordered_map&lt;string, string&gt; umap;初始桶数为8 应用：图邻接表STL选择邻接表：每个顶点一个邻居列表 考虑每个顶点的邻居用vector存，使用场景为： 初始从文件读取构造的图顶点id从0开始，且是连续的整形id； 后面会不断对图做reduce且不需要”回头“（即不会再需要对reduced图进行恢复）：将图规约为仅含当前顶点集的一个子集的导出子图，即实现上（不考虑”假删除“，比如像dancing link那样的链表数据结构，是因为并不需要恢复）表现为将一些顶点的邻居列表清空、将一些顶点的邻居列表中的一些顶点删除，图中实际存在的顶点的id变成可能不是连续的 则整个邻接表用unordered_map还是vector呢？具体来讲： typedef unsigned VID_TYPE; unordered_map&lt;VID_TYPE, vector&lt;VID_TYPE&gt;&gt; g_umap; vector&lt;vector&lt;VID_TYPE&gt;&gt; g_vec; 用g_umap还是g_vec？ 我觉得是g_vec： 底层存储上面举例已经考虑过： g_vec这个对象在栈上就三个指针，这三个指针指向堆中的数组，这个数组每个元素都是三个指针的vector对象，这个数组中每个元素的三个指针都指向堆中的一个元素为VID_TYPE的数组； g_umap这个对象在栈上有三个指针，这三个指针指向堆中的数组，这个数组每个元素是链表头指针，链表中每个元素至少是“键+三个指针的vector对象+下一个元素的地址”，其中每个指针都指向堆中的一个元素为VID_TYPE的数组 考虑g_umap没有出现冲突（可能有增加桶数重新哈希的过程）、每个链表都只有一个元素的最好情况，可以看到g_umap要比g_vec多存储键以及用于链表的指针：顶点数目个指针和键 考虑获取一个顶点的邻居列表 g_umap：需要用顶点id计算哈希值，然后取模得到头指针数组的下标（头指针数组首指针由g_umap这个栈上对象的数据成员得到），从头指针数组中取出链表首地址，如果链表只有一个元素，则由这个地址找到目标邻居列表vector的三个指针，返回这个对象（如果有多个元素，要沿着链表一步步找） g_vec：由顶点id访问元素为vector的数组（这个数组首指针由g_vec这个栈上对象的数据成员得到），得到目标邻居列表vector的三个指针，返回这个对象 可以看到，unordered_map由于链表增加了至少一次访存，并且增加了计算哈希值和取模的步骤 unordered_map可以在reduce删除顶点的时候释放掉已经删除的顶点的键值对从而及时释放存储、所以这点优于vector？这个说法站不住脚： 一方面，邻居列表为空的顶点在g_vec中只是占3个指针的空间 另一方面，unordered_map删除一个键值对，只是键值对删除了（从链表中删除），桶数目不会变（如果桶数目要缩小的话，所有桶的所有键值对都需要重新哈希，这个开销很大） [外加]reduce实现用g_vec，则reduce：原位覆盖+resize+shrink_to_fit： 遍历每个顶点的邻居列表neighbors，一个变量next_new_nbr_idx初始给0，然后如果这个邻居在目标顶点集中，则赋值给neighbors[next_new_nbr_idx++]，遍历结束后neighbors.resize(next_new_nbr_idx); neighbors.shrink_to_fit() resize传入参数若小于当前vector中元素数目，则不会有新的内存分配也不会有释放，只是截断然后析构后面的元素并设置capcity； 然后shrink_to_fit()释放后面的内存 因为在此应用场景下reduce不需要回头，即被从邻居列表中删除掉的顶点不会再重新加入，因此后面邻居列表要占用的内存一定不会比现在释放掉不用的剩下的还多，可以释放掉 [外加]为什么邻居列表不用list呢？list增删元素很快，且本应用场景中不需要随机访问，依次访问邻居即可，那为什么不用list呢？ 我的考虑：因为list底层实现是双向链表，存储的每个元素都多两个指针，在邻居列表存储的实际元素为VID_TYPE仅四个字节的情况下，多存储8个字节的指针，在对于边数为亿级的图感觉不是很合适（10^8个entry，每个12字节，要大约10^9字节，1G） 应用：广度优先搜索的队列用queue还是vector使用算法 用queue：初始时queue中有一个元素（出发点），然后不断从队首取出元素（并删除），并将队首的满足一些性质的邻居加入到队尾 用vector：vector中存储每一层：一个level，一个next_level 初始时一个元素，然后不断：遍历level中所有元素（不用删除），把当前元素的满足一些性质的邻居加入到next_level中，level遍历完成之后，把next_level移动赋值给level（移动赋值：这样即把next_level的存储数据直接给level（即level的三个指针直接赋值为next_level三个指针的值），level原先的数据会被析构和释放） 我觉得用queue更好 分析内存使用考虑队列中元素是原始类型，所以没有析构开销 用queue：初始时queue中有一个元素（出发点），然后不断从队首取出元素（并删除），并将队首的满足一些性质的邻居加入到队尾 queue默认用deque实现： 初始时会有一个map数组和一个存储数组 不断从头部取出和删除元素：由于是从头部删除，则不需要拷贝元素，只有指针移动，以及当当前数组没有元素时将当前数组释放 将队首的满足一些性质的邻居加入到队尾：往当前数组尾部加元素，如果满了就申请新的存储数组 最后会队列为空，总共申请队列的存储大小是所有入队元素（图BFS的话一个顶点只会入队一次且一定会入队一次，则是顶点数目个元素），在走到empty的时候它们全部都释放完了 用vector：vector中存储每一层：一个level，一个next_level 初始时一个元素，然后不断：遍历level中所有元素（不用删除），把当前元素的满足一些性质的邻居加入到next_level中，level遍历完成之后，把next_level移动赋值给level（移动赋值：这样即把next_level的存储数据直接给level（即level的三个指针直接赋值为next_level三个指针的值），level原先的数据会被析构和释放） 初始时：数组长度为1的数组 遍历level：这个只是每次解引用下指针 向next_level中加入元素：每次next_level都是从没有元素开始，vector长度以翻倍的方式增长，每次翻倍都需要找新地方、拷贝、析构和释放之前 把next_level移动赋值给level：析构和释放level 最后队列为空，每次处理一层都会从零开始扩充一个vector（最终大小等于下一层大小），然后会释放这一层 根据上述粗略的分析，用vector实现多了每一层的从0开始扩张的拷贝开销，其他部分类似，因此用queue更优","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"language_deep","slug":"c/language-deep","permalink":"http://example.com/categories/c/language-deep/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"数据库表连接查询","slug":"数据库表连接查询","date":"2022-07-16T09:49:54.858Z","updated":"2022-12-10T15:18:24.294Z","comments":true,"path":"2022/07/16/数据库表连接查询/","link":"","permalink":"http://example.com/2022/07/16/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E8%BF%9E%E6%8E%A5%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"数据库表连接（join）的简单解释 https://www.ruanyifeng.com/blog/2019/01/table-join.html 图解 SQL 中各种连接 JOIN - 知乎 (zhihu.com) 多表连接查询 内连接 外连接 交叉连接 连接查询是啥所谓”连接”，就是两张表根据关联字段，组合成一个数据集。 举例车站站点表。假设用的是关系型数据库（早期开发中估计这么干，现在估计用的都是图数据库） 我们建一张表 bus_sche，为了简单，表中只有上一站地点和下一站地点及唯一标识，然后插入一些模拟数据。 可以通过自连接查询上下站关系找到坐车线路 SELECT b.lastStation,b.nextStation,a.lastStation,a.nextStation FROM bus_sche a, bus_sche b WHERE b.nextStation = a.lastStation; 只在一张表中查询，表 bus_sche 使用了两个别名 bus_sche a, bus_sche b，因此相当于有两张表，用 WHERE条件连接查询 查询结果 四种连接（内外连接）字段不可以构成完全匹配的情况下： 只返回两张表匹配的记录，这叫内连接（inner join）。 返回匹配的记录，以及表 A 多余的记录，这叫左连接（left join）。 返回匹配的记录，以及表 B 多余的记录，这叫右连接（right join）。 返回匹配的记录，以及表 A 和表 B 各自的多余记录，这叫全连接（full join）。 这四种连接，又可以分成两大类：内连接（inner join）表示只包含匹配的记录，外连接（outer join）表示还包含不匹配的记录。所以，左连接、右连接、全连接都属于外连接。 颜色表示匹配关系（比如A.book_id&#x3D;B.book_id） 左连接的结果举例： SQL这四种连接的 SQL 语句如下。 SELECT * FROM A INNER JOIN B ON A.book_id=B.book_id; SELECT * FROM A LEFT JOIN B ON A.book_id=B.book_id; SELECT * FROM A RIGHT JOIN B ON A.book_id=B.book_id; SELECT * FROM A FULL JOIN B ON A.book_id=B.book_id; 上面的 SQL 语句还可以加上where条件从句，对记录进行筛选，比如只返回表 A 里面不匹配表 B 的记录。 SELECT * FROM A LEFT JOIN B ON A.book_id=B.book_id WHERE B.id IS null; 另一个例子，返回表 A 或表 B 所有不匹配的记录。 SELECT * FROM A FULL JOIN B ON A.book_id=B.book_id WHERE A.id IS null OR B.id IS null; 交叉连接“交叉连接”（cross join），指的是表 A 和表 B 不存在关联字段，这时表 A（共有 n 条记录）与表 B （共有 m 条记录）连接后，会产生一张包含 n x m 条记录的新表（见下图）。","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[]},{"title":"halo主题开发","slug":"halo主题开发","date":"2022-07-16T09:45:42.885Z","updated":"2022-12-10T15:19:23.529Z","comments":true,"path":"2022/07/16/halo主题开发/","link":"","permalink":"http://example.com/2022/07/16/halo%E4%B8%BB%E9%A2%98%E5%BC%80%E5%8F%91/","excerpt":"","text":"官方文档halo主题开发指南：Halo Documents侧边栏的开发者指南-主题开发（文档写得真好！） 基础 halo 博客深度定制与美化教程 (bestzuo.cn) 浏览器 F12 定位目标样式F12，然后&#96;&#96;ctrl+shift+c&#96;之后就可以 鼠标选择（指：鼠标悬停）界面元素定位html代码（“元素”tab中）和样式 同时还可以在右边开发者面板中临时修改样式查看效果 鼠标选择（指：鼠标悬停）html代码（“元素”tab中）定位界面元素 这个功能可以用来检查你写的元素有没有按预期显示 分析页面加载速度慢的原因以 Chrome 浏览器为例，F12 ，进入 NetWork 项，勾选 Disable cache，表示禁止浏览器缓存资源到本地，这样可以看到首次加载所有资源的耗时情况。 然后按 F5 刷新页面，点击 Time 进行排序，就可以看到每个资源的加载耗时情况，一般来说如字体这类比较大的资源加载慢是很正常的，而一些 js 如果加载时间靠后则说明该资源可能需要 CDN 加速或者更换加载源。 由于网络差异，上面所述页面资源加载时间并非在所有地区都相同，但是也可以提供一个参考 准备工作搭建开发环境准备工作 | Halo Documents 装java 下载.jar包：见Halo的“快速开始” java -jar halo-1.5.4.jar --spring.profiles.active=dev 启动完成之后，在用户目录即可看到 halo-dev 文件夹（如果是windows是C:\\user\\&lt;user_name&gt;\\目录下面有&#96;&#96;halo-dev&#96;文件夹） 如果是java -jar halo-1.5.4.jar，则在用户目录看到的是 .halo 文件夹 在启动halo的本机浏览器访问http://localhost:8090即可访问你的博客 vscode装前端开发插件 FreeMarker JS &amp; CSS Minifier：JS 和 CSS 压缩插件，其它如编译 Sass 或者 Less 的插件需要自己自行安装。 新建主题准备工作 | Halo Documents 在 ~/halo-dev/templates/themes 下新建一个文件夹，该文件夹就是你所新建的主题目录 非开发方式启动也可以以这种方式应用主题：直接把主题文件夹放到themes下面即可 开发约定准备工作 | Halo Documents 开发样板准备工作 | Halo Documents 目录结构官方示例目录结构准备工作 | Halo Documents ├── module // 公共模板目录 │ ├── comment.ftl // 比如：评论模板 │ ├── layout.ftl // 比如：布局模板 ├── source // 静态资源目录 │ ├── css // 样式目录 │ ├── images // 图片目录 │ ├── js // JS 脚本目录 │ └── plugins // 前端库目录 ├── index.ftl // 首页 ├── post.ftl // 文章页 ├── post_xxx.ftl // 自定义文章模板，如：post_diary.ftl。可在后台发布文章时选择。 ├── sheet.ftl // 自定义页面 ├── sheet_xxx.ftl // 自定义模板，如：sheet_search.ftl、sheet_author.ftl。可在后台发布页面时选择。 ├── archives.ftl // 归档页 ├── categories.ftl // 分类目录页 ├── category.ftl // 单个分类的所属文章页 ├── tags.ftl // 标签页面 ├── tag.ftl // 单个标签的所属文章页 ├── search.ftl // 搜索结果页 ├── links.ftl // 内置页面：友情链接 ├── photos.ftl // 内置页面：图库 ├── journals.ftl // 内置页面：日志 ├── 404.ftl // 404 页 ├── 500.ftl // 500 页 ├── README.md // README，一般用于主题介绍或说明 ├── screenshot.png // 主题预览图 ├── settings.yaml // 主题选项配置文件 └── theme.yaml // 主题描述文件 less min.cssLess是一门扩展性的 CSS 预处理语言，在 CSS 基础上增加了函数、变量等一些便于写代码并且易于读懂的功能，而 CSS 可以由 Less 编辑而成。也就是上面的 main.css 是由 main.less 通过编译所有子模块的 less 文件而成，**main.min.css 则是由 main.css 压缩而成。以上 Less 编译和 CSS 压缩都可以交由 Vscode 插件完成** 全局 CSS 文件代指 main.css，你需要将该 CSS 压缩为 main.min.css 并覆盖之前的 main.min.css 即可在页面生效；将会作用于所有页面 ftlHalo 的模板引擎为 FreeMarker，文件后缀名为ftl 可以参考FreeMarker Java Template Engine (apache.org) Freemark控制生成文本，比如满足条件的就会抄过去生成文本 配置文件（生成“主题设置”界面 如何获取设置值）配置文件 | Halo Documents 全局变量全局变量 | Halo Documents 公共宏模块公共宏模板 | Halo Documents 页面变量页面变量 | Halo Documents 模板标签模板标签 | Halo Documents","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"}]},{"title":"红黑树","slug":"红黑树","date":"2022-07-10T14:55:20.655Z","updated":"2022-12-10T15:21:14.326Z","comments":true,"path":"2022/07/10/红黑树/","link":"","permalink":"http://example.com/2022/07/10/%E7%BA%A2%E9%BB%91%E6%A0%91/","excerpt":"","text":"The-Art-Of-Programming-By-July&#x2F;03.01.md at master · julycoding&#x2F;The-Art-Of-Programming-By-July (github.com) 红黑树本质上是一棵近似平衡的二叉查找树 红黑树的查找、插入、删除的时间复杂度最坏为O(log n) 回顾：二叉查找树 若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意结点的左、右子树也分别为二叉查找树。 没有键值相等的结点（no duplicate nodes）。 红黑树性质红黑树的5条性质： 每个结点要么是红的，要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端NIL指针）是黑的。 如果一个结点是红的，那么它的俩个儿子都是黑的。 对于任一结点而言，其到叶结点的每一条路径都包含相同数目的黑结点。 正是红黑树的这5条性质，使得一棵n个结点是红黑树始终保持了logn的高度 旋转 通过对结点进行重新着色，以及对树进行相关的旋转操作，即修改树中某些结点的颜色及指针结构，来达到对红黑树进行插入或删除结点等操作后，继续保持它的性质或平衡。 左旋在某个结点x上做左旋操作：以x到y（x的右孩子）之间的链为“支轴”进行，它使y成为该孩子树新的根，y的左孩子b成为x的右孩子 #p[v]是v的父亲，left[v]right[v]是v的左右孩子 def LEFT-ROTATE(T, x): #在x上做左旋 y ← right[x] #modify3 right[x] ← left[y] p[left[y]] ← x #modify1 p[y] ← p[x] if p[x] = nil[T] #x是根 then root[T] ← y else if x = left[p[x]] #x是其父亲的左孩子 then left[p[x]] ← y else right[p[x]] ← y #x是其父亲的右孩子 #modify2 left[y] ← x p[x] ← y 右旋在某个结点x上做右旋操作：以x到y（x的左孩子）之间的链为“支轴”进行，它使y成为该孩子树新的根，y的右孩子c成为x的左孩子 红黑树的插入红黑树的插入相当于在二叉查找树插入的基础上，为了重新恢复平衡，继续做了插入修复操作。 向红黑树T中插入z： 搜索二叉树插入z 把z的左孩子、右孩子都赋为叶结点nil，再把z结点着为红色 旋转和调整着色 RB-INSERT(T, z) # 搜索二叉树插入 1 y ← nil[T] 2 x ← root[T] 3 while x ≠ nil[T] 4 do y ← x 5 if key[z] &lt; key[x] 6 then x ← left[x] 7 else x ← right[x] 8 p[z] ← y 9 if y = nil[T] 10 then root[T] ← z 11 else if key[z] &lt; key[y] 12 then left[y] ← z 13 else right[y] ← z # 涂色 # 把z的左孩子、右孩子都赋为叶结点nil，再把z结点着为红色 14 left[z] ← nil[T] 15 right[z] ← nil[T] 16 color[z] ← RED # 旋转和调整着色 17 RB-INSERT-FIXUP(T, z) 旋转和调整着色 RB-INSERT-FIXUP（T,z） 1 while color[p[z]] = RED 2 do if p[z] = left[p[p[z]]] 3 then y ← right[p[p[z]]] 4 if color[y] = RED 5 then color[p[z]] ← BLACK 6 color[y] ← BLACK 7 color[p[p[z]]] ← RED 8 z ← p[p[z]] 9 else if z = right[p[z]] 10 then z ← p[z] 11 LEFT-ROTATE(T, z) 12 color[p[z]] ← BLACK 13 color[p[p[z]]] ← RED 14 RIGHT-ROTATE(T, p[p[z]]) 15 else (same as then clause with &quot;right&quot; and &quot;left&quot; exchanged) 16 color[root[T]] ← BLACK while当前节点的父结点着色还是红色的，就继续调整 1 while color[p[z]] = RED 此时父结点的父结点一定存在，因为如果没有父结点即是根，而根不能是红色的 插入修复情况1：当前结点的父结点是红色且祖父结点的另一个子结点（叔叔结点）是红色即如下代码所示： 2 do if p[z] = left[p[p[z]]] # 如果父亲是祖父的左孩子 3 then y ← right[p[p[z]]] 4 if color[y] = RED 将当前结点的父结点和叔叔结点涂黑，祖父结点涂红，从祖父结点重新开始算法 5 then color[p[z]] ← BLACK 6 color[y] ← BLACK 7 color[p[p[z]]] ← RED 8 z ← p[p[z]] 当前一定是红色","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"gdb","slug":"gdb","date":"2022-07-10T07:06:13.000Z","updated":"2022-12-10T15:43:34.892Z","comments":true,"path":"2022/07/10/gdb/","link":"","permalink":"http://example.com/2022/07/10/gdb/","excerpt":"","text":"关注报错信息（搜索报错号） -rdynamic -g 编译，直接gdb运行（-rdynamic可以方便监控可能的段错误） 报错型bug调试建议：bt，从最靠近栈顶你写的函数，l那个函数和上一层函数，看p info这个函数的参数对不对（如果不好p info又没有写打印代码的话，先改源码在这个函数里面刚入口的地方加打印，然后r）不断向栈底看，直到参数没有问题的函数（就是它调用接下来的函数参数不对，而它自己传入的参数又没有问题，所以问题必然出在它里面到调用下一次函数之前），首先检查这个函数里面调用参数出错函数的代码有没有问题（检查传入的参数以及它们的来源。比如用来调用的参数不小心写混名字，参数在前面赋值的时候不小心赋错了用混了函数名），如果源码没有问题的话在这个函数处设条件断点（条件为参数取值为此时bt显示的值），然后r，到断点后单步 容器类型的参数要写打印代码（p info x都麻烦），注意把size也打印了（比如unorderedmap，没有分配的指针-&gt;size是奇怪值，但是for loop遍历打印内容可能却像空的一样） 逻辑型bug：断点从后往前以功能block为单位地设：如果运行到断点处值都正常，那说明问题只出在断点之后，如果不正常则要向前设断点（前面有地方有问题）（同时当前断点之后也不能保证没有问题），问题至少出在接下来的新断点之后 从后往前以功能为单位设断点的好处是，如果问题确实只出在最后一个功能block，那一下就定位问题所在了，前面不用都单步调试检查，不过这样要求你能够判断某个断点处各值是否正常，有时候这个是有难度的，而从头开始单步这个就比较简单 小规模代码的话可以把断点设很前，然后单步直到发现值不对劲发现问题 颜色和内容配置vim ~/.gdbinit gdbinit&#x2F;Gdbinit: Gdbinit for OS X, iOS and others - x86, x86_64 and ARM (github.com) r(un)在某处段错误后，打断点，然后可以r，这样程序会重新运行且你的断点还在（这样很好重新调试，一点点定位错误位置） 带参数调试调试带参数的程序：–args gdb --args ./main -d xxx -q xxx -f xxx 单步finish就是但单步执行到子函数内时，用step out就可以执行完子函数余下部分，并返回到上一层函数。在其他调试器中相当于step-out，作用是在栈中前进到到下一层，并在调用函数的下一行停止。 断点info b 查看当前设的断点 设断点bb test.c:9 b printNum 临时断点tb仅生效一次 tbreak test.c:l0 条件断点bb &lt;location&gt; if &lt;expression&gt; 的语法和c一样 假设程序某处发生崩溃，而崩溃的原因怀疑是某个地方出现了非期望的值，那么你就可以在这里断点观察，当出现该非法值时，程序断住。这个时候我们可以借助gdb来设置条件断点，例如： b test.c:23 if b==0 当在b等于0时，程序将会在第23行断住。它和condition有着类似的作用，假设上面的断点号为1，那么： condition 1 b==0 会使得b等于0时，产生断点1。而实际上可以很方便地用来改变断点产生的条件，例如，之前设置b&#x3D;&#x3D;0时产生该断点，那么使用condition可以修改断点产生的条件。 正则设置函数断点rbrbreak file:regex eg： rbreak printNum* #所有以printNum开头的函数都设置了断点 rbreak test.c:. #对test.c中的所有函数设置断点 rbreak test.c:^print #对以print开头的函数设置断点 watchpointwatch a 变量值被改写时断住 rwatch a 当变量值被读时断住 awatch a 被读或者被改写时断住 断点操作跳过断点ignore跳过次数 ignore 1 30 1是你要忽略的断点号，可以通过前面的方式查找到，30是需要跳过的次数。 禁用或启动断点disable有些断点暂时不想使用，但又不想删除，可以暂时禁用或启用。例如： disable #禁用所有断点 disable bnum #禁用标号为bnum的断点 enable #启用所有断点 enable bnum #启用标号为bnum的断点 enable delete bnum #启动标号为bnum的断点，并且在此之后删除该断点 保存读取断点保存 (gdb) save breakpoint &lt;文件名&gt;.bp 加载：使用-x参数指定断点文件 gdb &lt;可执行文件名&gt; -x &lt;bp文件名&gt;.bp 断点清除断点清除主要用到clear和delete命令。常见使用如下： clear #删除当前行所有breakpoints clear function #删除函数名为function处的断点 clear filename:function #删除文件filename中函数function处的断点 clear lineNum #删除行号为lineNum处的断点 clear f:lename：lineNum #删除文件filename中行号为lineNum处的断点 delete #删除所有breakpoints,watchpoints和catchpoints delete bnum #删除断点号为bnum的断点 查看变量值内存值有些复杂的结构体想看的话写个打印 格式控制格式控制字符如下： x 按十六进制格式显示变量。 d 按十进制格式显示变量。 u 按十六进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 p指定变量所在文件&#x2F;函数 p &#39;testGdb.h&#39;::a #testGdb.h文件中 p &#39;main&#39;::b #main函数中 打印指针所指多个值@ (gdb) p *d $2 = 0 (gdb) p *d@10 $3 = &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; (gdb) p *d@a #a是变量，当前值为10 $2 = &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; (gdb) $可表示上一个变量 可使用下面方式不断打印链表内容： (gdb) p *linkNode (这里显示linkNode节点内容) (gdb) p *$.next #$指上一个变量，即指刚刚p的那个linkNode (这里显示linkNode节点下一个节点的内容) 定义一个类似UNIX环境变量，例如： (gdb) set $index=0 (gdb) p b[$index++] $11 = 1 (gdb) p b[$index++] $12 = 2 (gdb) p b[$index++] $13 = 3 打印格式 (gdb) p/x c $19 = &#123;0x68, 0x65, 0x6c, 0x6c, 0x6f, 0x2c, 0x73, 0x68, 0x6f, 0x75, 0x77, 0x61, 0x6e, 0x67, 0x0&#125; (gdb) 用这种方式查看浮点数的二进制格式是怎样的是不行的，因为p&#x2F;t首先会将其转换成整型再转换为二进制表示，因此最终会得到8： (gdb) p e $1 = 8.5 (gdb) p/t e $2 = 1000 (gdb) infoinfo args 打印出当前函数的参数名及其值 info locals 打印出当前函数中所有局部变量及其值 info reg 查看寄存器值 xx/[n][f][u] addr n 表示要显示的内存单元数，默认值为1 f 表示要打印的格式，前面已经提到了格式控制字符 u 要打印的单元长度 addr 内存地址 单元类型常见有如下： b 字节 h 半字，即双字节 w 字，即四字节 g 八字节 把float变量e按照二进制方式打印，并且打印单位是一字节： (gdb) x/4tb &amp;e 0x7fffffffdbd4: 00000000 00000000 00001000 01000001 (gdb) display程序断住时，就显示某个变量的值 (gdb) display e 1: e = 8.5 查看哪些变量被设置了display info (gdb)into display Auto-display expressions now in effect: Num Enb Expression 1: y b 2: y e delete delete display num #num为前面变量前的编号,不带num时清除所有。 disable disable display num #num为前面变量前的编号，不带num时去使能所有 查看源码l(gdb) l test.c:1 (gdb) l test.c:printNum1 指定文件指定行之间： (gdb) l test.c:1,test.c:3 查找段错误位置段错误：硬件设备MMU发现访问了一个非法的虚拟地址，通知操作系统内核给进程发送11号信号，进程收到了一个11号信号，导致进程异常终 方法一： -rdynamic编译 gcc -g -rdynamic编译 gdb 然后r [root@localhost TEST]# gcc -g -rdynamic test.c [root@localhost TEST]# gdb ./a.out ... (gdb) r Starting program: /root/桌面/TEST/./a.out Program received signal SIGSEGV, Segmentation fault. 0x00000000004007d2 in main () at test.c:7 7 *ptr = 1; Missing separate debuginfos, use: debuginfo-install glibc-2.17-105.el7.x86_64 (gdb) 不用一步步调试我们就找到了出错位置在test.c文件的第4行 从这里我们还发现进程是由于收到了SIGSEGV信号而结束的。通过进一步的查阅文档(man 7 signal)，我们知道SIGSEGV默认handler的动作是打印”段错误”的出错信息，并产生Core文件 方法二：core文件 gcc -g 编译（加上-rdynamic也可以） 设置coredump文件大小为无限制（在运行可执行文件之前） ulimit -c unlimit .&#x2F;a.out 出现core.&lt;数字&gt;文件 gdb .&#x2F;a.out core.15180（gdb 目标文件 核心转移文件） [root@localhost TEST]# ./a.out 段错误(吐核) [root@localhost TEST]# ls a.out core.15180 test test.c [root@localhost TEST]# gdb ./a.out core.15180 ... [New LWP 15180] Core was generated by `./a.out&#39;. Program terminated with signal 11, Segmentation fault. ##0 0x00000000004007d2 in main () at test.c:7 7 *ptr = 1; Missing separate debuginfos, use: debuginfo-install glibc-2.17-105.el7.x86_64 (gdb) 调试qemu 下文qemu-system-riscv64可以来自： 我们使用的计算机都是基于x86架构的。如何把程序编译到riscv64架构的汇编？这需要我们使用“目标语言为riscv64机器码的编译器”，在我们的电脑上进行交叉编译。 使用现有的riscv-gcc编译器：两种方法 源码编译 从https://github.com/riscv/riscv-gcc clone下来，然后在x86架构上编译riscv-gcc编译器为可执行的x86程序，就可以运行它，来把你的程序源代码编译成riscv架构的可执行文件了。这有点像绕口令，但只要有一点编译原理的基础就可以理解。不过，这个riscv-gcc仓库很大，而且自己编译工具链总是一件麻烦的事。 使用别人已经编译好的编译器的可执行文件 也就是所谓的预编译（prebuilt）工具链，下载下来解压，放在你喜欢的地方，配好路径（把编译器的位置加到系统的PATH环境变量里），就能在终端使用了。我们推荐使用sifive公司提供的预编译工具链，**下载“GNU Embedded Toolchain ”。** 配置好后，在终端输入riscv64-unknown-elf-gcc -v查看安装的gcc版本, 如果输出一大堆东西且最后一行有gcc version 某个数字.某个数字.某个数字，说明gcc配置成功 因为gdb和qemu是两个应用不能直接交流，比较常用的方法是以tcp进行通讯，也就是让qemu在localhost::1234端口上等待。 编译：在lab0文件夹下打开终端，运行 $ qemu-system-riscv64 -S -s -hda ./bin/ucore.img WARNING: Image format was not specified for &#39;./bin/ucore.img&#39; and probing guessed raw. Automatically detecting the format is dangerous for raw images, write operations on block 0 will be restricted. Specify the &#39;raw&#39; format explicitly to remove the restrictions. VNC server running on 127.0.0.1:5900 开始gdb：然后在该文件夹下重新打开一个终端，运行 $ riscv64-unknown-elf-gdb ./bin/kernel GNU gdb (SiFive GDB 8.3.0-2020.04.1) 8.3 Copyright (C) 2019 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot; and &quot;show warranty&quot; for details. This GDB was configured as &quot;--host=x86_64-linux-gnu --target=riscv64-unknown-elf&quot;. Type &quot;show configuration&quot; for configuration details. For bug reporting instructions, please see: &lt;https://github.com/sifive/freedom-tools/issues&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type &quot;help&quot;. Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;... Reading symbols from ./bin/kernel... (No debugging symbols found in ./bin/kernel) (gdb) 接着连接qemu： (gdb) target remote :1234 Remote debugging using :1234 0x0000000000001000 in ?? () 连接成功输入si就可以进行运行下一条指令 (gdb) si 0x0000000000001004 in ?? () CMake生成的可执行文件gdb调试 (14条消息) CMake生成的可执行文件能够gdb调试_漫游学海之旅-CSDN博客 1 首先在CMakeLists.txt中加入 SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) 在下面加入： SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;) SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;) 原因是CMake 中有一个变量 CMAKE_BUILD_TYPE ,可以的取值是 Debug Release RelWithDebInfo &gt;和 MinSizeRel。 当这个变量值为 Debug 的时候,CMake 会使用变量 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_C_FLAGS_DEBUG 中的字符串作为编译选项生成 Makefile; 2 重新编译 $ cmake -DCMAKE_BUILD_TYPE=Debug Path 注： Path 为源码的文件夹路径（比如在项目文件夹下建build，在build里面cmake的话，则Path是..）， 如果 需要 Release 版 也可以 -DCMAKE_BUILD_TYPE ＝ Release 然后， $ cd Path #好像不用，比如在build目录下make就可以 $ make 3 可以调试 $ gdb sample 注：sample 为该可执行文件 多线程调试GDB多线程多进程调试 - 云+社区 - 腾讯云 (tencent.com) gdb 多线程调试 - 阿笨猫 - 博客园 (cnblogs.com) 举例-rdynamic -g编译后r之后报错，然后bt（已经bt过，现在是重新bt只显示我自己写的文件） q_v:1 q_v_n:2 d_v:2 d_v_n:4 dmap: sz:2 (1:2) (0:1) qmap: sz:2 (1:1) (0:1) dmap: sz:6491032 (2:1) (1:1) qmap: sz:1 (3:1) //看最栈顶我自己写的函数map_cover的参数，参数是map指针，内容不好确定是否正确，于是结束调试去在map_cover中刚进来的地方加打印代码（这样在crash时已经输出了出错调用的参数），同时结合自己的代码逻辑，为了确定map内容对不对还需确定是哪两个顶点的哪种类型邻居，因此在调用map_cover的check_nlf_cover中加打印dmap和qmap来自哪个顶点的代码 //然后重新编译和r，此时显示上文信息 //查看map_cover报错处的源码，看到报错在打印语句之后，所以最靠近报错处的dmap和qmap打印即出错调用map_cover传入的参数 //看到dmap的sz奇怪，另外注意到已经输出一次dmapqmap因此这是out_nlf的map_cover调用，因此定位是out_nlf的map_cover调用中dmap有问题（也注意到d_v_n:4，这个是在源代码检查无误之后去检查的，看d_v_n:4的out_nlf在check_nlf_cover中对不对） //查看上一层的源码out_nlf的map_cover调用中dmap的代码，还有dmap的来源代码，发现错误 //继续看check_nlf_cover的参数，部分看出是对的，可以先改一个错误编译gdb运行看看 Program received signal SIGFPE, Arithmetic exception. 0x0000000000416a95 in std::__detail::_Mod_range_hashing::operator() (this=0x630c48, __num=3, __den=0) at /usr/include/c++/4.8.2/bits/hashtable_policy.h:345 345 &#123; return __num % __den; &#125; Missing separate debuginfos, use: debuginfo-install libgcc-4.8.5-44.el7.x86_64 libstdc++-4.8.5-44.el7.x86_64 (gdb) bt -5 //bt ##5 0x000000000041a42a in FilterVertices::map_cover (dmap=0x630c48, qmap=0x630be8) at src/FilterVertices.cpp:777 ##6 0x00000000004199c0 in FilterVertices::check_nlf_cover (d_v=2, j=0, q_v=1, in_count=2, d_in_count=2, q_in_neighbors=0x62e228, d_in_neighbors=0x62e82c, query_graph=0x62e400, data_graph=0x62c300, candidates=0x631180) at src/FilterVertices.cpp:127 ##7 0x00000000004196e8 in FilterVertices::NLFFilter_1step (data_graph=0x62c300, query_graph=0x62e400, candidates=@0x7fffffffdd08: 0x631180, candidates_count=@0x7fffffffdd00: 0x631160) at src/FilterVertices.cpp:91 ##8 0x000000000041b244 in bulkq_nlf_filterCandi (qfilename_prefix=&quot;/media/data/hnu2022/yuanzhiqiu/DFiso_example/query_graph/query_&quot;, nlf_ave_candiScale=@0x7fffffffe0e8: 3.1974663790792123e-317, data_graph=0x62c300, qVScale=4, jb=1, je=2, one_step=true) at src/FilterQueryHelp.cpp:402 ##9 0x0000000000420f33 in main (argc=9, argv=0x7fffffffe448) at main.cpp:327 (gdb) l src/FilterVertices.cpp:777 //看map_cover打印是否在出错之前 772 return 0; 773 &#125; 774 775 for (auto qit : *qmap) 776 &#123; 777 auto it = dmap-&gt;find(qit.first); 778 if (it == dmap-&gt;end() || (it-&gt;second) &lt; qit.second) 779 &#123; 780 return 0; 781 &#125; (gdb) l src/FilterVertices.cpp:127 //看check_nlf_cover中out_nlf调用map_cover的源码（或者编辑器里面看也行） 122 &#123; 123 124 const std::unordered_map&lt;LabelID, ui&gt; *d_in_map = data_graph-&gt;getVertexInNLF(d_v_n); 125 const std::unordered_map&lt;LabelID, ui&gt; *d_out_map = query_graph-&gt;getVertexOutNLF(d_v_n);//d_out_map的来源，可以看到data_graph写成了query_graph，也发现下面一行也写错了 126 const std::unordered_map&lt;LabelID, ui&gt; *d_bi_map = query_graph-&gt;getVertexBiNLF(d_v_n); 127 if (map_cover(d_in_map, q_in_map) &amp;&amp; map_cover(d_out_map, q_out_map) &amp;&amp; map_cover(d_bi_map, q_bi_map))//看这第二个Map_cover调用，两个参数传入代码没有问题 128 &#123; 129 break; 130 &#125; 131 &#125; (gdb)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux下源码编译安装 设置环境变量","slug":"linux下源码编译安装 设置环境变量","date":"2022-07-10T04:53:49.000Z","updated":"2022-12-10T15:55:05.675Z","comments":true,"path":"2022/07/10/linux下源码编译安装 设置环境变量/","link":"","permalink":"http://example.com/2022/07/10/linux%E4%B8%8B%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%20%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"设置环境变量先学习下如何设置环境变量 To make the variable settings effect for each bash shell, put the exporting command to your ~/.bashrc, the individual per-interactive-shell startup file. bash中用于设置环境变量的语法如下 export VARIABLE=value Note that there is no space among the variable, the equals sign (“&#x3D;”) and the value. If the value has spaces, the value should be put in quotes. 比如 export PATH=$PATH:/home/yuanzhiqiu/Downloads/built/qemu-5.0.0 要检查它： echo $VARIABLE 让当前shell也配置生效 或者重启一个shell source ~/.bashrc 若系统如下设置：**$PATH在前，优先使用系统的。（因为系统在环境变量中查找目标文件时，找到第一个发现的位置就会停止搜索**） JAVA_HOME=/usr/local/java8 GCC8_HOME=/usr/local/gcc7 export PATH=$PATH:$JAVA_HOME/bin:$GCC8_HOME/bin 若将$PATH放在后面：这样优先使用自己安装的。 export PATH=$JAVA_HOME/bin:$GCC8_HOME/bin:$PATH https://blog.csdn.net/jhsword/article/details/95258625 linux非ROOT用户安装软件 源码编译安装安装流程非root用户没有权限，所以不能用apt-get命令一键安装，一般非root用户的安装流程为： wget命令下载软件源码，如：wget http://mama.indstate.edu/users/ice/tree/src/tree-1.7.0.tgz 解压：tar -zxvf ~ mkdir build &amp;&amp; cd build 配置安装目录和安装： 方法一：ccmake：ccmake .. 这样会出现让你配置cmake的界面，比如配置安装目录，这里设置下安装目录（默认是&#x2F;usr&#x2F;local） 然后make &amp;&amp; make install 方法二： 使用DESTDIR为make install指定安装目录：cmake.. 然后make &amp;&amp; make DESTDIR=/home/yuanzhiqiu/.local install 方法三：configure指定prefix：有configure文件的可以：先./configure --prefix=~/.local/usr/local/git/再make &amp;&amp; make install 修改 ~&#x2F;.bashrc 文件，配置环境变量，加入可执行文件路径，如: export PATH=/home/test/software1/bin:$PATH 注意一般都会在最后加上$PATH，这里是为了把在这之前设置的PATH都加入到PATH中，不然之前设置的PATH都会被覆盖，另外要注意liunx的配置文件路径分割符为冒号:,window 为分号；。 最后在已经开启且需要$PATH生效的shell中激活配置文件： source ~/.bashrc 通常非root用户的安装路径我习惯安装在 ~/local/usr/&lt;package_name&gt;/bin（ /home/&lt;usr_name&gt;/local/usr/&lt;package_name&gt;/bin）或者bin替换成sbin 因此会在 ~/local/usr/&lt;package_name&gt;/下执行源码下载命令（源码下载到哪个目录其实没关系的，指定好安装prefix即可），这样该目录下会出现一个&lt;package_name&gt;-&lt;version&gt;的源码目录，进入该目录进行编译安装，指定prefix为 ~/local/usr/&lt;package_name&gt;/（ /home/&lt;usr_name&gt;/local/usr/&lt;package_name&gt;/）","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"strace 输出所有系统调用","slug":"strace 输出所有系统调用","date":"2022-07-10T03:48:11.000Z","updated":"2022-12-10T15:56:12.458Z","comments":true,"path":"2022/07/10/strace 输出所有系统调用/","link":"","permalink":"http://example.com/2022/07/10/strace%20%E8%BE%93%E5%87%BA%E6%89%80%E6%9C%89%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","excerpt":"","text":"strace &lt;a.out&gt;","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"计算机保研面试2分钟英语自我介绍","slug":"计算机保研面试2分钟英语自我介绍","date":"2022-07-09T15:28:33.411Z","updated":"2022-12-10T16:01:37.303Z","comments":true,"path":"2022/07/09/计算机保研面试2分钟英语自我介绍/","link":"","permalink":"http://example.com/2022/07/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BF%9D%E7%A0%94%E9%9D%A2%E8%AF%952%E5%88%86%E9%92%9F%E8%8B%B1%E8%AF%AD%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"没有复杂句式和高级词汇（记不住），两分钟版本 姓名学校专业+总纲 Good Morning teachers. I am xxx from xxx University, majored in xxx.Next, I’d like to introduce myself from three aspects: major learning, scientific research, and student work. 专业学习：排名+绩点+荣誉 First, major learning.I ranked first in the major for 3 consecutive years with a GPA of 3.82.And I have won national scholarship and other honors. 科研经历2分钟时间可以展开来讲你希望老师问你的项目：内容(项目名称)+成果+贡献 Second, scientific research. The first work to mention is xxx(项目英文名称),First, my submission to CCKS was accepted, I was the first author.Second, I carried out experiments in C++, the code is about 3500 lines. My second work is xxx(项目英文名称),I carried out this project under professor X.(这个项目是跟着在面试的学院的一个老师做的，这位老师建议我可以在自我介绍或者问到项目的时候提一下是跟他做的)In this project, I First conducted literature research.Second, I carried out benchmark experiments in c++, and implemented the optimal complexity paper, the code is about 3800 lines. 这是不希望老师详细问的项目（和想去的研究方向关系很小+偏开发），带过（为什么提？hh凑时长+国家级奖项自己干了实际工作） In addition, I also worked in the embedded system and have won two national second prizes, mainly responsible for chip development. 学工：带过一下为啥要提？毕竟老师将来是要和你这个人相处的嘛~ Third, student work.I have served as the party secretary of my class for 3 yearsand the leader of the welcoming freshmen team.also, I am a member of my department volleyball team. 结束 That’s all. Thank you!","categories":[{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"个人博客后台服务器宕机解决","slug":"个人博客后台服务器宕机解决","date":"2022-07-09T15:25:19.314Z","updated":"2022-12-10T16:01:48.652Z","comments":true,"path":"2022/07/09/个人博客后台服务器宕机解决/","link":"","permalink":"http://example.com/2022/07/09/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E5%90%8E%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%95%E6%9C%BA%E8%A7%A3%E5%86%B3/","excerpt":"","text":"宕机恢复后如何重启服务服务器上重启博客后台服务： 检查是否有进程的comm是“java” ps -eo pid,comm | grep &quot;java&quot; 若无则运行halo jar包 nohup java -jar halo-1.5.4.jar &amp; 检查是否有进程的comm是“nginx”，若无则重启nginx服务 nginx -s reload #可能由于一些排错/usr/local/nginx/logs/nginx.pid文件会被清空或者被删除，则需先nginx -c /usr/local/nginx/conf/nginx.conf再reload 宕机原因和解决宕机现象直接现象：浏览器访问个人博客提示服务器拒绝连接，ssh远程连接工具无法连接上云服务器 真死机 服务器确确实实宕机了，导致服务不可用，无法访问。 假死机 由于硬件资源暂时性地被消耗殆尽，因而无法对外部指令进行响应的现象，比如CPU、内存、带宽被占满、磁盘空间耗尽。 宕机原因 访问量过高，超出系统承载能力，包括正常的短暂性突增，或者异常访问，比如黑客攻击等； 服务器配置过低，导致即便访问量不算太高也超出了系统承载能力，需要提高配置； 应用程序本身存在bug，比如死循环，消耗系统资源的逻辑导致资源耗尽； 某些系统参数配置不合理，比如fd个数或允许连接数过低等； 多线程造成的死锁现象，互相等待对方释放资源； 服务器硬件故障，比如内存故障，需要更换； 系统内核bug，比如软死锁等，需要升级内核； 人为误操作； 宕机排查和解决 首先判断是真死还是假死，如果假死，那等一段时间或手动杀死进程即可（当然建议检查杀死的高消耗进程对应的程序逻辑是否有不合理的地方），如果真死则需要进一步排查； 查看系统日志 &#x2F;var&#x2F;log&#x2F;messages，分析宕机时间前后的系统日志，看看是否有明显的报错，比如oom或内核bug； 如果启用了kdump，也可以查看宕机生成的crash文件，默认&#x2F;var&#x2F;crash目录下，注意生成时间是否对应； 查看监控数据，在宕机前有没有指标异常，比如CPU或内存突增，可能短暂突发上量超过系统承载能力； 也有可能是硬件故障，可以看下&#x2F;var&#x2F;log&#x2F;dmesg，或者登录远控查看系统日志，比如内存故障等，可能需要更换 没有办法的办法：重启云服务器的话一般控制台有重启按键，重启云服务器 所有日志文件 /var/log/messages — 包括整体系统信息，其中也包含系统启动期间的日志。此外，mail，cron，daemon，kern和auth等内容也记录在var/log/messages日志中。 /var/log/dmesg — 包含内核缓冲信息（kernel ring buffer）。在系统启动时，会在屏幕上显示许多与硬件有关的信息。可以用dmesg查看它们 /var/log/boot.log — 包含系统启动时的日志。 /var/log/daemon.log — 包含各种系统后台守护进程日志信息。 /var/log/dpkg.log – 包括安装或dpkg命令清除软件包的日志。 /var/log/kern.log – 包含内核产生的日志，有助于在定制内核时解决问题。 /var/log/lastlog — 记录所有用户的最近信息。这不是一个ASCII文件，因此需要用lastlog命令查看内容。 /var/log/maillog /var/log/mail.log — 包含来着系统运行电子邮件服务器的日志信息。例如，sendmail日志信息就全部送到这个文件中。 /var/log/user.log — 记录所有等级用户信息的日志 /var/log/Xorg.x.log — 来自X的日志信息 /var/log/alternatives.log – 更新替代信息都记录在这个文件中 /var/log/btmp – 记录所有失败登录信息。使用last命令可以查看btmp文件。例如，”last -f /var/log/btmp | more“ /var/log/cups — 涉及所有打印信息的日志 /var/log/anaconda.log — 在安装Linux时，所有安装信息都储存在这个文件中 /var/log/yum.log — 包含使用yum安装的软件包信息 /var/log/cron — 每当cron进程开始一个工作时，就会将相关信息记录在这个文件中 /var/log/secure — 包含验证和授权方面信息。例如，sshd会将所有信息记录（其中包括失败登录）在这里 /var/log/wtmp或/var/log/utmp — 包含登录信息。使用wtmp可以找出谁正在登陆进入系统，谁使用命令显示这个文件或信息等 /var/log/faillog – 包含用户登录失败信息。此外，错误登录命令也会记录在本文件中 /var/log/httpd/或/var/log/apache2 — 包含服务器access_log和error_log信息 /var/log/lighttpd/ — 包含light HTTPD的access_log和error_log /var/log/mail/ – 这个子目录包含邮件服务器的额外日志 /var/log/prelink/ — 包含.so文件被prelink修改的信息 /var/log/audit/ — 包含被 Linux audit daemon储存的信息 /var/log/samba/ – 包含由samba存储的信息 /var/log/sa/ — 包含每日由sysstat软件包收集的sar文件 /var/log/sssd/ – 用于守护进程安全服务","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"计算机保研简历面准备","slug":"计算机保研简历面准备","date":"2022-07-09T13:50:14.641Z","updated":"2022-12-10T16:01:59.896Z","comments":true,"path":"2022/07/09/计算机保研简历面准备/","link":"","permalink":"http://example.com/2022/07/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BF%9D%E7%A0%94%E7%AE%80%E5%8E%86%E9%9D%A2%E5%87%86%E5%A4%87/","excerpt":"","text":"我当时是按这个准备的面试~ 准备了我的两个科研项目，面试的时候项目相关问题基本全部覆盖（开放性问题除外，这个当场思考下）2022北叉大数据计科专业面经 成功上岸 对于每个打算被问的项目梳理如下内容： 情境：研究的什么问题，这个项目大概是干啥的（或输入输出，架构和各模块的大致设计）），研究的问题有什么实际应用场景 我在这个项目中贡献了什么：写了哪些代码，代码量多少，调研了哪些论文，完成了什么功能模块，有什么收获，（提出idea和证明，论文撰写） 结果：成果有哪些，实验结果怎么样（数据拿出来） 收获 如果是科研项目还需对如下每个阶段你干了什么、产出怎么样进行梳理：调研-实验（实验设计，数据集）-分析和结论-下一步方向 如果科研项目中是你提出的idea，则你需要复习你的idea： 解决什么问题 为什么能解决问题 怎么解决问题的 为什么实验可以证明你的idea可以解决问题，具体的效果怎么样 idea灵感怎么来的 对于每个打算被问的项目大致准备下如下问题：具体的问题： 介绍下这个项目 项目的亮点（比如处理的数据规模达百亿级别，你怎么做到的） 遇到了什么困难怎么解决的 一类的问题： 为什么这样做（每一个选择，比如为什么你的idea中选择3个顶点的图拓扑而不是4个或更多顶点，为什么实验进行对比的时候选择这些算法，为什么不选其他算法来做对比） 夏令营申请材料和面试时会呈现给老师的材料（如简历、申请表、个人陈述、ppt）中涉及到的概念和技术点，至少能说出其概念、原理、作用、优点 比如子图匹配：子图匹配是什么，有什么应用场景，通用解决的框架是什么 ppt和自我介绍指导： 自我介绍的 PPT 里体现自己所做的工作，例如写了哪些代码，代码量多少，调研了哪些论文，完成了什么功能模块，有什么收获，有什么收获，++拿出证据来++ 简洁+突出重点（不会的别提，很会的则引导过去） 关于语速，慢一点好","categories":[{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"linux源码阅读开发环境搭建","slug":"linux源码阅读开发环境搭建","date":"2022-07-09T13:10:10.809Z","updated":"2022-12-10T16:03:09.781Z","comments":true,"path":"2022/07/09/linux源码阅读开发环境搭建/","link":"","permalink":"http://example.com/2022/07/09/linux%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"","text":"vscode阅读linux源码方法一 一站式配置vscode目前存在的问题：仍然有一些红线报错，但是不影响跳转定义 vscode 安装插件 Remote-SSH：本机安装 C&#x2F;C++ 插件：remote安装（在remote安装插件的方法：先Remote-SSH连接上remote） 编译内核源码[编译内核（简单版）](# 编译内核（简单版）) 获取.vscode和生成compile_commands.jsonamezin&#x2F;vscode-linux-kernel: Visual Studio Code project&#x2F;compile_commands.json generator for Linux kernel sources and out-of-tree modules (github.com) 然后就可以了 完成之后打开某参与编译的c文件后，需要一段时间（大概5分钟）等建立索引，然后就可以支持跳转、悬停显示了 方法二Global（找不到u32等的定义） VSCode 阅读 Linux 代码怎么才不卡顿？这样做才能快的飞起！-51CTO.COM u32等的定义在v5.10中有22处的样子，所以其真正的定义来源要看你的编译，而这种方法没有利用编译信息 远程主机安装 global 工具apt install global 安装完之后，确认两个二进制文件，global，gtags， 一般在 &#x2F;usr&#x2F;bin&#x2F; 目录下。有这两个文件，就说明 OK 。 Linux 源码下载，库支持下载和生成 源码放到远程的目录 库支持参见编译的环境依赖 还是有头文件需要编译才生成： c - Can’t find the source of some “asm”, “generated” header files in linux kernel? - Unix &amp; Linux Stack Exchange I don’t have any idea where to look for these files: #include &lt;generated/timeconst.h&gt; /* /include/linux/jiffies.h */ #include &lt;generated/bounds.h&gt; #include &lt;generated/autoconf.h&gt; /* /include/linux/kconfig.h */ #include &lt;generated/asm-offsets.h&gt; 解答： You’ll find the header files used by your build in /lib/modules/$(uname -r)/build/, see for example find /lib/modules/$(uname -r)/build/ -name timeconst.h All these files are generated during the build, in various ways; timeconst.h is built by kernel/time/timeconst.bc. /lib/modules/$(uname -r)/build/ stores the generated headers (and a few other files) corresponding to the running kernel; the intention is to make them available for external module builds in particular. If you’re building a new kernel, you’ll find the generated files in your build tree (after a kernel build, or an in-tree-module build). vscode 安装插件 Remote-SSH：本机 C&#x2F;C++ 插件：remote（在remote安装插件的方法：先Remote-SSH连接上remote），如果首次安装在remote上需要配置 C&#x2F;C++ GNU Global：用于符号解析，remote vscode 配置 global 路径vscode 的settings(ssh)里： 在 vscode 的 settings.json 配置里，指定 global 的相关路径。 &quot;gnuGlobal.globalExecutable&quot;: &quot;/usr/bin/global&quot;, &quot;gnuGlobal.gtagsExecutable&quot;: &quot;/usr/bin/gtags&quot;, // 指明生成的符号表存放在哪个位置 &quot;gnuGlobal.objDirPrefix&quot;: &quot;/mnt/.global&quot; 注意：”gnuGlobal.objDirPrefix” 的路径必须要手动创建好（一个这个名字的空文件即可），如果不存在，会导致后续 Rebuild 的失败。 比如： 在当前目录下创建一个.global文件夹，里面创建一个gnuGlobal.objDirPrefix文件，然后配置”gnuGlobal.objDirPrefix”: “.global” 测试是否成功执行远程主机上的 Gtags测试一下安装配置的是否正确。shift + command + P 把命令面板掉出来，执行 Global: Show GNU Global Version 命令，看是否能成功显示版本。在右下角显示版本号，那么就说明一切就绪： global (GNU GLOBAL) 6.6.4 生成符号表 shift + command + P 把命令面板调出来，执行 Global: Rebuild Gtags Database 命令。等待右下角的通知，如果显示： Build tag files successfully 那么就说明符号表解析完成了。符号表生成成功会在 “gnuGlobal.objDirPrefix” 的路径里生成三个文件： root@ubuntu20:/mnt/opensource/linux-3.10# ll -lh /mnt/.global/mnt/opensource/linux-3.10/ total 395M drwxr-xr-x 2 root root 4.0K Feb 14 19:06 ./ drwxr-xr-x 3 root root 4.0K Feb 14 18:33 ../ -rw-r--r-- 1 root root 7.6M Feb 14 19:06 GPATH -rw-r--r-- 1 root root 278M Feb 14 19:06 GRTAGS -rw-r--r-- 1 root root 109M Feb 14 19:06 GTAGS 1.2.3.4.5.6.7. 方法三clangd（无法定义跳转） https://blog.csdn.net/xhnmdlfl/article/details/117911630 vscode 安装插件 Remote-SSH：本机 clangd：remote和本机（在remote安装插件的方法：先Remote-SSH连接上remote），如果首次安装在remote上需要配置 安装clangd在VSCode Extension组件页搜索clangd，在插件介绍界面点击安装即可。 需要注意的是clangd有两个安装选项，一个是安装到本地，也就是windows系统上，也可以选择安装到远程服务器上，比如页面显示可以看到有个”Install in SSH: 192.168.50.170”安装选项，这两个都需要安装。 linux远程服务器上的clangd默认是安装到~&#x2F;.vscode-server&#x2F;目录下。 VSCode在安装linux版本的clangd时是在github上下载安装包然后通过ssh导入到服务器上，正常途径访问不了github的同学这一步可能会超时安装失败，可以通过其他途径到clangd的 github发布页 按平台下载安装包，安装包在linux系统上解压出来，然后手动拷贝到对应系统目录即可。如果没有系统权限，参考vscode默认方式安装到自己的home目录也可以（可能需要自己导出路径到环境变量）。 需要注意的是如果VSCode之前安装过C++ Intellisense插件需要禁用或者卸载掉，因为会和clangd插件有冲突。 vscode 插件配置配置clangd在已安装的Extension组件页选中clangd，点击图标旁边的齿轮打开设置页，User和Remote标签页中的Clangd Arguments都按照下面设置（点击Add Item，一个item输入下面的一行） –compile-commands-dir&#x3D;${workspaceFolder}–background-index–completion-style&#x3D;detailed–header-insertion&#x3D;never-log&#x3D;info 设置完后关掉设置页面即可，vs会自动保存。 生成compile_commands.json在当前目录就会生成compile_commands.json： bear make 或 amezin&#x2F;vscode-linux-kernel: Visual Studio Code project&#x2F;compile_commands.json generator for Linux kernel sources and out-of-tree modules (github.com) 触发clangd工作内核源码根目录，也就是compile_commands.json所在的目录，这个目录就作为我们的worksapce了。 在左边文件列表里双击任何一个.c内核源文件（需要是参与编译的），这个时候你就可以看到最下面状态栏clangd开始执行indexing了，也就是解析workspace下compile_commands.json文件里描述的所有源文件，创建索引数据库（保存在workspace目录下的.cache&#x2F;clangd目录下），待所有索引文件创建完成再回到代码窗口可以看到#include后面的头文件名下面都有了下划线，这个时候代码里的函数、变量、宏定义和头文件就可以通过Ctrl+鼠标左键点击来跳转查看定义了，指针悬停在这些地方也会显示出预览了。 相比source insight创建index，感觉clangd要快不少，而且创建的index数据库也比较小。后续如果文件改动了，clangd在启动的时候会自动重新同步并生成新的index，但是如果新增了文件的话就需要重新执行bear make去生成新的compile_commands.json，这样新的文件才会被索引。 编译内核（简单版）[详细版（含安装内核）](# How to compile and install Linux Kernel 5.16.9) 在远程主机上 [安装编译环境](# Step 4. Install the required compilers and other tools) 下载源码和解压缩 wget -c https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz unxz -v linux-5.16.9.tar.xz tar xvf linux-5.16.9.tar 配置内核features：照抄远程主机linux内核的 cd linux-5.16.9 cp -v /boot/config-$(uname -r) .config 编译（在linux-5.16.9目录下） make 或者指定线程数目 make -j $(nproc) #系统核数 修改源码后编译也是make，亲测初次编译后，8核编译时间2分钟 [详细版编译安装内核]How to compile and install Linux Kernel 5.16.9 How to compile and install Linux Kernel 5.16.9 from source code - nixCraft (cyberciti.biz) This step by step howt o covers compiling Linux kernel version 5.16.9 under an Ubuntu or Debian Linux. The following instructions successfully tested on an RHEL CentOS 7&#x2F;8 (and clones), Debian Linux, Ubuntu Linux and Fedora Linux 31&#x2F;32. However, instructions remain the same for any other Linux distribution. The procedure to build (compile) and install the latest Linux kernel from source is as follows: Grab the latest kernel from kernel.org Verify kernel Untar the kernel tarball Copy existing Linux kernel config file Compile and build Linux kernel 5.16.9 Install Linux kernel and modules (drivers) Update Grub configuration Reboot the system 你将需要至少 12 GB 的本地可用磁盘空间来完成内核的编译过程 Step 1. Get the latest Linux kernel source codeThe filename would be linux-x.y.z.tar.xz, where x.y.z is actual Linux kernel version number. For example file linux-5.16.9.tar.xz represents Linux kernel version 5.16.9. Use the wget command to download Linux kernel source code:$ wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz Step 2. Extract tar.xz fileYou really don’t have to extract the source code in &#x2F;usr&#x2F;src. You can extract the source code in your $HOME directory or any other directory using the following unzx command or xz command:$ unxz -v linux-5.16.9.tar.xz OR$ xz -d -v linux-5.16.9.tar.xz 这个是得到.tar文件 Verify Linux kernel tartball with pgp（如果不用安装而只是编译的话不用这步）First grab the PGP signature for linux-5.16.9.tar:$ wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.signTry to verify it:$ gpg --verify linux-5.16.9.tar.signSample outputs: gpg: assuming signed data in &#39;linux-5.16.9.tar&#39; gpg: Signature made Sun 12 Aug 2018 04:00:28 PM CDT gpg: using RSA key 79BE3E4300411886 gpg: Can&#39;t check signature: No public key Grab the public key from the PGP keyserver in order to verify the signature i.e. RSA key ID 79BE3E4300411886 (from the above outputs):$ gpg --recv-keys 79BE3E4300411886Sample outputs: gpg: key 79BE3E4300411886: 7 duplicate signatures removed gpg: key 79BE3E4300411886: 172 signatures not checked due to missing keys gpg: /home/vivek/.gnupg/trustdb.gpg: trustdb created gpg: key 79BE3E4300411886: public key &quot;Linus Torvalds &lt;torvalds@kernel.org&gt;&quot; imported gpg: no ultimately trusted keys found gpg: Total number processed: 1 gpg: imported: 1 Now verify gpg key again with the gpg command:$ gpg --verify linux-5.16.9.tar.signSample outputs: gpg: assuming signed data in &#39;linux-5.16.9.tar&#39; gpg: Signature made Sun 12 Aug 2018 04:00:28 PM CDT gpg: using RSA key 79BE3E4300411886 gpg: Good signature from &quot;Linus Torvalds &lt;torvalds@kernel.org&gt;&quot; [unknown] gpg: aka &quot;Linus Torvalds &lt;torvalds@linux-foundation.org&gt;&quot; [unknown] gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: ABAF 11C6 5A29 70B1 30AB E3C4 79BE 3E43 0041 1886 If you do not get “BAD signature” output from the “gpg –verify” command, untar&#x2F;extract the Linux kernel tarball using the tar command, enter:$ tar xvf linux-5.16.9.tar Step 3. Configure the Linux kernel features and modulesBefore start building the kernel, one must configure Linux kernel features. You must also specify which kernel modules (drivers) needed for your system. The task can be overwhelming for a new user. I suggest that you copy existing config file using the cp command:$ cd linux-5.16.9 $ cp -v /boot/config-$(uname -r) .configSample outputs: &#39;/boot/config-4.15.0-30-generic&#39; -&gt; &#39;.config&#39; Step 4. Install the required compilers and other toolsYou must have development tools such as GCC compilers and related tools installed to compile the Linux kernel. How to install GCC and development tools on a Debian&#x2F;Ubuntu LinuxType the following apt command or apt-get command to install the same:$ sudo apt-get install build-essential libncurses-dev bison flex libssl-dev libelf-devSee “Ubuntu Linux Install GNU GCC Compiler and Development Environment” for more info. How to install GCC and development tools on a CentOS&#x2F;RHEL&#x2F;Oracle&#x2F;Scientific LinuxTry yum command:$ sudo yum group install &quot;Development Tools&quot;OR$ sudo yum groupinstall &quot;Development Tools&quot;Additional packages too:$ sudo yum install ncurses-devel bison flex elfutils-libelf-devel openssl-devel How to install GCC and development tools on a Fedora LinuxRun the following dnf command:$ sudo dnf group install &quot;Development Tools&quot;$ sudo dnf install ncurses-devel bison flex elfutils-libelf-devel openssl-devel Step 5. Configuring the kernel[optional]Now you can start the kernel configuration by typing any one of the following command in source code directory: $ make menuconfig – Text based color menus, radiolists &amp; dialogs. This option also useful on remote server if you wanna compile kernel remotely. $ make xconfig – X windows (Qt) based configuration tool, works best under KDE desktop $ make gconfig – X windows (Gtk) based configuration tool, works best under Gnome Dekstop. For example, run make menuconfig command launches following screen:$ make menuconfigYou have to select different options as per your need. Each configuration option has HELP button associated with it so select help button to get help. Please note that ‘make menuconfig’ is optional. I used it here to demonstration purpose only. You can enable or disable certain features or kernel driver with this option. It is easy to remove support for a device driver or option and end up with a broken kernel. For example, if the ext4 driver is removed from the kernel configuration file, a system may not boot. When in doubt, just leave support in the kernel. Step 5. How to compile a Linux KernelbuildStart compiling and tocreate a compressed kernel image, enter:$ makeTo speed up compile time, pass the -j as follows:## use 4 core/thread ## $ make -j 4 ## get thread or cpu core count using nproc command ## $ make -j $(nproc)Compiling and building the Linux kernel going take a significant amount of time. The build time depends upon your system’s resources such as available CPU core and the current system load. So have some patience. build之前会有很多选项要你选择（网络、IO、…），我一路默认（除了内核压缩模式，我下载的是.xz所以选择对应的） Install the Linux kernel modules$ sudo make modules_install Install the Linux kernelSo far we have compiled the Linux kernel and installed kernel modules. It is time to install the kernel itself:$ sudo make install It will install three files into &#x2F;boot directory as well as modification to your kernel grub configuration file: initramfs-5.16.9.img System.map-5.16.9 vmlinuz-5.16.9 Step 6. Update grub configYou need to modify Grub 2 boot loader configurations. Type the following command at a shell prompt as per your Linux distro: CentOS&#x2F;RHEL&#x2F;Oracle&#x2F;Scientific and Fedora Linux$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg$ sudo grubby --set-default /boot/vmlinuz-5.16.9` You can confirm the details with the following commands: `grubby --info=ALL | moregrubby --default-indexgrubby --default-kernel Debian&#x2F;Ubuntu LinuxThe following commands are optional as make install does everything for your but included here for historical reasons only:$ sudo update-initramfs -c -k 5.16.9$ sudo update-grub How to build and install the latest Linux kernel from source codeYou have compiled a Linux kernel. The process takes some time, however now you have a custom Linux kernel for your system. Let us reboot the system. Reboot Linux computer and boot into your new kernelJust issue the reboot command or shutdown command:# rebootVerify new Linux kernel version after reboot:$ uname -mrsSample outputs: Linux 5.16.9 x86_64 Conclusion – Linux Compile Kernel version 5.16.9Configurations! You completed various steps to build the Linux kernel from source code and compiled kernel should be running on your system. I strongly suggest that you always keep backup of essential data and visit the kernel.org page here for more info.","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"powershell","slug":"powershell","date":"2022-07-09T12:58:18.393Z","updated":"2022-12-10T16:06:20.247Z","comments":true,"path":"2022/07/09/powershell/","link":"","permalink":"http://example.com/2022/07/09/powershell/","excerpt":"","text":"删除文件（夹）rmdir递归删除 rmdir /s folder 查看所有文件dir查看包含隐藏文件的所有文件 dir /A *","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"tmux","slug":"tmux","date":"2022-07-09T12:54:32.169Z","updated":"2022-12-10T16:06:48.935Z","comments":true,"path":"2022/07/09/tmux/","link":"","permalink":"http://example.com/2022/07/09/tmux/","excerpt":"","text":"Tmux所有快捷键都要通过前缀键（Ctrl+b）唤起，在tmux窗口中可以使用； tmux命令在普通终端和tmux窗口中均可以使用； 多个会话，每个会话可以创建多个窗口，每个窗口可以划分为多个窗格； 以会话为单位attach上某个会话 新建tmux #新建一个会话，编号从0开始 tmux new -t &lt;session-name&gt; Tmux 窗口底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息 重新接入tmux a[ttach] -t &lt;num or session-name&gt; 帮助Ctrl+b ? 退出Ctrl+b d 退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行 查看（从而切换）会话Ctrl+b s 查看当前所有的 Tmux 会话（有些不会列出来） tmux list-s(ession) 查看所有的 Tmux 会话 杀死您可以tmux kill-server用来干净利落地杀死所有tmux打开的会话（和服务器）。 如果您要保留在tmux会话中，请使用tmux kill-session -a来关闭所有其他会话。 要关闭特定会话，请使用tmux list-s(essions)查看要终止的会话，然后使用tmux kill-session -t targetSession终止该特定会话。 您也可以使用彻底杀死所有tmux进程pkill -f tmux。 重命名Ctrl+b $ 重命名当前会话；重命名指定会话 tmux rename-session -t &lt;num or session-name&gt; &lt;new-name&gt; 鼠标开启： 先按Ctrl + B， 松开以后，输入冒号，输入set -g mouse on 回车 解除： 先按Ctrl + B， 松开以后，输入冒号，输入set -g mouse off 回车 窗格操作 窗格操作：对于当前窗口window Ctrl+b % 左右划分 Ctrl+b “ 上下划分 Ctrl+b &lt;方向键&gt; 切换当前窗格 Ctrl+b x 删除当前窗格 Ctrl+b { 当前窗格左移； Ctrl+b } 当前窗格右移 Ctrl+b q 显示当前会话所有窗格的编号 窗口操作： Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息 Ctrl+b p：（previous）切换到上一个窗口（按照状态栏上的顺序） Ctrl+b n：（next）切换到下一个窗口。 Ctrl+b &lt;number&gt;：切换到指定编号的窗口，其中的&lt;number&gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。 Ctrl+b ,：窗口重命名。 列出当前所有 Tmux 会话的信息 tmux info 重新加载当前的 Tmux 配置 tmux source-file ~/.tmux.con Xshell断开连接后仍保持服务器程序执行的方法（tmux）tmux比nohup方便，建议使用tmux。 先安装tmux：sudo apt-get install tmux 然后用命令：tmux new -s session_name 新开一个会话 在会话里启动进程后，回到原本界面的方法： 先按下ctrl+b，然后再单独按d 此时会话里的进程仍然在运行 重新回到会话里查看进程的方法：tmux a -t session_name 查看会话中历史记录：先按ctrl+b，然后按Page Up ，Page Down 可以同时新建多个会话s1,s2,s3 在会话间切换的命令： 先按ctrl+b ，再按s，然后就可以在会话间选择其中一个，按enter进入。 即使关闭xhsell，会话也仍然存在，如果里面有进程，会持续运行。 除非进入会话中把进程关闭掉。 关闭会话的方法： tmux kill-session -t session_name","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"git","slug":"git","date":"2022-07-09T12:48:53.716Z","updated":"2022-12-10T16:07:02.453Z","comments":true,"path":"2022/07/09/git/","link":"","permalink":"http://example.com/2022/07/09/git/","excerpt":"","text":"git 廖雪峰 跟踪文本文件的改动 不要使用Windows自带的记事本编辑任何文本文件。原因是Microsoft开发记事本的团队使用了一个非常弱智的行为来保存UTF-8编码的文件，他们自作聪明地在每个文件开头添加了0xefbbbf（十六进制）的字符 基础用法1.git init把当前目录变成Git可以管理的仓库： $ mkdir learngit $ cd learngit $ git init Initialized empty Git repository in /Users/michael/learngit/.git/ 2.git add commit git add $ git add readme.txt git commit $ git commit -m &quot;wrote a readme file&quot; [master (root-commit) eaadf4e] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt -m后面输入的是本次提交的说明 查看 git status diff log查看工作区状态 $ git status 查看文件变化 $ git diff readme.txt diff --git a/readme.txt b/readme.txt index 46d49bf..9247db6 100644 --- a/readme.txt +++ b/readme.txt @@ -1,2 +1,2 @@ -Git is a version control system. +Git is a distributed version control system. Git is free software. 查看日志 git log命令显示从最近到最远的提交日志 $ git log $ git log --pretty=oneline 1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -&gt; master) append GPL e475afc93c209a690c39c13a46716e8fa000c366 add distributed eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0 wrote a readme file 一大串类似1094adb...的是commit id（版本号），Git的commit id是一个SHA1计算出来的一个非常大的数字，用十六进制表示 版本切换git reset 在Git中，用HEAD表示当前版本，也就是最新的提交，上一个版本就是HEAD^，上上一个版本就是HEAD^^，往上100个版本写成HEAD~100 回退到上一版本 $ git reset --hard HEAD^ HEAD is now at e475afc add distributed 提供版本号（比如刚刚回退之前的最新版本的版本号开头是1094a，想到那个版本） 版本号没必要写全，前几位就可以了，Git会自动去找 $ git reset --hard 1094a HEAD is now at 83b0afe append GPL 原理 Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL： ┌────┐ │HEAD│ └────┘ │ └──&gt; ○ append GPL │ ○ add distributed │ ○ wrote a readme file 改为指向add distributed： ┌────┐ │HEAD│ └────┘ │ │ ○ append GPL │ │ └──&gt; ○ add distributed │ ○ wrote a readme file 然后顺便把工作区的文件更新了。 git refloggit reflog查看你的每一次命令： $ git reflog e475afc HEAD@&#123;1&#125;: reset: moving to HEAD^ 1094adb (HEAD -&gt; master) HEAD@&#123;2&#125;: commit: append GPL e475afc HEAD@&#123;3&#125;: commit: add distributed eaadf4e HEAD@&#123;4&#125;: commit (initial): wrote a readme file 第一列是版本号 丢弃修改git checkout reset git checkout -- file 用版本库里的版本替换工作区的版本（让这个文件回到最近一次git commit或git add时的状态） $ git checkout -- readme.txt 命令git checkout -- readme.txt意思就是，把readme.txt文件 用版本库里的版本替换工作区的版本，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 git reset HEAD &lt;file&gt;可以把暂存区的修改撤销掉（unstage），重新放回工作区： $ git reset HEAD readme.txt Unstaged changes after reset: M readme.txt 删除文件$ rm test.txt 把工作区文件删除之后（test.txt是已经提交了的）， 用命令git rm删掉，并且git commit： $ git rm test.txt rm &#39;test.txt&#39; $ git commit -m &quot;remove test.txt&quot; [master d46f35e] remove test.txt 1 file changed, 1 deletion(-) delete mode 100644 test.txt 现在，文件就从版本库中被删除了。 远程仓库设置user name和email如果你是第一次使用，或者还没有配置过的话需要操作一下命令，自行替换相应字段。 git config --global user.name &quot;Luke.Deng&quot; git config --global user.email &quot;xiangshuo1992@gmail.com&quot; git config –list 查看当前Git环境所有配置，还可以配置一些命令别名之类的。 远程仓库地址操作添加远程仓库：进入本地仓库执行：origin是给远程源的一个命名，你可以随便取 git remote add origin &lt;远程仓库git的地址&gt; 修改远程仓库地址： git remote set-url origin &lt;remote-url&gt; 仓库路径查询查询： git remote -v 删除指定的远程仓库： git remote rm origin git push 本地仓库推送到远程仓库（已关联）将本地当前分支 推送到 远程指定分支上（分支名字方向是 按**数据传输方向 -&gt;**）： git push &lt;远程仓库“名字”，在remote add的时候取的名字&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; #若两个分支名字只写一个，则默认这俩分支名都是它 比如： git push origin master # 将当前仓库的master分支推送到origin的master分支 git push origin main baseline # 将当前仓库的main分支推送到origin的baseline分支 -f：强制推送到远程仓库，且覆盖远程代码库 git push -f origin master git pull 从远程获取代码并合并本地的版本分支名字方向是 按**数据传输方向 -&gt;**： git pull &lt;远程仓库“名字”，在remote add的时候取的名字&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 比如： git pull origin master git clone远程仓库进入本地目录： git clone &lt;远程仓库git地址&gt; 这样执行git clone的目录下fork来的那个目录就是一个git目录了，并且自动关联远程仓库 克隆指定分支 git clone -b &lt;指定分支名&gt; &lt;远程仓库git地址&gt; gitignore在项目开发过程中个，一般都会添加 .gitignore 文件，规则很简单，但有时会发现，规则不生效。原因是 .gitignore 只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交。 git rm -r --cached . git add . git commit -m &quot;update .gitignore&quot; 本地仓库关联git服务器上的.gitstep1 git服务器上操作下文用表示git服务器的外网ip地址 附：root如何创建用户： 例如创建“张三”用户： useradd zhangsan passwd hnuzs [可选]ssh免登陆操作 此步骤是为了在本地服务器连接远程git服务器时免于输入用户密码，具体操作如下： 将本地服务器的公钥id_rsa.pub传入远程git服务器的&#x2F;home&#x2F;&#x2F;.ssh&#x2F;authorized_keys认证文件中。 cat id_rsa.pub &gt;&gt; authorized_keys #pwd:/home/&lt;user_name&gt;/.ssh 创建并初始化git仓库 首先创建一个目录作为git仓库并赋予所属用户： cd /home/&lt;user_name&gt; mkdir zsgitrepo chown &lt;user_name&gt;:&lt;user_name&gt; zsgitrepo/ 接着使用git命令创建一个裸仓库，服务器上的git仓库通常以.git结尾，并更改仓库所属用户： cd zsgitrepo git init --bare zsrepo.git chown -R &lt;user_name&gt;:&lt;user_name&gt; zsrepo.git step2 本地服务器上操作 添加远程版本库 git remote add origin git@&lt;git_server_ip&gt;:/home/&lt;user_name&gt;/xxrepo/xx.git # git@&lt;git_server_ip&gt;:&lt;absolute path to your .git on git server&gt; 关联后举例：git clone克隆仓库注意clone的.git的地址 $ git clone &lt;user_name&gt;@&lt;git_server_ip&gt;:/home/&lt;user_name&gt;/zsgitrepo/zsrepo.git Cloning into &#39;zsrepo&#39;... 公匙解决 remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. 解决方法： 本地服务器生成公匙并上传到远程服务器上，具体操作： linux下生成公匙，传公匙到github上：参考链接 windows下生成公匙：见下文 上传到其他git服务器上：见下文 然后remote用ssh的地址，不用http的地址 linux下公匙私匙生成公匙上传githubwindows下公匙私匙生成 SSH-key 在Windows下如何生成公钥和私钥 在centos上搭建git服务器并自动同步代码 - 云+社区 - 腾讯云 (tencent.com) git安装好后 右键选择Git GUI Here-&gt;Help-&gt;Show SSH Key 就能得到私钥和公钥 公钥上传远程git服务器的认证文件中cat id_rsa.pub &gt;&gt; authorized_keys #pwd:/home/&lt;user_name&gt;/.ssh/ 如果没有~&#x2F;.ssh&#x2F;authorized_keys就新建一个 cd /home/&lt;user_name&gt; mkdir .ssh chmod 700 .ssh touch .ssh/authorized_keys chmod 600 .ssh/authorized_keys git原理暂存区工作区（Working Directory）：比如刚刚git init所在的那个目录 版本库（Repository）：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用 git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用 git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。现在改成main了 gitflow流程概念 错误示范： 不知道他怎么搞的，直接 push 到 master 分支去了，直接跨过开发分支和测试分支，直接合到 master 发布分支上去了（一般来说，master都是有保护的！）。 这还不算什么。。。如果只是这样就还好，关键是他看有写代码冲突就直接在 master 分支上对已经成功发版的代码增删改！！！ 一般来说，团队合作开发的话，每个人都需要在自己的功能分支 feat&#x2F;XXX 上开发，最后一起合并到总的开发分支 dev 上，然后将开发分支 dev 合并到测试分支上，最后将测试分支合并到正式发布分支上。 其中总的开发分支一般叫做 dev 分支，正式发布分支一般是叫 main&#x2F;master&#x2F;release 分支。 一般的开发流程： 比如说有 A、B、C 三个人协助进行功能开发： 1、首先 A、B、C 三位小伙伴从总开发分支 Dev 上开辟自己的功能分支，分别是 feat&#x2F;AXXX、feat&#x2F;BXXX、feat&#x2F;CXXX，也就是图中 feat&#x2F;AXXX、feat&#x2F;BXXX、feat&#x2F;CXXX 的三条线； 2、然后在自己的开发机上进行开发，这里的开发机可以是本地环境也可以是一些云端的开发机。开发完毕后，再分别合到总开发分支 dev 上，也就是图中蓝色的三条线，在这个过程中可能会产生一些代码冲突，挨个 solve 即可； 3、接着在 dev 分支上确认所有功能开发完毕，进行简单自测，fix 一些 bug 后再向测试分支上进行合并； 4、这个时候就可以艾特测试组的同学来进行测试，测试通过后再合到 master 分支进行发布。 GitFlow流程 - 简书 (jianshu.com) git提交-m规范type （scope）: message 参数介绍： 1、type：指的代码的提交类型，不同的提交类型表示对应不同的代码改动，比如： feat：新功能的开发 fix：bug的修复 docs：文档格式的改动 style：代码格式改变 refactor：对已有的功能进行重构 perf：性能优化 test：增加测试 build：改变了build工具 revert：撤销上一次的commit提交 chore：构建过程或辅助工具的变动 2、scope：用于说明commit影响的范围，比如：权限模块、还是首页 3、message： 对提交的代码做一个简短的说明，不能过长。 fix（系统菜单图标）：添加缺少的图标 问题git: Failed to connect to 127.0.0.1 port 1080: Connection refused在git init顶层目录下 git config --global --unset http.proxy git config --global --unset https.proxy OpenSSL SSL_read: Connection was reset, errno 10054git config --global http.sslVerify &quot;false&quot; Failed to connect to github.com port 443 after 21114 ms: Timed out用ssh的那个地址","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"}],"author":"zhiqiuyuan"},{"title":"netstat 查看udptcp连接","slug":"netstat 查看udptcp连接","date":"2022-07-09T07:23:48.608Z","updated":"2022-12-10T16:07:18.976Z","comments":true,"path":"2022/07/09/netstat 查看udptcp连接/","link":"","permalink":"http://example.com/2022/07/09/netstat%20%E6%9F%A5%E7%9C%8Budptcp%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"netstatnetstat -nt —&gt;&gt;&gt;查看tcp连接 netstat -nua —&gt;&gt;&gt;查看udp连接 [root@dbserver ~]# netstat -nt ---&gt;&gt;&gt;查看tcp连接 Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.80.187:22 192.168.80.1:54458 ESTABLISHED tcp 0 0 192.168.80.187:22 192.168.80.1:54455 ESTABLISHED tcp 0 0 192.168.80.187:22 192.168.80.1:52256 ESTABLISHED tcp 0 0 192.168.80.187:22 192.168.80.1:52264 ESTABLISHED tcp 0 0 192.168.80.187:7432 192.168.80.1:54515 ESTABLISHED [root@dbserver ~]# netstat -nua ---&gt;&gt;&gt;查看udp连接 Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 0.0.0.0:5353 0.0.0.0:* udp 0 0 0.0.0.0:41277 0.0.0.0:* udp 0 0 127.0.0.1:323 0.0.0.0:* udp 0 0 0.0.0.0:978 0.0.0.0:* udp 0 0 192.168.122.1:53 0.0.0.0:* udp 0 0 0.0.0.0:67 0.0.0.0:* udp 0 0 0.0.0.0:111 0.0.0.0:* udp6 0 0 ::1:323 :::* udp6 0 0 ::1:61020 ::1:61020 ESTABLISHED udp6 0 0 :::978 :::* udp6 0 0 :::111 :::* [root@dbserver ~]# 如下取自man netstat的结果： Recv-Q Established: The count of bytes not copied by the user program connected to this socket. Listening: Since Kernel 2.6.18 this column contains the current syn backlog. Send-Q Established: The count of bytes not acknowledged by the remote host. Listening: Since Kernel 2.6.18 this column contains the maximum size of the syn backlog.","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"npm","slug":"npm","date":"2022-07-09T06:45:08.601Z","updated":"2022-12-10T16:07:54.221Z","comments":true,"path":"2022/07/09/npm/","link":"","permalink":"http://example.com/2022/07/09/npm/","excerpt":"","text":"创建项目 给项目添加package.json文件 npm init index.html放public目录下 js放src目录下 运行npm install #安装依赖 npm start #u 安装模块到指定目录默认情况下（即npm install XXX），在哪个文件夹下运行npm，npm就在当前目录创建一个文件夹node_modules，然后将要安装的程序安装到文件夹node_modules里面 如果将安装的程序安装到我们指定的目录而不是当前目录： 设置npm安装程序时的默认位置 npm config set prefix &quot;C:\\Users\\Default\\AppData\\Roaming\\npm\\node_modules&quot; 设置npm安装程序时的缓存位置 npm config set cache &quot;C:\\Users\\Default\\AppData\\Roaming\\npm\\node_cache&quot; 设置环境变量NODE_PATH NODE_PATH = C:\\Users\\Default\\AppData\\Roaming\\npm\\node_global\\node_modules 然后在使用npm安装程序时在后面加一个参数-g即可将安装的程序安装到我们指定的目录（比如npm install XXX -g）C:\\Users\\Default\\AppData\\Roaming\\npm\\node_modules","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"vim操作","slug":"vim操作","date":"2022-07-09T06:10:04.849Z","updated":"2022-12-10T16:09:22.202Z","comments":true,"path":"2022/07/09/vim操作/","link":"","permalink":"http://example.com/2022/07/09/vim%E6%93%8D%E4%BD%9C/","excerpt":"","text":"配置you should modify the vim configuration file. The file is called vimrc, and it is located under /etc/vim directory. We first make a copy of it to the home directory by cp command: cp /etc/vim/vimrc ~/.vimrc open .vimrc using vim: vim ~/.vimrc builtin help system报错&#x2F;etc&#x2F;apt&#x2F;sources.list” E212: Can’t open file for writing Running :h E212 inside Vim :h &lt; 全选复制粘贴缓冲区Vim 中的复制、删除的内容默认都会被存放到默认（未命名）寄存器中，之后可以通过粘贴操作读取默认寄存器中的内容。寄存器是完成这一过程的中转站，Vim 支持的寄存器非常多，其中常用的有 a-zA-Z0-9+&quot;。 其中： 0-9：表示数字寄存器，是 Vim 用来保存最近复制、删除等操作的内容，其中 0 号寄存器保存的是最近一次的操作内容。 a-zA-Z：表示用户寄存器，Vim 不会读写这部分寄存器 &quot;（单个双引号）：未命名的寄存器，是 Vim 的默认寄存器，例如删除、复制等操作的内容都会被保存到这里。 +：剪切板寄存器，关联系统剪切板，保存在这个寄存器中的内容可以被系统其他程序访问，也可以通过这个寄存器访问其他程序保存到剪切板中的内容。 全选并复制到系统剪切板【好像没用？】gg 到首行，然后 &quot;+yG 把行首到行尾的内容复制到 + 寄存器。 &quot;+yy // 复制当前行到剪切板 &quot;+p // 将剪切板内容粘贴到光标后面 &quot;ayy // 复制当前行到寄存器 a &quot;ap // 将寄存器 a 中的内容粘贴到光标后面 根据平台不同，要分两种情况。先用下面命令确定你属于哪一种， vim --version | grep clipboard 不支持系统粘贴板情况一， 如果结果里你找到加号开头的**+clipboard**， 恭喜你，你的vim没问题，是你姿势问题。 用**&quot;+y** 代替y将选中的内容复制到系统剪贴板，效果和ctrl-c一致。 用**&quot;+p**代替p将剪贴板内容复制到指定位置，也可以用ctrl-v。 d，x，c，s也一样，用之前前面加**&quot;+**。 如果想偷懒用y直接把内容复制到系统剪贴板，需要到vim配置文件.vimrc里加一行属性。用下面命令开始配置， vim ~/.vimrc 然后，加入下面这行， set clipboard=unnamed 现在你的y，d，x，p已经能和 ctrl-c和ctrl-v 一个效果，并且能互相混用。 情况二， 如果找到的是负号开头的**-clipboard，**说明你的vim不支持系统剪切板，我的MacOS系统自带vim就不支持，所以跑来了。需要先重新安装vim， Linux系统， sudo apt install vim-gtk MacOS， brew install vim 安装好之后，重复情况一的操作即可。 命令 选定文本块。使用v进入可视模式，移动光标键选定内容。 复制的命令是y，即yank（提起） ，常用的命令如下：y 在使用v模式选定了某一块的时候，复制选定块到缓冲区用；yy 复制整行（nyy或者yny ，复制n行，n为数字）；y^ 复制当前到行头的内容；y$ 复制当前到行尾的内容；yw 复制一个word （nyw或者ynw，复制n个word，n为数字）；yG 复制至档尾（nyG或者ynG，复制到第n行，例如1yG或者y1G，复制到档尾） 剪切的命令是d，即delete，d与y命令基本类似，所以两个命令用法一样，包括含有数字的用法.d 剪切选定块到缓冲区；dd 剪切整行d^ 剪切至行首d$ 剪切至行尾dw 剪切一个worddG 剪切至档尾 粘贴的命令式p，即put（放下）p 小写p代表贴至游标后（下），因为游标是在具体字符的位置上，所以实际是在该字符的后面P 大写P代表贴至游标前（上）整行的复制粘贴在游标的上（下）一行，非整行的复制则是粘贴在游标的前（后） 全选：ggVG 注： 命令前面加数字表示重复的次数，加字母表示使用的缓冲区名称。使用英文句号”.”可以重复上一个命令。 navigate非编辑（normal）模式下： 行间shift+g 跳转到最后一行 gg 跳转到第一行 nG 移动光标到当前文件的第n行:n 移动光标到当前文件的第n行 (同上) 行内0 移动光标到当前行行首$ 移动光标到当前行行尾^ 移动光标到当前行的第一个非空字符 单词级w 移动到下一单词的开头b 移动到上一单词的开头e 移动到光标所在单词的末尾 查找1，查找 在normal模式下按下/即可进入查找模式，输入要查找的字符串并按下回车。 Vim会跳转到第一个匹配。按下n查找下一个，按下N查找上一个。 Vim查找支持正则表达式，例如/vim$匹配行尾的&quot;vim&quot;。 需要查找特殊字符需要转义，例如/vim\\$匹配&quot;vim$&quot;。 2，大小写敏感查找 在查找模式中加入\\c表示大小写不敏感查找，\\C表示大小写敏感查找。例如： /foo\\c 将会查找所有的&quot;foo&quot;,&quot;FOO&quot;,&quot;Foo&quot;等字符串。 3，查找当前单词 在normal模式下按下*即可查找光标所在单词（word）， 要求每次出现的前后为空白字符或标点符号。例如当前为foo， 可以匹配foo bar中的foo，但不可匹配foobar中的foo。 这在查找函数名、变量名时非常有用。 按下g*即可查找光标所在单词的字符序列，每次出现前后字符无要求。 即foo bar和foobar中的foo均可被匹配到。 替换:s（substitute）命令用来查找和替换字符串。语法如下： :&#123;作用范围&#125;s/&#123;目标&#125;/&#123;替换&#125;/&#123;替换标志&#125; 例如:%s/foo/bar/g会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。 :%s/blog_os/yzq_os/g 作用范围作用范围分为当前行、全文、选区等等。 当前行： :s/foo/bar/g 全文： :%s/foo/bar/g 选区，在Visual模式下选择区域后输入:，Vim即可自动补全为 :&#39;&lt;,&#39;&gt;。 :&#39;&lt;,&#39;&gt;s/foo/bar/g 2-11行： :5,12s/foo/bar/g 当前行.与接下来两行+2： :.,+2s/foo/bar/g 代码折叠在可折叠处（大括号中间）：1 zc 折叠2 zC 对所在范围内所有嵌套的折叠点进行折叠3 zo 展开折叠4 zO 对所在范围内所有嵌套的折叠点展开5 [z 到当前打开的折叠的开始处。6 ]z 到当前打开的折叠的末尾处。7 zj 向下移动。到达下一个折叠的开始处。关闭的折叠也被计入。8 zk 向上移动到前一折叠的结束处。关闭的折叠也被计入。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"vscode通用操作 vscode安装卸载","slug":"vscode通用操作 vscode安装卸载","date":"2022-07-09T06:09:18.684Z","updated":"2022-12-10T16:10:54.419Z","comments":true,"path":"2022/07/09/vscode通用操作 vscode安装卸载/","link":"","permalink":"http://example.com/2022/07/09/vscode%E9%80%9A%E7%94%A8%E6%93%8D%E4%BD%9C%20vscode%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD/","excerpt":"","text":"ubuntu20.04下安装和启动ubuntu20.04使用 apt 安装Visual Studio Code 在官方的微软 Apt 源仓库中可用。想要安装它，按照下面的步骤来： 以 sudo 用户身份运行下面的命令，更新软件包索引，并且安装依赖软件： sudo apt update sudo apt install software-properties-common apt-transport-https wget 使用 wget 命令插入 Microsoft GPG key ： wget -q https://packages.microsoft.com/keys/microsoft.asc -O- | sudo apt-key add - 启用 Visual Studio Code 源仓库，输入： sudo add-apt-repository &quot;deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main&quot; 一旦 apt 软件源被启用，安装 Visual Studio Code 软件包： sudo apt install code 当一个新版本被发布时，你可以通过你的桌面标准软件工具，或者在你的终端运行命令，来升级 Visual Studio Code 软件包： sudo apt update sudo apt upgrade ubuntu20.04启动VS Code 也可以通过在终端命令行输入code进行启动。 快捷键折叠展开 折叠所有 Ctrl+K, 0. 展开所有 Ctrl+K, J. windows彻底卸载字体比较好看的一种： settings-&gt;搜索font font family填： Consolas, &#39;Courier New&#39;, monospace 关闭保存时自动格式化 https://www.jianshu.com/p/9e7589a0153a 方法一： 看看自己的编辑器插件里面有没有安装Prettier – Code formatter这个插件，如果有的话，直接禁用。 方法二： 打开vs code首选项里面的设置，分别搜索editor.formatOnSave以及editor.formatOnType，将对应设置前的选择框取消勾选。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python安装模块","slug":"python安装模块","date":"2022-07-09T04:45:21.248Z","updated":"2022-12-10T16:11:26.801Z","comments":true,"path":"2022/07/09/python安装模块/","link":"","permalink":"http://example.com/2022/07/09/python%E5%AE%89%E8%A3%85%E6%A8%A1%E5%9D%97/","excerpt":"","text":"python3 pipwindows pip install &lt;package_name&gt; linuxpython3: pip3 install &lt;package_name&gt; 网上搜一下，不一定和import的一样 –user 仅为当前用户安装10.13 安装私有的包 — python3-cookbook 3.0.0 文档 Python有一个用户安装目录，通常类似”~&#x2F;.local&#x2F;lib&#x2F;python3.3&#x2F;site-packages”。 要强制在这个目录中安装包，可使用安装选项“–user”","categories":[{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"ubuntu+virtualbox虚拟机安装后操作","slug":"ubuntu+virtualbox虚拟机安装后操作","date":"2022-07-09T04:39:00.743Z","updated":"2022-12-10T16:11:40.683Z","comments":true,"path":"2022/07/09/ubuntu+virtualbox虚拟机安装后操作/","link":"","permalink":"http://example.com/2022/07/09/ubuntu+virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%E5%90%8E%E6%93%8D%E4%BD%9C/","excerpt":"","text":"装ubuntu虚拟机参考网上教程 [可选]装ubuntu虚拟机后virtualbox安装增强功能设备-&gt;安装增强功能 sudo su cd /media mkdir cdrom mount /dev/cdrom /media/cdrom 然后跑去根目录找一下VBoxLinuxAdditions.run在哪里，应该在&#x2F;media&#x2F;cdrom中 cd / sudo find -name &quot;*VBoxLinuxAdditions*&quot; 运行它 sudo apt-get install linux-headers-$(uname -r) #先这个 sudo ./media/cdrom/VBoxLinuxAddition.run #r 换源在ubuntu下执行sudo apt-get update时，经常会遇到报错： 1 Err http://security.ubuntu.com precise-security InRelease 2 3 Err http://security.ubuntu.com precise-security Release.gpg 4 Temporary failure resolving &#39;security.ubuntu.com&#39; 5 Err http://cn.archive.ubuntu.com precise InRelease 6 7 Err http://cn.archive.ubuntu.com precise-updates InRelease 8 9 Err http://cn.archive.ubuntu.com precise-backports InRelease 10 11 Err http://cn.archive.ubuntu.com precise Release.gpg 12 Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 13 Err http://cn.archive.ubuntu.com precise-updates Release.gpg 14 Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 15 Err http://cn.archive.ubuntu.com precise-backports Release.gpg 16 Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 17 Reading package lists... Done 18 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise/InRelease 19 20 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise-updates/InRelease 21 22 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise-backports/InRelease 23 24 W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/precise-security/InRelease 25 26 W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/precise-security/Release.gpg Temporary failure resolving &#39;security.ubuntu.com&#39; 27 28 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise/Release.gpg Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 这是因为镜像源除出了问题，一般都会推荐使用国内的镜像源，比如163或者阿里云或者清华大学的镜像服务器 （强烈建议使用清华镜像） 清华镜像源官网：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 将下列文本添加到&#x2F;etc&#x2F;apt&#x2F;sources.list文件里 # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse 或者进入repogen.simplylinux.ch 选择合适的Ubuntu版本后，在ubuntu Branches下全选 拉至网页最下，点击生产，复制list下内容，添加到&#x2F;etc&#x2F;apt&#x2F;sources.list中即可 具体参考https://jingyan.baidu.com/article/afd8f4de66efcf34e286e993.html?st=2&amp;os=0&amp;bd_page_type=1&amp;net_type=2 修改镜像源之后需要重新更新： sudo apt-get update sudo apt-get upgrade 如果执行sudo apt-get update仍然报错，问题在于DNS没有配置好。按下方配置 配置DNS解决方法： sudo vi /etc/resolv.conf 在其中添加： # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 127.0.1.1 #这里用的是阿里云的DNS服务器 nameserver 223.5.5.5 nameserver 223.6.6.6 设置字体命令行设置系统字体 sudo dpkg-reconfigure console-setup gnome-tweaks 装中文输入法 谷歌输入法ubuntu20.04 安装fcitx-googlepinyinsudo apt-get install fcitx-googlepinyin 配置language support安装完成后打开菜单栏（按键盘上ctrl和alt之间的那个键，就是windows里的win键，在ubuntu里叫super），键盘输入language support并打开。 第一次打开会显示语言支持没有完全安装，点击安装并输入密码开始安装。 安装好后就能进入语言支持界面，最下面一行Keyboard input method system，默认是iBus，点击下拉单切换到fcitx（系统初始没有fctix，安装fcitx-googlepinyin的时候会装好fcitx）。然后重启电脑。 输入法配置重启之后在右上角状态栏点击键盘图标，在下拉单里选择倒数第三个Configure进入配置界面。 点击输入方法设置左下角的+号，进入添加输入方法界面。取消“只显示当前语言”选项的勾选，输入pinyin搜索到系统现有的拼音输入法。选择Google Pinyin并点击OK确认。 关闭设置，谷歌输入法配置完成。可以点击右上角状态栏的键盘图片切换到谷歌输入法，切换输入法的快捷键是ctrl+space，可以在刚关闭的输入方法设置界面里第二项Global Config里修改快捷键。 ping通主机和虚拟机 网络地址转换设置端口转发（推荐） 这样配置之后主机直接连接192.168.56.1:5556会自动转发到虚拟机的3325端口 192.168.56.1来自：本机ipconfig 效果比如 虚拟机上运行server程序 ip_port = (&#39;&#39;, 3325) sk = socket.socket() sk.bind(ip_port) sk.listen(5) while True: print(&#39;server waiting...&#39;) conn, addr = sk.accept() client_data = conn.recv(1024) print(client_data.decode()) conn.sendall(&#39;不要回答,不要回答,不要回答&#39;.encode()) conn.close() 本机运行client程序可以成功通信 ip_port = (&#39;192.168.56.1&#39;, 5556) sk = socket.socket() sk.connect(ip_port) sk.sendall(&#39;请求占领地球&#39;.encode()) server_reply = sk.recv(1024) print(server_reply.decode()) sk.close() 终端快捷键ctrl+alt+t 打开终端 ctrl + shift + t 添加终端多标签 alt+1 alt+2切换多标签","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"访问github和google","slug":"访问github和google","date":"2022-07-09T04:25:46.538Z","updated":"2022-12-10T16:11:54.868Z","comments":true,"path":"2022/07/09/访问github和google/","link":"","permalink":"http://example.com/2022/07/09/%E8%AE%BF%E9%97%AEgithub%E5%92%8Cgoogle/","excerpt":"","text":"Github访问加速访问网址加速dev-sidecar fastGithub（目前在用它，好用） git clone push等加速用ssh的地址，不用http的 访问谷歌 插件 edge浏览器IGG谷歌访问助手插件 谷歌镜像 全渠道搜索_思谋上网导航 (scmor.com) 翻墙vpn","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"halo文章分类","slug":"halo文章分类","date":"2022-07-09T00:13:11.043Z","updated":"2022-12-10T16:12:26.307Z","comments":true,"path":"2022/07/09/halo文章分类/","link":"","permalink":"http://example.com/2022/07/09/halo%E6%96%87%E7%AB%A0%E5%88%86%E7%B1%BB/","excerpt":"","text":"可能用到的管理后台功能后台中 “文章”-“分类目录”可以创建分类（发布文章的时候也可以） “外观”-“菜单设置”可以设置博客顶部菜单栏的内容，以及每一项的路径 由于允许指定每一项的路径，因此可以将这里的路径指向自定义页面","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"}],"author":"zhiqiuyuan"},{"title":"nginx排错","slug":"nginx排错","date":"2022-07-08T23:58:43.160Z","updated":"2022-12-10T16:12:34.168Z","comments":true,"path":"2022/07/09/nginx排错/","link":"","permalink":"http://example.com/2022/07/09/nginx%E6%8E%92%E9%94%99/","excerpt":"","text":"比如502 Bad GateWay 查看nginx目录下logs下的error.log这个是debug开始，找到对应问题出现时间的报错信息 解决举例比如大概07:30:04时访问我的博客后台报错nginx 502，于是查看error.log： 2022/07/09 07:30:04 [error] 41038#0: *3286 connect() failed (111: Connection refused) while connecting to upstream, client: 182.109.237.75, server: zhiqiuyuan.site, request: &quot;GET /admin HTTP/1.1&quot;, upstream: &quot;http://127.0.0.1:8090/admin&quot;, host: &quot;120.48.116.29&quot; 这说明我服务器ip120.48.116.29上端口8090连接不上 所以先检查我服务器上端口8090运行的服务还在不（我在端口8090运行halo jar包） ps -eo pid,comm | grep &quot;java&quot; 发现没有进程，所以重新nohup运行halo jar包 等1min后解决","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"2022北大叉院 大数据科学研究中心 计科 夏令营面经","slug":"2022北大叉院 大数据科学研究中心 计科 夏令营面经","date":"2022-07-08T14:12:48.202Z","updated":"2022-12-10T16:12:43.171Z","comments":true,"path":"2022/07/08/2022北大叉院 大数据科学研究中心 计科 夏令营面经/","link":"","permalink":"http://example.com/2022/07/08/2022%E5%8C%97%E5%A4%A7%E5%8F%89%E9%99%A2%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83%20%E8%AE%A1%E7%A7%91%20%E5%A4%8F%E4%BB%A4%E8%90%A5%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"本人情况 末985 rank1 两项科研经历，第一项有一篇中文一作在投，第二项没发表成果 面试前一天被接收了于是自我介绍里面改成被接收了，不管怎么说，中文的，很菜 一些可以忽略不计的竞赛（两项很水的国二，一项很水的省二，全部都偏开发） 由于机缘巧合大概今年2月份联系到了北叉的老师，上述第二项科研工作是在老师的指导下干的。想去北大建议提前联系老师，争取能够在老师那做科研项目，既可以学东西又可以证明自己 面经硕士层次面试20分钟没有机试没有笔试2022.7.4倒数第二个，大概下午2点40开始 英文自我介绍2min 通知邮件说可以用ppt，然后现场不准用ppt 感觉老师们都面累了 我还坚持了一会我想用ppt因为之前没有准备过不带ppt的英语自我介绍(哭 然后老师们不让 最后还好练得次数足够多可以把稿子背出来orz 问项目。先让我讲一个印象最深刻的项目，然后抓着这个项目问你提出的方法是啥，有没有和典型方法进行对比，实验结果怎么样 我讲的是我发了文章的那个项目，因为有自己提出的idea所有老师可能就一直抓着这个来尝试听懂了 还有老师们没有做我这个方向的hhh然后很艰难地问我问题，我的解答老师好像没有听懂(哭 好不容易撑到了10分钟感觉 问我专业啥情况，怎么排名的 我专业是试验班，大二分流去的智能，所以老师问咋招生以及咋排名的 尬住了，老师不知道要问什么，在看我的申请材料 麻，重来一次我一定这个时候主动开始bb我调研的那些文献用的什么方法、有什么共性、有什么改进，以及多提一下之前和北大老师合作的项目 问数学：线性代数（特征值和特征向量是啥，正定矩阵是啥） 继续尬住 我申请表上有个实验是在十亿规模的图上的，问我有没有什么算法设计上和普通规模的图要考虑的不一样的点 答：没有（呜呜呜服务器内存大就没有问题），只是在开发上运行时间比较长有采取应对服务器中途断开的一些方法 寄 继续尬住，看手表，好，时间到了你走吧 被移出会议室 END 第一场夏令营面试，寄 结果2022.7.5 更新：联系的北大老师昨晚来确认名额了，今天下午也接到北叉秘书电话了，拿到优营 总结2022.7.6更新： 提前联系老师挺重要的，不是说和老师邮件几句话很重要，而是争取到在老师指导下做科研的机会（如果你有一定的实力，在这个过程中可以很好地让老师看到你的潜力，提前占坑，另外也是对于老师的一个考核，看ta风格你喜不喜欢），所以2月份可以开始联系老师了 大佬另说，有很多大佬没有联系老师也入营且拿到优营了，菜鸡自知所以提早争取机会呜呜呜 rk也挺重要的，我当时联系老师的时候老师有确认过两次我是否rk1 可能是末9的原因，学校水平稍低的情况下看rk来判断你的专业知识水平也可以理解了hh 开发类竞赛对于保研的重要程度似乎远小于上述两点，我的开发类竞赛面试的时候老师没有提到过，时间有限的情况下推荐科研&gt;竞赛（ACM另说，这个真的牛，机试菜鸡仰望） u1s1，可能是我参加的开发类竞赛过于水+答辩成分过重+自我驱动能力欠缺，感觉参加三四个比赛学到的东西不如搞一个没有产出的科研项目学到的东西多； 另外，也是u1s1，任何一个项目，不管是课设还是竞赛还是科研还是参与开源项目还是实习还是你自己写的工具，如果你在其中确实做出了很有含金量的工作，那这个就是很好的履历，是你可以被老师反复提问和与老师交流的点，说科研重要个人认为大概是出于一种概率的说法（即平均来讲，你本科阶段能接触到的各种项目中，在科研项目中你做出高含金量工作的可能性相对比较大）+对于研究生阶段所需能力的直接检验","categories":[{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"halo+云服务器(centos)搭建个人博客","slug":"halo+云服务器(centos)搭建个人博客","date":"2022-07-08T13:57:05.695Z","updated":"2022-12-10T16:12:52.913Z","comments":true,"path":"2022/07/08/halo+云服务器(centos)搭建个人博客/","link":"","permalink":"http://example.com/2022/07/08/halo+%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8(centos)%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"鸣谢codesheep的教程 Why do you need a personal blog? show who you are and what you can do When you complete a project, you can put it in your portfolio for all to see 1.购买云服务器我选择的是百度智能云，操作系统为centos 得到服务器的公网ip地址，下称 2.云服务器安装环境java11 用于运行halo jar包 yum install java-11-openjdk -y 查看版本 java -version nginx 用于配置端口转发 源码编译安装 下载源码压缩包 官网下载：nginx: download 比如nginx-1.17.10版本的 下载nginx-1.17.10.tar.gz到&#x2F;root目录下（下面以此为例） 安装依赖 yum install gcc yum install pcre-devel yum install openssl openssl-devel 源码编译安装 创建目录和源码解压（目标是把nginx可可执行文件放在目录&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;下面） cd /usr/local/ mkdir nginx cd nginx tar zxvf /root/nginx-1.17.10.tar.gz -C ./ 进入源码目录，编译安装 cd nginx-1.17.10 ./configure # 如果后面需要配置成https的话，nginx需要安装https支持，则要加参数： # ./configure --with-http_ssl_module make &amp;&amp; make install # make会输出可执行文件到当前目录/objs/下面，make install其实可选 安装完成后，Nginx的可执⾏⽂件位置位于/usr/local/nginx/sbin/nginx 添加环境变量（可选） 可以把上述可执行文件位置添加到环境变量$PATH（这样直接nginx的话shell找得到nginx的可执行文件在哪里），或者以后运行的时候指定路径 在~&#x2F;.bashrc最后添加一行 export PATH=$PATH:/usr/local/nginx/sbin/ 然后使得配置在当前shell生效： source ~/.bashrc 可以检查一下$PATH内容： echo $PATH 3.运行halo和配置端口转发 参考Halo和几分钟，拥有⾃⼰的⾼颜值网站！代码都不用写_哔哩哔哩_bilibili 获取和后台运行jar包wget -c https://dl.halo.run/release/halo-1.5.4.jar nohup java -jar halo-1.5.4.jar &amp; #nohup，no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行 #&amp;的意思是后台运行 此时浏览器访问http:&#x2F;&#x2F;:8090会进入首次配置界面，填写信息后会进入管理后台 以后访问http:&#x2F;&#x2F;:8090是你的博客界面，http:&#x2F;&#x2F;:8090&#x2F;admin是后台管理界面 [可选]配置端口转发如果想直接http:&#x2F;&#x2F;访问的就是你的博客界面： 修改nginx配置文件 按如上方式安装的nginx则配置文件在&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf下面，是nginx.conf 新增upstream，并将server监听的端口80转发到upstream上 upstream halo &#123; server 127.0.0.1:8090; &#125; server &#123; listen 80; server_name localhost; client_max_body_size 1024m; #设置允许上上传文件的大小，因为nginx默认的是限制1M location / &#123; proxy_pass http://halo; #这个halo和上面的upstream名字一致 proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 重启nginx服务 nginx -s reload [可选]4.域名http://www.访问的就是你的博客，则需购买域名并绑定域名到公网ip 注册域名我选的是腾讯云注册域名 域名需要备案 绑定域名到公网ip以腾讯云为例，其他的可以搜官方文档 进入我的域名 - 域名注册 - 控制台 (tencent.com)，对要绑定的域名点击“解析” “添加记录” 主机记录：www 记录类型：A 线路类型：默认 记录值： TTL：600 点击”确定“ 点击新出现记录的三角形图标，启动解析 过大约10分钟之后，ping www.如果ping通则ok了 [可选]5.配置httpsSSL证书 申请免费ssl证书和下载证书 一般在注册域名的网站都有申请免费SSL证书的入口 比如腾讯云可以直接搜索”ssl证书“然后有入口，按指示操作即可，认证挺快的 证书申请成功后请下载对应服务器类型的证书文件，这里使用的是Nginx 上传 .key 与 .pem 后缀的两个文件，上传到服务器中 比如nginx目录下cert目录下（按上述nginx安装方式即目录&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;cert&#x2F;下） 配置nginx.conf 如下修改nginx.conf文件（主要注意改域名和证书文件路径） upstream halo &#123; server 127.0.0.1:8090; &#125; ## 配置http转发到https server &#123; listen 80; # 将demo.uanin.com改为您自己的域名 server_name demo.uanin.com; # 上传文件大小的限制 client_max_body_size 1024m; # 将所有http请求通过rewrite重定向到https。 rewrite ^(.*)$ https://$host$1 permanent; &#125; ## 配置demo.uanin.com的ssl server &#123; listen 443 ssl; # 将demo.uanin.com改为您自己的域名 server_name demo.uanin.com; # 上传文件大小的限制 client_max_body_size 1024m; # 将证书文件存放路径和证书的密钥文件名替换成自己存放路径与证书的密钥文件名。 ssl_certificate /usr/local/nginx/cert/3977015_demo.uanin.com.pem; ssl_certificate_key /usr/local/nginx/cert/3977015_demo.uanin.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://halo; #这个halo和上面的upstream名字一致 &#125; &#125; nginx reload重新生效nginx -s reload 可能报错解决 如果之前安装nginx时没有参数指定安装https支持的话，会报错nginx: [emerg] the “ssl“ parameter requires ngx_http_ssl_module，解决法： 先获取之前编译安装nginx的参数，然后再加上–with-http_ssl_module的参数重新configure-make（获取之前参数主要是希望重新编译安装得到的可执行文件只是比之前多了https支持，而不是少了些东西）： nginx -V #显示的configure arguments:后面的内容即之前nginx的make参数 重新源码编译 # 进入nginx源码目录，然后 ./configure &lt;之前安装给configure的参数&gt; --with-http_ssl_module make #这会输出可执行文件到当前目录/objs/下面 然后将原先&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx覆盖为新的可执行文件 nginx -s stop #先停止运行，才能覆盖成功的 cp ./objs/nginx /usr/local/nginx/sbin/nginx 此时nginx -s reload可能会报错nginx: [error] invalid PID number “” in “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;nginx.pid 因为reload会从nginx.pid文件中读取进程pid，此时如果nginx.pid没有内容，则会报错如上， 所以可以重新指定一下配置文件，然后reload： nginx -c /usr/local/nginx/conf/nginx.conf #这样之后nginx.pid里面就有一个pid了 nginx -s reload 检查配置完成上述之后，浏览器访问或者www.的话浏览器会自动请求https:&#x2F;&#x2F;开头的url 此时访问后台和博客的url： https://&lt;your_server_ip&gt; #博客 https://&lt;your_server_ip&gt;/admin #后台 https://www.&lt;your_domain_name&gt; #博客 https://www.&lt;your_domain_name&gt;/admin #后台 注意halo后台“系统”-“博客设置”(-“基础选项”-“常规设置”)-“博客地址”更新http为https 其他操作备份和迁移比如迁移服务器：把旧服务器中的&#x2F;.halo目录整个迁移为新服务器的&#x2F;.halo目录，然后新服务器重新运行halo jar包 旧服务器备份：把~&#x2F;.halo压缩 tar -zvcf ~/.halo.tar.gz ~/.halo # 得到~/.halo.tar.gz 移到新服务器中 在旧服务器上运行 scp ~/.halo.tar.gz &lt;新服务器用户名&gt;@&lt;新服务器ip地址&gt;:~/.halo.tar.gz #scp即secure copy，是用来进行远程文件拷贝的。数据传输使用 ssh，并且和ssh 使用相同的认证方式，提供相同的安全保证 scp也可以直接目录拷贝，scp -r递归拷贝，但是亲测感觉压缩之后传输快一点 新服务器中解压 在~&#x2F;目录下 tar -zvxf .halo.tar.gz 新服务器上重新执行上文步骤2、3、4、5 可能问题 访问后台的时候加载不出来，F12报错net::ERR_ABORTED 404 (Not Found)： 先确认下服务器上halo jar包还在运行不 ps -eo pid,comm | grep &quot;java&quot; #搜索被java命令唤起的进程 如果还在，可能需要重新清除缓存，然后重新登录后台","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"}],"author":"zhiqiuyuan"}],"categories":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/categories/leetcode/"},{"name":"概统","slug":"概统","permalink":"http://example.com/categories/%E6%A6%82%E7%BB%9F/"},{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"},{"name":"ML","slug":"ML","permalink":"http://example.com/categories/ML/"},{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tools","slug":"tools","permalink":"http://example.com/categories/tools/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"},{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"},{"name":"linux","slug":"linux","permalink":"http://example.com/categories/linux/"},{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"},{"name":"os","slug":"course/os","permalink":"http://example.com/categories/course/os/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"},{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"java","slug":"java","permalink":"http://example.com/categories/java/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"gcc","slug":"c/gcc","permalink":"http://example.com/categories/c/gcc/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"},{"name":"language","slug":"python/language","permalink":"http://example.com/categories/python/language/"},{"name":"debug","slug":"python/debug","permalink":"http://example.com/categories/python/debug/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"},{"name":"tool","slug":"rust/tool","permalink":"http://example.com/categories/rust/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"},{"name":"db","slug":"graph/db","permalink":"http://example.com/categories/graph/db/"},{"name":"GPU","slug":"GPU","permalink":"http://example.com/categories/GPU/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"},{"name":"language_deep","slug":"c/language-deep","permalink":"http://example.com/categories/c/language-deep/"},{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"http://example.com/tags/leetcode/"},{"name":"leetcode-easy","slug":"leetcode-easy","permalink":"http://example.com/tags/leetcode-easy/"},{"name":"leetcode-brain-teaser","slug":"leetcode-brain-teaser","permalink":"http://example.com/tags/leetcode-brain-teaser/"},{"name":"leetcode-binary-tree","slug":"leetcode-binary-tree","permalink":"http://example.com/tags/leetcode-binary-tree/"},{"name":"leetcode-string","slug":"leetcode-string","permalink":"http://example.com/tags/leetcode-string/"},{"name":"leetcode-bit-trick","slug":"leetcode-bit-trick","permalink":"http://example.com/tags/leetcode-bit-trick/"},{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"},{"name":"ML","slug":"ML","permalink":"http://example.com/tags/ML/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"},{"name":"tex","slug":"tex","permalink":"http://example.com/tags/tex/"},{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"},{"name":"tool","slug":"tool","permalink":"http://example.com/tags/tool/"},{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"},{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"},{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"},{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"}]}