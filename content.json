{"meta":{"title":"zhiqiuyuan's blog","subtitle":"Spend Time on things I am willing to do my best","description":"grapher","author":"zhiqiuyuan","url":"http://example.com","root":"/"},"pages":[{"title":"","date":"2022-12-27T16:07:07.888Z","updated":"2022-12-07T16:22:59.313Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"下面写关于自己的内容"},{"title":"","date":"2022-12-27T16:07:07.887Z","updated":"2022-12-07T16:26:51.178Z","comments":true,"path":"404.html","permalink":"http://example.com/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除"},{"title":"我的朋友们","date":"2022-12-27T16:07:07.888Z","updated":"2022-12-07T16:27:27.549Z","comments":true,"path":"friends/index.html","permalink":"http://example.com/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"所有标签","date":"2022-12-27T16:07:07.888Z","updated":"2022-12-07T16:23:46.111Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2022-12-27T16:07:07.888Z","updated":"2022-12-07T16:24:12.001Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"所有随笔","date":"2023-01-01T14:12:23.300Z","updated":"2023-01-01T14:11:27.152Z","comments":true,"path":"writing/index.html","permalink":"http://example.com/writing/index.html","excerpt":"","text":""}],"posts":[{"title":"hexo主题volantis自定义页面","slug":"hexo主题volantis自定义页面","date":"2023-01-01T14:04:00.000Z","updated":"2023-01-01T14:25:50.720Z","comments":true,"path":"2023/01/01/hexo主题volantis自定义页面/","link":"","permalink":"http://example.com/2023/01/01/hexo%E4%B8%BB%E9%A2%98volantis%E8%87%AA%E5%AE%9A%E4%B9%89%E9%A1%B5%E9%9D%A2/","excerpt":"","text":"在source/目录下的index.md的链接：source/about/index.md的访问链接为博客链接/about，在.yml文件中导航栏处配置url时写about/ font-matter中layout: docs指定使用themes/layout/下哪个ejs文件作为模板，比如上述的index.md文件 post.&lt;name&gt;可以获取每篇博客的font-matter中的值 举例：新建类似首页的显示个人随笔的页面首先在source下新建目录writing，然后在source/writing下新建index.md，内容： 1234---layout: writingtitle: 所有随笔--- 其中layout指定模板使用themes/layout/writing.ejs 对于仅在这个页面显示而不在博客首页显示的文章，在font-matter中新增一个键： 123---is_writing: true--- 新增themes/layout/writing.ejs文件内容如下：参考首页(index.ejs) 12345&lt;%- partial(&#x27;_pre&#x27;) %&gt;&lt;div id=&quot;l_main&quot; class=&#x27;&lt;%- page.sidebar == false ? &#x27; no_sidebar&#x27; : &#x27;&#x27; %&gt;&#x27;&gt; &lt;%- partial(&#x27;_partial/writing&#x27;) %&gt;&lt;/div&gt;&lt;%- partial(&#x27;_partial/writing_side&#x27;) %&gt; 以及themes/layout/_partial/writing.ejs文件：参考首页(_partial/archive.ejs)，主要是根据post.is_writing来判断文章性质 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;% if (site.posts &amp;&amp; site.posts.length &gt; 0) &#123; %&gt; &lt;section class=&quot;post-list&quot;&gt; &lt;% if (!page.prev) &#123; %&gt; &lt;% if (is_home()) &#123; %&gt; &lt;% site.pages.each(function(post)&#123; %&gt; &lt;% if (post.pin &amp;&amp; post.is_writing) &#123; %&gt; &lt;% if (page.group == undefined || post.group == page.group) &#123; %&gt; &lt;div class=&#x27;post-wrapper&#x27;&gt; &lt;%- partial(&#x27;post&#x27;, &#123;post: post&#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;% site.posts.sort(&#x27;date&#x27;, -1).each(function(post)&#123; %&gt; &lt;% if (post.pin &amp;&amp; post.is_writing) &#123; %&gt; &lt;% if (page.group == undefined || post.group == page.group) &#123; %&gt; &lt;div class=&#x27;post-wrapper&#x27;&gt; &lt;%- partial(&#x27;post&#x27;, &#123;post: post&#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;% &#125; else if (page.posts &amp;&amp; page.posts.length &gt; 0) &#123; %&gt; &lt;% page.posts.each(function(post)&#123; %&gt; &lt;% if (post.pin &amp;&amp; post.is_writing) &#123; %&gt; &lt;div class=&#x27;post-wrapper&#x27;&gt; &lt;%- partial(&#x27;post&#x27;, &#123;post: post&#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;% if (page.posts &amp;&amp; page.posts.length &gt; 0) &#123; %&gt; &lt;% page.posts.each(function(post)&#123; %&gt; &lt;% if (!post.pin &amp;&amp; post.is_writing) &#123; %&gt; &lt;div class=&#x27;post-wrapper&#x27;&gt; &lt;%- partial(&#x27;post&#x27;, &#123;post: post&#125;) %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125;) %&gt; &lt;% &#125; %&gt; &lt;/section&gt; &lt;% if (page &amp;&amp; page.posts) &#123; %&gt; &lt;% if (page.total &gt; 1) &#123; %&gt; &lt;br&gt; &lt;div class=&quot;prev-next&quot;&gt; &lt;% if (page.prev != 0) &#123; %&gt; &lt;a class=&quot;prev&quot; rel=&quot;prev&quot; href=&quot;&lt;%= url_for(page.prev_link) %&gt;&quot;&gt; &lt;section class=&quot;post prev white-box &lt;%- theme.custom_css.body.effect.join(&#x27; &#x27;) %&gt;&quot; &gt; &lt;i class=&quot;fa-solid fa-chevron-left&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt;&amp;nbsp;&lt;%- __(&#x27;post.prev_page&#x27;) %&gt;&amp;nbsp; &lt;/section&gt; &lt;/a&gt; &lt;% &#125; %&gt; &lt;p class=&quot;current&quot;&gt; &lt;%= page.current%&gt; / &lt;%= page.total%&gt; &lt;/p&gt; &lt;% if (page.next != 0) &#123; %&gt; &lt;a class=&quot;next&quot; rel=&quot;next&quot; href=&quot;&lt;%= url_for(page.next_link) %&gt;&quot;&gt; &lt;section class=&quot;post next white-box &lt;%- theme.custom_css.body.effect.join(&#x27; &#x27;) %&gt;&quot;&gt; &amp;nbsp;&lt;%- __(&#x27;post.next_page&#x27;) %&gt;&amp;nbsp;&lt;i class=&quot;fa-solid fa-chevron-right&quot; aria-hidden=&quot;true&quot;&gt;&lt;/i&gt; &lt;/section&gt; &lt;/a&gt; &lt;% &#125; %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt;&lt;% &#125; %&gt; 以及themes/layout/_partial/writing_side.ejs文件：参考首页(_partial/side.ejs) 导航栏增加一项指向新增的页面：修改_config.volantis.yml 12345navbar: menu: - name: 随笔 icon: fa-solid fa-info-circle url: writing/","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}],"author":"zhiqiuyuan"},{"title":"尝试40分钟一节课管理","slug":"writing-2023-1-1-尝试40分钟一节课管理","date":"2023-01-01T13:47:47.000Z","updated":"2023-01-01T14:36:28.776Z","comments":true,"path":"2023/01/01/writing-2023-1-1-尝试40分钟一节课管理/","link":"","permalink":"http://example.com/2023/01/01/writing-2023-1-1-%E5%B0%9D%E8%AF%9540%E5%88%86%E9%92%9F%E4%B8%80%E8%8A%82%E8%AF%BE%E7%AE%A1%E7%90%86/","excerpt":"","text":"","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"写作题目","slug":"writing-写作题目","date":"2023-01-01T11:20:20.000Z","updated":"2023-01-01T13:49:17.547Z","comments":true,"path":"2023/01/01/writing-写作题目/","link":"","permalink":"http://example.com/2023/01/01/writing-%E5%86%99%E4%BD%9C%E9%A2%98%E7%9B%AE/","excerpt":"","text":"决定尝试40分钟一节课来管理自己每天的时间，以课为单位分配时间给任务 今天为啥白搞了写作博客 为啥发了年终说说或者拼图拼了很久的说说会想反复看 感觉自己劲用错了地方，聪明劲没有发挥出来 如何平衡科研和其他学习","categories":[],"tags":[],"author":"zhiqiuyuan"},{"title":"LSM tree","slug":"LSM-tree","date":"2022-12-22T13:30:23.000Z","updated":"2022-12-29T14:56:26.827Z","comments":true,"path":"2022/12/22/LSM-tree/","link":"","permalink":"http://example.com/2022/12/22/LSM-tree/","excerpt":"","text":"LSM树详解 - 知乎 (zhihu.com) rocksdb的存储方式就是这种","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"Gremlin入门","slug":"Gremlin入门","date":"2022-12-21T09:42:14.000Z","updated":"2022-12-29T14:56:26.827Z","comments":true,"path":"2022/12/21/Gremlin入门/","link":"","permalink":"http://example.com/2022/12/21/Gremlin%E5%85%A5%E9%97%A8/","excerpt":"","text":"resource 入门 Apache TinkerPop Introduction to Gremlin Gremlin Query Language - JanusGraph TinkerPop Documentation (apache.org) start-steps 详细（或速查，目录是按字母序的所有steps）TinkerPop Documentation (apache.org) graph-traversal-steps Germlin core steps 来自TinkerPop Documentation (apache.org) graph-traversal-steps As Stepprovide a label to the step that can later be accessed by steps and data structures AddEdge Stephttps://tinkerpop.apache.org/docs/3.5.3/reference/#addedge-step add edge eg: Add co-developer edge with a year-property between marko and his collaborators. gremlin&gt; g.V(1).as(&#39;a&#39;).out(&#39;created&#39;).in(&#39;created&#39;).where(neq(&#39;a&#39;)).addE(&#39;co-developer&#39;).from(&#39;a&#39;).property(&#39;year&#39;,2009) ==&gt;e[13][1-co-developer-&gt;4] ==&gt;e[14][1-co-developer-&gt;6] Graph Step (V E)read vertices, V(), or edges, E(), from the graph Has Stephttps://tinkerpop.apache.org/docs/3.5.3/reference/#has-step filter vertices, edges, and vertex properties based on their properties Select Stephttps://tinkerpop.apache.org/docs/3.5.3/reference/#select-step select() select an element based on a&#x2F;many static key a traversal that emits a key eg: a static key gremlin&gt; g.V().out().out() ==&gt;v[5] ==&gt;v[3] gremlin&gt; g.V().out().out().path() ==&gt;[v[1],v[4],v[5]] ==&gt;[v[1],v[4],v[3]] gremlin&gt; g.V().as(&#39;x&#39;).out().out().select(&#39;x&#39;) ==&gt;v[1] ==&gt;v[1] gremlin&gt; g.V().out().as(&#39;x&#39;).out().select(&#39;x&#39;) ==&gt;v[4] ==&gt;v[4] gremlin&gt; g.V().out().out().as(&#39;x&#39;).select(&#39;x&#39;) // pointless ==&gt;v[5] ==&gt;v[3] eg: many static keys gremlin&gt; g.V().as(&#39;a&#39;).out().as(&#39;b&#39;).out().as(&#39;c&#39;).select(&#39;a&#39;,&#39;b&#39;,&#39;c&#39;) ==&gt;[a:v[1],b:v[4],c:v[5]] ==&gt;[a:v[1],b:v[4],c:v[3]]","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"cpp priority_queue","slug":"cpp-priority-queue","date":"2022-12-21T04:23:02.000Z","updated":"2022-12-29T14:56:26.826Z","comments":true,"path":"2022/12/21/cpp-priority-queue/","link":"","permalink":"http://example.com/2022/12/21/cpp-priority-queue/","excerpt":"","text":"概述 最大堆 时间复杂度： 取堆顶（最大元素）：O(1) 插入&#x2F;删除堆顶：O(logn)，n为堆中元素数目 自定义判断“大”的函数：方法一：&lt;操作符成员函数class T &#123; ... bool operator&lt;(const T&amp;r)&#123;...&#125; &#125;; priority_queue&lt;T&gt; q; 方法二：小于函数auto my_less = [](const T&amp;l, const T&amp;r)&#123;...&#125;; // or: auto my_less = [](T l, T r)&#123;...&#125;; priority_queue&lt;T, vector&lt;T&gt;, decltype(my_less)&gt; q(my_less); 注意： 第二个模板参数是必须的 构造函数需要传参自定义的比较函数 成员函数 取堆顶 top shan’chu堆顶 pop 入堆 push, emplace","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"vscode思维导图 draw.io插件","slug":"vscode思维导图-draw-io插件","date":"2022-12-20T08:16:28.000Z","updated":"2022-12-29T14:56:26.824Z","comments":true,"path":"2022/12/20/vscode思维导图-draw-io插件/","link":"","permalink":"http://example.com/2022/12/20/vscode%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE-draw-io%E6%8F%92%E4%BB%B6/","excerpt":"","text":"用vscode画思维导图、流程图等好用的插件：draw.io.Integration 装好之后，用vscode打开后缀名为 .drawio, .dio, .drawio.svg or .drawio.png中任意文件，即可进入画图界面：","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python3 mkdir","slug":"python3-mkdir","date":"2022-12-20T04:15:38.000Z","updated":"2022-12-29T14:56:26.821Z","comments":true,"path":"2022/12/20/python3-mkdir/","link":"","permalink":"http://example.com/2022/12/20/python3-mkdir/","excerpt":"","text":"import os create dir：recusive, create if not exists, else throw error os.makedirs(path[,mode]) check path exists： if(os.path.)","categories":[{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"language","slug":"python/language","permalink":"http://example.com/categories/python/language/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"python3 cmd debug pdb","slug":"python3-cmd-debug-pdb","date":"2022-12-20T03:42:11.000Z","updated":"2022-12-29T14:56:26.821Z","comments":true,"path":"2022/12/20/python3-cmd-debug-pdb/","link":"","permalink":"http://example.com/2022/12/20/python3-cmd-debug-pdb/","excerpt":"","text":"单文件debug app.py in app.py import pdb; pdb.set_trace() cmd: python3 -m pdb app.py arg1 arg2 然后就开始debug，和gdb类似的界面和指令","categories":[{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"debug","slug":"python/debug","permalink":"http://example.com/categories/python/debug/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"c++编译坑","slug":"c-编译坑","date":"2022-12-11T05:34:42.000Z","updated":"2022-12-29T14:56:26.820Z","comments":true,"path":"2022/12/11/c-编译坑/","link":"","permalink":"http://example.com/2022/12/11/c-%E7%BC%96%E8%AF%91%E5%9D%91/","excerpt":"","text":"给gcc的文件的顺序https://stackoverflow.com/questions/19901934/libpthread-so-0-error-adding-symbols-dso-missing-from-command-line找不到symbol定义可能是顺序不对，或者循环依赖的库没有写到后面重复出现 gcc还是g++找不到symbol定义可能是写成gcc了：比如，gcc和g++版本不一样，而symbol是在高版本g++标准库中才有定义的，这样会报错","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"nm 符号表 各段","slug":"nm 符号表 各段","date":"2022-12-10T15:59:01.622Z","updated":"2022-12-10T15:59:01.622Z","comments":true,"path":"2022/12/10/nm 符号表 各段/","link":"","permalink":"http://example.com/2022/12/10/nm%20%E7%AC%A6%E5%8F%B7%E8%A1%A8%20%E5%90%84%E6%AE%B5/","excerpt":"","text":"linux下强大的文件分析工具 – nm - 知乎 (zhihu.com) 检查分析二进制文件、库文件、可执行文件中的符号表，返回二进制文件中各段的信息。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"objdump 反汇编","slug":"objdump 反汇编","date":"2022-12-10T15:57:36.065Z","updated":"2022-12-10T15:57:36.065Z","comments":true,"path":"2022/12/10/objdump 反汇编/","link":"","permalink":"http://example.com/2022/12/10/objdump%20%E5%8F%8D%E6%B1%87%E7%BC%96/","excerpt":"","text":"objdump options &lt;可执行文件名&gt; -d:将代码段反汇编 -S:将代码段反汇编的同时，将反汇编代码和源代码交替显示，**编译时需要给出-g**，即需要调试信息。 -C:将C++符号名逆向解析。 -l（这个是L）:反汇编代码中插入源代码的文件名和行号。 -j section:仅反汇编指定的section。可以有多个-j参数来选择多个section。 举例objdump -j .text -l -C -S a.out # 仅反汇编.text段，打印源文件名和行号且逆向解析符号 AT&amp;T汇编语法* 寄存器命名原则 AT&amp;T: %eax Intel: eax * 源/目的操作数顺序 AT&amp;T: movl %eax, %ebx Intel: mov ebx, eax * 常数/立即数的格式 AT&amp;T: movl $_value, %ebx Intel: mov eax, _value 把value的地址放入eax寄存器 AT&amp;T: movl $0xd00d, %ebx Intel: mov ebx, 0xd00d * 操作数长度标识 AT&amp;T: movw %ax, %bx Intel: mov bx, ax * 寻址方式 AT&amp;T: immed32(basepointer, indexpointer, indexscale) Intel: [basepointer + indexpointer × indexscale + imm32)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"bison 匹配模式执行动作 语法匹配","slug":"bison 匹配模式执行动作 语法匹配","date":"2022-12-10T15:51:06.501Z","updated":"2022-12-10T15:53:04.645Z","comments":true,"path":"2022/12/10/bison 匹配模式执行动作 语法匹配/","link":"","permalink":"http://example.com/2022/12/10/bison%20%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%BC%8F%E6%89%A7%E8%A1%8C%E5%8A%A8%E4%BD%9C%20%E8%AF%AD%E6%B3%95%E5%8C%B9%E9%85%8D/","excerpt":"","text":"基础用法.y每个 Bison 文件由 %% 分成三部分。 %&#123; ##include &lt;stdio.h&gt; /* 这里是序曲 */ /* 这部分代码会被原样拷贝到生成的 .c 文件的开头 */ int yylex(void); void yyerror(const char *s); %&#125; /* 这些地方可以输入一些 bison 指令 */ /* 比如用 %start 指令指定起始符号，用 %token 定义一个 token */ %start reimu %token REIMU %% /* 从这里开始，下面是解析规则 */ reimu : marisa &#123; /* 这里写与该规则对应的处理代码 */ puts(&quot;rule1&quot;); &#125; | REIMU &#123; /* 这里写与该规则对应的处理代码 */ puts(&quot;rule2&quot;); &#125; ; /* 规则最后不要忘了用分号结束哦～ */ /* 这种写法表示 ε —— 空输入 */ marisa : &#123; puts(&quot;Hello!&quot;); &#125; %% /* 这里是尾声 */ /* 这部分代码会被原样拷贝到生成的 .c 文件的末尾 */ int yylex(void) &#123; int c = getchar(); // 从 stdin 获取下一个字符 switch (c) &#123; case EOF: return YYEOF; case &#39;R&#39;: return REIMU; default: return 0; // 返回无效 token 值，迫使 bison 报错 &#125; &#125; void yyerror(const char *s) &#123; fprintf(stderr, &quot;%s\\n&quot;, s); &#125; int main(void) &#123; yyparse(); // 启动解析 return 0; &#125; 另外有一些值得注意的点： Bison 传统上将 token 用大写单词表示，将 symbol 用小写字母表示。 Bison 能且只能生成解析器源代码（一个 .c 文件），并且入口是 yyparse，所以为了让程序能跑起来，你需要手动提供 main 函数（但不一定要在 .y 文件中——你懂“链接”是什么，对吧？）。 Bison 不能检测你的 action code 是否正确——它只能检测文法的部分错误，其他代码都是原样粘贴到 .c 文件中。 Bison 需要你提供一个 yylex 来获取下一个 token。 Bison 需要你提供一个 yyerror 来提供合适的报错机制。 顺便提一嘴，上面这个 .y 是可以工作的——尽管它只能接受两个字符串。把上面这段代码保存为 reimu.y，执行如下命令来构建这个程序： 编译运行$ bison reimu.y $ gcc reimu.tab.c $ ./a.out R&lt;-- 不要回车在这里按 Ctrl-D rule2 $ ./a.out &lt;-- 不要回车在这里按 Ctrl-D Hello! rule1 $ ./a.out blablabla &lt;-- 回车或者 Ctrl-D Hello! rule1 &lt;-- 匹配到了 rule1 syntax error &lt;-- 发现了错误 于是我们验证了上述代码的确识别了该文法定义的语言 &#123; &quot;&quot;, &quot;R&quot; &#125;。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"flex 匹配模式执行动作 词法匹配","slug":"flex 匹配模式执行动作 词法匹配","date":"2022-12-10T15:50:34.845Z","updated":"2022-12-10T15:53:11.643Z","comments":true,"path":"2022/12/10/flex 匹配模式执行动作 词法匹配/","link":"","permalink":"http://example.com/2022/12/10/flex%20%E5%8C%B9%E9%85%8D%E6%A8%A1%E5%BC%8F%E6%89%A7%E8%A1%8C%E5%8A%A8%E4%BD%9C%20%E8%AF%8D%E6%B3%95%E5%8C%B9%E9%85%8D/","excerpt":"","text":"定义%&#123; Declarations %&#125; Definitions %% Rules %% User subroutines 输入文件的第 1 段 %{ 和 %} 之间的为 声明（Declarations） ，都是 C 代码，这些代码会被原样的复制到 lex.yy.c 文件中，一般在这里声明一些全局变量和函数，这样在后面可以使用这些变量和函数。 第 2 段 %} 和 %% 之间的为 定义（Definitions），在这里可以定义正则表达式中的一些名字，可以在 规则（Rules） 段被使用，如本文件中定义了 WORD 为 ([^ \\t\\n\\r\\a]+) ， 这样在后面可以用 {WORD} 代替这个正则表达式。 第 3 段为 规则（Rules） 段，上一个例子中已经详细说明过了。 第 4 段为 用户定义过程（User subroutines） 段，也都是 C 代码，本段内容会被原样复制到 yylex.c 文件的最末尾，一般在此定义第 1 段中声明的函数。 函数和变量yywrapyywrap 函数的作用是将多个输入文件打包成一个输入，当 yylex 函数读入到一个文件结束（EOF）时，它会向 yywrap 函数询问， yywrap 函数返回 1 的意思是告诉 yylex 函数后面没有其他输入文件了，此时 yylex 函数结束，yywrap 函数也可以打开下一个输入文件，再向 yylex 函数返回 0 ，告诉它后面还有别的输入文件，此时 yylex 函数会继续解析下一个输入文件。总之，由于我们不考虑连续解析多个文件，因此此处返回 1 。 关于刚刚匹配到的字符串 flex 提供的两个全局变量 yytext 和 yyleng，分别用来表示刚刚匹配到的字符串以及它的长度","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"awk 行处理","slug":"awk 行处理","date":"2022-12-10T15:49:59.867Z","updated":"2022-12-10T15:49:59.867Z","comments":true,"path":"2022/12/10/awk 行处理/","link":"","permalink":"http://example.com/2022/12/10/awk%20%E8%A1%8C%E5%A4%84%E7%90%86/","excerpt":"","text":"对于文本中每一行（匹配Pattern的部分）根据分隔符划分，并做action操作 分隔符可指定，默认空格或tab 比如 log.txt文本内容如下： 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange,apple,mongo 行匹配基础用法awk &#39;&#123;[pattern] action&#125;&#39; &#123;filenames&#125; #行匹配语句 awk &#39;&#39; 只能用单引号 # 或者可以管道传入要处理的文本 ls -i |awk &#39;&#123;print $1&#125;&#39; 实例： # 每行按空格或TAB分割，输出文本中的1、4项 $ awk &#39;&#123;print $1,$4&#125;&#39; log.txt --------------------------------------------- 2 a 3 like This&#39;s 10 orange,apple,mongo # 格式化输出 $ awk &#39;&#123;printf &quot;%-8s %-10s\\n&quot;,$1,$4&#125;&#39; log.txt --------------------------------------------- 2 a 3 like This&#39;s 10 orange,apple,mongo -F 指定分割字符 变量awk -F #-F相当于内置变量FS, 指定分割字符 实例： # 使用&quot;,&quot;分割 $ awk -F, &#39;&#123;print $1,$2&#125;&#39; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange apple # 或者使用内建变量 $ awk &#39;BEGIN&#123;FS=&quot;,&quot;&#125; &#123;print $1,$2&#125;&#39; log.txt --------------------------------------------- 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange apple # 使用多个分隔符.先使用空格分割，然后对分割结果再使用&quot;,&quot;分割（看-F &#39;&#39;中传递的字符，第一个是空格，第二个是,） $ awk -F &#39;[ ,]&#39; &#39;&#123;print $1,$2,$5&#125;&#39; log.txt --------------------------------------------- 2 this test 3 Are awk This&#39;s a 10 There apple # 分割结果这样： 2 this is a test 3 Are you like awk This&#39;s a test 10 There are orange apple mongo -v 设置变量，可用于分割结果的拼接或计算awk -v # 设置变量 实例： $ awk -va=1 &#39;&#123;print $1,$1+a&#125;&#39; log.txt # 设置变量a --------------------------------------------- 2 3 3 4 This&#39;s 1 10 11 $ awk -va=1 -vb=s &#39;&#123;print $1,$1+a,$1b&#125;&#39; log.txt --------------------------------------------- 2 3 2s 3 4 3s This&#39;s 1 This&#39;ss 10 11 10s 设置了变量b和a $1b 表示拼接 $1+a 表示如果$1是数字则做计算，否则就是a -f awk脚本awk -f &#123;awk脚本&#125; &#123;文件名&#125; 实例： $ awk -f cal.awk log.txt","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"grep 正则匹配过滤","slug":"grep 正则匹配过滤","date":"2022-12-10T15:49:20.418Z","updated":"2022-12-10T15:49:20.418Z","comments":true,"path":"2022/12/10/grep 正则匹配过滤/","link":"","permalink":"http://example.com/2022/12/10/grep%20%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E8%BF%87%E6%BB%A4/","excerpt":"","text":"grep [-acinv] [--color=auto] &#39;搜寻字符串&#39; filename -a ：将 binary 文件以 text 文件的方式搜寻数据 -c ：计算找到 ‘搜寻字符串’的次数 -i ：忽略大小写的不同 -n ：顺便输出行号 -v ：反向选择，不含搜寻字符串的 grep -i &#39;D&#39; &lt;file2.txt | sort &gt; result.txt 搜索 file2.txt 中的d字母，将输出分类并写入分类文件到 result.txt tail -f /usr/loca/apache/logs/access.log |grep -v &#39;.jpg&#39; 输出不含‘.jpg’的","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"less head tail sed","slug":"less head tail sed","date":"2022-12-10T15:48:41.646Z","updated":"2022-12-10T15:48:41.646Z","comments":true,"path":"2022/12/10/less head tail sed/","link":"","permalink":"http://example.com/2022/12/10/less%20head%20tail%20sed/","excerpt":"","text":"lessless /etc/profile 参数 -N 显示行号 less的动作命令: j 向下移动一行；同vi k 向上移动一行；同vi f 向下滚动一屏；forword b 向上滚动一屏；backword 以上部分命令，请使用q退出 head tailhead -n 10 /etc/profile #显示/etc/profile的前10行内容 tail -n 5 /etc/profile #显示/etc/profile的最后5行内容 sed显示所有内容，包括不可打印的字符 sed -n l &lt;filename&gt; Linux 打印文本部分行内容（前几行，指定行，中间几行，跨行，奇偶行，后几行，最后一行，匹配行） (jiangliheng.github.io)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"文本文件编码方式查看与修改","slug":"文本文件编码方式查看与修改","date":"2022-12-10T15:47:49.197Z","updated":"2022-12-10T15:47:49.197Z","comments":true,"path":"2022/12/10/文本文件编码方式查看与修改/","link":"","permalink":"http://example.com/2022/12/10/%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E7%BC%96%E7%A0%81%E6%96%B9%E5%BC%8F%E6%9F%A5%E7%9C%8B%E4%B8%8E%E4%BF%AE%E6%94%B9/","excerpt":"","text":"linux下 修改文件编码方式从utf-8到ansi iconv -f utf8 -t gbk -o ansi.txt utf8.txt -f: from -t: to 查看文件编码方式 file &lt;filename&gt; # cp @ cp in ~/cp_lab/src/lexer [10:38:09] $ file lexical_analyzer_utf8.l lexical_analyzer_utf8.l: C source, UTF-8 Unicode text, with CRLF line terminators #utf-8 # cp @ cp in ~/cp_lab/src/lexer [10:38:17] $ file lexical_analyzer.l lexical_analyzer.l: C source, ISO-8859 text, with CRLF line terminators #ansi 或者vim之后 :set fileencoding windows下notepad++下","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"stat 文件元数据查看","slug":"stat 文件元数据查看","date":"2022-12-10T15:45:35.423Z","updated":"2022-12-10T15:45:35.423Z","comments":true,"path":"2022/12/10/stat 文件元数据查看/","link":"","permalink":"http://example.com/2022/12/10/stat%20%E6%96%87%E4%BB%B6%E5%85%83%E6%95%B0%E6%8D%AE%E6%9F%A5%E7%9C%8B/","excerpt":"","text":"stat file display file or file system status $ stat answer1 File: answer1 Size: 82 Blocks: 8 IO Block: 4096 regular file Device: 805h/2053d Inode: 1634042 Links: 1 Access: (0664/-rw-rw-r--) Uid: ( 1000/yuanzhiqiu) Gid: ( 1000/yuanzhiqiu) Access: 2022-03-25 20:00:39.873936779 +0800 Modify: 2022-03-24 17:58:23.341854352 +0800 Change: 2022-03-24 17:58:23.341854352 +0800 Birth: -","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux命令行 限制管理","slug":"linux命令行 限制管理","date":"2022-12-10T15:41:30.352Z","updated":"2022-12-10T15:41:30.352Z","comments":true,"path":"2022/12/10/linux命令行 限制管理/","link":"","permalink":"http://example.com/2022/12/10/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%20%E9%99%90%E5%88%B6%E7%AE%A1%E7%90%86/","excerpt":"","text":"概述软硬极限极限分为软性和硬性。 The hard limit is the maximum value that is allowed for the soft limit. Any changes to the hard limit require root access. The soft limit is the value that Linux uses to limit the system resources for running processes. The soft limit cannot be greater than the hard limit. 通过 ulimit 命令，用户可更改软极限 ulimit命令作用对象由于 ulimit 命令影响当前 shell 环境，所以它将作为 shell 常规内置命令提供。如果在独立的命令执行环境中调用该命令，则不影响调用者环境的文件大小极限。 关于用户和系统资源极限的更多信息，请参见 AIX 5L Version 5.2 Technical Reference: Base Operating System and Extensions Volume 1 中的 getrlimit、setrlimit 或 vlimit子例程。 参数-a 列出所有当前资源极限。 -c 以 512 字节块为单位，指定核心转储的大小。 -d 以 K 字节为单位指定数据区域的大小。 -f 使用 Limit 参数时设定文件大小极限（以块计），或者在未指定参数时报告文件大小极限。缺省值为 -f 标志。 -H 指定设置某个给定资源的硬极限。如果用户拥有 root 用户权限，可以增大硬极限。任何用户均可减少硬极限。 -m 以 K 字节为单位指定物理存储器的大小。 -n 指定一个进程可以拥有的文件描述符的数量的极限。 -s 以 K 字节为单位指定堆栈的大小。 -S 指定为给定的资源设置软极限。软极限可增大到硬极限的值。如果 -H 和 -S 标志均未指定，极限适用于以上二者。 -t 指定每个进程所使用的秒数。 ulimit -a命令 To review the hard ulimit settings, enter the following command: ulimit -aH user1@host1 ˜$ ulimit -aH core file size (blocks, -c) unlimited data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 100000 max locked memory (kbytes, -l) unlimited max memory size (kbytes, -m) unlimited open files (-n) 100000 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) unlimited cpu time (seconds, -t) unlimited max user processes (-u) 257262 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited To review the soft ulimit, enter the following command: ulimit -aS Command output similar to the following example is displayed: user1@host1 ˜$ ulimit -aS core file size (blocks, -c) 0 data seg size (kbytes, -d) unlimited scheduling priority (-e) 0 file size (blocks, -f) unlimited pending signals (-i) 100000 max locked memory (kbytes, -l) unlimited max memory size (kbytes, -m) unlimited open files (-n) 100000 pipe size (512 bytes, -p) 8 POSIX message queues (bytes, -q) 819200 real-time priority (-r) 0 stack size (kbytes, -s) 10240 cpu time (seconds, -t) unlimited max user processes (-u) 257262 virtual memory (kbytes, -v) unlimited file locks (-x) unlimited 字段含义 fsize 用户创建的文件大小限制。此定义值（512字节为单位）为该用户可以生成的最大文件的大小。 core 生成的core文件大小的限制（512字节为单位）。 cpu 用户进程可用cpu的限定值（以秒为单位）。普通用户只能将此值减小，root可以将此值增大。这里要注意的是进程使用CPU的时间取决于AIX Kernel（核心程序）进程调度算法，该值在此仅做参考。 data 进程数据段大小的限定值（以字节为单位）。 stack 进程**堆栈段大小的限定值（以字节**为单位）。 rss 进程常驻内存段的限定值（以字节为单位）。AIX核心并不参考此限定。 nofiles 进程中打开文件的最大数量。 修改limit修改文件change the hard and soft ulimit settings for InfoSphere Streams administrators that belong to the @streamsadmin user group. On RHEL and CentOS, edit the &#x2F;etc&#x2F;security&#x2F;limits.d&#x2F;91-nofile.conf file as shown in the following example: @streamsadmin - nofile open-files-value @streamsadmin hard nproc max-user-processes-value @streamsadmin soft nproc max-user-processes-value @streamsadmin hard stack unlimited @streamsadmin soft stack 20480 ulimit临时修改ulimit -c unlimited #-c:core file size 修改核心转储文件允许的大小为无限制","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux命令行进程管理","slug":"linux命令行进程管理","date":"2022-12-10T15:40:30.090Z","updated":"2022-12-10T15:40:30.090Z","comments":true,"path":"2022/12/10/linux命令行进程管理/","link":"","permalink":"http://example.com/2022/12/10/linux%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86/","excerpt":"","text":"管理jobs要启动一个进程到后台，追加一个“&amp;”到命令后面 kill 发信号kill -STOP [pid] 发送SIGSTOP (17,19,23)停止一个进程，而并不消灭这个进程。 kill -CONT [pid] 发送SIGCONT (19,18,25)重新开始一个停止的进程。 kill -KILL [pid] 发送SIGKILL (9)强迫进程立即停止，并且不实施清理操作。 kill -9 -1 终止你拥有的全部进程。 kill -STOP 1234 将该进程暂停。 如果要让它恢复到后台，用kill -CONT 1234 （很多在前台运行的程序这样是不行的） 如果要恢复到前台，请在当时运行该进程的那个终端用jobs命令查询暂停的进程。 然后用 fg 〔job号〕把进程恢复到前台。 举例：gdb调试时ctrl+z如何重启此时会进入收到SIGINT的提示界面， 另外起一个终端把暂停的进程的PID启动 如果在显示这个界面后再次ctrl+z，此时会把gdb进程给挂起，这样fg的话程序还是暂停状态，要把暂停的父进程 PPID也发送-CONT才行 gdb里面显示收到CONT信号就c 比如 PID PPID %MEM %CPU COMMAND 198765 198757 0.5 98.5 baseline 两次ctrl+z之后，要重启需要fg %1并且kill -CONT 198757（父进程）","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"pmap","slug":"pmap","date":"2022-12-10T15:39:20.787Z","updated":"2022-12-10T15:39:20.787Z","comments":true,"path":"2022/12/10/pmap/","link":"","permalink":"http://example.com/2022/12/10/pmap/","excerpt":"","text":"pmap（对于每个进程）pmap 命令可以查看进程的内存映像信息，其输出内容来自于/proc/&lt;pid&gt;/maps和/proc/&lt;pid&gt;/smaps这两个文件，maps文件包含了每一段内存的大概描述，smaps里包含了具体每段的详细信息 pmap [options] pid 参数 Options 功能 -x, –extended 显示扩展格式 -d, –device 显示设备格式 -q, –quiet 不显示头尾行 -A, –range low,high 显示给定地址范围的结果，参数以逗号分隔 -X 显示比 -x 选项更详细的信息， 信息来自文件 /proc/PID/smaps -XX 显示 kernel能提供的一切信息 -c, –read-rc 读取默认配置 -V, –version 显示版本信息 举例pmap -x 7642 命令打印进程 7642 的内存信息，其中 扩展格式和设备格式字段含义如下 字段 含义 Address 映像起始地址 Kbytes 映像大小 RSS 驻留集大小 Dirty 脏页大小 Mode 映像权限 Mapping 映像支持文件,[anon]为已分配内存,[stack]为程序堆栈 Offset 文件偏移 Device 设备名 # 进程启动命令 7642: java -Xmx256m -server -XX:+PrintGCApplicationStoppedTime -jar bin/center.jar Address Kbytes RSS Dirty Mode Mapping 0000000000400000 4 0 0 r-x-- java 0000000000600000 4 4 4 rw--- java 00000000018dc000 1208 1092 1092 rw--- [ anon ] 00000000f0000000 257536 134672 134672 rw--- [ anon ] 00000000ffb80000 4608 0 0 ----- [ anon ] 0000000100000000 12080 12052 12052 rw--- [ anon ] 0000000100bcc000 1036496 0 0 ----- [ anon ] 00007f53dda8d000 256 60 60 rw--- [ anon ] ...... 12345678910111213","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"iostat","slug":"iostat","date":"2022-12-10T15:38:39.596Z","updated":"2022-12-10T15:38:39.596Z","comments":true,"path":"2022/12/10/iostat/","link":"","permalink":"http://example.com/2022/12/10/iostat/","excerpt":"","text":"iostat（对于每个设备）显示所有设备负载情况 iostat [选项] [&lt;指定设备名&gt;] [&lt;时间间隔&gt;] [&lt;次数&gt;] 参数 -c： 显示CPU使用情况 -d： 显示磁盘使用情况 -N： 显示磁盘阵列(LVM) 信息 -n： 显示NFS 使用情况 -t： 报告每秒向终端读取和写入的字符数和CPU的信息 -p： [磁盘] 显示磁盘和分区的情况 -k： 以 KB 为单位显示 -m： 以 M 为单位显示 -V： 显示版本信息 -x： 显示详细信息 (-c)cpu %user：CPU处在用户模式下的时间百分比。 %nice：CPU处在带NICE值的用户模式下的时间百分比。 %system：CPU处在系统模式下的时间百分比。 %iowait：CPU等待输入输出完成时间的百分比。 如果%iowait的值过高，表示硬盘存在I&#x2F;O瓶颈 %steal：管理程序维护另一个虚拟处理器时，虚拟CPU的无意识等待时间百分比。 %idle：CPU空闲时间百分比。 %idle值高，表示CPU较空闲，如果%idle值高但系统响应慢时，有可能是CPU等待分配内存，此时应加大内存容量。 %idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要解决的资源是CPU。 (-d)disk **device: **磁盘名称 tps: 每秒钟发送到的I&#x2F;O请求数. Blk_read&#x2F;s:每秒读取的block数. Blk_wrtn&#x2F;s:每秒写入的block数. **Blk_read:**读入的block总数. **Blk_wrtn:**写入的block总数. 举例 频率 iostat 1 5间隔1秒，总共显示5次 iostat -d 2每隔2秒,显示一次磁盘统计信息. iostat -d 2 3每隔2秒,显示一次磁盘统计信息.总共输出3次. iostat -d sda显示指定硬盘信息 iostat -x sda sdb 2 3每隔2秒显示一次sda, sdb两个设备的扩展统计信息,共输出3次. iostat -p sda 2 3每隔2秒显示一次sda及上面所有分区的统计信息,共输出3次. iostat -m以M为单位显示所有信息 ps（对于每个进程）ps #列出所有你启动的进程 ps -eo pid,ppid,%mem,%cpu,stat,comm --sort=-%cpu | head ps：命令名字 -e：选择所有进程 -o：自定义输出格式 –sort=-%cpu：基于 CPU 使用率对输出结果排序 PID：进程的 ID PPID：父进程的 ID %MEM：进程使用的 RAM 比例 %CPU：进程占用的 CPU 比例 Command：进程名字 stat：进程状态 ps -efT #线程","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"pidstat","slug":"pidstat","date":"2022-12-10T15:38:02.167Z","updated":"2022-12-10T15:38:02.167Z","comments":true,"path":"2022/12/10/pidstat/","link":"","permalink":"http://example.com/2022/12/10/pidstat/","excerpt":"","text":"pidstat（对于每个进程）Linux 运行进程实时监控pidstat命令详解 pidstat主要用于监控全部或指定进程占用系统资源的情况，如CPU，内存、设备IO、任务切换、线程等。 pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息。 pidstat [ 选项 ] [ &lt;时间间隔&gt; ] [ &lt;次数&gt; ] 指定采样周期和采样次数pidstat命令指定采样周期和采样次数，命令形式为”pidstat [option] interval [count]”，以下pidstat输出以2秒为采样周期，输出10次cpu使用统计信息： pidstat 2 10 **cpu(-u)**（默认参数）使用-u选项，pidstat将显示各活动进程的cpu使用统计，执行”pidstat -u”与单独执行”pidstat”的效果一样。 linux:~ # pidstat Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 11:37:19 PID %usr %system %guest %CPU CPU Command …… 11:37:19 11452 0.00 0.00 0.00 0.00 2 bash 11:37:19 11509 0.00 0.00 0.00 0.00 3 dd 含义： PID：进程ID %usr：进程在用户空间占用cpu的百分比 %system：进程在内核空间占用cpu的百分比 %guest：进程在虚拟机占用cpu的百分比 %CPU：进程占用cpu的百分比 CPU：处理进程的cpu编号 Command：当前进程对应的命令 内存(-r)linux:~ # pidstat -r -p 13084 1 Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 15:08:18 PID minflt/s majflt/s VSZ RSS %MEM Command 15:08:19 13084 133835.00 0.00 15720284 15716896 96.26 mmmm 15:08:20 13084 35807.00 0.00 15863504 15849756 97.07 mmmm 15:08:21 13084 19273.87 0.00 15949040 15792944 96.72 mmmm 以上各列输出的含义如下： minflt&#x2F;s: 每秒次缺页错误次数(minor page faults)，次缺页错误次数意即虚拟内存地址映射成物理内存地址产生的page fault次数 majflt&#x2F;s: 每秒主缺页错误次数(major page faults)，当虚拟内存地址映射成物理内存地址时，相应的page在swap中，这样的page fault为major page fault，一般在内存使用紧张时产生 VSZ: 该进程使用的**虚拟内存**(以kB为单位) RSS: 该进程使用的**物理内存**(以kB为单位) %MEM: 该进程使用**物理内存的百分比** Command: 拉起进程对应的命令 IO(-d)linux:~ # pidstat -d 1 2 Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 17:11:36 PID kB_rd/s kB_wr/s kB_ccwr/s Command 17:11:37 14579 124988.24 0.00 0.00 dd 17:11:37 PID kB_rd/s kB_wr/s kB_ccwr/s Command 17:11:38 14579 105441.58 0.00 0.00 dd 输出信息含义 kB_rd&#x2F;s: 每秒进程从磁盘读取的数据量(以kB为单位) kB_wr&#x2F;s: 每秒进程向磁盘写的数据量(以kB为单位) Command: 拉起进程对应的命令 针对特定进程统计(-p)使用-p选项，我们可以查看特定进程的系统资源使用情况： linux:~ # pidstat -r -p 1 1 Linux 2.6.32.12-0.7-default (linux) 06/18/12 _x86_64_ 18:26:17 PID minflt/s majflt/s VSZ RSS %MEM Command 18:26:18 1 0.00 0.00 10380 640 0.00 init 18:26:19 1 0.00 0.00 10380 640 0.00 init …… 举例pidstat -u 1 pidstat -r 1 pidstat -d 1 以上命令以1秒为信息采集周期，分别获取cpu、内存和磁盘IO的统计信息。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux进程状态 ps指定stat字段可查看","slug":"linux进程状态 ps指定stat字段可查看","date":"2022-12-10T15:36:45.536Z","updated":"2022-12-10T15:36:45.536Z","comments":true,"path":"2022/12/10/linux进程状态 ps指定stat字段可查看/","link":"","permalink":"http://example.com/2022/12/10/linux%E8%BF%9B%E7%A8%8B%E7%8A%B6%E6%80%81%20ps%E6%8C%87%E5%AE%9Astat%E5%AD%97%E6%AE%B5%E5%8F%AF%E6%9F%A5%E7%9C%8B/","excerpt":"","text":"[转载] Linux进程状态解析之R、S、D、T、Z、X-阿里云开发者社区 (aliyun.com) stat字段比如R+ R (TASK_RUNNING)，可执行状态只有在该状态的进程才可能在CPU上运行。而同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构（进程控制块）被放入对应CPU的可执行队列中（一个进程最多只能出现在一个CPU的可执行队列中）。进程调度器的任务就是从各个CPU的可执行队列中分别选择一个进程在该CPU上运行。 很多操作系统教科书将正在CPU上执行的进程定义为RUNNING状态、而将可执行但是尚未被调度执行的进程定义为READY状态，这两种状态在linux下统一为 TASK_RUNNING状态。 S (TASK_INTERRUPTIBLE)，可中断的睡眠状态。处于这个状态的进程因为等待某某事件的发生（比如等待socket连接、等待信号量），而被挂起。这些进程的task_struct结构被放入对应事件的等待队列中。当这些事件发生时（由外部中断触发、或由其他进程触发），对应的等待队列中的一个或多个进程将被唤醒。 通过ps命令我们会看到，一般情况下，进程列表中的绝大多数进程都处于TASK_INTERRUPTIBLE状态（除非机器的负载很高）。毕竟CPU就这么一两个，进程动辄几十上百个，如果不是绝大多数进程都在睡眠，CPU又怎么响应得过来。 D (TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态。与TASK_INTERRUPTIBLE状态类似，进程处于睡眠状态，但是此刻进程是不可中断的。不可中断，指的并不是CPU不响应外部硬件的中断，而是指进程不响应异步信号（所以此状态下kill发信号也无法终止进程）（When the process is sleeping uninterruptibly, the signal will be noticed when the process returns from the system call or trap.）。 是由于**在等待IO**，比如磁盘IO，网络IO，其他外设IO，如果进程正在等待的IO在较长的时间内都没有响应，那么就被ps看到了，同时也就意味着很有可能有IO出了问题，可能是外设本身出了故障，也可能是比如挂载的远程文件系统已经不可访问等操作时出现的问题。 引起D状态的根本原因是由于IO等待，若你对某个磁盘的IO操作特别频繁，就会造成后续的IO操作处于等待状态，即处于D状态。此时，你可以使用iostat命令查看当前操作的磁盘的IO是否达到瓶颈值，若达到可以从用户层面入手调整IO操作。 TASK_UNINTERRUPTIBLE状态存在的意义就在于，内核的某些处理流程是不能被打断的。如果响应异步信号，程序的执行流程中就会被插入一段用于处理异步信号的流程（这个插入的流程可能只存在于内核态，也可能延伸到用户态），于是原有的流程就被中断了。（参见《linux内核异步中断浅析》）在进程对某些硬件进行操作时（比如进程调用read系统调用对某个设备文件进行读操作，而read系统调用最终执行到对应设备驱动的代码，并与对应的物理设备进行交互），可能需要使用TASK_UNINTERRUPTIBLE状态对进程进行保护，以避免进程与设备交互的过程被打断，造成设备陷入不可控的状态。这种情况下的TASK_UNINTERRUPTIBLE状态总是非常短暂的，通过ps命令基本上不可能捕捉到 T (TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态。向进程发送一个SIGSTOP信号，它就会因响应该信号而进入TASK_STOPPED状态（除非该进程本身处于TASK_UNINTERRUPTIBLE状态而不响应信号）。（SIGSTOP与SIGKILL信号一样，是非常强制的。不允许用户进程通过signal系列的系统调用重新设置对应的信号处理函数。）向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。 当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态。“正在被跟踪”指的是进程暂停下来，等待跟踪它的进程对它进行操作。比如在gdb中对被跟踪的进程下一个断点，进程在断点处停下来的时候就处于TASK_TRACED状态。而在其他时候，被跟踪的进程还是处于前面提到的那些状态。 对于进程本身来说，TASK_STOPPED和TASK_TRACED状态很类似，都是表示进程暂停下来。而TASK_TRACED状态相当于在TASK_STOPPED之上多了一层保护，处于TASK_TRACED状态的进程不能响应SIGCONT信号而被唤醒。只能等到调试进程通过ptrace系统调用执行PTRACE_CONT、PTRACE_DETACH等操作（通过ptrace系统调用的参数指定操作），或调试进程退出，被调试的进程才能恢复TASK_RUNNING状态。 Z (TASK_DEAD - EXIT_ZOMBIE)，退出状态，进程成为僵尸进程。进程在退出的过程中，处于TASK_DEAD状态。 在这个退出过程中，进程占有的所有资源将被回收，除了task_struct结构（以及少数资源）以外。于是进程就只剩下task_struct这么个空壳，故称为僵尸。之所以保留task_struct，是因为task_struct里面保存了进程的退出码、以及一些统计信息。而其父进程很可能会关心这些信息。比如在shell中，$?变量就保存了最后一个退出的前台进程的退出码，而这个退出码往往被作为if语句的判断条件。当然，内核也可以将这些信息保存在别的地方，而将task_struct结构释放掉，以节省一些空间。但是使用task_struct结构更为方便，因为在内核中已经建立了从pid到task_struct查找关系，还有进程间的父子关系。释放掉task_struct，则需要建立一些新的数据结构，以便让父进程找到它的子进程的退出信息。 父进程可以通过wait系列的系统调用（如wait4、waitid）来等待某个或某些子进程的退出，并获取它的退出信息。然后wait系列的系统调用会顺便将子进程的尸体（task_struct）也释放掉。子进程在退出的过程中，内核会给其父进程发送一个信号，通知父进程来“收尸”。这个信号默认是SIGCHLD，但是在通过clone系统调用创建子进程时，可以设置这个信号。 通过下面的代码能够制造一个EXIT_ZOMBIE状态的进程： #include void main() &#123; if (fork()) while(1) sleep(100); &#125; 编译运行，然后ps一下： kouu@kouu-one:~/test$ ps -ax | grep a\\.out 10410 pts/0 S+ 0:00 ./a.out 10411 pts/0 Z+ 0:00 [a.out] 10413 pts/1 S+ 0:00 grep a.out 只要父进程不退出，这个僵尸状态的子进程就一直存在。那么如果父进程退出了呢，谁又来给子进程“收尸”？当进程退出的时候，会将它的所有子进程都托管给别的进程（使之成为别的进程的子进程）。托管给谁呢？可能是退出进程所在进程组的下一个进程（如果存在的话），或者是1号进程。所以每个进程、每时每刻都有父进程存在。除非它是1号进程。 1号进程，pid为1的进程，又称init进程。linux系统启动后，第一个被创建的用户态进程就是init进程。它有两项使命：1、执行系统初始化脚本，创建一系列的进程（它们都是init进程的子孙）；2、在一个死循环中等待其子进程的退出事件，并调用waitid系统调用来完成“收尸”工作；init进程不会被暂停、也不会被杀死（这是由内核来保证的）。它在等待子进程退出的过程中处于TASK_INTERRUPTIBLE状态，“收尸”过程中则处于TASK_RUNNING状态。 X (TASK_DEAD - EXIT_DEAD)，退出状态，进程即将被销毁。而进程在退出过程中也可能不会保留它的task_struct。比如这个进程是多线程程序中被detach过的进程（进程？线程？参见《linux线程浅析》）。或者父进程通过设置SIGCHLD信号的handler为SIG_IGN，显式的忽略了SIGCHLD信号。（这是posix的规定，尽管子进程的退出信号可以被设置为SIGCHLD以外的其他信号。）此时，进程将被置于EXIT_DEAD退出状态，这意味着接下来的代码立即就会将该进程彻底释放。所以EXIT_DEAD状态是非常短暂的，几乎不可能通过ps命令捕捉到。 进程的初始状态进程是通过fork系列的系统调用（fork、clone、vfork）来创建的，内核（或内核模块）也可以通过kernel_thread函数创建内核进程。这些创建子进程的函数本质上都完成了相同的功能——将调用进程复制一份，得到子进程。（可以通过选项参数来决定各种资源是共享、还是私有。）那么既然调用进程处于TASK_RUNNING状态（否则，它若不是正在运行，又怎么进行调用？），则子进程默认也处于TASK_RUNNING状态。另外，在系统调用调用clone和内核函数kernel_thread也接受CLONE_STOPPED选项，从而将子进程的初始状态置为 TASK_STOPPED。 进程状态变迁进程自创建以后，状态可能发生一系列的变化，直到进程退出。而尽管进程状态有好几种，但是进程状态的变迁却只有两个方向——从TASK_RUNNING状态变为非TASK_RUNNING状态、或者从非TASK_RUNNING状态变为TASK_RUNNING状态。也就是说，如果给一个TASK_INTERRUPTIBLE状态的进程发送SIGKILL信号，这个进程将先被唤醒（进入TASK_RUNNING状态），然后再响应SIGKILL信号而退出（变为TASK_DEAD状态）。并不会从TASK_INTERRUPTIBLE状态直接退出。 进程从非TASK_RUNNING状态变为TASK_RUNNING状态，是由别的进程（也可能是中断处理程序）执行唤醒操作来实现的。执行唤醒的进程设置被唤醒进程的状态为TASK_RUNNING，然后将其task_struct结构加入到某个CPU的可执行队列中。于是被唤醒的进程将有机会被调度执行。 而进程从TASK_RUNNING状态变为非TASK_RUNNING状态，则有两种途径：1、响应信号而进入TASK_STOPED状态、或TASK_DEAD状态；2、执行系统调用主动进入TASK_INTERRUPTIBLE状态（如nanosleep系统调用）、或TASK_DEAD状态（如exit系统调用）；或由于执行系统调用需要的资源得不到满足，而进入TASK_INTERRUPTIBLE状态或TASK_UNINTERRUPTIBLE状态（如select系统调用）。显然，这两种情况都只能发生在进程正在CPU上执行的情况下。 stat字段低位&lt; 优先级高的进程 N 优先级较低的进程 L 有些页被锁进内存 s 进程的领导者（在它之下有子进程） l 多进程的（使用 CLONE_THREAD, 类似 NPTL pthreads） + 位于后台的进程组","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"命令行颜色","slug":"命令行颜色","date":"2022-12-10T15:28:58.394Z","updated":"2022-12-10T15:28:58.394Z","comments":true,"path":"2022/12/10/命令行颜色/","link":"","permalink":"http://example.com/2022/12/10/%E5%91%BD%E4%BB%A4%E8%A1%8C%E9%A2%9C%E8%89%B2/","excerpt":"","text":"ANSI转义序列 - 维基百科，自由的百科全书 (wikipedia.org) Build your own Command Line with ANSI escape codes (lihaoyi.com) Red: \\u001b[31m Reset: \\u001b[0m This \\u001b character is the special character that starts off most Ansi escapes echo -e &quot;\\x1b[31mhello world\\x1b[0m&quot; 用期望颜色替换 31(代表红色) 即可 \\x1b[&lt;color_code&gt;m \\x1b[0m debug output level： | ERROR | 红色(31) | 表示发生严重错误，很可能或者已经导致程序崩溃 || WARN | 黄色(93) | 表示发生不常见情况，但是并不一定导致系统错误 || INFO | 蓝色(34) | 比较中庸的选项，输出比较重要的信息，比较常用 || DEBUG | 绿色(32) | 输出信息较多，在 debug 时使用 || TRACE | 灰色(90) | 最详细的输出，跟踪了每一步关键路径的执行 | 名称 前景色代码 背景色代码 黑 30 40 红 31 41 绿 32 42 黄 33 43 蓝 34 44 品红 35 45 青 36 46 白 37 47 亮黑（灰） 90 100 亮红 91 101 亮绿 92 102 亮黄 93 103 亮蓝 94 104 亮品红 95 105 亮青 96 106 亮白 97 107","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"ls","slug":"ls","date":"2022-12-10T15:28:20.916Z","updated":"2022-12-10T15:28:20.916Z","comments":true,"path":"2022/12/10/ls/","link":"","permalink":"http://example.com/2022/12/10/ls/","excerpt":"","text":"-luse a long listing format missing:~$ ls -l /home drwxr-xr-x 1 missing users 4096 Jun 15 2019 missing First, the d at the beginning of the line tells us that missing is a directory. Then follow three groups of three characters (rwx). These indicate what permissions the owner of the file (missing), the owning group (users), and everyone else respectively have on the relevant item. A - indicates that the given principal does not have the given permission -i-inode print the index number of each file","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"文件系统查看 df","slug":"文件系统查看 df","date":"2022-12-10T15:27:53.158Z","updated":"2022-12-10T15:27:53.158Z","comments":true,"path":"2022/12/10/文件系统查看 df/","link":"","permalink":"http://example.com/2022/12/10/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9F%A5%E7%9C%8B%20df/","excerpt":"","text":"report file system disk space usage Filesystem Size Used Avail Use% Mounted on -h-h, –human-readable print sizes in powers of 1024 (e.g., 1023M) df -h –max-depth-a, –all include pseudo, duplicate, inaccessible file systems du -ah --max-depth=1 &lt;目录，缺省为当前目录&gt; 单独列出&lt;目录路径&gt;各一级子项占用的容量 -sdu -sh &lt;目录，缺省为当前目录&gt; 查看&lt;目录路径&gt;总共占的容量（而不单独列出各子项占用的容量） -Tprint file system type Filesystem Type 1K-blocks Used Available Use% Mounted on","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"bash快捷键","slug":"bash快捷键","date":"2022-12-10T15:26:19.635Z","updated":"2022-12-10T15:26:19.635Z","comments":true,"path":"2022/12/10/bash快捷键/","link":"","permalink":"http://example.com/2022/12/10/bash%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"","text":"ctrl+R 可以搜索历史输入指令","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash文件判断和比较","slug":"bash文件判断和比较","date":"2022-12-10T15:25:50.468Z","updated":"2022-12-10T15:26:30.803Z","comments":true,"path":"2022/12/10/bash文件判断和比较/","link":"","permalink":"http://example.com/2022/12/10/bash%E6%96%87%E4%BB%B6%E5%88%A4%E6%96%AD%E5%92%8C%E6%AF%94%E8%BE%83/","excerpt":"","text":"比较符 说明 举例 -e filename 如果filename存在，则为真 [ -e &#x2F;var&#x2F;log&#x2F;syslog ] -d filename 如果filename为目录，则为真 [ -d &#x2F;tmp&#x2F;mydir ] -f filename 如果filename常规文件，则为真 [ -f &#x2F;usr&#x2F;bin&#x2F;grep ] -L filename 如果filename为符号链接，则为真 [ –L &#x2F;usr&#x2F;bin&#x2F;grep ] -r filename 如果filename可读，则为真 [ –r &#x2F;var&#x2F;log&#x2F;syslog ] -w filename 如果filename可写，则为真 [ –w &#x2F;varmytmp.txt ] -x filename 如果filename可执行，则为真 [ –x &#x2F;usr&#x2F;bin&#x2F;grep ] -s filename 如果filename不是空白文件，则为真 -u filename 如果filename有SUID属性，则为真 -g filename 如果filename有SGID属性，则为真 -k filename 如果filename有stickybit属性，则为真 file1 –nt file2 如果file1比file2新，则为真 file1 –ot file2 如果file1比file2旧，则为真","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash特殊符号 特殊变量","slug":"bash特殊符号 特殊变量","date":"2022-12-10T15:24:22.958Z","updated":"2022-12-10T15:24:22.958Z","comments":true,"path":"2022/12/10/bash特殊符号 特殊变量/","link":"","permalink":"http://example.com/2022/12/10/bash%E7%89%B9%E6%AE%8A%E7%AC%A6%E5%8F%B7%20%E7%89%B9%E6%AE%8A%E5%8F%98%E9%87%8F/","excerpt":"","text":"特殊符号$()和`` 命令代换替换为命令输出（输出到stdout的内容）， 所有的shell支持使用反引号的方式进行命令替换， 命令替换可以嵌套，需要注意的是如果使用反引号的形式，在内部反引用前必须使用反斜杠转义 Current_Folder=$(cd `dirname $0`; pwd) $ nproc 1 $ make -j $(nproc) #即make -j 1 $ echo $(date) #即echo 2021年 11月 04日 星期四 21:41:54 CST 2021年 11月 04日 星期四 21:41:54 CST $ date 2021年 11月 04日 星期四 21:41:56 CST $(()) 算术代换 匹配符 说明 $(()) 例如 echo $((4 + 6)) 特殊变量$#expands to the number of arguments (positional parameters) i.e. $1, $2 ... passed to the script in question or the shell in case of argument directly passed to the shell e.g. in bash -c &#39;...&#39; ..... $1, $2 …arguments (positional parameters) passed to the script in question or the shell in case of argument directly passed to the shell e.g. in bash -c &#39;...&#39; ..... $0, $1, $2 …就是对应给shell的命令，以whitespace分隔， 所以$1, $2 … argument， $0 exe name","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"SSE编译flag","slug":"SSE编译flag","date":"2022-12-10T14:21:00.585Z","updated":"2022-12-10T14:21:15.047Z","comments":true,"path":"2022/12/10/SSE编译flag/","link":"","permalink":"http://example.com/2022/12/10/SSE%E7%BC%96%E8%AF%91flag/","excerpt":"","text":"gcc或g++编译：SSE2不用给flag##include &lt;immintrin.h&gt; 给flag -march=native","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"}],"tags":[{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"operf -t thread举例","slug":"operf-t-thread举例","date":"2022-12-09T14:55:43.000Z","updated":"2022-12-29T14:56:26.810Z","comments":true,"path":"2022/12/09/operf-t-thread举例/","link":"","permalink":"http://example.com/2022/12/09/operf-t-thread%E4%B8%BE%E4%BE%8B/","excerpt":"","text":"命令profile程序（-t则将把每个线程分开统计并分别输出，-k指定内核调试文件，这样会得到内核的调用信息） sudo operf -t -k /usr/lib/debug/lib/modules/$(uname -r)/vmlinux ./main 根据得到的采集数据输出结果 opreport -o symbols.txt -l 输出输出的symbols.txt例如：三个线程每个线程分开统计，下面的%每一列是一个线程（每个%列求和是100），是按第一%列进行降序排序的 附：测试程序main.cpp#include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;mutex&gt; #include &lt;algorithm&gt; #include &lt;vector&gt; using namespace std; mutex stdout_mut; // return first element int sort_work(int sz) &#123; std::vector&lt;int&gt; arr(sz); for (int i = 0; i &lt; sz; ++i) arr[i] = rand(); sort(arr.begin(), arr.end()); return arr[0]; &#125; void compute1() &#123; int re = sort_work(100000); lock_guard&lt;mutex&gt; lk(stdout_mut); cout &lt;&lt; pthread_self() &lt;&lt; &#39; &#39; &lt;&lt; re &lt;&lt; endl; &#125; void compute2() &#123; int re = sort_work(99999); lock_guard&lt;mutex&gt; lk(stdout_mut); cout &lt;&lt; pthread_self() &lt;&lt; &#39; &#39; &lt;&lt; re &lt;&lt; endl; &#125; int main() &#123; srand(time(0)); thread th1(compute1); th1.join(); thread th2(compute1); th2.join(); lock_guard&lt;mutex&gt; lk(stdout_mut); cout &lt;&lt; &quot;main thread: &quot; &lt;&lt; pthread_self() &lt;&lt; endl; return 0; &#125; makefileTARGET=main main:$&#123;TARGET&#125;.cpp makefile g++ -std=c++11 -g -Wall -rdynamic -pthread -o main $&#123;TARGET&#125;.cpp clean:main rm -rf main","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"tool","slug":"tool","permalink":"http://example.com/tags/tool/"}],"author":"zhiqiuyuan"},{"title":"linux性能监测工具学习计划","slug":"linux性能监测工具学习计划","date":"2022-12-09T14:52:38.000Z","updated":"2022-12-29T14:56:26.803Z","comments":true,"path":"2022/12/09/linux性能监测工具学习计划/","link":"","permalink":"http://example.com/2022/12/09/linux%E6%80%A7%E8%83%BD%E7%9B%91%E6%B5%8B%E5%B7%A5%E5%85%B7%E5%AD%A6%E4%B9%A0%E8%AE%A1%E5%88%92/","excerpt":"","text":"学这个！Linux Performance (brendangregg.com)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"plan","slug":"plan","permalink":"http://example.com/categories/plan/"},{"name":"tool","slug":"plan/tool","permalink":"http://example.com/categories/plan/tool/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"tool","slug":"tool","permalink":"http://example.com/tags/tool/"}],"author":"zhiqiuyuan"},{"title":"社交网络复习","slug":"社交网络复习","date":"2022-12-09T11:36:23.000Z","updated":"2022-12-29T14:53:29.980Z","comments":true,"path":"2022/12/09/社交网络复习/","link":"","permalink":"http://example.com/2022/12/09/%E7%A4%BE%E4%BA%A4%E7%BD%91%E7%BB%9C%E5%A4%8D%E4%B9%A0/","excerpt":"","text":"未看但是可能要看： 2.4 分支限界算法中：多项式近似算法，page 35 2.4 KT index，page 63 1.1 图的基本概念、类型 1.2 幂律分布、图的测度参数、随机图 2.1 顶点及边的中心性计算 n为全图顶点数目 无向图的度中心性：顶点的度（可以通过除以最大可能值n-1来标准化度数） 2.2 可达性&amp;最短路径 Dijkstra算法： 直到所有顶点都加入集合S A*算法： 直到所有顶点都加入集合S 其中g(n)的计算：传递计算 2.3 稠密子图搜索定义和算法 k-core定义 算法 degree(u)&gt;degree(v)：即看在order中在v（当前顶点）右边的v邻居 算法举例：page 34-50 k-truss定义 算法 举例：page 54-63 k-clique定义 原始算法 举例：page 69-79 算法KCLIST 举例：page 82-86（如果看不懂，建议先看简单算法的举例） 比较 2.4 图关键字搜索r-clique 分支限界算法 举例：page 20-33 k-NK搜索二跳标签索引 举例和应用：线性扫描L(v1)和L(v3) k-Nk查询定义 前向搜索(FS) 其中“查找dist(q,vi)”通过查二跳标签索引L(q)和L(vi)得到 二跳标签后向索引根据二跳标签索引L构建LB： 前向后向搜索(FBS) 举例： 2.5 图结构差异性搜索基于连通分量的结构差异性是一个顶点的性质 基于核心的结构差异性是一个顶点的性质 问题 CC-TopK Core-TopK CC-TopK的基于度的简单方法bound 算法 举例： 2.6 图划分标签更新过程： 两个扩展：（当多个标签具有相同的最高频率，不再是随机选一个） 定义： 3.1 社区检测 COPRA重叠社区发现算法COPRA 算法 举例 解： 对于每个顶点： 删除标签：系数&gt;&#x3D;1&#x2F;2的标签保留；若所有标签都系数&lt;1&#x2F;2，则保留其中系数最高的标签；若有多个系数相同的这种标签，则随机保留其中一个； 对于保留的标签，进行系数归一化（所有标签系数之和为1） 传播：对于每个顶点，对于其邻居中的每个标签L，扫描它的所有邻居将该标签的系数求和，再除以邻居数目，得到L的系数 以此类推，见作业答案 3.2 异常检测评测指标 精确率P，召回率R F-measure（是P和R的一个平均数） ROC 曲线（TPR（即召回率）：样本中的正例有多少被预测正确了；FPR：样本中的负例有多少被预测正确了） SpotLight 算法图模型 每个Gt是一个有向二部图 算法 如何提取spotlight草图v(G)：先选取k个查询子图（分别对应v(G)坐标的k个维度），然后计算每个维度（对应查询子图的边权之和） 举例： 3.3 频繁子图挖掘定义 子图的支持度：（在输入的多个图中的）出现次数 一个图中出现（不管多少次），计一次 举例： Apriori算法 AGM 基于Apriori算法的频繁子图挖掘算法图编码 合并两个含有k个顶点（且共有一个k-1个顶点的子图）的图：如果用编码 算法 3.5 图概要 无损图表示 ”超节点映射“：记录每个超节点代表原图中的哪些点 （超点连接的）存储开销 贪婪算法 算法 举例s(x,y)计算举例 page42和page45 算法举例 page41-48","categories":[{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"github+hexo+volantis主题搭建博客","slug":"github-hexo-volantis主题搭建博客","date":"2022-12-08T15:31:20.000Z","updated":"2023-01-01T11:21:17.655Z","comments":true,"path":"2022/12/08/github-hexo-volantis主题搭建博客/","link":"","permalink":"http://example.com/2022/12/08/github-hexo-volantis%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"参考：GitHub Pages + Hexo搭建个人博客网站，史上最全教程 搭建创建github仓库新建public仓库，命名为&lt;用户名&gt;.github.io 仓库settings中pages项启用github pages（默认是启用了的） 本地hexo 安装 Hexo 1npm install -g hexo-cli 验证是否安装成功：查看版本 1hexo -v 创建一个项目 hexo-blog 1hexo init hexo-blog # 将在当前目录下创建一个名为hexo-blog的目录，这个目录后面称作&lt;博客目录&gt; 更换主题：以volantis主题为例 在&lt;博客目录&gt;下： 下载主题源码，以后就可以魔改了 1git clone https://github.com/volantis-x/hexo-theme-volantis.git themes/volantis 修改&lt;博客目录&gt;目录下的_config.yml： 1theme: volantis 关联github仓库配置好后，执行hexo g -d可以直接发布到github： 安装hexo-deployer-git 1npm install hexo-deployer-git --save 修改根目录下的 _config.yml，配置 GitHub 相关信息 12345deploy: type: git repo: https://github.com/yaorongke/yaorongke.github.io.git branch: main token: ghp_3KakcaPHerunNRyMerofcFd9pblU282FSbsY 其中 token 为 GitHub 的 Personal access tokens(settings - developer settings- Personal access tokens) [可选]volantis主题优化参考：Volantis volantis主题提供非常友好的配置方式：将&lt;博客目录&gt;/themes/volantis/_config.yml复制到&lt;博客目录&gt;下，命名为_config.volantis.yml，然后对这个yml文件进行配置即可（此配置文件的优先级高于_config.yml） 搜索 标题和内容搜索简直是支持成为好用博客的最重要因素了！ 这里以使用hexo search为例 enable： 在&lt;博客目录&gt;下运行下述，安装支持： 1npm i hexo-generator-json-content 配置_config.volantis.yml： 123search: enable: true service: hexo # hexo, algolia, meilisearch 其他配置：修改_config.volantis.yml中的search下面的配置即可 暗黑模式在顶部导航栏新增dark&#x2F;light mode切换按钮： _config.volantis.yml： 1234567navbar: ... menu: ... - name: 暗黑模式 icon: fa-solid fa-moon toggle: darkmode 文章分类和标签页面 分类页面 Create file if not exists: source/categories/index.md 12345---layout: categoryindex: truetitle: 所有分类--- 标签页面 Create file if not exists: source/tags/index.md 12345---layout: tagindex: truetitle: 所有标签--- 文章给分类和标签给文章写了分类和标签之后会自动在首页、分类页面、标签页面形成对应内容 分类 多级分类：分类B是分类A的子类 123---categories: [分类A, 分类B]--- 并列分类：分类A和B是并列分类 12345---categories: - [分类A] - [分类B]--- 多级+并列分类 12345---categories: - [分类A, 分类B] - [分类C, 分类D]--- 标签 12345---tags: - tag1 - tag2--- 其他页面见页面配置 - Volantis，比如“关于页面”、“友链页面”等 评论以giscus为例 _config.volantis.yml： 12345678910111213141516comments: ... service: giscus ... giscus: # 以下配置按照 yml 格式增删填写即可 # repo: xxx/xxx # repo-id: xxx # category: xxx # category-id: xxx # mapping: &quot;pathname&quot; # reactions-enabled: &quot;1&quot; # emit-metadata: &quot;0&quot; # lang: &quot;zh-CN&quot; # 以上配置按照 yml 格式增删填写即可 上述comments/giscus下方的配置填啥： 进入giscus，按Repository这里说的配置你的github仓库（每一步不会的就戳蓝色链接进去，有手把手步骤） 配置github仓库完成后，回到giscus，从Repository开始填写你的信息：主要填一下你的Repository，接下来的通常用默认勾选的就可以 然后下方Enable giscus处就会出现给你的配置信息，对着填即可 引用自己上传的素材等指的是在yml文件中引用（文章中引用的格式见下文）上传到source目录下，然后在yml文件中可以用/路径来引用比如引用图片source/img/test.jpg是用/img/test.jpg 侧边栏配置https://volantis.js.org/v5/theme-settings/#%E4%BE%A7%E8%BE%B9%E6%A0%8F%E9%85%8D%E7%BD%AE 搭建后维护写文章参考页面配置 - Volantis [可选]引用图片 配置：修改&lt;博客目录&gt;目录下的_config.yml：打开这个配置是为了在生成文章的时候生成一个同名的资源目录用于存放图片文件等 1post_asset_folder: true 语法：在文章中引用这个目录中的图片的方式：（举例：cute.jpg在这个同名目录下）（用markdown语法引用图片![]()有时会失效，推荐下述） 12&#123;% asset_img cute.jpg cute_sirotan %&#125;&#123;% asset_img cute.jpg %&#125; 引用网图： 12![img_name](https://xxx.com/xx.jpg)![](https://xxx.com/xx.jpg) 新建文章1hexo new &quot;&lt;post_name&gt;&quot; this will generate .md and folder under /source/_post folder specify path --path,-p 1hexo new &quot;hello_title&quot; --path writing/hello this will create source/_posts/writing/hello.md file with the following front matter: 1234---title: hello_titledate: 2019-04-04 23:51:44--- The --path option is not documented, but it is listed when using hexo help new. 删除文章来自How do I delete a post in hexo - Stack Overflow There is no command to delete a post on Hexo, but follow this steps : Delete the post under source/_post folder Run hexo clean to delete the database (db.json) and assets folder Run hexo generateto generate the new blog without your deleted post Run hexo deploy to deploy your blog [给文章分类and加标签](# 文章给分类和标签)文章置顶123---pin: true--- 设置文章作者Volantis 支持多个作者在一个站点发布文章，其他作者信息需要写在数据文件中，例如：blog/source/_data/author.yml 12345678Jon: name: Jon Snow avatar: https://cn.bing.com/th?id=AMMS_fc8f99fd41ebd737a71c4e13806db9a0&amp;w=110&amp;h=110&amp;c=7&amp;rs=1&amp;qlt=80&amp;pcl=f9f9f9&amp;cdv=1&amp;dpr=2&amp;pid=16.1 url: https://gameofthrones.fandom.com/wiki/Jon_SnowDany: name: Daenerys Targaryen avatar: https://tse1-mm.cn.bing.net/th?id=OIP.Yax4wLzIFbcBVUa_RsKywQHaLH&amp;w=80&amp;h=80&amp;c=8&amp;rs=1&amp;qlt=90&amp;dpr=2&amp;pid=3.1&amp;rm=2 url: https://gameofthrones.fandom.com/wiki/Daenerys_Targaryen 在文章中设置作者： 1234---title: Jon Snow | Game of Thrones Wiki | Fandomauthor: Jon--- 自定义文章模板修改&lt;博客顶层目录&gt;/scaffolds/post.md即可 volantis主题支持的文章中的标签https://castiele.gitee.io/2020/10/23/volantis-article/ 写文章后发布到博客在&lt;博客目录&gt;下： 每次内容更新之后：g生成文件，-ddeploy，如果完成[关联github](# 关联github仓库)则执行这行还会推送到github上 1hexo g -d 当github上反应不是很及时时，可以本地启动查看内容 1hexo s 可以在http://localhost:4000访问 halo文章导入hexohalo管理后台的系统-小工具 hexo高级_posts目录下文章分级管理以“按年月日”分级管理为例 效果： 12345678910_posts└─2022 └─12 └─10 ├─blog1 ├─blog2 ... ... ... ... 配置&lt;博客目录&gt;下的_config.yml： 1new_post_name: :year/:month/:day/:title.md 这样hexo new &lt;blog_name&gt;就会自动创建目录（如果不存在的话）_posts/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;/，并在该目录下生成&lt;blog_name&gt;.md和&lt;blog_name&gt;空目录 文章网页链接配置default配置文章的网页链接会在文章标题前加上/&lt;year&gt;/&lt;month&gt;/&lt;day&gt;/，这是因为在_config.yml中设置了的缘故，如果希望网页链接没有日期前缀而只是文章标题，则可以配置_config.yml如下： 1permalink: :name/","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"}],"author":"zhiqiuyuan"},{"title":"rust learning source link","slug":"rust学习资源链接","date":"2022-12-07T15:50:58.000Z","updated":"2022-12-29T14:56:26.812Z","comments":true,"path":"2022/12/07/rust学习资源链接/","link":"","permalink":"http://example.com/2022/12/07/rust%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%BA%90%E9%93%BE%E6%8E%A5/","excerpt":"","text":"入门学习：rust语言圣经 https://course.rs/first-try/editor.html","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"cargo","slug":"cargo","date":"2022-12-07T15:49:46.000Z","updated":"2022-12-29T14:56:26.792Z","comments":true,"path":"2022/12/07/cargo/","link":"","permalink":"http://example.com/2022/12/07/cargo/","excerpt":"","text":"cargo run 编译运行cargo run 首先对项目进行编译，然后再运行默认是debug模式，在这种模式下，代码的编译速度会非常快，运行速度就慢了. 原因是，在 debug 模式下，Rust 编译器不会做任何的优化高性能：cargo run --release cargo check 检查能否通过编译cargo check快速的检查一下代码能否编译通过。因此该命令速度会非常快，能节省大量的编译时间。","categories":[{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"tool","slug":"rust/tool","permalink":"http://example.com/categories/rust/tool/"}],"tags":[{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"}],"author":"zhiqiuyuan"},{"title":"数据库概念-transaction","slug":"数据库概念","date":"2022-11-22T11:31:44.010Z","updated":"2022-12-10T13:55:09.094Z","comments":true,"path":"2022/11/22/数据库概念/","link":"","permalink":"http://example.com/2022/11/22/%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5/","excerpt":"","text":"A transaction is a logical, atomic unit of work that contains one or more SQL statements. A transaction groups SQL statements so that they are either all committed, which means they are applied to the database, or all rolled back, which means they are undone from the database.","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"bash条件判断if 字符串 整数","slug":"bash条件判断if 字符串 整数","date":"2022-11-13T03:36:54.137Z","updated":"2022-12-10T13:56:01.128Z","comments":true,"path":"2022/11/13/bash条件判断if 字符串 整数/","link":"","permalink":"http://example.com/2022/11/13/bash%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%ADif%20%E5%AD%97%E7%AC%A6%E4%B8%B2%20%E6%95%B4%E6%95%B0/","excerpt":"","text":"https://blog.csdn.net/yusiguyuan/article/details/17054231","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"调试奇怪bug","slug":"调试奇怪bug","date":"2022-11-08T07:26:44.976Z","updated":"2022-12-10T14:16:58.648Z","comments":true,"path":"2022/11/08/调试奇怪bug/","link":"","permalink":"http://example.com/2022/11/08/%E8%B0%83%E8%AF%95%E5%A5%87%E6%80%AAbug/","excerpt":"","text":"valgrind gdb细粒度跟踪（这个超级牛啊） 可以不断确定要在哪里打断点，然后r，带着已经打的断点重新观察 经验malloc abortheap is corrupt：被程序写了不该写的地方，比如在数组&#x2F;vector长度后面写东西 std::vector&lt;VertexIdType&gt; new_vps(problem_num*2); //... for(...) new_vps[pos++] = vps[2 * i]; // 如果这里越界写，可能就会把heap搞坏 //下面这里可能就会abort VertexIdType *ranges = new VertexIdType[batch_num * 2]; 这个通常可以通过检查所有new来的原始数组的写入 是否有越界来找原因，通常这个“所有数组”是 “在delete abort发生的数组 之前new申请的数组”（这些数组都在堆上，如果这些数组写越界了，把后面申请的数组也写了，由于俩数组可能元素类型不一样，所以会出现heap crupt的问题）（说通常是因为，堆分配不一定是后面分配的地址在前面分配的后面，不过数组本身确实是连续内存） 或者是内存不够 delete or delete[]Type* p = new Type;如果是delete[] p，会把p当做数组首地址去释放，这个数组的长度undefined，如果不是1的话会释放多次且是释放数组首地址+sizeof(数组元素)的地址","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"windows查看文件被啥进程占用 资源监视器","slug":"windows查看文件被啥进程占用 资源监视器","date":"2022-10-25T01:20:00.939Z","updated":"2022-12-10T13:59:33.613Z","comments":true,"path":"2022/10/25/windows查看文件被啥进程占用 资源监视器/","link":"","permalink":"http://example.com/2022/10/25/windows%E6%9F%A5%E7%9C%8B%E6%96%87%E4%BB%B6%E8%A2%AB%E5%95%A5%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%20%E8%B5%84%E6%BA%90%E7%9B%91%E8%A7%86%E5%99%A8/","excerpt":"","text":"（按windows键然后输入任务管理器）任务管理器-（上方横栏）性能-（下方）打开资源监视器或者直接搜资源监视器-（下方）搜索句柄 输入完整路径，得占用其的PID","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"文件被explore.exe占用无法通过文件资源管理器重命名","slug":"文件被exploreexe占用无法通过文件资源管理器重命名","date":"2022-10-25T01:15:50.419Z","updated":"2022-12-10T14:01:13.317Z","comments":true,"path":"2022/10/25/文件被exploreexe占用无法通过文件资源管理器重命名/","link":"","permalink":"http://example.com/2022/10/25/%E6%96%87%E4%BB%B6%E8%A2%ABexploreexe%E5%8D%A0%E7%94%A8%E6%97%A0%E6%B3%95%E9%80%9A%E8%BF%87%E6%96%87%E4%BB%B6%E8%B5%84%E6%BA%90%E7%AE%A1%E7%90%86%E5%99%A8%E9%87%8D%E5%91%BD%E5%90%8D/","excerpt":"","text":"explore.exe是文件资源管理器的进程，所以得通过命令行来重命名 先关掉文件资源管理器，然后通过git bash用mv重命名（不推荐powershell的ren等，貌似有问题，总提示找不到）","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"embedding matrix","slug":"embedding matrix","date":"2022-10-20T08:40:09.797Z","updated":"2022-12-10T14:02:45.089Z","comments":true,"path":"2022/10/20/embedding matrix/","link":"","permalink":"http://example.com/2022/10/20/embedding%20matrix/","excerpt":"","text":"embedding matrix：多列，每列是一个单词对应的特征向量 这个矩阵*one_hot向量（n个单词则是n维向量，只有一个1）得到这个向量表示的单词的特征向量 或者对于一个变量，其值域为D，是离散的，其中有|D|个不同取值，则embedding matrix：多列，每列是一个取值对应的特征向量 或者不通过矩阵乘法的方式得到某值对应的特征向量，而是通过哈希表的方式，值-&gt;对应特征向量，则视图是 多行，每行是一个取值对应的特征向量","categories":[{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"},{"name":"ML","slug":"ML","permalink":"http://example.com/categories/ML/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"i.i.d. 独立同分布","slug":"iid 独立同分布","date":"2022-10-20T07:31:15.640Z","updated":"2022-12-10T14:03:44.723Z","comments":true,"path":"2022/10/20/iid 独立同分布/","link":"","permalink":"http://example.com/2022/10/20/iid%20%E7%8B%AC%E7%AB%8B%E5%90%8C%E5%88%86%E5%B8%83/","excerpt":"","text":"i.i.d.独立同分布 (Independent and identically distributed random variables)一组随机变量中每个变量的概率分布都相同，且这些随机变量互相独立","categories":[{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"}],"tags":[{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 2021VLDB NeuroCard_one cardinality estimator for all tables","slug":"论文笔记 2021VLDB NeuroCard_one cardinality estimator for all tables","date":"2022-10-20T02:29:49.877Z","updated":"2022-12-10T14:31:20.584Z","comments":true,"path":"2022/10/20/论文笔记 2021VLDB NeuroCard_one cardinality estimator for all tables/","link":"","permalink":"http://example.com/2022/10/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202021VLDB%20NeuroCard_one%20cardinality%20estimator%20for%20all%20tables/","excerpt":"","text":"codehttps://github.com/neurocard problem problem related 名词解释cardinity即解的大小（解包含多个tuple（有多个tuple都是解），解的大小是tuple的数量） 前置知识AR模型即用采样的方法得到条件概率 AR 结构： Conor Durkan and Charlie Nash. 2019. Autoregressive Energy Machines. InProceedings of the 36th International Conference on Machine Learning (Proceedingsof Machine Learning Research), Kamalika Chaudhuri and Ruslan Salakhutdinov(Eds.), Vol. 97. PMLR, Long Beach, California, USA, 1735–1744 Naru是AR模型形式化query inference阶段： model总体T是ARmodel中的“给定一个T”的T 我们的目标：构建一个输入为所有表格的所有列的模型 模型结构： 采集样本（作为训练数据）从full join中选取tuple采样的目标： 算法框架： [step1]得到join_key列step1：Computing join counts(别人提出) 得到采样的概率对一个表格进行采样：这个表由很多tuple组成，每个tuple有一个采样它的概率，这个阶段就是给每个表格的每个tuple计算这个概率 [step2]得到join_key列step2：采样 举例 join中null部分的处理 [step3]得到join key列之后把内容列补全 外加：full join中总行数 comment：采集多个样本可以并行（因为独立同分布） factorization（处理训练数据：将采样得到行转换成特征向量） 名词解释：embeding matrix 每个tuple的每一列在这一步之后都对应1~多个特征向量了： 这样处理的话，对于列的filter条件可以如何处理：","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2020VLDB Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning","slug":"论文笔记 2020VLDB Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning","date":"2022-10-20T01:49:14.075Z","updated":"2022-12-10T14:31:11.131Z","comments":true,"path":"2022/10/20/论文笔记 2020VLDB Buffer Pool Aware Query Scheduling via Deep Reinforcement Learning/","link":"","permalink":"http://example.com/2022/10/20/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202020VLDB%20Buffer%20Pool%20Aware%20Query%20Scheduling%20via%20Deep%20Reinforcement%20Learning/","excerpt":"","text":"名词解释 问题 模型总图 输入在内存中cache了哪些block 每个query要请求哪些block 形式化 实验效果","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"vmstat 系统内存监控","slug":"vmstat 系统内存监控","date":"2022-10-19T01:17:46.629Z","updated":"2022-12-10T14:07:03.136Z","comments":true,"path":"2022/10/19/vmstat 系统内存监控/","link":"","permalink":"http://example.com/2022/10/19/vmstat%20%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E7%9B%91%E6%8E%A7/","excerpt":"","text":"https://www.cnblogs.com/sjli-blog/p/15076966.html vmstat的常规用法：vmstat interval times即每隔interval秒采样一次，共采样times次，如果省略times,则一直采集数据，直到用户手动停止为止。 [yuanzhiqiu@graph vertex_disjoint_path]$ vmstat 1 2 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 5759288 15041652 128 162632320 3 6 16 14 0 0 1 0 98 0 0 4 0 5759288 15040160 128 162632352 0 0 0 27 27335 54270 1 1 97 0 0 第一行显示了系统自启动以来的平均值，第二行开始显示现在正在发生的情况，接下来的行会显示每5秒间隔发生了什么，每一列的含义在头部，如下所示： ▪ procs：r这一列显示了多少进程在等待cpu，b列显示多少进程正在不可中断的休眠（等待IO）。 ▪ memory：swapd列显示了多少块被换出了磁盘（页面交换），剩下的列显示了多少块是空闲的（未被使用），多少块正在被用作缓冲区，以及多少正在被用作操作系统的缓存。 ▪ swap：显示交换活动：每秒有多少块正在被换入（从磁盘）和换出（到磁盘）。 ▪ io：显示了多少块从块设备读取（bi）和写出（bo）,通常反映了硬盘I&#x2F;O。 ▪ system：显示每秒中断(in)和上下文切换（cs）的数量。 ▪ cpu：显示所有的cpu时间花费在各类操作的百分比，包括执行用户代码（非内核），执行系统代码（内核），空闲以及等待IO。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"内存泄漏检测工具valgrind","slug":"内存泄漏检测工具valgrind","date":"2022-10-19T01:09:57.699Z","updated":"2022-12-10T14:07:26.796Z","comments":true,"path":"2022/10/19/内存泄漏检测工具valgrind/","link":"","permalink":"http://example.com/2022/10/19/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E6%A3%80%E6%B5%8B%E5%B7%A5%E5%85%B7valgrind/","excerpt":"","text":"原理和简介Valgrind follows each allocation in your program and tracks it to see if it is returned properly, continue to be referenced or is lost in space, which is a ‘memory leak’. And as any leak, given enough time you will drown, in this case require more and more memory, until either you program is eating up your whole computer, or you get out of memory. 常用--tool=memcheck是默认选项 valgrind --leak-check=yes YourRunCommand valgrind --leak-check=full YourRunCommand https://tutorialadda.com/gdb/what-is-valgrind-and-how-to-debug-memory-related-issue-using-valgrind#:~:text=Valgrind%20is%20a%20debugging%20tool%20used%20for%20memory,to%20optimize%20memory%20uses%20during%20running%20the%20program. 配合gdbhttps://www.responsive.se/thomas/2013/09/20/debugging-memory-leaks-with-valgrind-and-gdb/","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"excel OFFSET函数","slug":"excel OFFSET函数","date":"2022-10-16T08:05:12.186Z","updated":"2022-12-10T14:08:00.995Z","comments":true,"path":"2022/10/16/excel OFFSET函数/","link":"","permalink":"http://example.com/2022/10/16/excel%20OFFSET%E5%87%BD%E6%95%B0/","excerpt":"","text":"OFFSET(reference, rows, cols, [height], [width])excel的索引从1开始前三个参数指定左上角，height和width指定这个区域的大小（height：行数，width：列数）ROW()获取当前行索引 如下表示求区域（A3单元格为区域左上角，区域高是ROW()-4行，宽是1列）的均方差（&#x3D;SQRT(VAR(…))） =STDEV(OFFSET(A3,0,0,ROW()-4,1)) 这个公式放在A14，则是求图中数字(A3:A12)的方差","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"linux函数运行时间监控 oprofile 用opref替代opcontrol","slug":"linux函数运行时间监控 oprofile 用opref替代opcontrol","date":"2022-10-14T08:43:34.911Z","updated":"2022-12-10T14:08:23.474Z","comments":true,"path":"2022/10/14/linux函数运行时间监控 oprofile 用opref替代opcontrol/","link":"","permalink":"http://example.com/2022/10/14/linux%E5%87%BD%E6%95%B0%E8%BF%90%E8%A1%8C%E6%97%B6%E9%97%B4%E7%9B%91%E6%8E%A7%20oprofile%20%E7%94%A8opref%E6%9B%BF%E4%BB%A3opcontrol/","excerpt":"","text":"oprofile的Q&amp;A：https://oprofile.sourceforge.io/faq/ 先operfSYNOPSIS operf [ options ] [ --system-wide | --pid &lt;pid&gt; | [ command [ args ] ] ] One (and only one) of either command , --pid or --system-wide is required. desOperf is an OProfile tool that can be used in place of opcontrol for profiling. Operf uses the Linux Performance Events Subsystem, and hence, does not require the use of the opcon‐ trol daemon – in fact, operf and opcontrol usage are mutually exclusive. By default, operf uses &#x2F;oprofile_data as the session-dir and stores profiling data there. You can change this by way of the –session-dir option. The usual post-profiling analysis tools such as opreport(1) and opannotate(1) can be used to generate profile reports. The post-processing analysis tools will search for samples in &#x2F;oprofile_data first. If that directory does not exist, the post-process‐ ing tools use the standard session-dir of &#x2F;var&#x2F;lib&#x2F;oprofile. Statistics, such as total samples received and lost samples, are written to the operf.log file that can be found in the &#x2F;samples directory. options指定监控对象command[args] 这部分和你普通运行程序时的命令一样 The command or application to be profiled. args are the input arguments that the command or application requires. One (and only one) of either command , --pid or --system-wide is required.--pid / -p PID This option enables operf to profile a running application. PID should be the process ID of the process you wish to profile. When finished profiling (e.g., when the profiled process ends), press Ctrl-c to stop operf. If you run operf –pid as a background job (i.e., with the &amp;), you must stop it in a controlled manner in order for it to process the profile data it has collected. Use kill -SIGINT for this purpose. 其他选项--vmlinux / k vmlinux_path 不带这个参数的话不会统计内核的symbols Why do the profile tools fail to open the vmlinux kernel image ?Probably because you have accidentally specified the vmlinuz not vmlinux file. If you don’t have a vmlinux file, most Linux distributions provide a kernel debuginfo package that includes it. Otherwise, you need to recompile your kernel from source. If you’re not interested in kernel samples, then don’t use the –vmlinux option (and for legacy profiling, use opcontrol –no-vmlinux). A vmlinux file that matches the running kernel that has symbol and/or debuginfo. Kernel samples will be attributed to this binary, allowing post-processing tools (like opreport) to attribute samples to the appropriate kernel symbols. --callgraph / -g This option enables the callgraph to be saved during profiling. NOTE: The full callchain is recorded, so there is no depth limit. --separate-thread / -t This option categorizes samples by thread group ID (tgid) and thread ID (tid). The ‘–separate-thread’ option is useful for seeing per-thread samples in multi- threaded applications. When used in conjunction with the ‘–system-wide’ option, the ‘–separate-thread’ option is also useful for seeing per-process (i.e., per- thread group) samples for the case where multiple processes are executing the same program during a profiling run. --separate-cpu / -c This option categorizes samples by cpu. --session-dir / -d path This option specifies the session path to hold the sample data. If not specified, the data is saved in the oprofile_data directory on the current path --lazy-conversion / -l Use this option to reduce the overhead of operf during profiling. Normally, profile data received from the kernel is converted to OProfile format during profiling time. This is typically not an issue when profiling a single application. But when using the –system-wide option, this on-the-fly conversion process can cause noticeable overhead, particularly on busy multi-processor systems. The –lazy-con‐ version option directs operf to wait until profiling is completed to do the conver‐ sion of profile data. opreport 输出解释 https://oprofile.sourceforge.io/doc/opreport.html opgprof-p不给的话默认是当前目录下的oprofile_data目录，-o不给的话默认生成gmon.out，可以作为gprof的输入 opgprof -o &lt;output_file&gt; -p &lt;oprofile_data_path&gt; 举例先收集统计数据，在当前目录下运行（-g希望能够输出call graph） sudo operf -g ./main -m msbfs -g test_graph.txt -o . -p vertex_pairs.txt 在当前目录下oprofile_data得到数据（此目录可以备份起来，之后还可以基于此目录生成各种分析文件），然后输出分析结果，在当前目录下运行（如果operf是command指定监控对象的，则用opreport不需要指定command） 将所有符号的统计结果（按占用cpu周期的降序）symbols.txt中，还有调用图 opreport -o symbols.txt -l opreport -o call_graph.txt -c opreport -l中输出的image name列中，no-vmlinux表示the time spent by the linux kernel，the application binary itself 在这里的名字就是可执行文件的名字，比如main，xxx.so是time spent in the shared libraries your application uses 同时profile内核举例获取vmlinux文件安装kernel debuginfo centos: https://iwmj.wordpress.com/2018/09/15/how-to-download-and-install-debuginfo-packages-for-centos/ Firstly, get the target packages from http://debuginfo.centos.org through wget&#x2F;curl # cat /etc/redhat-release CentOS Linux release 7.4.1708 (Core) # this means your system is centos 7, which determines download address wget http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-common-x86_64-$(uname -r).rpm wget http://debuginfo.centos.org/7/x86_64/kernel-debuginfo-$(uname -r).rpm Then install them yum install kernel-debuginfo-common-x86_64-$(uname -r).rpm yum install kernel-debuginfo-$(uname -r).rpm 然后会得到/usr/lib/debug/lib/modules/$(uname -r)/vmlinux，这个可以-k传递给opref extract-vmlinux脚本解压vmlinuz operf报告解压得到的文件invalid https://blog.packagecloud.io/how-to-extract-and-disassmble-a-linux-kernel-image-vmlinuz/ centos： 获取解压脚本sudo yum install kernel-devel-$(uname -r) You will be able to find the extract-linux script at &#x2F;usr&#x2F;src&#x2F;kernels&#x2F;$(uname -r)&#x2F;scripts&#x2F;extract-vmlinux 解压： A good first step is to create a temporary directory and copy the kernel image to it: mkdir ~/tmp/kernel-extract sudo cp /boot/vmlinuz-$(uname -r) ~/tmp/kernel-extract/ Now, run the extract-vmlinux script to extract the image. cd ~/tmp/kernel-extract/ sudo &lt;path_to_extract-vmlinux&gt; vmlinuz-$(uname -r) &gt; vmlinux 比如&#x2F;usr&#x2F;src&#x2F;kernels&#x2F;$(uname -r)&#x2F;scripts&#x2F;extract-vmlinux operf 加上-k指定vmlinux file的路径 sudo operf -k /tmp/kernel-extract/vmlinux-$(uname -r) ./main -m msbfs -g test_graph.txt -o . -p vertex_pairs.txt 适用应用 多线程可 cpu占用型的可 太小的程序统计的不完全","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux监控函数调用时间 gprof gcov","slug":"linux监控函数调用时间 gprof gcov","date":"2022-09-30T03:07:57.441Z","updated":"2022-12-10T14:09:02.870Z","comments":true,"path":"2022/09/30/linux监控函数调用时间 gprof gcov/","link":"","permalink":"http://example.com/2022/09/30/linux%E7%9B%91%E6%8E%A7%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E6%97%B6%E9%97%B4%20gprof%20gcov/","excerpt":"","text":"https://blog.csdn.net/yuyin86/article/details/6671472 gprof[每个函数的调用时间] 仅单线程、用户态gprof的基本用法：1． 使用 -pg 选项编译和链接你的应用程序 ，在gcc编译程序的时候，加上-pg选项，如果是大项目，就在makefile里面修改编译选项，-pg放在那里都行。例如： gcc -pg -o test test.c 2． 执行你的应用程序使之生成供gprof 分析的数据，运行刚才的程序： ./test input.txt output.txt 这样就生成了一个gmon.out文件，该文件就包含了profiling的数据。3. gprof ./test gmon.out 会输出分析结果到标准输出./test不用传上面运行传入的参数这里可以给gprof传参数，man gprof 不加参数输出的是所有函数的累计执行时间，剔除了children的执行时间；加上-F等参数还会输出call graph（每个函数谁调用它它调用谁以及时间以及被当前函数调用次数在总被调用次数的占比，并且按照self+children总时间降序，相当好的一张表）gprof -FTask1 ./test gmon.out 仅为函数Task1以及其孩子生成call graph gprof举例先编译参数加上-pg编译产生可执行文件 g++ -std=c++11 -g -pg main.cpp -o main 然后正常运行 ./main -m msbfs -g test_graph.txt -o . -p vertex_pairs.txt 然后会在运行的当前目录下生成gmon.out文件分析此文件输出分析结果。此文件可以备份起来，之后还可以基于此文件以及对应的可执行文件生成各种分析文件这会输出各函数的调用时间（降序，去除孩子的执行时间） gprof ./main gmon.out 这除了上述还会输出callgraph（每个函数的执行时间（包括孩子的执行时间），以及孩子的执行时间）传入-F的过滤似乎无效，但是会出发输出callgraph gprof -FComputeTask ./main gmon.out gcov[每行执行时间]https://blog.csdn.net/qq_32534441/article/details/90645316","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux查看cache大小","slug":"linux查看cache大小","date":"2022-09-30T01:48:38.367Z","updated":"2022-12-10T14:09:22.141Z","comments":true,"path":"2022/09/30/linux查看cache大小/","link":"","permalink":"http://example.com/2022/09/30/linux%E6%9F%A5%E7%9C%8Bcache%E5%A4%A7%E5%B0%8F/","excerpt":"","text":"getconf显示的大小数据单位为byte所有CACHE相关的参数 getconf -a | grep CACHE cache line大小 getconf -a | grep CACHE_LINESIZE Intel的一般是64字节： LEVEL1_ICACHE_LINESIZE 64 LEVEL1_DCACHE_LINESIZE 64 LEVEL2_CACHE_LINESIZE 64 LEVEL3_CACHE_LINESIZE 64 LEVEL4_CACHE_LINESIZE 0","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"模板类static成员静态数据成员","slug":"模板类static成员静态数据成员","date":"2022-09-28T02:02:06.209Z","updated":"2022-12-10T14:30:53.375Z","comments":true,"path":"2022/09/28/模板类static成员静态数据成员/","link":"","permalink":"http://example.com/2022/09/28/%E6%A8%A1%E6%9D%BF%E7%B1%BBstatic%E6%88%90%E5%91%98%E9%9D%99%E6%80%81%E6%95%B0%E6%8D%AE%E6%88%90%E5%91%98/","excerpt":"","text":"https://blog.csdn.net/zhizhengguan/article/details/116108271 语法1：定义在.h.h文件： template &lt;typename T&gt; class the_class&#123; static int id; &#125;; template &lt;typename T&gt; int the_class&lt;T&gt;::id = 0; 编译链接为模板类static成员分配的地址 这个取决于链接器，有些版本的链接器不支持此特殊处理，会报错，那么用语法2 由于定义在头文件中，如果多个.cpp文件包含了此头文件会导致有多个定义的问题，情况比如：call1.cpp #include &lt;iostream&gt; #include &quot;the_class.h&quot; void call1()&#123; the_class&lt;int&gt; c; std::cout &lt;&lt; c.id &lt;&lt; &quot;\\n&quot;; &#125;; call2.cpp #include &lt;iostream&gt; #include &quot;the_class.h&quot; void call2()&#123; the_class&lt;int&gt; c; std::cout &lt;&lt; c.id &lt;&lt; &quot;\\n&quot;; &#125;; main.cpp #include &lt;string&gt; #include &lt;iostream&gt; void call1(); void call2(); int main()&#123; call1(); call2(); return 0; &#125; call1.cpp和call2.cpp定义的call1()和call2()两个函数都生成了类模板the_class的实例the_class，编译器会分别在编译两个代码文件所生成的目标文件中，为其静态成员变量the_class&lt;int&gt;::id分配内存地址。而按照类静态成员的概念，所有类实例应该共享同一套静态成员存储空间。在链接时，链接器将随机选择一个目标中的空间作为最终存储空间，从而使不同目标文件中的多个等价目标实例共享同一套静态成员空间。 语法2：定义在.cpp和模板类成员函数定义和申明分离的写法类似，要在.cpp文件中写对模板类的实例化申明 .h文件： template &lt;typename T&gt; class the_class&#123; static int id; &#125;; .cpp文件： #include &quot;the_class.h&quot; template class the_class&lt;int&gt;; template class the_class&lt;long long&gt;; template &lt;typename T&gt; int the_class&lt;T&gt;::id = 0;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"vscode调试c++查看变量的二进制表示","slug":"vscode调试c++查看变量的二进制表示","date":"2022-09-27T14:04:59.926Z","updated":"2022-12-10T14:16:30.043Z","comments":true,"path":"2022/09/27/vscode调试c++查看变量的二进制表示/","link":"","permalink":"http://example.com/2022/09/27/vscode%E8%B0%83%E8%AF%95c++%E6%9F%A5%E7%9C%8B%E5%8F%98%E9%87%8F%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E8%A1%A8%E7%A4%BA/","excerpt":"","text":"方法一：watch窗口加expression后缀expression[,suffix]无后缀：十进值,x或,h：十六进制,o：八进制,b：二进制（低地址在右边）比如：undone.reg,b（reg是undone的private成员，也可以监控） 方法二：gdb内存查看命令xF5启动调试在断点处停住后，可以在debug console中通过-exec前缀执行gdb的命令比如内存查看指令x（gdbx命令详解 https://blog.csdn.net/allenlinrui/article/details/5964046）x/tb中数字为1表示显示一个单元，t表示以二进制格式显示，b表示一个单元是一个字节下述为查看undone.reg的首字节（reg是undone类型的private成员，也可以查看） -exec x/tb &amp;undone.reg 二进制显示时低地址在右边 -exec x/tb &amp;cross.reg 0x7ffff72d7bc8: 00000001 # 1是最低位bit","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"unorder_map插入键 值调用默认构造函数","slug":"unorder_map插入键 值调用默认构造函数","date":"2022-09-26T09:04:03.916Z","updated":"2022-12-10T14:17:44.149Z","comments":true,"path":"2022/09/26/unorder_map插入键 值调用默认构造函数/","link":"","permalink":"http://example.com/2022/09/26/unorder_map%E6%8F%92%E5%85%A5%E9%94%AE%20%E5%80%BC%E8%B0%83%E7%94%A8%E9%BB%98%E8%AE%A4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/","excerpt":"","text":"判断是否有某键，不用count而是用find，因为如果存在某键的话，count会返回键的所有个数，也就是会遍历所有，而不是找到了就返回 []向Fr中插入键n，值调用默认构造函数 if (Fr.find(n) == Fr.end()) &#123; Fr[n]; &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"模板定义和声明分离方法","slug":"模板定义和声明分离方法","date":"2022-09-26T07:19:03.072Z","updated":"2022-12-10T14:18:17.941Z","comments":true,"path":"2022/09/26/模板定义和声明分离方法/","link":"","permalink":"http://example.com/2022/09/26/%E6%A8%A1%E6%9D%BF%E5%AE%9A%E4%B9%89%E5%92%8C%E5%A3%B0%E6%98%8E%E5%88%86%E7%A6%BB%E6%96%B9%E6%B3%95/","excerpt":"","text":"调用可以和定义或申明不在一起 不分离申明和定义都放在.h文件中函数模板 template &lt;typename T&gt; void testprint(T i) &#123; std::cout &lt;&lt; i &lt;&lt; std::endl; &#125; 类模板 template &lt;typename T&gt; class A &#123; T data; void func()&#123; //definition &#125; &#125;; 分离需要在.cpp文件中添加实例化申明 函数模板.h template &lt;typename T&gt; void testprint(T i); .cpp template void testprint&lt;int&gt;(T i); 这里 template &lt;typename T&gt; void testprint(T i) &#123; std::cout &lt;&lt; i &lt;&lt; std::endl; &#125; 类模板.h template &lt;typename T&gt; class A &#123; T data; void func(); &#125;; .cpp template class A&lt;int&gt;; 这里 template &lt;typename T&gt; void A&lt;T&gt;::func()&#123; //definition &#125; 结论 可以不分离就不分离了，实在要分离，如果 有很多模板函数的目标扩展类都是一样的话，可以把它们写成一个模板类的成员函数，这样在cpp文件中写实例化申明的时候只要对类写就可以，而不用对每个函数都写","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"SSE指令速查链接","slug":"SSE指令速查链接","date":"2022-09-23T08:56:48.260Z","updated":"2022-12-10T14:20:15.508Z","comments":true,"path":"2022/09/23/SSE指令速查链接/","link":"","permalink":"http://example.com/2022/09/23/SSE%E6%8C%87%E4%BB%A4%E9%80%9F%E6%9F%A5%E9%93%BE%E6%8E%A5/","excerpt":"","text":"指令速查中文部分（从这里猜测用什么关键词去下面的官方文档中搜）https://packagewjx.github.io/2018/11/12/sse-note/官方（这个超级好，搜索迅速，给了描述、实现指令、头文件、对应指令集标准等）https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"}],"tags":[{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"cpp对齐","slug":"cpp对齐","date":"2022-09-22T06:54:42.540Z","updated":"2022-12-10T14:27:34.092Z","comments":true,"path":"2022/09/22/cpp对齐/","link":"","permalink":"http://example.com/2022/09/22/cpp%E5%AF%B9%E9%BD%90/","excerpt":"","text":"栈：alignas specifier (since C++11) alignas specifier (since C++11) - cppreference.com Specifies the alignment requirement of a type or an object. Syntaxalignas( expression ) \\1) expression must be an integral constant expression that evaluates to zero, or to a valid value for an alignment or extended alignment. describeThe object or the type declared by such a declaration will have its alignment requirement equal to the strictest (largest) non-zero expression of all alignas specifiers used in the declaration, unless it would weaken the natural alignment of the type. If the strictest (largest) alignas on a declaration is weaker than the alignment it would have without any alignas specifiers (that is, weaker than its natural alignment or weaker than alignas on another declaration of the same object or type), the program is ill-formed: struct alignas(8) S &#123;&#125;; struct alignas(1) U &#123; S s; &#125;; // error: alignment of U would have been 8 without alignas(1) Invalid non-zero alignments, such as alignas(3) are ill-formed. Valid non-zero alignments that are weaker than another alignas on the same declaration are ignored. alignas(0) is always ignored. 堆：posix_memalignint posix_memalign(void **__memptr, size_t __alignment, size_t __size) Allocate memory of SIZE bytes with an alignment of ALIGNMENT, return a pointer to the allocated memory in memptr Upon successful completion(return 0), the value pointed to by memptr shall be a multiple of alignment. 举例new(visitLists[a]) Bitset[subgraphSize]();在visitLists[a]这个地址开始处的内存处，构造一个类型为Bitset[subgraphSize]的object std::array&lt;Bitset*,2&gt; visitLists; for(int a=0; a&lt;2; a++) &#123; //分配内存 const auto ret=posix_memalign(reinterpret_cast&lt;void**&gt;(&amp;(visitLists[a])),64,sizeof(Bitset)*subgraphSize); if(unlikely(ret!=0)) &#123; //告诉编译器ret!=0很可能为假 //#define unlikely(x) __builtin_expect(!!(x), 0) throw -1; &#125; //构造 new(visitLists[a]) Bitset[subgraphSize](); //create an object of type `Bitset[subgraphSize]`, through calling () constructor, //directly into storage at memory address `visitLists[a]`. &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"cpp new placement new","slug":"cpp new placement new","date":"2022-09-22T03:12:45.839Z","updated":"2022-12-10T14:26:09.970Z","comments":true,"path":"2022/09/22/cpp new placement new/","link":"","permalink":"http://example.com/2022/09/22/cpp%20new%20placement%20new/","excerpt":"","text":"new expression - cppreference.com Creates and initializes objects with dynamic storage duration, that is, objects whose lifetime is not necessarily limited by the scope in which they were created. Syntax::(optional) new ( type ) initializer(optional) (1) ::(optional) new new-type initializer(optional) (2) ::(optional) new (placement-params) ( type ) initializer(optional) (3) ::(optional) new (placement-params) new-type initializer(optional) (4) \\1) Attempts to create an object of type, denoted by the type-id type, which may be array type, and may include a placeholder type specifier (since C++11), or include a class template name whose argument is to be deduced by class template argument deduction (since C++17). \\2) Same as (1), but new-type cannot include parentheses: new int(*[10])(); // error: parsed as (new int) (*[10]) () new (int (*[10])()); // okay: allocates an array of 10 pointers to functions new int + 1; // okay: parsed as (new int) + 1, increments a pointer returned by new int new int * 1; // error: parsed as (new int*) (1) \\3) Same as (1), but provides additional arguments to the allocation function, see placement new. \\4) Same as (2), but provides additional arguments to the allocation function. placement newIf placement-params are provided, they are passed to the allocation function as additional arguments. Such allocation functions are known as “placement new”, after the standard allocation function void* operator new(std::size_t, void*), which simply returns its second argument unchanged. This is used to construct objects in allocated storage: // within any block scope... &#123; // Statically allocate the storage with automatic storage duration // which is large enough for any object of type `T`. alignas(T) unsigned char buf[sizeof(T)]; T* tptr = new(buf) T; // Construct a `T` object, placing it directly into your // pre-allocated storage at memory address `buf`. tptr-&gt;~T(); // You must **manually** call the object&#39;s destructor // if its side effects is depended by the program. &#125; // Leaving this block scope automatically deallocates `buf`. c++17的一些说明本文未记录 举例new(visitLists[a]) Bitset[subgraphSize]();在visitLists[a]这个地址开始处的内存处，构造一个类型为Bitset[subgraphSize]的object std::array&lt;Bitset*,2&gt; visitLists; for(int a=0; a&lt;2; a++) &#123; //分配内存 //int posix_memalign(void **__memptr, size_t __alignment, size_t __size) //Allocate memory of SIZE bytes with an alignment of ALIGNMENT, return a pointer to the allocated memory in memptr //Upon successful completion(return 0), the value pointed to by memptr shall be a multiple of alignment. const auto ret=posix_memalign(reinterpret_cast&lt;void**&gt;(&amp;(visitLists[a])),64,sizeof(Bitset)*subgraphSize); if(unlikely(ret!=0)) &#123; //告诉编译器ret!=0很可能为假 //#define unlikely(x) __builtin_expect(!!(x), 0) throw -1; &#125; //构造 new(visitLists[a]) Bitset[subgraphSize](); //create an object of type `Bitset[subgraphSize]`, through calling () constructor, //directly into storage at memory address `visitLists[a]`. &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"mmap munmap","slug":"mmap munmap","date":"2022-09-21T10:45:34.349Z","updated":"2022-12-10T14:27:06.735Z","comments":true,"path":"2022/09/21/mmap munmap/","link":"","permalink":"http://example.com/2022/09/21/mmap%20munmap/","excerpt":"","text":"Memory-mapped fileA memory-mapped file is a segment of virtual memory[1] that has been assigned a direct byte-for-byte correlation with some portion of a file or file-like resource. This resource is typically a file that is physically present on disk, but can also be a device, shared memory object, or other resource that the operating system can reference through a file descriptor. Once present, this correlation between the file and the memory space permits applications to treat the mapped portion as if it were primary memory. BenefitsThe benefit of memory mapping a file is increasing I&#x2F;O performance, especially when used on large files. For small files, memory-mapped files can result in a waste of slack space[7] as memory maps are always aligned to the page size, which is mostly 4 KiB. Therefore, a 5 KiB file will allocate 8 KiB and thus 3 KiB are wasted. Accessing memory mapped files is faster than using direct read and write operations for two reasons. Firstly, a system call is orders of magnitude slower than a simple change to a program’s local memory. Secondly, in most operating systems the memory region mapped actually is the kernel’s page cache (file cache), meaning that no copies need to be created in user space. Certain application-level memory-mapped file operations also perform better than their physical file counterparts. Applications can access and update data in the file directly and in-place, as opposed to seeking from the start of the file or rewriting the entire edited contents to a temporary location. Since the memory-mapped file is handled internally in pages, linear file access (as seen, for example, in flat file data storage or configuration files) requires disk access only when a new page boundary is crossed, and can write larger sections of the file to disk in a single operation. A possible benefit of memory-mapped files is a “lazy loading“, thus using small amounts of RAM even for a very large file. Trying to load the entire contents of a file that is significantly larger than the amount of memory available can cause severe thrashing as the operating system reads from disk into memory and simultaneously writes pages from memory back to disk. Memory-mapping may not only bypass the page file completely, but also allow smaller page-sized sections to be loaded as data is being edited, similarly to demand paging used for programs. The memory mapping process is handled by the virtual memory manager, which is the same subsystem responsible for dealing with the page file. Memory mapped files are loaded into memory one entire page at a time. The page size is selected by the operating system for maximum performance. Since page file management is one of the most critical elements of a virtual memory system, loading page sized sections of a file into physical memory is typically a very highly optimized system function.[8] DrawbacksThe major reason to choose memory mapped file I&#x2F;O is performance. Nevertheless, there can be tradeoffs. The standard I&#x2F;O approach is costly due to system call overhead and memory copying. The memory-mapped approach has its cost in minor page faults—when a block of data is loaded in page cache, but is not yet mapped into the process’s virtual memory space. In some circumstances, memory mapped file I&#x2F;O can be substantially slower than standard file I&#x2F;O.[10] Another drawback of memory-mapped files relates to a given architecture’s address space: a file larger than the addressable space can have only portions mapped at a time, complicating reading it. For example, a 32-bit architecture such as Intel’s IA-32 can only directly address 4 GiB or smaller portions of files. An even smaller amount of addressable space is available to individual programs—typically in the range of 2 to 3 GiB, depending on the operating system kernel. This drawback however is virtually eliminated on modern 64-bit architecture. mmap also tends to be less scalable than standard means of file I&#x2F;O, since many operating systems, including Linux, has a cap on the number of cores handling page faults. Extremely fast devices, such as modern NVM Express SSDs, are capable of making the overhead a real concern.[11] I&#x2F;O errors on the underlying file (e.g. its removable drive is unplugged or optical media is ejected, disk full when writing, etc.) while accessing its mapped memory are reported to the application as the SIGSEGV&#x2F;SIGBUS signals on POSIX, and the EXECUTE_IN_PAGE_ERROR structured exception on Windows. All code accessing mapped memory must be prepared to handle these errors, which don’t normally occur when accessing memory. Only hardware architectures with an MMU can support memory-mapped files. On architectures without an MMU, the operating system can copy the entire file into memory when the request to map it is made, but this is extremely wasteful and slow if only a little bit of the file will be accessed, and can only work for files that will fit in available memory. Common usesPerhaps the most common use for a memory-mapped file is the process loader in most modern operating systems (including Microsoft Windows and Unix-like systems.) When a process is started, the operating system uses a memory mapped file to bring the executable file, along with any loadable modules, into memory for execution. Most memory-mapping systems use a technique called demand paging, where the file is loaded into physical memory in subsets (one page each), and only when that page is actually referenced.[12] In the specific case of executable files, this permits the OS to selectively load only those portions of a process image that actually need to execute. Another common use for memory-mapped files is to share memory between multiple processes. In modern protected mode operating systems, processes are generally not permitted to access memory space that is allocated for use by another process. (A program’s attempt to do so causes invalid page faults or segmentation violations.) There are a number of techniques available to safely share memory, and memory-mapped file I&#x2F;O is one of the most popular. Two or more applications can simultaneously map a single physical file into memory and access this memory. For example, the Microsoft Windows operating system provides a mechanism for applications to memory-map a shared segment of the system’s page file itself and share data via this section. mmap munmaphttps://man7.org/linux/man-pages/man2/mmap.2.html SYNOPSIS#include &lt;sys/mman.h&gt; void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); int munmap(void *addr, size_t length); mmap: DESCRIPTIONmmap() creates a new mapping in the virtual address space of thecalling process. The starting address(virtual address) for the new mapping isspecified in addr. The length argument specifies** the length ofthe mapping** (which must be greater than 0). If addr is NULL, then the kernel chooses the (page-aligned)address(virtual address) at which to create the mapping; this is the most portablemethod of creating a new mapping. If addr is not NULL, then thekernel takes it as a hint about where to place the mapping; onLinux, the kernel will pick a nearby page boundary (but alwaysabove or equal to the value specified by&#x2F;proc&#x2F;sys&#x2F;vm&#x2F;mmap_min_addr) and attempt to create the mappingthere. If another mapping already exists there, the kernel picksa new address that may or may not depend on the hint. Theaddress of the new mapping is returned as the result of the call. The contents of a file mapping (as opposed to an anonymousmapping; see MAP_ANONYMOUS below), are initialized using lengthbytes starting at offset offset in the file (or other object)referred to by the file descriptor fd. offset must be a multipleof the page size as returned by sysconf(_SC_PAGE_SIZE). After the mmap() call has returned, the file descriptor, fd, canbe closed immediately without invalidating the mapping. The prot argument describes the desired memory protection of themapping (and must not conflict with the open mode of the file).It is either PROT_NONE or the bitwise OR of one or more of thefollowing flags: PROT_EXECPages may be executed. PROT_READPages may be read. PROT_WRITEPages may be written. PROT_NONEPages may not be accessed. mmap: The flags argumentThe flags argument determines whether updates to the mapping arevisible to other processes mapping the same region, and whetherupdates are carried through to the underlying file. Thisbehavior is determined by including exactly one of the followingvalues in flags: MAP_SHAREDShare this mapping. Updates to the mapping are visible toother processes mapping the same region, and (in the caseof file-backed mappings) are carried through to theunderlying file. (To precisely control when updates arecarried through to the underlying file requires the use ofmsync(2).) MAP_SHARED_VALIDATE (since Linux 4.15)This flag provides the same behavior as MAP_SHARED exceptthat MAP_SHARED mappings ignore unknown flags in flags.By contrast, when creating a mapping usingMAP_SHARED_VALIDATE, the kernel verifies all passed flagsare known and fails the mapping with the error EOPNOTSUPPfor unknown flags. This mapping type is also required tobe able to use some mapping flags (e.g., MAP_SYNC). MAP_PRIVATECreate a private copy-on-write mapping. Updates to themapping are not visible to other processes mapping thesame file, and are not carried through to the underlyingfile. It is unspecified whether changes made to the fileafter the mmap() call are visible in the mapped region. munmapThe munmap() system call deletes the mappings for the specifiedaddress range, and causes further references to addresses withinthe range to generate invalid memory references. The region isalso automatically unmapped when the process is terminated. Onthe other hand, closing the file descriptor does not unmap theregion. The address addr must be a multiple of the page size (but lengthneed not be). All pages containing a part of the indicated rangeare unmapped, and subsequent references to these pages willgenerate SIGSEGV. It is not an error if the indicated range doesnot contain any mapped pages. Does mmap copy data to the memory?c - Does mmap really copy data to the memory? - Stack Overflow The only thing the mmap function really does is change some kernel data structures, and possibly the page table. It doesn’t actually put anything into physical memory at all. After you call mmap, the allocated region probably doesn’t even point to physical memory: accessing it will cause a page fault. This kind of page fault is transparently handled by the kernel mmap() vs. reading blocks using mmap() versus reading in blocks via C++’s fstream library compare A call to mmap has more overhead than read (just like epoll has more overhead than poll, which has more overhead than read). Changing virtual memory mappings is a quite expensive operation on some processors for the same reasons that switching between different processes is expensive. The IO system can already use the disk cache, so if you read a file, you’ll hit the cache or miss it no matter what method you use. However, Memory maps are generally faster for random access, especially if your access patterns are sparse and unpredictable. Memory maps allow you to keep using pages from the cache until you are done. This means that if you use a file heavily for a long period of time, then close it and reopen it, the pages will still be cached. With read, your file may have been flushed from the cache ages ago. This does not apply if you use a file and immediately discard it. (If you try to mlock pages just to keep them in cache, you are trying to outsmart the disk cache and this kind of foolery rarely helps system performance). Reading a file directly is very simple and fast. The discussion of mmap&#x2F;read reminds me of two other performance discussions: Some Java programmers were shocked to discover that nonblocking I/O is often slower than blocking I/O, which made perfect sense if you know that nonblocking I/O requires making more syscalls. Some other network programmers were shocked to learn that epoll is often slower than poll, which makes perfect sense if you know that managing epoll requires making more syscalls. ConclusionUse memory maps if you access data randomly, keep it around for a long time, or if you know you can share it with other processes (MAP_SHARED isn’t very interesting if there is no actual sharing). Read files normally if you access data sequentially or discard it after reading. And if either method makes your program less complex, do that. For many real world cases there’s no sure way to show one is faster without testing your actual application and NOT a benchmark. When should I use mmap for file access? POSIX environments provide at least two ways of accessing files. There’s the standard system calls open(), read(), write(), and friends, but there’s also the option of using mmap() to map the file into virtual memory. When is it preferable to use one over the other? benefit and when to usemmap is great if you have multiple processes accessing data in a read only fashion from the same file. mmap allows all those processes to share the same physical memory pages, saving a lot of memory. mmap also allows the operating system to optimize paging operations. For example, consider two programs; program A which reads in a 1MB file into a buffer creating with malloc, and program B which mmaps the 1MB file into memory. If the operating system has to swap part of A‘s memory out, it must write the contents of the buffer to swap before it can reuse the memory. In B‘s case any unmodified mmap‘d pages can be reused immediately because the OS knows how to restore them from the existing file they were mmap‘d from. (The OS can detect which pages are unmodified by initially marking writable mmap‘d pages as read only and catching seg faults, similar to Copy on Write strategy). mmap is also useful for inter process communication. You can mmap a file as read &#x2F; write in the processes that need to communicate and then use synchronization primitives in the mmap&#39;d region (this is what the MAP_HASSEMAPHORE flag is for). awkwardnessOne place mmap can be awkward is if you need to work with very large files on a 32 bit machine. This is because mmap has to find a contiguous block of addresses in your process’s address space that is large enough to fit the entire range of the file being mapped. This can become a problem if your address space becomes fragmented, where you might have 2 GB of address space free, but no individual range of it can fit a 1 GB file mapping. In this case you may have to map the file in smaller chunks than you would like to make it fit. Another potential awkwardness with mmap as a replacement for read &#x2F; write is that you have to start your mapping on offsets of the page size. If you just want to get some data at offset X you will need to fixup that offset so it’s compatible with mmap. And finally, read &#x2F; write are the only way you can work with some types of files. mmap can’t be used on things like pipes and ttys.","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"c++ data types __m128i","slug":"c++ data types __m128i","date":"2022-09-21T08:35:50.997Z","updated":"2022-12-10T14:32:06.952Z","comments":true,"path":"2022/09/21/c++ data types __m128i/","link":"","permalink":"http://example.com/2022/09/21/c++%20data%20types%20__m128i/","excerpt":"","text":"__m128i__m128i | Microsoft Learn The __m128i data type, for use with the Streaming SIMD Extensions 2 (SSE2) instructions intrinsics, is defined in &lt;emmintrin.h&gt;. eg: /usr/local/gcc-9.3.0/lib/gcc/x86_64-pc-linux-gnu/9.3.0/include/emmintrin.h // data_types__m128i.cpp #include &lt;emmintrin.h&gt; int main() &#123; __m128i x; &#125; RemarksUsing variables of type __m128i will cause the compiler to generate the SSE2 movdqa instruction. This instruction does not cause a fault on Pentium III processors but will result in silent failure, with possible side effects caused by whatever instructions movdqa translates into on Pentium III processors. You should not access the __m128i fields directly. You can, however, see these types in the debugger. A variable of type __m128i maps to the XMM[0-7] registers. Variables of type __m128i are automatically aligned on 16-byte boundaries. The __m128i data type is not supported on ARM processors.","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 2014SC Scalable and high performance betweenness centrality on the gpu","slug":"论文笔记 2014SC Scalable and high performance betweenness centrality on the gpu","date":"2022-09-17T09:27:09.726Z","updated":"2022-12-10T14:32:18.066Z","comments":true,"path":"2022/09/17/论文笔记 2014SC Scalable and high performance betweenness centrality on the gpu/","link":"","permalink":"http://example.com/2022/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202014SC%20Scalable%20and%20high%20performance%20betweenness%20centrality%20on%20the%20gpu/","excerpt":"","text":"一些定义和知识betweenness中心性 比较不同图的BC：（(n-1)(n-2)是除了v之外所有不同点对的数目，且含方向） 求BC的著名算法 [7] U. Brandes, “A Faster Algorithm for Betweenness Centrality,” Journalof Mathematical Sociology, vol. 25, pp. 163–177, 2001. 上述的GPU版本Jia [23] Y. Jia, V. Lu, J. Hoberock, M. Garland, and J. C. Hart, “Edge v. NodeParallelism for Graph Centrality Metrics,” GPU Computing Gems, vol. 2,pp. 15–30, 2011. 问题：不需要在这层inspect的点边或者边也inspect了，因为是给每个点&#x2F;边一个thread （需要记录前驱是因为我们需要知道路径是否经过xx点，因此完整路径是要记录的） GPU-FAN（虽然但是，这个显然就是上面的改了一点点，还更菜） [34] Z. Shi and B. Zhang, “Fast Network Centrality Analysis using GPUs,”BMC bioinformatics, vol. 12, no. 1, p. 149, 2011 前驱记录 算法变量（perblock的block指CUDA术语中的thread block） S和ends记录每层的顶点，类似CSR的结构 1 初始化 2 计算所有点对间最短路径数目 目前本文还没有提出新的东西","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 B类2002ESA External-memory breadth-first search with sublinear IO","slug":"论文笔记 B类2002ESA External memory breadth","date":"2022-09-17T08:03:06.650Z","updated":"2022-12-10T14:33:14.693Z","comments":true,"path":"2022/09/17/论文笔记 B类2002ESA External memory breadth/","link":"","permalink":"http://example.com/2022/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20B%E7%B1%BB2002ESA%20External%20memory%20breadth/","excerpt":"","text":"related workexternal BFS 算法1 预处理 非随机划分 回顾：欧拉图： 2 和[1999 SODA]几乎一样的BFS（只是多了个有序文件放最近用到的邻接表） 不一样的地方：维护一个有序的文件H用于获取邻接表：（H有序：H中存放的内容是边entry，有序按边entry字典序） 如何获取L(t-1)的邻居：","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 1999SODA IO-complexity of graph algorithms","slug":"论文笔记 1999SODA IOcomplexity of graph algorithms","date":"2022-09-17T03:25:31.428Z","updated":"2022-12-10T14:33:45.435Z","comments":true,"path":"2022/09/17/论文笔记 1999SODA IOcomplexity of graph algorithms/","link":"","permalink":"http://example.com/2022/09/17/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%201999SODA%20IOcomplexity%20of%20graph%20algorithms/","excerpt":"","text":"尚未全部阅读 parallel disk model（对于BFS没啥大用）模型 BD(j-1)定位红色框（trackj前有j-1个track（红框），每个track有BD个records）；B(k-1)在红框中定位蓝框（红框中，diskk前有k-1个block（蓝框），每个block有B个records）；i在蓝框中定位record IO compute BFS一个性质level(t-1)邻居的并集得到初始level(t)，此level(t)中要去除的已经visited（入队）的顶点，只可能在level(t-1)∪level(t-2)中 证明（by me）：如果初始level(t)中有level(t-3)中的顶点，则说明level(t-1)中有顶点有邻居在level(t-3)（因为level(t)是level(t-1)邻居的并集），而如果level(t-1)中有顶点有邻居在level(t-3)，则该顶点应该在处理level(t-3)的时候被入队到下一个level，即应该属于level(t-2)，这与该顶点属于level(t-1)矛盾证明（by [2002 ESA] External-memory breadth-first search with sublinear I&#x2F;O）： 算法","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2020VLDB Traversing Large Graphs on GPUs with Unified Memory","slug":"论文笔记 2020VLDB Traversing Large Graphs on GPUs with Unified Memory","date":"2022-09-16T02:27:01.163Z","updated":"2022-12-10T14:36:24.294Z","comments":true,"path":"2022/09/16/论文笔记 2020VLDB Traversing Large Graphs on GPUs with Unified Memory/","link":"","permalink":"http://example.com/2022/09/16/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202020VLDB%20Traversing%20Large%20Graphs%20on%20GPUs%20with%20Unified%20Memory/","excerpt":"","text":"问题 且cpu部分的存储貌似只是内存，没有考虑外存那些 在UVM settings下讨论（CUDA支持） related work本文作为对比对象的： 大图放多GPU或GPU和CPU GPU BFS external BFS：已计划 一些定义 UVM CSR和BFS 分析factors that impact performance(DATA ACCESS PATTERN)： Dependence on the Source Node Dependence on Graph Ordering Dependence on Directedness 问题形式化（貌似没有用） 理想的order： 1 HARMONIC LOCALITY ORDERING希望的从随机的顶点出发BFS，所以希望 这个在无向图中可以 计算 算法“精确” 代替上面的c(x) 计算中心性 给order 不是严格按照中心性降序作为order的原因以及设计： 近似 把上式展开，相同d的项放在一起，得到的和式，第一项对应和x距离为1的所有点，第二项对应和x距离为2的所有点…","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"An Overview of Semi-External Graph System","slug":"An Overview of Semi","date":"2022-09-15T06:56:54.995Z","updated":"2022-12-10T14:38:24.003Z","comments":true,"path":"2022/09/15/An Overview of Semi/","link":"","permalink":"http://example.com/2022/09/15/An%20Overview%20of%20Semi/","excerpt":"","text":"来自2022FAST Practicably Boosting the Processing Performance of BFS-like Algorithms on Semi-External Graph System via IO-Efficient Graph Ordering 存储 I&#x2F;O optimization techniques Pre-processing","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"db","slug":"graph/db","permalink":"http://example.com/categories/graph/db/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"conda环境切换","slug":"conda环境切换","date":"2022-09-14T12:53:22.653Z","updated":"2022-12-10T14:41:28.116Z","comments":true,"path":"2022/09/14/conda环境切换/","link":"","permalink":"http://example.com/2022/09/14/conda%E7%8E%AF%E5%A2%83%E5%88%87%E6%8D%A2/","excerpt":"","text":"装好miniconda之后有的conda命令（miniconda：相比起anaconda不会自带几千个包） conda activate &lt;env_name&gt; 比如conda activate basebase外的其他环境的存储目录在&lt;miniconda的安装目录&gt;/envs下（比如/home/yuanzhiqiu/miniconda3）","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"DNS error","slug":"DNS error","date":"2022-09-14T12:12:21.281Z","updated":"2022-12-10T14:41:56.393Z","comments":true,"path":"2022/09/14/DNS error/","link":"","permalink":"http://example.com/2022/09/14/DNS%20error/","excerpt":"","text":"https://stackoverflow.com/questions/9393409/ssh-could-not-resolve-hostname-github-com-name-or-service-not-known-fatal-th ssh: Could not resolve hostname github.com: Name or service not known fatal: The remote end hung up unexpectedly ubuntu上： ping github.com, if ping failed. it is DNS error. sudo vim /etc/resolv.conf, then add: nameserver 8.8.8.8 nameserver 8.8.4.4Or it can be a genuine network issue. Restart your network-manager using sudo service network-manager restart or fix it up","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2017FAST Graphene_Fine-Grained IO Management for Graph Computing","slug":"论文笔记 2017FAST Graphene_Fine Grained IO Management for Graph Computing","date":"2022-09-14T03:19:38.733Z","updated":"2022-12-10T14:42:31.256Z","comments":true,"path":"2022/09/14/论文笔记 2017FAST Graphene_Fine Grained IO Management for Graph Computing/","link":"","permalink":"http://example.com/2022/09/14/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202017FAST%20Graphene_Fine%20Grained%20IO%20Management%20for%20Graph%20Computing/","excerpt":"","text":"一些definition 1 Bitmap Based, Asynchronous IO1 store block size依据： 2 bitmap（这个） bitmap size: 举例：benefit: 3 Asynchronous IO upper bound for IO size(size for each IO transaction) 依据： IO context number： what is IO context: 2 Balancing Data and Workload1 图数据划分 2 处理 回顾：metadata放内存，graphdata放外存 详细和举例： 3 HugePage support大页可以降低TLB misses：因为TLB中line的内容是页表的entry","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2016SIGMOD iBFS_Concurrent Breadth-First Search on GPUs","slug":"论文笔记 2016SIGMOD iBFS_Concurrent Breadth First Search on GPUs","date":"2022-09-13T09:22:20.912Z","updated":"2022-12-10T14:43:03.652Z","comments":true,"path":"2022/09/13/论文笔记 2016SIGMOD iBFS_Concurrent Breadth First Search on GPUs/","link":"","permalink":"http://example.com/2022/09/13/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202016SIGMOD%20iBFS_Concurrent%20Breadth%20First%20Search%20on%20GPUs/","excerpt":"","text":"问题 code related workCPU-多BFS实例 MSBFS VLDB[26] Manuel Then, Moritz Kaufmann, Fernando Chirigati,Tuan-Anh Hoang-Vu, Kien Pham, Alfons Kemper,Thomas Neumann, and Huy T Vo. The more themerrier: Efficient multi-source graph traversal.Proceedings of the VLDB Endowment, 8(4), 2014. CCF-B [27] Ahmet Erdem Sarıyuce, Erik Saule, Kamer Kaya, and ¨Umit V ¸Cataly ¨ urek. Regularizing graph centrality ¨computations. Journal of Parallel and DistributedComputing, 2014. CCF-B IPDPS [28] Ahmet Erdem Sariyuce, Erik Saule, Kamer Kaya, andUmit V Catalyurek. Hardware&#x2F;software vectorizationfor closeness centrality on multi-&#x2F;many-corearchitectures. In International Parallel &amp; DistributedProcessing Symposium Workshops (IPDPSW), pages1386–1395. IEEE, 2014. GPU-多BFS实例 见上面[27] SC [35]Adam McLaughlin and David A Bader. Scalable andhigh performance betweenness centrality on the gpu.In International Conference for High PerformanceComputing, Networking, Storage and Analysis (SC),pages 572–583. IEEE, 2014 一些字母含义和取值 ideaexample中状态数组SA的图示说明 典型的BFS observation on shared frontiers 1 JOINT TRAVERSAL 和MSBFS类似+GPU设计 data structure generate JFQ implementation of JFQ example 2 GROUPBY 这个好（将BFS分组以最大化组内BFS的frontiers share）原理结论 结论的详细得出过程 speedup指相对于串行、分离地执行这个group中的BFS而言的加速比（串行时间&#x2F;此方案时间） idea规则对于两个BFS实例而言 q的选择： 规则应用方法 N be default &#x3D; 128 效果： 规则的直观解释： 3 GPU-BASED BITWISE OPERATIONS 和MSBFS类似+GPU设计idea数据结构 实现： expansion inspection Early Termination：This newly freed-up thread will then be scheduled to work on other frontiers. frontier generation","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2012PPoPP Scalable GPU Graph Traversal","slug":"论文笔记 2012PPoPP Scalable GPU Graph Traversal","date":"2022-09-10T09:58:42.602Z","updated":"2022-12-10T14:43:59.639Z","comments":true,"path":"2022/09/10/论文笔记 2012PPoPP Scalable GPU Graph Traversal/","link":"","permalink":"http://example.com/2022/09/10/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202012PPoPP%20Scalable%20GPU%20Graph%20Traversal/","excerpt":"","text":"details: High-Performance and Scalable GPU Graph Traversal我读的这篇详细的 BFS approach componentsContract-Expand Two-Phase gatheringCoarse-Grained, Warp-Based Gathering Fine-Grained, Scan-Based Gathering Scan+Warp+CTA Gathering 举例 filter(过滤已经visited的、vertex_frontier-&gt;edge_frontier)bitmask Warp Culling History Culling code Duane Merrill. 2011. Back40 computing: Fast and efficient software primitives for GPU computing.http://code.google.com/p/back40computing/这个现在被合并到 https://nvlabs.github.io/cub/","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"CUDA编程模型","slug":"CUDA编程模型","date":"2022-09-09T08:17:04.729Z","updated":"2022-12-10T14:45:20.431Z","comments":true,"path":"2022/09/09/CUDA编程模型/","link":"","permalink":"http://example.com/2022/09/09/CUDA%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model overall thread hierarchy：将问题划分为线程块block Thread blocks are required to execute independently: It must be possible to execute them in any order, in parallel or in series. Threads within a block can cooperate by sharing data through some shared memory and by synchronizing their execution to coordinate memory accesses. thread num within one block: all threads of a block are expected to reside on the same processor core and must share the limited memory resources of that core. On current GPUs, a thread block may contain up to 1024 threads. 16x16 (256 threads) is a common choice. cooperate: one can specify synchronization points in the kernel by calling the __syncthreads() intrinsic function; __syncthreads() acts as a barrier at which all threads in the block must wait before any is allowed to proceed. Shared Memory gives an example of using shared memory. In addition to __syncthreads(), the Cooperative Groups API provides a rich set of thread-synchronization primitives. For efficient cooperation, the shared memory is expected to be a low-latency memory near each processor core (much like an L1 cache) and __syncthreads() is expected to be lightweight. 下图：编程模型到硬件的映射 一个SM是一个multiprocessor，类似于一个处理器 block间并行独立因此： a compiled CUDA program can execute on any number of multiprocessors, and only the runtime system needs to know the physical multiprocessor count. program modelKernelsdefintion and call C++ functions defined using the __global__ declaration specifier calling with &lt;&lt;griddim, blockdim&gt;&gt; xxdim can be of type int or dim3 griddim: how the blocks are arranged&#x2F;indexed blockdim: how the threads in a block are arranged&#x2F;indexed elaboration and egs see [Thread Hierarchy](# Thread Hierarchy) when called, are executed N times in parallel by N different CUDA threads (N defined by &lt;&lt;griddim, blockdim&gt;&gt;). Each thread that executes the kernel is given a unique thread ID that is accessible within the kernel through built-in variables. “N defined by &lt;&lt;griddim, blockdim&gt;&gt;“ so a kernel can be executed by multiple equally-shaped thread blocks simple eg adds two vectors A and B of size N and stores the result into vector C: // Kernel definition __global__ void VecAdd(float* A, float* B, float* C) &#123; int i = threadIdx.x; C[i] = A[i] + B[i]; &#125; int main() &#123; ... // Kernel invocation with N threads VecAdd&lt;&lt;&lt;1, N&gt;&gt;&gt;(A, B, C); ... &#125; Thread Hierarchyindex built-in variable threadIdx is a 3-component vector, so that threads can be identified using a one-dimensional, two-dimensional, or three-dimensional thread index, forming a one-dimensional, two-dimensional, or three-dimensional block of threads（指的是 一个block内线程的编排，是block内的相对位置） threadIdx and thread ID： For a one-dimensional block, they are the same for a two-dimensional block of size *(Dx, Dy)*（size: in terms of thread num）, the thread ID of a thread of index (x, y) is (x + y Dx) for a three-dimensional block of size (Dx, Dy, Dz), the thread ID of a thread of index (x, y, z) is (x + y Dx + z Dx Dy). 一个问题的所有block的编排也采用类似的方式，built-in variable blockIdx 定位thread：blockIdx+blockDim定位哪个block，然后在block中threadIdx+threadDim定位哪个thread eg: structure-in-blockadds two matrices A and B of size NxN and stores the result into matrix C: // Kernel definition __global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]) &#123; int i = threadIdx.x; int j = threadIdx.y; C[i][j] = A[i][j] + B[i][j]; &#125; int main() &#123; ... // Kernel invocation with one block of N * N * 1 threads int numBlocks = 1; dim3 threadsPerBlock(N, N); MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ... &#125; eg: both-structure-in-block-and-gridblocks are arranged in 2-dimention threads in a block are arranged in 2-dimention // Kernel definition __global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]) &#123; int i = blockIdx.x * blockDim.x + threadIdx.x; int j = blockIdx.y * blockDim.y + threadIdx.y; if (i &lt; N &amp;&amp; j &lt; N) C[i][j] = A[i][j] + B[i][j]; &#125; int main() &#123; ... // Kernel invocation dim3 threadsPerBlock(16, 16); dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y); // For simplicity, this example assumes that the number of threads per grid in each dimension is evenly divisible by the number of threads per block in that dimension MatAdd&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(A, B, C); ... &#125; Memory HierarchyCUDA threads may access data from multiple memory spaces during their execution. Each thread has private local memory. Each thread block has shared memory visible to all threads of the block and with the same lifetime as the block. All threads have access to the same global memory. There are also two additional read-only memory spaces accessible by all threads: the constant and texture memory spaces. The global, constant, and texture memory spaces are optimized for different memory usages (see Device Memory Accesses). The global, constant, and texture memory spaces are persistent across kernel launches by the same application. by me: 这样的memory层次划分是和硬件对应的 Heterogeneous Programming the CUDA programming model assumes that the CUDA threads execute on a physically separate device that operates as a coprocessor to the host running the C++ program. This is the case, for example, when the kernels execute on a GPU and the rest of the C++ program executes on a CPU. The CUDA programming model also assumes that both the host and the device maintain their own separate memory spaces in DRAM, referred to as host memory and device memory, respectively. Therefore, a program manages the global, constant, and texture memory spaces visible to kernels through calls to the CUDA runtime (described in Programming Interface). This includes device memory allocation and deallocation as well as data transfer between host and device memory. Unified Memory provides managed memory to bridge the host and device memory spaces. Managed memory is accessible from all CPUs and GPUs in the system as a single, coherent memory image with a common address space. This capability enables oversubscription of device memory and can greatly simplify the task of porting applications by eliminating the need to explicitly mirror data on host and device. See Unified Memory Programming for an introduction to Unified Memory.","categories":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/categories/GPU/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"}],"author":"zhiqiuyuan"},{"title":"GPU入门","slug":"GPU入门","date":"2022-09-06T09:26:37.248Z","updated":"2022-12-10T14:45:30.961Z","comments":true,"path":"2022/09/06/GPU入门/","link":"","permalink":"http://example.com/2022/09/06/GPU%E5%85%A5%E9%97%A8/","excerpt":"","text":"学习自：https://qiankunli.github.io/2021/08/18/gpu.htmlNVIDA官方手册：https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#abstract 整体感知 GPU 的整个处理过程是一个流式处理（Stream Processing）的过程，分支条件少（少用控制语句） 每个GPU核心（是个电路） 只有 取指令、指令译码、ALU 以及执行这些计算需要的寄存器和缓存 现代 CPU 里的晶体管变得越来越多，越来越复杂，其实已经不是用来实现“计算”这个核心功能，而是拿来实现处理乱序执行、进行分支预测，以及高速缓存部分。GPU把这些部分去除了the GPU can hide memory access latencies with computation, instead of relying on large data caches and complex flow control to avoid long memory access latencies, both of which are expensive in terms of transistors. 一个 GPU ：多个这样并行的 GPU 电路 内存访问（分离式架构）：（gpu作为外设可以访问cpu内存，但）cpu 和gpu 最擅长访问自己的内存 GPU 硬件架构 每个 GPU 都由一组 SM（流式多处理器Streaming Multiprocessor，核心Core） 构成； 线程调度器（Warp Scheduler）：线程束（Warp）是最基本的单元，每个线程束中包含 32 个并行的线程，它们使用不同的数据执行相同的命令，调度器会负责这些线程的调度； 访问存储单元（Load&#x2F;Store Queues）：在核心和内存之间快速传输数据； 特殊函数的计算单元（Special Functions Unit、SPU） 存储和缓存数据的寄存器文件（Register File） 共享内存（Shared Memory） 执行速度CUDA 核心在每个时钟周期都可以准确的执行一次整数或者浮点数的运算 CPU 与GPU 协作（分离式） 分离式： GPU 是一个外设，有驱动程序 MMIO: Memory-Mapped I&#x2F;O锁页：操作系统常用的操作，可以使硬件外设直接访问物理内存。”被锁定“的页面被os标记为不可被os 换出 驱动程序提供的接口： 一般的外设：输出数据地址 command_operation(输入数据地址) 这个意思是类似于函数申明：cpu控制向输入数据地址写数据，调用接口，等中断，然后从输出数据地址读数据 gpu：输出数据地址 command_operation(指令序列,输入数据地址) 典型工作流程: 应用层（cpu上执行）调用某个会调用GPU的API，如 OpenGL 或 CUDA OpenGL 或 CUDA 库，通过 UMD (User Mode Driver)，提交 workload 到 KMD (Kernel Mode Driver) Kernel Mode Driver 写 CSR MMIO，把它提交给 GPU 硬件 GPU 硬件开始工作… 完成后，DMA 到内存，发出中断给 CPU CPU 找到中断处理程序 —— Kernel Mode Driver 此前向 OS Kernel 注册过的 —— 调用它 中断处理程序找到是哪个 workload 被执行完毕了，…最终驱动唤醒相关的应用 CUDA(一种GPU驱动程序)编程 https://zhuanlan.zhihu.com/p/34587739nvida官方手册：https://developer.nvidia.com/zh-cn/blog/cuda-intro-cn/ 编程模型这些抽象提供了细粒度的数据并行和线程并行，嵌套在粗粒度的数据并行和任务并行中。它们指导程序员将问题划分为可以由++线程块++并行独立解决的粗略子问题，并将每个子问题划分为可以由++块内所有线程++并行协作解决的更精细的部分。 一个问题（grid）划分为多个线程块（block或者warp；gridDim个），线程块之间独立执行； 每个线程块有多个thread（blockDim个），每个线程块对应一个deviceFunction（kernel） 编程模型和硬件的关系 A cooperative thread array (or CTA) is a group of threads that will be co-located on the same multiprocessor（即比如此图中到同一个SM上的所有block的所有thread，它们属于一个CTA）each block of threads can be scheduled on any of the available multiprocessors within a GPU, in any order（指block之间的顺序？）, concurrently or sequentially, so that a compiled CUDA program can execute on any number of multiprocessors, and only the runtime system needs to know the physical multiprocessor count. 概念 在CUDA中：host指代CPU及其内存，而用device指代GPU及其内存 三类函数：函数类型 谁执行 谁调用global 设备端执行 可以从主机调用也可以从某些特定设备调用device 设备端执行 设备端调用 host 主机端执行 主机调用 device 函数和global函数因为需要在GPU上运行，因此不能调用常见的一些 C&#x2F;C++ 函数（因为这些函数没有对应的 GPU 实现） 典型的CUDA程序的执行流程如下：分配host内存，并进行数据初始化；分配device内存，并从host将数据拷贝到device上；调用CUDA的核函数在device上完成指定的运算；将device上的运算结果拷贝到host上；释放device和host上分配的内存。 编程举例一维数组加法x+y-&gt;z // __global__ 表示在device上执行，从host中调用 // 两个向量加法kernel，grid和block均为一维 // 每个thread的任务是“跨步”对位加法 __global__ void add(float* x, float * y, float* z, int n)&#123; // 获取全局索引：这个thread的indx，这是第几个thread int index = threadIdx.x + blockIdx.x * blockDim.x; // 步长：共有这么多thread int stride = blockDim.x * gridDim.x; for (int i = index; i &lt; n; i += stride)&#123; z[i] = x[i] + y[i]; &#125; &#125; int main()&#123; int N = 1 &lt;&lt; 20; int nBytes = N * sizeof(float); // 申请host内存 float *x, *y, *z; x = (float*)malloc(nBytes); y = (float*)malloc(nBytes); z = (float*)malloc(nBytes); // 初始化数据 for (int i = 0; i &lt; N; ++i)&#123; x[i] = 10.0; y[i] = 20.0; &#125; // 申请device内存 float *d_x, *d_y, *d_z; cudaMalloc((void**)&amp;d_x, nBytes); cudaMalloc((void**)&amp;d_y, nBytes); cudaMalloc((void**)&amp;d_z, nBytes); // 将host数据拷贝到device cudaMemcpy((void*)d_x, (void*)x, nBytes, cudaMemcpyHostToDevice); cudaMemcpy((void*)d_y, (void*)y, nBytes, cudaMemcpyHostToDevice); // 定义kernel的执行配置 dim3 blockSize(256); dim3 gridSize((N + blockSize.x - 1) / blockSize.x); // 执行kernel add &lt;&lt; &lt; gridSize, blockSize &gt;&gt; &gt;(d_x, d_y, d_z, N); // 将device得到的结果拷贝到host cudaMemcpy((void*)z, (void*)d_z, nBytes, cudaMemcpyDeviceToHost); // 检查执行结果 float maxError = 0.0; for (int i = 0; i &lt; N; i++) maxError = fmax(maxError, fabs(z[i] - 30.0)); std::cout &lt;&lt; &quot;最大误差: &quot; &lt;&lt; maxError &lt;&lt; std::endl; // 释放device内存 cudaFree(d_x); cudaFree(d_y); cudaFree(d_z); // 释放host内存 free(x); free(y); free(z); return 0; &#125;","categories":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/categories/GPU/"}],"tags":[{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"}],"author":"zhiqiuyuan"},{"title":"rockdb leveldb handbook链接","slug":"rockdb leveldb handbook链接","date":"2022-09-04T03:04:12.326Z","updated":"2022-12-10T14:47:04.623Z","comments":true,"path":"2022/09/04/rockdb leveldb handbook链接/","link":"","permalink":"http://example.com/2022/09/04/rockdb%20leveldb%20handbook%E9%93%BE%E6%8E%A5/","excerpt":"","text":"leveldb: https://leveldb-handbook.readthedocs.io/zh/latest/basic.htmlrocksdb: https://www.bookstack.cn/read/rocksdb-6.14-en/79f0ebf380de6ff5.md","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"}],"author":"zhiqiuyuan"},{"title":"leveldb SSTable sst文件 sst解析工具","slug":"leveldb SSTable sst文件 sst解析工具","date":"2022-09-04T02:45:23.278Z","updated":"2022-12-10T14:47:27.567Z","comments":true,"path":"2022/09/04/leveldb SSTable sst文件 sst解析工具/","link":"","permalink":"http://example.com/2022/09/04/leveldb%20SSTable%20sst%E6%96%87%E4%BB%B6%20sst%E8%A7%A3%E6%9E%90%E5%B7%A5%E5%85%B7/","excerpt":"","text":"https://leveldb-handbook.readthedocs.io/zh/latest/sstable.html SStable文件格式物理结构 一个sstable文件按照固定大小进行块划分，默认每个块的大小为4KiB。 每个Block中，除了存储数据以外，还会存储两个额外的辅助字段： 压缩类型：说明了Block中存储的数据是否进行了数据压缩，若是，采用了哪种算法进行压缩。leveldb中默认采用Snappy算法进行压缩。 CRC校验码：校验范围包括数据以及压缩类型。 逻辑结构将一个sstable分为： data block: 用来存储key value数据对； filter block: 用来存储一些过滤器相关的数据（布隆过滤器），但是若用户不指定leveldb使用过滤器，leveldb在该block中不会存储任何内容； meta Index block: 用来存储filter block的索引信息（索引信息指在该sstable文件中的偏移量以及数据长度）； index block：index block中用来存储每个data block的索引信息； footer: 用来存储meta index block及index block的索引信息； 注意，1-4类型的区块，其物理结构都是如1.1节所示，每个区块都会有自己的压缩信息以及CRC校验码信息。 data block结构一个data block中的数据部分（不包括压缩类型、CRC校验码）按逻辑以下图进行划分： entry存储keyvalue数据key 由于sstable中所有的keyvalue对都是严格按序存储的，为了节省存储空间，leveldb并不会为每一对keyvalue对都存储完整的key值，而是存储与上一个key非共享的部分，避免了key重复内容的存储。 每间隔若干个keyvalue对，将为该条记录重新存储一个完整的key。重复该过程（默认间隔值为16），每个重新存储完整key的点称之为Restart point。 加速查找：由于每个Restart point存储的都是完整的key值，因此在sstable中进行数据查找时，可以首先利用restart point点的数据进行键值比较，以便于快速定位目标数据所在的区域；当确定目标数据所在区域时，再依次对区间内所有数据项逐项比较key值，进行细粒度地查找； entry格式每个entry的格式如下图所示： 与前一条记录key共享部分的长度； 与前一条记录key不共享部分的长度； value长度； 与前一条记录key非共享的内容； value内容； 举例restart_interval&#x3D;2entry one : key&#x3D;deck,value&#x3D;v1entry two : key&#x3D;dock,value&#x3D;v2entry three: key&#x3D;duck,value&#x3D;v3 三组entry按上图的格式进行存储。值得注意的是restart_interval为2，因此每隔两个entry都会有一条数据作为restart point点的数据项，存储完整key值。因此entry3存储了完整的key。 此外，第一个restart point为0（偏移量），第二个restart point为16，restart point共有两个，因此一个datablock数据段的末尾添加了下图所示的数据： 尾部数据记录了每一个restart point的值，以及所有restart point的个数。 SST dump tool编译sst_dump 参考https://shashangka.com/2020/06/26/rocksdb-administration-and-data-access-tool/ 在rocksdb源码顶层目录下 # generate cmake cache mkdir build cd build cmake .. 然后回到rocksdb源码顶层目录下 # config cmake and build cmake --build ./build --config Debug --target sst_dump # --build: specify where cmake cache locates 得到sst_dump在&lt;--build指定的目录&gt;/tools下 使用https://github.com/facebook/rocksdb/wiki/Administration-and-Data-Access-Tool Printing entries in SST file./sst_dump --file=/path/to/sst/000829.sst --command=scan --read_num=5 This command will print the first 5 keys in the SST file to the screen. the output may look like this &#39;Key1&#39; @ 5: 1 =&gt; Value1 &#39;Key2&#39; @ 2: 1 =&gt; Value2 &#39;Key3&#39; @ 4: 1 =&gt; Value3 &#39;Key4&#39; @ 3: 1 =&gt; Value4 &#39;Key5&#39; @ 1: 1 =&gt; Value5 The output can be interpreted like this &#39;&lt;key&gt;&#39; @ &lt;sequence number&gt;: &lt;type&gt; =&gt; &lt;value&gt; Please notice that if your key has non-ascii characters, it will be hard to print it on screen, in this case it’s a good idea to use --output_hex like this ./sst_dump --file=/path/to/sst/000829.sst --command=scan --read_num=5 --output_hex You can also specify where do you want to start reading from and where do you want to stop by using --from and --to like this ./sst_dump --file=/path/to/sst/000829.sst --command=scan --from=&quot;key2&quot; --to=&quot;key4&quot; You can pass --from and --to using hexadecimal as well by using --input_key_hex ./sst_dump --file=/path/to/sst/000829.sst --command=scan --from=&quot;0x6B657932&quot; --to=&quot;0x6B657934&quot; --input_key_hex C","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"}],"author":"zhiqiuyuan"},{"title":"跳跃列表","slug":"跳跃列表","date":"2022-09-04T01:44:28.314Z","updated":"2022-12-10T14:49:07.287Z","comments":true,"path":"2022/09/04/跳跃列表/","link":"","permalink":"http://example.com/2022/09/04/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8/","excerpt":"","text":"https://zh.wikipedia.org/wiki/%E8%B7%B3%E8%B7%83%E5%88%97%E8%A1%A8 概述 使得包含n个元素的有序序列的查找和插入操作的平均时间复杂度都是O(log n)，优于数组的O(n)复杂度 一个多层次的链表。与前一层（下面一层）链表元素的数量相比，每一层链表中的元素的数量更少。每一层是有序的 构造跳跃列表是按层建造的。底层是一个普通的有序链表。每个更高层都充当下面列表的“快速通道”，在第i层（下面的层）中的每个元素按某个固定的概率p（通常为1/2或1/4）出现在第i+1层（上面的层）中，直到当前层元素个数为1 每个元素平均出现在1/1-p个列表中，而最高层的元素（通常是在跳跃列表前端的一个特殊的头元素）在log&#123;1/p&#125;n个列表中出现。 查找在查找目标元素时，从顶层列表、头元素起步。算法沿着每层链表搜索，直至找到一个大于或等于目标的元素，或者到达当前层列表末尾。如果该元素等于目标元素，则表明该元素已被找到；如果该元素大于目标元素或已到达链表末尾，则退回到当前层的上一个元素，然后转入下一层进行搜索。举例见插入 每层链表中预期的查找步数最多为1/p，而层数为log&#123;1/p&#125;n，所以查找的总体步数为log&#123;p&#125;n/p，由于p是常数，查找操作总体的时间复杂度为O(logn)。而通过选择不同p值，就可以在查找代价和存储代价之间获取平衡。 插入和查找类似插入80 80&lt;&#x3D;30? 80&lt;&#x3D;30?no 80&lt;&#x3D;50? 80&lt;&#x3D;50?no 走到nil所以向下走80&lt;&#x3D;70? 80&lt;&#x3D;70?no 80&lt;&#x3D;90? 80&lt;&#x3D;90?yes, insert","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"leveldb底层概述和Files","slug":"leveldb底层概述和Files","date":"2022-09-04T01:16:33.962Z","updated":"2022-12-10T14:50:20.335Z","comments":true,"path":"2022/09/04/leveldb底层概述和Files/","link":"","permalink":"http://example.com/2022/09/04/leveldb%E5%BA%95%E5%B1%82%E6%A6%82%E8%BF%B0%E5%92%8CFiles/","excerpt":"","text":"https://leveldb-handbook.readthedocs.io/zh/latest/basic.htmlhttps://github.com/google/leveldb/blob/main/doc/impl.md leveldb架构 leveldb写流程概述 将所有的写操作写到日志文件（log文件）中 将内容写入到内存中 先memtable，等到其存储内容的容量达到阈值时（默认为4MB），便将其转换成一个不可修改的memtable，与此同时创建一个新的memtable，供用户继续进行读写操作。 当一个immutable memtable被创建时，leveldb的后台压缩进程便会将利用其中的内容，创建一个sstable，持久化到磁盘文件中。 memtable 其中数据按用户定义的排序方法排序之后按序存储 跳表实现，这种数据结构绝大多数操作的时间复杂度为O(log n) immutable memtable和memtable的结构定义完全一样 写入磁盘 compaction 虽然每个memetable中所有的数据都是按序排列的，但是当多个memetable数据持久化到磁盘后，对应的不同的sstable之间是存在交集的（比如两个table中都出现了某条kv pair），在读操作时，需要对所有的sstable文件进行遍历，严重影响了读取效率。因此leveldb后台会“定期“整合这些sstable文件，该过程也称为compaction。 随着compaction的进行，sstable文件在逻辑上被分成若干层，由内存数据直接dump出来的文件称为level 0层文件，后期整合而成的文件为level i 层文件 manifest版本版本定义 一个版本中主要记录了 每一层中所有文件的元数据，元数据包括（1）文件大小（2）最大key值（3）最小key值。 一些进行compaction的统计值，来控制compaction的进行 元数据结构举例（goleveldb，类型在名后面）// tFile holds basic information about a table. type tFile struct &#123; fd storage.FileDesc seekLeft int32 size int64 imin, imax internalKey &#125; 版本结构举例type version struct &#123; s *session // session - version levels []tFiles // file meta 每层文件的元数据 // 压缩信息 // Level that should be compacted next and its compaction score. // Score &lt; 1 means compaction is not strictly needed. These fields // are initialized by computeCompaction() cLevel int // next level cScore float64 // current score cSeek unsafe.Pointer closing bool ref int released bool &#125; 创建版本当每次compaction完成（或者换一种更容易理解的说法，当每次sstable文件有新增或者减少），leveldb都会创建一个新的version manifest文件记录版本更新(versionEdit) 每次leveldb启动时，都会创建一个新的Manifest文件 下图是一个manifest文件的示意图，其中包含了3条versionEdit记录，每条记录包括（1）新增哪些sst文件（2）删除哪些sst文件（3）当前compaction的下标（4）日志文件编号（5）操作seqNumber等信息。 通过这些信息，leveldb便可以在启动时，基于一个空的version，不断apply这些记录，最终得到一个上次运行结束时的版本信息。 current记载当前的manifest文件名 *.loglog files(WAL) LOG and LOG.oldInformational messages are printed to files named LOG and LOG.old","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"}],"author":"zhiqiuyuan"},{"title":"NebulaGraph存储","slug":"NebulaGraph存储","date":"2022-09-03T02:17:55.202Z","updated":"2022-12-10T14:50:50.396Z","comments":true,"path":"2022/09/03/NebulaGraph存储/","link":"","permalink":"http://example.com/2022/09/03/NebulaGraph%E5%AD%98%E5%82%A8/","excerpt":"","text":"架构 架构总览 - Nebula Graph Database 手册 (nebula-graph.com.cn) Meta 服务是由 nebula-metad 进程提供的，负责数据管理，例如 Schema 操作、集群管理和用户权限管理等。 所有 nebula-metad 进程构成了基于 Raft 协议的集群，其中一个进程是 leader，其他进程都是 follower。leader 是由多数派选举出来，只有 leader 能够对客户端或其他组件提供服务，其他 follower 作为候补，如果 leader 出现故障，会在所有 follower 中选举出新的 leader Graph 服务负责处理计算请求，由 nebula-graphd 进程提供。 Storage 服务负责存储数据，由 nebula-storaged 进程提供。 Storage 服务 Storage 服务 - Nebula Graph Database 手册 (nebula-graph.com.cn) Nebula Graph 使用 RocksDB 作为本地存储引擎，实现了自己的 KVStore Storage 写入流程 数据存储格式KV存储 key：点和边的信息 value：点和边的属性信息，将属性信息编码后按顺序存储 为了支持在线变更 Schema，在编码属性时，会加入对应的 Schema 版本信息 点 字段 说明 Type key 类型。长度为 1 字节。 PartID 数据分片编号。长度为 3 字节。此字段主要用于 Storage 负载均衡（balance）时方便根据前缀扫描整个分片的数据。 VertexID 点 ID。当点 ID 类型为 int 时，长度为 8 字节；当点 ID 类型为 string 时，长度为创建图空间时指定的fixed_string长度。 TagID 点关联的 Tag ID。长度为 4 字节。 SerializedValue 序列化的 value，用于保存点的属性信息。 边 字段 说明 Type key 类型。长度为 1 字节。 PartID 数据分片编号。长度为 3 字节。此字段主要用于 Storage 负载均衡（balance）时方便根据前缀扫描整个分片的数据。 VertexID 点 ID。前一个VertexID在出边里表示起始点 ID，在入边里表示目的点 ID；后一个VertexID出边里表示目的点 ID，在入边里表示起始点 ID。 Edge type 边的类型。大于 0 表示出边，小于 0 表示入边。长度为 4 字节。 Rank 用来处理两点之间有多个同类型边的情况。用户可以根据自己的需求进行设置，例如存放交易时间、交易流水号等。长度为 8 字节， PlaceHolder 预留字段。长度为 1 字节。 SerializedValue 序列化的 value，用于保存边的属性信息。 获取属性 由于属性的长度是固定的，查询时可以根据偏移量快速查询。在解码之前，需要先从 Meta 服务中查询具体的 Schema 信息（并缓存） 切边逻辑上的一条边对应着硬盘上的两个键值对： 起点 SrcVertex 通过边 EdgeA 连接目的点 DstVertex，形成路径(SrcVertex)-[EdgeA]-&gt;(DstVertex)，这两个点和一条边会以 6 个键值对（2(src)+2(dst)+2(edge)）的形式保存在存储层的两个不同分片，即 Partition x 和 Partition y 中 服务架构 Store Engine 层 Storage 服务的最底层，是一个单机版本地存储引擎，提供对本地数据的get、put、scan等操作。相关接口存储在KVStore.h和KVEngine.h文件 数据分片 数据量过大，单机存不下 -&gt; 将图元素切割，并存储在不同逻辑分片（Partition）上 分片 ID 和机器地址之间的映射是随机的，不能假定任何两个分片位于同一台机器上 分片算法 静态 Hash：对点 VID 进行取模操作（得到分片ID：pId = vid % numParts + 1），同一个点的所有 Tag、出边和入边信息都会存储到同一个分片 Raft What is Raft used for？ 分布式系统中，同一份数据通常会有多个副本，这样即使少数副本发生故障，系统仍可正常运行。这就需要一定的技术手段来保证多个副本之间的一致性。通过 保证集群所有节点 log 一致性 来保证。 每个分片的所有副本共同组成一个 Raft group，其中一个副本是 leader，其他副本是 follower 缓存Nebula Graph 自行实现了 Storage 缓存管理指 内存 中缓存外存的内容","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"db","slug":"graph/db","permalink":"http://example.com/categories/graph/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"Raft","slug":"Raft","date":"2022-09-03T02:17:27.443Z","updated":"2022-12-10T14:53:12.586Z","comments":true,"path":"2022/09/03/Raft/","link":"","permalink":"http://example.com/2022/09/03/Raft/","excerpt":"","text":"https://docs.nebula-graph.com.cn/3.2.0/1.introduction/3.nebula-graph-architecture/4.storage-service/#raft https://cloud.tencent.com/developer/article/1826594 简介 分布式系统中，同一份数据通常会有多个副本，这样即使少数副本发生故障，系统仍可正常运行。这就需要一定的技术手段来保证多个副本之间的一致性。 通过 保证集群所有节点log一致性 来保证 log一致性保证了即可保证多个副本之间的数据一致性 基本原理 赢得”超过半数”副本投票的（候选）副本成为 Leader，由 Leader 代表所有副本对外提供服务；其他 Follower 作为备份。 当该 Leader 出现异常后（通信故障、运维命令等），其余 Follower 进行新一轮选举，投票出一个新的 Leader。 Leader 和 Follower 之间通过心跳的方式相互探测是否存活，并以 Raft-wal 的方式写入硬盘，超过多个心跳仍无响应的副本会被认为发生故障。并以 Raft-wal 的方式写入硬盘 啥意思？写入探测结果？ 读写流程 对于客户端的每个写入请求，Leader 会将该写入以 Raft-wal 的方式，将该条同步给其他 Follower，并只有在“超过半数”副本都成功收到 Raft-wal 后，才会返回客户端该写入成功（即日志复制：所有 log 都必须交给 leader 节点处理，并由 leader 复制给其他节点）。 对于客户端的每个读取请求，都直接访问 Leader，而 Follower 并不参与读请求服务。","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"},{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"WAL Write Ahead Log预写日志","slug":"WAL Write Ahead Log预写日志","date":"2022-09-03T01:31:41.414Z","updated":"2022-12-10T14:53:44.033Z","comments":true,"path":"2022/09/03/WAL Write Ahead Log预写日志/","link":"","permalink":"http://example.com/2022/09/03/WAL%20Write%20Ahead%20Log%E9%A2%84%E5%86%99%E6%97%A5%E5%BF%97/","excerpt":"","text":"https://www.cnblogs.com/xuwc/p/14037750.html 在使用 WAL 的系统中，**所有的修改在提交之前都要先写入 log 文件中(写入log文件是写入永久存储)**。log 文件中通常包括 redo 和 undo 信息 使用 WAL 的数据库系统不会再每新增一条 WAL 日志就将其刷入数据库文件中，一般**积累一定的量然后批量写入(checkpoint)**，通常使用「页」为单位，这是磁盘的写入单位 一方面 WAL 中记录事务的更新内容，通过 WAL 将随机的脏页写入变成顺序的日志刷盘 另一方面，WAL 通过 buffer 的方式改单条磁盘刷入为缓冲批量刷盘 再者从 WAL 数据到最终数据的同步过程中可以采用并发同步的方式 这样极大提升数据库写入性能，因此，WAL 的写入能力决定了数据库整体性能的上限，尤其是在高并发时","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"powershell美化 powershell字体 powershell颜色","slug":"powershell美化字体颜色","date":"2022-09-02T07:09:19.755Z","updated":"2022-12-10T14:53:54.945Z","comments":true,"path":"2022/09/02/powershell美化字体颜色/","link":"","permalink":"http://example.com/2022/09/02/powershell%E7%BE%8E%E5%8C%96%E5%AD%97%E4%BD%93%E9%A2%9C%E8%89%B2/","excerpt":"","text":"设置颜色 安装colortoolscoop install colortool 预览主题 列出哪些主题 colortool -s 预览主题，比如OneHalfDark.itermcolors colortool OneHalfDark.itermcolors 设置主题（将方案同时应用于当前控制台和默认控制台）colortool -b OneHalfDark.itermcolors 附：colortool 的相关命令-c --current：打印当前应用方案的颜色表 -q --quiet：使用后不要打印颜色表 -e --errors：在控制台上报告方案分析错误 -d --defaults：仅将方案应用于注册表中的默认值 -b --both：将方案同时应用于当前控制台和默认控制台。 -x --xterm：使用VT序列设置颜色。用于设置WSL中的颜色。仅适用于Windows版本&gt;=17048。 -s --schemes：显示所有可用的方案 -l --location：显示schemes目录的完整路径 -v --version：显示版本号 -o --output&lt;filename&gt;：将当前颜色表输出到文件（以.ini格式） 设置字体 下载字体（https://blog.csdn.net/Z_YMing/article/details/103082807有`yahe mona&#96;字体下载连接） 安装字体 解压缩，右键ttf文件选择安装 修改注册表 powershell右键-属性-字体","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"graph schema","slug":"graph schema","date":"2022-09-02T02:34:14.281Z","updated":"2022-12-10T14:54:56.397Z","comments":true,"path":"2022/09/02/graph schema/","link":"","permalink":"http://example.com/2022/09/02/graph%20schema/","excerpt":"","text":"https://docs.tigergraph.com/gsql-ref/current/tutorials/gsql-101/ Every graph has a schema, or a model describing the types of vertices and edges that appear in a graph.（描述图中有哪些类型的点边，每种类型有哪些属性，以及点边类型之间有哪些关系） a graph showing a group of friends and when each of them met schema： the Friendship edge answers the question, “What type of entity is connected by friendship?” graph：","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"linux启动docker服务","slug":"linux启动docker服务","date":"2022-09-01T12:49:03.848Z","updated":"2022-12-10T14:55:08.817Z","comments":true,"path":"2022/09/01/linux启动docker服务/","link":"","permalink":"http://example.com/2022/09/01/linux%E5%90%AF%E5%8A%A8docker%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"安装和启动这个写很好：Install Docker Engine on Ubuntu 在上述教程install之后docker run hello-word之前可能需要启动docker后台服务：sudo service docker starthow would you know that the service name was docker： You can see them using service --status-all docker原理To generate this message, Docker took the following steps: The Docker client contacted the Docker daemon. The Docker daemon pulled the “hello-world” image from the Docker Hub.(amd64) The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. 配置 linux-postinstall boot自启动：On Debian and Ubuntu, the Docker service is configured to start on boot by default. 配置非root docker run","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"bash获取命令退出代码","slug":"bash获取命令退出代码","date":"2022-09-01T06:39:40.106Z","updated":"2022-12-10T14:55:51.510Z","comments":true,"path":"2022/09/01/bash获取命令退出代码/","link":"","permalink":"http://example.com/2022/09/01/bash%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E9%80%80%E5%87%BA%E4%BB%A3%E7%A0%81/","excerpt":"","text":"echo $?即输出上一条执行命令的退出码另外if command; then fi也是对command的退出码进行判断，如果为0则条件成立","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash超时kill","slug":"bash超时kill","date":"2022-09-01T03:05:21.939Z","updated":"2022-12-10T14:56:46.027Z","comments":true,"path":"2022/09/01/bash超时kill/","link":"","permalink":"http://example.com/2022/09/01/bash%E8%B6%85%E6%97%B6kill/","excerpt":"","text":"timeout 3 sleep 30 当 sleep 执行 3 秒的时候就会终止 包裹程序未超时，timeout传递退出代码（--preserve-status）（亲测似乎不加此选项也会保护退出代码） timeout --preserve-status 1m ping -c 5 Nostromo.local echo $? # 如果timeout包裹的程序超时，则返回值为124，否则为未超时程序的返回代码","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash遍历数组","slug":"bash遍历数组","date":"2022-09-01T03:03:35.605Z","updated":"2022-12-10T14:56:35.727Z","comments":true,"path":"2022/09/01/bash遍历数组/","link":"","permalink":"http://example.com/2022/09/01/bash%E9%81%8D%E5%8E%86%E6%95%B0%E7%BB%84/","excerpt":"","text":"无下标控制，类似range-for array=(hello word) for element in $array do echo $element done","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash变量计数加一","slug":"bash变量计数加一","date":"2022-09-01T03:02:15.966Z","updated":"2022-12-10T14:56:25.514Z","comments":true,"path":"2022/09/01/bash变量计数加一/","link":"","permalink":"http://example.com/2022/09/01/bash%E5%8F%98%E9%87%8F%E8%AE%A1%E6%95%B0%E5%8A%A0%E4%B8%80/","excerpt":"","text":"i=1 # in loop body i=`expr $i + 1`","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash获取命令输出内容 一维或多维","slug":"bash获取命令输出内容 一维或多维","date":"2022-09-01T02:44:00.490Z","updated":"2022-12-10T14:57:19.481Z","comments":true,"path":"2022/09/01/bash获取命令输出内容 一维或多维/","link":"","permalink":"http://example.com/2022/09/01/bash%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E8%BE%93%E5%87%BA%E5%86%85%E5%AE%B9%20%E4%B8%80%E7%BB%B4%E6%88%96%E5%A4%9A%E7%BB%B4/","excerpt":"","text":"一维 line=`cat syntest.sh | wc -l` echo $line 多维：返回数组 fnames=`ls testcase/functional | grep .sy` for fname in $&#123;fnames[@]&#125; do echo $fname done","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"bash条件判断命令执行返回值","slug":"bash条件判断命令执行返回值","date":"2022-09-01T02:41:36.175Z","updated":"2022-12-10T14:57:35.187Z","comments":true,"path":"2022/09/01/bash条件判断命令执行返回值/","link":"","permalink":"http://example.com/2022/09/01/bash%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E8%BF%94%E5%9B%9E%E5%80%BC/","excerpt":"","text":"if diff test.sh syntest.sh &gt; tmpout; then # diff比较如果相同则返回0，则会if条件成立走上面的分支 echo &quot;same.&quot; else echo &quot;different.&quot; fi rm -rf tmpout","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"}],"author":"zhiqiuyuan"},{"title":"gcc生成32位x86和arm汇编并运行","slug":"gcc生成32位x86和arm汇编并运行","date":"2022-09-01T01:36:43.763Z","updated":"2022-12-10T14:58:35.438Z","comments":true,"path":"2022/09/01/gcc生成32位x86和arm汇编并运行/","link":"","permalink":"http://example.com/2022/09/01/gcc%E7%94%9F%E6%88%9032%E4%BD%8Dx86%E5%92%8Carm%E6%B1%87%E7%BC%96%E5%B9%B6%E8%BF%90%E8%A1%8C/","excerpt":"","text":"main.c测试内容 #include &lt;stdio.h&gt; int main() &#123; printf(&quot;hello\\n&quot;); return 0; &#125; ubuntu装环境sudo apt update sudo apt install build-essential sudo apt install gcc-multilib sudo apt install -y flex sudo apt install -y bison sudo apt install -y qemu sudo apt install -y qemu-system sudo apt install -y qemu-user sudo apt-get install gcc-arm-linux-gnueabi x86 32位生成汇编x86 ATT 32位main. c -&gt; x86_32.s gcc -O0 -o x86_32.s -S -masm=att -m32 -fno-exceptions -fno-asynchronous-unwind-tables -fno-builtin -fno-pie main.c 这个需要gcc−multilib正确装好（因为需要32位的lib） 运行生成可执行文件 32位 gcc -m32 x86_32.s -o x86_32 qemu运行 qemu-i386 ./x86_32 或者./x86_32，会隐式调用qemu arm 32位生成汇编arm-linux-gnueabi-gcc -o arm.s -S -O0 main.c -fno-asynchronous-unwind-tables 运行生成可执行文件 arm-linux-gnueabi-gcc arm.s -o arm -static qemu运行 qemu-arm ./arm 或者./arm，会隐式调用qemu","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"gcc","slug":"c/gcc","permalink":"http://example.com/categories/c/gcc/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 GraphChi_Large-Scale Graph Computation on Just a PC","slug":"论文笔记 GraphChi_Large Scale Graph Computation on Just a PC","date":"2022-08-31T11:29:24.796Z","updated":"2022-12-10T14:59:01.325Z","comments":true,"path":"2022/08/31/论文笔记 GraphChi_Large Scale Graph Computation on Just a PC/","link":"","permalink":"http://example.com/2022/08/31/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20GraphChi_Large%20Scale%20Graph%20Computation%20on%20Just%20a%20PC/","excerpt":"","text":"GraphChi: Large-Scale Graph Computation on Just a PC | USENIX2012 OSDI Parallel Sliding Windows (PSW) 关键：以interval为单元的BSP(Bulk-Synchronous Parallel)；设计存储layout，使得获取一个interval中所有顶点的邻居只需要 顺序 访问全图磁盘存储 一次 回忆阅读推荐：3.6 Analysis of the I&#x2F;O Costs PSW processing a interval1. load subgraph For each interval, we associate a shard, which stores all the edges that have destination in the interval. Edges are stored in the order of their source（看下图的shard1中的src列，顶点是in order的） Intervals are chosen to balance the number of edges in each shard 且interval的划分就是对顶点1-&gt;|V|这个长区间进行划分（从而在前面的interval中的顶点id小于后面的interval中的顶点id） requires only P sequential disk reads to process each interval 【问题】可是就按照邻接表（出邻居）随机存储所有顶点的邻居的话，想要获取一个顶点集合的所有出边和入边，对于磁盘的访问也是可以只要P sequential disk reads的呀？【解答】是的，但是邻接表是对于每个顶点获取一次邻居都需要P sequential disk reads，而这个方法是对于一个interval中所有顶点获取邻居只需要P sequential disk reads 2. Parallel Updates executes the user-defined update-function for each vertex( in this interval) in parallel vertices that have edges with both end-points in the same interval are flagged as critical, and are updated in sequential order 3. write back把subgraph中有更新的edge value写回，文章中没有提出新的idea，只是分析了一下写回对于磁盘的访问 例子 remark graph traversals or vertex queries are not efficient in the model, because loading the neighborhood of a single vertex requires scanning a complete memory-shard.","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"wsl WSL 拒绝访问 Access is denied","slug":"wsl WSL 拒绝访问 Access is denied","date":"2022-08-21T15:27:28.822Z","updated":"2022-12-10T14:59:11.699Z","comments":true,"path":"2022/08/21/wsl WSL 拒绝访问 Access is denied/","link":"","permalink":"http://example.com/2022/08/21/wsl%20WSL%20%E6%8B%92%E7%BB%9D%E8%AE%BF%E9%97%AE%20Access%20is%20denied/","excerpt":"","text":"计算机重新启动后，Windows 10 上新安装的 Ubuntu 子系统向我展示了Access is denied.Press any key to continue… 解决有关解决方案，请参阅 github 问题答案。https://github.com/microsoft/WSL/issues/4920#issuecomment-658808564 当 WSL 自动关闭并且您需要使用管理员权限重新启动它时，就会发生这种情况。以管理员身份打开 Powershell&#x2F;CMD 并运行wsl. WSL 将启动，您可以关闭窗口。现在可以正常使用 WSL。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"lsof 查看资源被进程占用情况","slug":"lsof 查看资源被进程占用情况","date":"2022-08-16T02:27:01.989Z","updated":"2022-12-10T15:01:03.177Z","comments":true,"path":"2022/08/16/lsof 查看资源被进程占用情况/","link":"","permalink":"http://example.com/2022/08/16/lsof%20%E6%9F%A5%E7%9C%8B%E8%B5%84%E6%BA%90%E8%A2%AB%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%E6%83%85%E5%86%B5/","excerpt":"","text":"打开文件的进程定位到打开的进程 lsof &lt;file&gt; $ lsof /opt/mysql/data/5690/mysql-error.log COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME mysqld 12858 actiontech-universe 1w REG 253,1 6345 20083533 /opt/mysql/data/5690/mysql-error.log mysqld 12858 actiontech-universe 2w REG 253,1 6345 20083533 /opt/mysql/data/5690/mysql-error.log 端口占用lsof 查看端口占用语法格式： lsof -i lsof -i:端口号 查看服务器 8000 端口的占用情况： $ lsof -i:8000 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nodejs 26993 root 10u IPv4 37999514 0t0 TCP *:8000 (LISTEN) 可以看到 8000 端口已经被轻 nodejs 服务占用。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"cmake","slug":"cmake","date":"2022-08-16T02:23:54.603Z","updated":"2022-12-10T15:01:14.482Z","comments":true,"path":"2022/08/16/cmake/","link":"","permalink":"http://example.com/2022/08/16/cmake/","excerpt":"","text":"cmake https://www.jianshu.com/p/cdd6e56c2422 指定编译标准CXX标准set(CMAKE_CXX_STANDARD 14) # c++14 PROJECT基本用法：指定工程名称（完成路径赋值） # 顶层CMakeLists.txt cmake_minimum_required (VERSION 3.10.2) project (mytest) 指定当前的工程名称为mytest。实际上在调用project命令指定当前工程名字的同时，cmake内部会为如下变量赋值： PROJECT_NAME：将当前工程的名称赋值给PROJECT_NAME，对于本例子，就是$&#123;PROJECT_NAME&#125;=mytest。 PROJECT_SOURCE_DIR：当前工程的源码路径。 &lt;PROJECT-NAME&gt;_SOURCE_DIR：指定工程的源码路径，这个变量和PROJECT_SOURCE_DIR的区别就是，&lt;PROJECT-NAME&gt;_SOURCE_DIR跟具体的工程名字关联起来，若&lt;PROJECT-NAME&gt;就是当前工程，则该变量和PROJECT_SOURCE_DIR相等。 PROJECT_BINARY_DIR：当前工程的二进制路径。 &lt;PROJECT-NAME&gt;_BINARY_DIR：指定工程的二进制路径，这个变量和PROJECT_BINARY_DIR的区别就是，&lt;PROJECT-NAME&gt;_BINARY_DIR跟具体的工程名字关联起来，若&lt;PROJECT-NAME&gt;就是当前工程，则该变量和PROJECT_BINARY_DIR相等。 CMAKE_PROJECT_NAME：顶层工程的名称。例如当前调用的CMakeLists.txt位于顶层目录（可以理解为使用cmake命令首次调用的那个CMakeLists.txt），那么工程名还会赋值给CMAKE_PROJECT_NAME。 变量cmake变量定义的方式有两种：隐式定义和显式定义。 隐式定义前面举了一个隐式定义的例子，就是PROJECT指令，他会隐式的定义_BINARY_DIR和_SOURCE_DIR两个变量。 显示定义显式定义的例子我们前面也提到了,使用 SET 指令,就可以构建一个自定义变量了。比如: s(HELLO_SRC main.c) 就可以通过${HELLO_SRC}来引用这个自定义变量(main.c)了. 举例 设置编译参数，指定拿哪些文件build： cmake_minimum_required( VERSION 2.8 ) project(disjoint_path) set(CMAKE_CXX_STANDARD 11) # 设置编译参数 set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11 -g -Wall -rdynamic -pthread&quot;) set(CMAKE_RUNTIME_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) set(CMAKE_ARCHIVE_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) set(CMAKE_LIBRARY_OUTPUT_DIRECTORY $&#123;PROJECT_BINARY_DIR&#125;) include_directories($&#123;PROJECT_SOURCE_DIR&#125;) include_directories($&#123;PROJECT_BINARY_DIR&#125;) # set self-define var set(MAIN_FILE_LIST # 目录结构：这些文件都和CMakeLists.txt在项目顶层目录下，同级 main.cpp TwoConnected.cpp TwoConnected.h Graph.cpp Graph.h config.h ) # add_executable add_executable(main $&#123;MAIN_FILE_LIST&#125;) 如何编译： # 项目顶层目录下 mkdir build &amp; cd build cmake .. make main 链接库和链接参数： cmake_minimum_required(VERSION 3.15) project(rdb_example) set(CMAKE_CXX_STANDARD 14) set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11 -g -Wall -rdynamic -pthread&quot;) add_executable(simple_rdb_eg simple_adjlist.cpp) # 目录结构：simple_adjlist.cpp和CMakeLists.txt在项目顶层目录下，同级 target_link_libraries(simple_rdb_eg librocksdb.a -lpthread -llz4 -lsnappy -lbz2 -lzstd -ldl libz.so) #librocksdb.a已经设置$PATH可以通过环境变量$PATH找到 make simple_rdb_eg编译","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"make","slug":"make","date":"2022-08-16T02:22:53.426Z","updated":"2022-12-10T15:01:23.055Z","comments":true,"path":"2022/08/16/make/","link":"","permalink":"http://example.com/2022/08/16/make/","excerpt":"","text":"make http://www.ruanyifeng.com/blog/2015/02/make.html 代码变成可执行文件，叫做编译（compile）；先编译这个，还是先编译那个（即编译的安排），叫做构建（build）。Make是最常用的构建工具，主要用于C语言的项目。但是实际上 ，任何只要某个文件有变化，就要重新构建的项目，都可以用Make构建。 重构的标准”目标”是否重新构建的判断标准：只要有一个前置文件不存在，或者有过更新（前置文件的last-modification时间戳比目标的时间戳新），”目标”就需要重新构建。 Makefile指明的命令是如何在shell中执行的每行命令在一个单独的shell中执行。这些Shell之间没有继承关系。 var-lost: export foo=bar echo &quot;foo=[$$foo]&quot; 上面代码执行后（make var-lost），取不到foo的值。因为两行命令在两个不同的进程执行。 一个解决办法是将两行命令写在一行，中间用分号分隔。 var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; 另一个解决办法是在换行符前加反斜杠转义。 var-kept: export foo=bar; \\ echo &quot;foo=[$$foo]&quot; 最后一个方法是加上.ONESHELL:命令。 .ONESHELL: var-kept: export foo=bar; echo &quot;foo=[$$foo]&quot; Makefile语法规则：t: p1 p2 “p1 p2”称为前置条件 伪目标除了文件名，目标还可以是某个操作的名字，这称为”伪目标”（phony target） 可以明确声明clean是”伪目标”，申明以后，When it is time to consider such a target, make will run its recipe unconditionally, regardless of whether a file with that name exists or what its last-modification time is 写法如下： .PHONY clean clean: rm *.o 默认目标make的默认目标是第一个目标 设置默认目标： .DEFAULT_GOAL := main #设置main为默认目标 main: #不过话说默认目标习惯上最好命名为default啦 @ echo default target 一般规则make会首先寻找普通的生成规则，如果没找到，就尝试用一般规则 %.gas : %.c Makefile $(CC1) -o $*.gas $*.c %.nas : %.gas Makefile $(GAS2NASK) $*.gas $*.nas 比如makefile中没有main.gas的“菜单”，会尝试用下面这样来生成main.gas： main.gas : main.c Makefile $(CC1) -o main.gas main.c 回声正常情况下，make会打印每条命令（，然后再执行），这就叫做回声（echoing） 在命令的前面加上@，就可以关闭该行的回声（即执行该行之前不打印该行）。 变量Makefile 允许使用等号自定义变量。 txt = Hello World test: @echo $(txt) 上面代码中，变量 txt 等于 Hello World。调用时，变量需要放在 $( ) 之中。 调用Shell变量，需要在美元符号前，再加一个美元符号，这是因为Make命令会对美元符号转义。 test: @echo $$HOME 有时，变量的值可能指向另一个变量。 v1 = $(v2) 上面代码中，变量 v1 的值是另一个变量 v2。这时会产生一个问题，v1 的值到底在定义时扩展（静态扩展），还是在运行时扩展（动态扩展）？如果 v2 的值是动态的，这两种扩展方式的结果可能会差异很大。 为了解决类似问题，Makefile一共提供了四个赋值运算符 （&#x3D;、:&#x3D;、？&#x3D;、+&#x3D;），它们的区别请看StackOverflow。 VARIABLE = value ### 在执行时扩展，允许递归扩展。 VARIABLE := value ### 在定义时扩展。 VARIABLE ?= value ### 只有在该变量为空时才设置值。 VARIABLE += value ### 将值追加到变量的尾端。 内置变量（Implicit Variables）Make命令提供一系列内置变量，比如，**$(CC) 指向当前使用的编译器，$(MAKE) 指向当前使用的Make工具**。这主要是为了跨平台的兼容性，详细的内置变量清单见手册。 output: $(CC) -o output input.c 自动变量（Automatic Variables）Make命令还提供一些自动变量，它们的值与当前规则有关。主要有以下几个。 （1）$@ $@指代当前目标，就是Make命令当前构建的那个目标。比如，make foo的 $@ 就指代foo。 a.txt b.txt: touch $@ 等同于下面的写法。 a.txt: touch a.txt b.txt: touch b.txt （2）$&lt; $&lt; 指代第一个前置条件。比如，规则为 t: p1 p2，那么$&lt; 就指代p1。 a.txt: b.txt c.txt cp $&lt; $@ 等同于下面的写法。 a.txt: b.txt c.txt cp b.txt a.txt （3）$? $? 指代比目标更新的所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，其中 p2 的时间戳比 t 新，$?就指代p2。 （4）$^ $^ 指代所有前置条件，之间以空格分隔。比如，规则为 t: p1 p2，那么 $^ 就指代 p1 p2 。 （5）$* $ 指代匹配符 % 匹配的部分， 比如% 匹配 f1.txt 中的f1 ，$ 就表示 f1。 （6）$(@D) 和 $(@F) $(@D) 和 $(@F) 分别指向 $@ 的目录名和文件名。比如，$@是 src&#x2F;input.c，那么$(@D) 的值为 src ，$(@F) 的值为 input.c。 （7）$(&lt;D) 和 $(&lt;F) $(&lt;D) 和 $(&lt;F) 分别指向 $&lt; 的目录名和文件名。 所有的自动变量清单，请看手册。下面是自动变量的一个例子。 dest/%.txt: src/%.txt @[ -d dest ] || mkdir dest cp $&lt; $@ 上面代码将 src 目录下的 txt 文件，拷贝到 dest 目录下。首先判断 dest 目录是否存在，如果不存在就新建，然后，$&lt; 指代前置文件（src&#x2F;%.txt）， $@ 指代目标文件（dest&#x2F;%.txt）。 判断和循环Makefile使用 Bash 语法，完成判断和循环。 ifeq ($(CC),gcc) libs=$(libs_for_gcc) else libs=$(normal_libs) endif 上面代码判断当前编译器是否 gcc ，然后指定不同的库文件。 LIST = one two three all: for i in $(LIST); do \\ echo $$i; \\ done ## 等同于 all: for i in one two three; do \\ echo $i; \\ done 上面代码的运行结果。 one two three 函数Makefile 还可以使用函数，格式如下。 $(function arguments) ## 或者 $&#123;function arguments&#125; Makefile提供了许多内置函数，可供调用。下面是几个常用的内置函数。 （1）shell 函数 shell 函数用来执行 shell 命令 srcfiles := $(shell echo src/&#123;00..99&#125;.txt) （2）wildcard 函数 wildcard 函数用来在 Makefile 中，替换 Bash 的通配符。 srcfiles := $(wildcard src/*.txt) （3）替换函数 替换函数的写法是：变量名 + 冒号 + 替换规则。 min: $(OUTPUT:.js=.min.js) 上面代码的意思是，将变量OUTPUT中的 .js 全部替换成 .min.js 。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 2014VLDB The More the Merrier Efficient Multi-Source Graph Traversal","slug":"论文笔记 2014VLDB The More the Merrier Efficient Multi Source Graph Traversal","date":"2022-08-13T08:36:44.519Z","updated":"2022-12-10T15:02:10.116Z","comments":true,"path":"2022/08/13/论文笔记 2014VLDB The More the Merrier Efficient Multi Source Graph Traversal/","link":"","permalink":"http://example.com/2022/08/13/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%202014VLDB%20The%20More%20the%20Merrier%20Efficient%20Multi%20Source%20Graph%20Traversal/","excerpt":"","text":"MSBFSThe More the Merrier: Efficient Multi-Source Graph TraversalVLDB 2014 基准 bit op ANP（这个） tuningcache line heuristic maximum sharing way of grouping BFSs reason:","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"有sudo的ubuntu安装指定版本gcc","slug":"有sudo的ubuntu安装指定版本gcc","date":"2022-08-11T09:20:17.946Z","updated":"2022-12-10T15:02:42.614Z","comments":true,"path":"2022/08/11/有sudo的ubuntu安装指定版本gcc/","link":"","permalink":"http://example.com/2022/08/11/%E6%9C%89sudo%E7%9A%84ubuntu%E5%AE%89%E8%A3%85%E6%8C%87%E5%AE%9A%E7%89%88%E6%9C%ACgcc/","excerpt":"","text":"https://blog.csdn.net/qq_29007291/article/details/84953671","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"win10开机自动执行命令 后台运行","slug":"win10开机自动执行命令 后台运行","date":"2022-08-11T04:57:04.841Z","updated":"2022-12-10T15:02:53.840Z","comments":true,"path":"2022/08/11/win10开机自动执行命令 后台运行/","link":"","permalink":"http://example.com/2022/08/11/win10%E5%BC%80%E6%9C%BA%E8%87%AA%E5%8A%A8%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4%20%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C/","excerpt":"","text":"打开startup文件夹：win+R键入shell:startup回车，打开的文件夹即是 在这个文件夹中放xx.bat脚本或者应用xx.exe（或它们的快捷方式），即会开机执行它们 这样执行.bat文件是在前台执行，且会有一个黑框，消除黑框的方法： https://codeantenna.com/a/3gznir1890 在startup文件夹中放xx.vbs文件来代替原先的bat文件（或它们的快捷方式），文件内容为 Set ws = CreateObject(&quot;Wscript.Shell&quot;) ws.run &quot;cmd /c H:\\myBlog\\start_personal_blog.bat&quot;,vbhide 其中H:\\myBlog\\start_personal_blog.bat为希望后台运行隐藏黑框的命令","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"vscode配置c++项目 include路径等","slug":"vscode配置c++项目 include路径等","date":"2022-08-11T03:58:44.361Z","updated":"2022-12-10T15:03:16.612Z","comments":true,"path":"2022/08/11/vscode配置c++项目 include路径等/","link":"","permalink":"http://example.com/2022/08/11/vscode%E9%85%8D%E7%BD%AEc++%E9%A1%B9%E7%9B%AE%20include%E8%B7%AF%E5%BE%84%E7%AD%89/","excerpt":"","text":"装c++环境gcc和g++都要以ubuntu为例 sudo apt-get instal gcc sudo apt-get instal g++ #没装会报错找不到比如iostream头文件 配置vscode https://blog.csdn.net/jinking01/article/details/106186575 装c/c++、c++ IntelliSense插件version1.70开始c++ IntelliSense没了，合并到c/c++了 include path关键是 配置c++ IntelliSense插件：这个插件会帮你解决所有include path的问题ctrl+shift+P打开Command Palette,运行C/C++: Edit configurations... 生成c_cpp_properties.json debug配置F5会生成launch.json，然后配置这个文件有些时候不会，则在项目顶层目录的.vscode目录下新建launch.json，打开此文件在编辑界面右下角会出现add configuration...按钮，点击然后选择c/c++(gdb): Launch，然后填写launch.json内容即可program指明调试的可执行文件路径，args指定传递给可执行文件program的参数，比如： &#123; // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387 &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ &#123; &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;/home/yuanzhiqiu/external_multi_bfs/vertex_disjoint_path/build/main&quot;, &quot;args&quot;: [ &quot;-n&quot;, &quot;2&quot;, &quot;-b&quot;, &quot;128&quot;, &quot;-m&quot;, &quot;msbfs&quot;, &quot;-g&quot;, &quot;/home/yuanzhiqiu/test_dataset/disjoint_test.txt&quot;, //disjoint_test split_vertex_test &quot;-p&quot;, &quot;/home/yuanzhiqiu/vertex_pairs/disjoint_test.txt&quot;, &quot;-o&quot;, &quot;.&quot;, ], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;$&#123;fileDirname&#125;&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;gdb&quot;, &quot;setupCommands&quot;: [ &#123; &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;, &quot;text&quot;: &quot;-enable-pretty-printing&quot;, &quot;ignoreFailures&quot;: true &#125;, &#123; &quot;description&quot;: &quot;Set Disassembly Flavor to Intel&quot;, &quot;text&quot;: &quot;-gdb-set disassembly-flavor intel&quot;, &quot;ignoreFailures&quot;: true &#125; ] &#125; ] &#125; 启动调试如何调试：自己编译，然后F5唤起调试","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"WSL wsl","slug":"WSL wsl","date":"2022-08-11T03:04:12.898Z","updated":"2022-12-10T15:03:27.447Z","comments":true,"path":"2022/08/11/WSL wsl/","link":"","permalink":"http://example.com/2022/08/11/WSL%20wsl/","excerpt":"","text":"安装教程https://zhuanlan.zhihu.com/p/386590591?utm_campaign=shareopn&amp;utm_medium=social&amp;utm_oi=1123716080996339712&amp;utm_psn=1540980178544648192&amp;utm_source=wechat_session WSL中访问本地文件 在“&#x2F;mnt”目录下有“c”、“d”、“e”等文件夹，分别表示本地的C盘、D盘、E盘，直接cd到相应路径下即可 vscode打开WSL中的目录安装Remote-WSL插件，然后ctrl+shift+p打开控制面板输入Remote-WSL，选择比如open folder啥啥的 ssh连接WSL 参考https://cloud.tencent.com/developer/article/1538305 sudo vim /etc/ssh/sshd_config，把PasswordAuthentication no改成PasswordAuthentication yes 重启ssh服务sudo service ssh restart ifconfig查看ip（inet即ip地址，不为127.0.0.1的那个网卡的inet即所求），然后ssh &lt;usrname&gt;@&lt;ip&gt;即可连接 ssh连接WSL中的docker假设在wsl中可以以如下配置连接tigergraph docker Host tigerg HostName localhost User tigergraph Port 14022 则在pc上对~/.ssh/config新增如下配置（实际上是把wsl作为跳板机） # my dell pc windows wsl Host wsl # 参考&quot;ssh连接WSL&quot;中的配置 HostName 172.17.165.64 User yuanzhiqiu # tigergraph docker on my dell wsl Host tigerg HostName localhost User tigergraph Port 14022 ProxyCommand ssh -W %h:%p wsl # 看这里，通过跳板机 然后即可在本机上ssh tigerg连接上wsl上的docker注意连接之前，wsl上要先启动docker服务和对应容器（sudo service docker start, docker start tigergraph） 免密登录配置好本机-&gt;wsl，本机-&gt;wsl上的docker容器，即可ssh tigerg免密：将本机的公匙传入wsl和wsl上的docker容器中的~/.ssh/authorized_keys 查看已安装的WSL以及运行状态wsl -l -v 或者 下载工具LxRunOffline（一个非常强大的管理子系统的工具），下载并解压后，在解压目录中打开 PowerShell 查看已安装的子系统 ./LxRunOffline.exe list 查看WSL所在目录 查看子系统所在目录（LxRunOffline） ./LxRunOffline.exe get-dir -n Ubuntu-18.04 移动到非C盘 参考https://learnku.com/articles/46234https://blog.csdn.net/yihuajack/article/details/119915303 下载工具LxRunOffline 停止运行中要迁移的系统 wsl --shutdown 新建目标目录并授权 icacls D:\\wsl\\installed /grant &quot;cnguu:(OI)(CI)(F)&quot; 目标目录：D:\\wsl\\installed用户名：cnguu此步骤失败了似乎没事 迁移系统 .\\LxRunOffline move -n Ubuntu-18.04 -d D:\\wsl\\installed\\Ubuntu-18.04","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"跨越跳板服务器传送文件 登录目标服务器","slug":"跨越跳板服务器传送文件 登录目标服务器","date":"2022-08-11T02:18:26.976Z","updated":"2022-12-10T15:04:24.005Z","comments":true,"path":"2022/08/11/跨越跳板服务器传送文件 登录目标服务器/","link":"","permalink":"http://example.com/2022/08/11/%E8%B7%A8%E8%B6%8A%E8%B7%B3%E6%9D%BF%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BC%A0%E9%80%81%E6%96%87%E4%BB%B6%20%E7%99%BB%E5%BD%95%E7%9B%AE%E6%A0%87%E6%9C%8D%E5%8A%A1%E5%99%A8/","excerpt":"","text":"A-&gt;B-&gt;CA&lt;-B&lt;-C 配置A-&gt;B免密，A-&gt;C免密 把A的公匙上传到B和C的~/.ssh/authorized_keys中 公匙生成命令（.pub文件为公匙）ssh-keygen -t rsa 在A的~/.ssh/config增加：Host B #跳板机 HostName B_ip User B_user Port 22 Host C #目标机 HostName C_ip #C的ip，可以是跳板机能理解的内网ip（不一定要公网ip） User C_user ProxyCommand ssh -W %h:%p B #rewrite every ProxyJump command using ProxyCommand #A通过跳板机B连接到C 验证ssh连接&#x2F;连接服务器验证上述免密登录是否成功：在A上 能否登录B ssh B 或者ssh B_usr@B_ip 能否登录C命令同上 如果都能登录上scp才可以成功 传送scp在windows powershell中也可以用 # A-&gt;C scp file_path C:file_path # A&lt;-C scp C:file_path file_path","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux服务器间文件传送 .tar.gz文件压缩和解压","slug":"linux服务器间文件传送 targz文件压缩和解压","date":"2022-08-11T01:46:09.175Z","updated":"2022-12-10T15:04:36.515Z","comments":true,"path":"2022/08/11/linux服务器间文件传送 targz文件压缩和解压/","link":"","permalink":"http://example.com/2022/08/11/linux%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%97%B4%E6%96%87%E4%BB%B6%E4%BC%A0%E9%80%81%20targz%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9%E5%92%8C%E8%A7%A3%E5%8E%8B/","excerpt":"","text":"旧服务器备份：把~&#x2F;.halo压缩 tar -zvcf ~/.halo.tar.gz ~/.halo # 得到~/.halo.tar.gz 移到新服务器中在旧服务器上运行 scp ~/.halo.tar.gz &lt;新服务器用户名&gt;@&lt;新服务器ip地址&gt;:~/.halo.tar.gz #scp即secure copy，是用来进行远程文件拷贝的。数据传输使用 ssh，并且和ssh 使用相同的认证方式，提供相同的安全保证 scp在服务器之间文件传送 https://www.xiebruce.top/578.html scp也可以直接目录拷贝，scp -r递归拷贝，但是亲测感觉压缩之后传输快一点 新服务器中解压在~&#x2F;目录下 tar -zvxf .halo.tar.gz","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"解决应用商店Microsoft store打不开 代码0x80131500","slug":"解决应用商店Microsoft store打不开 代码0x80131500","date":"2022-08-11T01:10:13.261Z","updated":"2022-12-10T15:04:56.258Z","comments":true,"path":"2022/08/11/解决应用商店Microsoft store打不开 代码0x80131500/","link":"","permalink":"http://example.com/2022/08/11/%E8%A7%A3%E5%86%B3%E5%BA%94%E7%94%A8%E5%95%86%E5%BA%97Microsoft%20store%E6%89%93%E4%B8%8D%E5%BC%80%20%E4%BB%A3%E7%A0%810x80131500/","excerpt":"","text":"解决方法：https://zhuanlan.zhihu.com/p/116654088事后还原：勾选 TLS 1.0，取消勾选TLS 1.2","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"linux文件打开系统调用 追加写覆盖写","slug":"linux文件打开系统调用 追加写覆盖写","date":"2022-08-10T07:48:23.457Z","updated":"2022-12-10T15:05:10.118Z","comments":true,"path":"2022/08/10/linux文件打开系统调用 追加写覆盖写/","link":"","permalink":"http://example.com/2022/08/10/linux%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8%20%E8%BF%BD%E5%8A%A0%E5%86%99%E8%A6%86%E7%9B%96%E5%86%99/","excerpt":"","text":"man page: https://man7.org/linux/man-pages/man2/open.2.html const char* file = &quot;test_file.txt&quot;; int pfd = open(file, O_WRONLY | O_CREAT | O_APPEND, 0777); O_WRONLY：只写O_CREAT：如果不存在则创建O_APPEND：追加写0777：所有组给全部权限 int pfd = open(file, O_WRONLY | O_CREAT | O_TRUNC, 0777); O_TRUNC：覆盖写","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"RDF三元组数据转schema图","slug":"RDF三元组数据转schema图","date":"2022-08-06T06:48:24.168Z","updated":"2022-12-10T15:05:41.429Z","comments":true,"path":"2022/08/06/RDF三元组数据转schema图/","link":"","permalink":"http://example.com/2022/08/06/RDF%E4%B8%89%E5%85%83%E7%BB%84%E6%95%B0%E6%8D%AE%E8%BD%ACschema%E5%9B%BE/","excerpt":"","text":"schema：反映顶点label之间的关系，以及Label会有哪些常量类型用G6 &lt;id&gt; &lt;label&gt; &lt;vertex label&gt;. &lt;id&gt; &lt;edge label&gt; &lt;id&gt;. &lt;id&gt; &lt;vertex property&gt; literal. 不可以拖拽http://graphviz.herokuapp.com/?token=eeb362635d6b026b24d7b012b3ba6ee7想尝试https://github.com/magjac/graphviz-visual-editor 加箭头https://g6.antv.vision/zh/docs/manual/middle/elements/edges/arrow可以拖拽https://g6.antv.vision/zh/examples/net/forceDirected#basicForceDirected graphvizdigraph ClassDiagram &#123; #//////////////////////////////// Introduction \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ /* This graph is meant as a starting point to help you create UML Class Diagrams by providing a preset for edges and nodes. To use it, you need to take the folowing steps: - Copy and paste (or &quot;save as&quot;) this graph into a new file - Rename the relevant labels (anything with the word &quot;Example&quot; in it). - Add nodes (inside subgraphs when needed) - Add connections for the nodes Make sure you place your connections under the right headers, otherwise the decoration won&#39;t match the UML specifications. For each module you should use a separate subgraph. Make sure the name of your subgraph starts with `cluster_` If you don&#39;t like the colors, the easiest way to ammend this is by changing the defined colorscheme (currently &quot;pastel13&quot;) in the &quot;General Styles&quot; section to any other 3-scheme. All available colorschemes can be found at http://www.graphviz.org/doc/info/colors.html#brewer */ #/////////////////////////////// General Styles \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ graph [ label = &quot;Example \\n Class Diagram&quot; labelloc = t //dpi = 200 ranksep=0.65 nodesep=0.40 rankdir=BT bgcolor=&quot;#FFFFDD&quot; style=&quot;dotted, filled&quot; fillcolor=&quot;#FFFFFF&quot; ] edge [arrowhead=empty] //空心箭头 =none则无箭头 node [ labeljust=&quot;l&quot; colorscheme=&quot;pastel13&quot; style=filled fillcolor=3 shape=record ] #/////////////////////////////////// subgraph \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\ //可以添加很多子图 subgraph schema &#123; //label = &quot;Example \\n subgraph Diagram&quot; //子图标题 //nodes alarm [label=&quot;&#123;alarm|arriveTime&#125;&quot;] lip [label=&quot;&#123;lip|slotnum&#125;&quot;] &#125; &#123; //edges lip -&gt; alarm [label=&quot;like&quot;] lip -&gt; alarm [label=&quot;happen&quot;] &#125; &#125;//ClassDiagram","categories":[{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}]},{"title":"生成树","slug":"生成树","date":"2022-08-06T03:38:52.959Z","updated":"2022-12-10T15:06:25.394Z","comments":true,"path":"2022/08/06/生成树/","link":"","permalink":"http://example.com/2022/08/06/%E7%94%9F%E6%88%90%E6%A0%91/","excerpt":"","text":"生成树最大生成树的性质","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[]},{"title":"MIT 6.S081 Operating System Engineering 资源汇总","slug":"MIT 6S081 Operating System Engineering 资源汇总","date":"2022-08-06T01:19:50.111Z","updated":"2022-12-10T15:07:09.849Z","comments":true,"path":"2022/08/06/MIT 6S081 Operating System Engineering 资源汇总/","link":"","permalink":"http://example.com/2022/08/06/MIT%206S081%20Operating%20System%20Engineering%20%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB/","excerpt":"","text":"https://csdiy.wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/MIT6.S081/ 课程资源课程网站：https://pdos.csail.mit.edu/6.828/2021/schedule.html课程视频：https://www.youtube.com/watch?v=L6YqHxYHa7A，每节课的链接详见课程网站 B站 https://www.bilibili.com/video/BV19k4y1C7kA/?spm_id_from=333.788.recommend_more_video.0&amp;vd_source=b980455be8f7254fee312ed56a30137b课程视频翻译文档：https://mit-public-courses-cn-translatio.gitbook.io/mit6-s081/课程教材：https://pdos.csail.mit.edu/6.828/2021/xv6/book-riscv-rev2.pdf课程作业：https://pdos.csail.mit.edu/6.828/2021/schedule.html，11个lab，具体要求详见课程网站 xv6 补充资源见https://csdiy.wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/MIT6.S081/ 一些可以参考的博客见https://csdiy.wiki/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/MIT6.S081/","categories":[{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"},{"name":"os","slug":"course/os","permalink":"http://example.com/categories/course/os/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"论文笔记 multi-terminal network flows","slug":"论文笔记 multiterminal network flows","date":"2022-08-05T08:26:54.181Z","updated":"2022-12-10T15:07:39.429Z","comments":true,"path":"2022/08/05/论文笔记 multiterminal network flows/","link":"","permalink":"http://example.com/2022/08/05/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20multiterminal%20network%20flows/","excerpt":"","text":"定义bij：顶点Ni到顶点Nj间边Bij的容量fij：顶点Ni到顶点Nj的最大流流量F是fij构成的方阵 贡献判定一个F是否能在某些网络拓扑中达到 判定算法：求fij；然后在构造最大生成树时检查是否违反这个 (1)可以自然推出：&gt;&#x3D;i-p任意“路径”（注意路径上“相邻”两点不需要有边相连）的minflow 证明过程中提出：以fij作为边Bij的权重构造一棵最大生成树，对于任意一条不在该树上的边ip，i到p的最大流 等于 该树上i到p（唯一）的路径的minflow condense graph构造（注意(A,A’)是最小割） 性质（ordinary nodes是指在A中（A中是因为A‘中的顶点在condense graph中已经被收缩成一个点了）、非Ni的顶点） n-1次最大流求解就求出全图所有点对之间的最大流不断做划分顶点的事，然后 证明中提出的一个性质： 这个性质应用到最终划分所得树上，以及根据划分过程，得到最终树的性质：关键是这个性质使得可以n-1代替n(n-1)&#x2F;2、进行合并：最终树的边既是cut又是maxflow，cut则两点间maxflow&lt;&#x3D;min(树上路径)，maxflow则两点间maxflow&gt;&#x3D;min(树上路径)，因此两点间maxflow&#x3D;&#x3D;min(树上路径) 划分过程原文描述完思路之后还有一个详细例子 证明阅读lemma1证明","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"disjoint-path-max-flow problem","slug":"disjoint path max flow problem","date":"2022-08-04T09:29:36.158Z","updated":"2022-12-10T15:10:20.912Z","comments":true,"path":"2022/08/04/disjoint path max flow problem/","link":"","permalink":"http://example.com/2022/08/04/disjoint%20path%20max%20flow%20problem/","excerpt":"","text":"defintions unit network单位网络：每个顶点要么只有一条出边且容量为1，要么只有一条入边且容量为1 unit capacity network单位容量网络：所有边容量&#x3D;1 reductions of problem versionundirected-&gt;directed https://stackoverflow.com/questions/29741691/maximum-flow-in-the-undirected-graph 正确性： - for max-flow：It can be easily proven that in such conversion, flow only propagates through one of the two edges and always one of them is not used max flow: directed-&gt;undirected Faster Energy Maximization for Faster Maximum Flow方法： 证明： directed vertex disjoint -&gt; directed edge disjoint general relationship between max-flow and disjointedge-disjoint -&gt; max-flow对于单位容量、整数流的网络，augment paths after adjustment are edge-disjoint：edge-disjoint来自于 边容量都是1，流是{0,1}流 最大流最小割定理 这个定理可以看出，最大流的大小取决于网络拓扑（因为等于最小s-t割的容量） 定义 augment path for f in G：s-t path in Gf Gf：残余网络，G上流上f得到的：对于流f流过的边(u,v)，正向边(u,v)的容量为c(u,v)-f(u,v)，反向边(v,u)的容量为f(u,v) s-t cut：顶点集的划分 proof 因此证明只需要 在对f没有augment path时，找到一个s-t cut满足这个iff后面的特征即可，下面找这个s-t cut if then是因为 没有augment path for f，则没有s-t path in Gf，所以Ef中一些边不存在 2 disjoint path第一条augment path的选择， 正确性定理的(2)-&gt;(1)：对于f没有augment path -&gt; f是G中最大流因此 对于最大流&gt;&#x3D;2的单位容量、整数流网络，随意选择第一条augment path，都一定可以找到第二条augment path 因为 如果选择某条augment path作为第一条之后找不到其他augment path了，则根据“对于f没有augment path -&gt; f是G中最大流”有此时的flow就是最大流，但此时的流量只有1，这与流最大&gt;&#x3D;2矛盾，所以一定可以找到第二条augment path (2)-&gt;(1) proof框架（详细见下方proof）：如果对f不存在augment path，则存在s-t cut满足c(S,T)&#x3D;|f|（注意这个是全局的而不是局部的！），则f是最大流 效率（时间复杂度） 随意选择第一条augment path都一定可以找到第二条augment path的话，则考虑怎样选取进行求解的速度最快 如何选取第一条和第二条augment path，使得效率最高？","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"论文笔记 Faster Energy Maximization for Faster Maximum Flow","slug":"论文笔记 Faster Energy Maximization for Faster Maximum Flow","date":"2022-08-04T07:57:51.764Z","updated":"2022-12-10T15:10:41.949Z","comments":true,"path":"2022/08/04/论文笔记 Faster Energy Maximization for Faster Maximum Flow/","link":"","permalink":"http://example.com/2022/08/04/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0%20Faster%20Energy%20Maximization%20for%20Faster%20Maximum%20Flow/","excerpt":"","text":"思考目前没有看完，刚看完central path的定义，在看norm的定义，浏览了下算法overall，似乎文章主要目标在max-flow的max，augment path的步骤文章中是直接说执行这个步骤，即这个步骤和往昔的max-flow算法是一样的，而++max-flow的disjoint是cancel flow提供的++，通过augment path步骤构造路径，而我们只需要两条augment path即可，这样似乎没有必要阅读全文：是否值得继续阅读取决于一个问题：即第一条augment path的选择是否会影响能否找到两条以及找到两条的效率： 如果存在两条edge-disjoint，则若利用cancel flow，是否对于任意的第一条augment path，都可以找到第二条augment path（从而修正一下得到两条edge-disjoint）？ 如果是的话，是否 对于第一条aygment path的选择，其可以对于整体找两条augment path有效率提升？ 解决的问题最大流：其中BT*f&#x3D;tX即（BT*f即得到一个n维向量，表示每个顶点的净流量（出-入））满足flow conservation，所有顶点除了st都入流&#x3D;出流，即净流&#x3D;0，s是出，t是入，且s出量&#x3D;t入量 V是标量，V的梯度（下三角）是m维向量（V对于每条边求偏导） 无向图 Preliminaries定义d-flow即满足顶点净流量&#x3D;&#x3D;dv ab-flow即满足flow conservation energy和electrical d-flow 能量回忆物理：电功率i^2*relectrical d-flow即满足顶点净流量&#x3D;&#x3D;dv、minimize能量的 maximum flow problem Laplacian of the graph G with resistances r n*n矩阵，Lij&#x3D;0，如果顶点ij之间没有边相连；&#x3D;负的 ij间边电阻的倒数之和，如果顶点ij之间有边相连 B矩阵：对于每条边（即B的每行）只有两个端点（即B的每行只有两列非零，1和-1）；B矩阵的每一列（即每个顶点的），表示对应顶点的出边入边情况 推导思考：B转置*R-1得到的是：n*m矩阵，是B转置每一列都分别乘 该列对应的边的电阻的倒数再乘以B，对于目标矩阵n*n的每个格子ij，思考：顶点i和j 的入边出边记录 对位相乘再相加 -&gt; 对于每条边，这条边要么在顶点ij之间，要么不在，在的话对位相乘结果是”-1”(-1*1&#x2F;r)，不在的话则至少有一边是0，则对位相乘结果是0 R-1*B，得到：m*n矩阵，是B矩阵每一行（每条边）都乘以对应边的电阻的倒数可以看出求出φ就可以求出f帽 提出的定义central path为了转换优化问题，观察到在最优时： 因此定义central path（满足V(f)最小时点(f,t,y)在central path上）： 以及定义描述离central path距离的measurement： 先定义电阻 再定义measurement： 也定义描述最大流距离“流最大”的measurement： 算法overall","categories":[{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"}],"tags":[]},{"title":"图拉普拉斯","slug":"图拉普拉斯","date":"2022-08-04T06:41:06.661Z","updated":"2022-12-10T15:11:15.993Z","comments":true,"path":"2022/08/04/图拉普拉斯/","link":"","permalink":"http://example.com/2022/08/04/%E5%9B%BE%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF/","excerpt":"","text":"学习自 https://zhuanlan.zhihu.com/p/484348911 定义梯度 拉普拉斯算子 图拉普拉斯公式给定一个有n个顶点的图G&#x3D;(V,E)，其拉普拉斯矩阵被定义为L&#x3D;D-A，D其中为图的度矩阵，A为图的邻接矩阵。 推导 (4) 拉普拉斯矩阵中的第i行反应了第i个节点在对其他所有节点产生扰动时所产生的增益累积。图拉普拉斯反映了当我们在节点i上施加一个势，这个势以哪个方向能够多顺畅的流向其他节点。","categories":[{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"},{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"}],"tags":[{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"}],"author":"zhiqiuyuan"},{"title":"多对数函数polylogarithmic","slug":"多对数函数polylogarithmic","date":"2022-08-04T03:03:20.000Z","updated":"2022-12-10T15:11:31.346Z","comments":true,"path":"2022/08/04/多对数函数polylogarithmic/","link":"","permalink":"http://example.com/2022/08/04/%E5%A4%9A%E5%AF%B9%E6%95%B0%E5%87%BD%E6%95%B0polylogarithmic/","excerpt":"","text":"https://zh.wikipedia.org/zh-cn/%E5%A4%9A%E5%B0%8D%E6%95%B8%E5%87%BD%E6%95%B8","categories":[{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"},{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"c重定向stdout然后恢复stdout 文件权限编码 chmod","slug":"c重定向stdout然后恢复stdout 文件权限编码 chmod","date":"2022-07-29T02:25:17.309Z","updated":"2022-12-10T15:12:07.055Z","comments":true,"path":"2022/07/29/c重定向stdout然后恢复stdout 文件权限编码 chmod/","link":"","permalink":"http://example.com/2022/07/29/c%E9%87%8D%E5%AE%9A%E5%90%91stdout%E7%84%B6%E5%90%8E%E6%81%A2%E5%A4%8Dstdout%20%E6%96%87%E4%BB%B6%E6%9D%83%E9%99%90%E7%BC%96%E7%A0%81%20chmod/","excerpt":"","text":"重定向https://stackoverflow.com/questions/47719965/how-to-redirect-stdout-to-a-file-and-then-restore-stdout-back 举例#include &lt;iostream&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; using namespace std; int main() &#123; /*redirect stdout to file*/ int pfd = open(&quot;file&quot;, O_WRONLY | O_CREAT, 0777); // now pfd is descriptor to &quot;file&quot; int saved = dup(1); // now 1 and saved both are descriptor to STDOUT // int dup2(int oldfd, int newfd); dup2(pfd, 1); // would close descriptor 1 first, then now 1 and pfd both are descriptor to &quot;file&quot;(pfd previously pointed to) close(pfd); // close descriptor pfd cout &lt;&lt; &quot;This goes into file&quot; &lt;&lt; endl; // fflush(stdout); // NOTE that endl or fflush(stdout) after printf is necessary to flush content in buffer into file /*restore stdout*/ dup2(saved, 1); // would close descriptor 1 first, then now 1 and saved both are descriptor to STDOUT(saved previously pointed to) close(saved); // close descriptor saved cout &lt;&lt; &quot;This goes into console&quot; &lt;&lt; endl; return 0; &#125; RAII异常处理时c++编译器保证会（按顺序）调用所有对象的析构函数，因此把重定向和恢复操作封装到类中会异常安全 上面举例那种，如果在重定向之后、恢复之前程序abort了，则不会进行stdout恢复 全局一个实例#include &lt;iostream&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; using namespace std; // implement redirect stdout in class: exception safety // destructors of all objects are ensured to be called when exception occurs(ensured by compiler) // redirect stdout to file when constructing instance, restore when destructing // NOTE: only one success instance is allowed class RedirectStdout &#123; int saved; int redirected_success; static int success_instance_count; public: int is_success() &#123; return redirected_success; &#125; // redirect stdout to file RedirectStdout(const char *file) &#123; if (success_instance_count == 1) &#123; cout &lt;&lt; &quot;only one success instance is allowed!&quot; &lt;&lt; endl; redirected_success = 0; return; &#125; // TODO: check these syscall&#39;s return value // now 1 is descriptor to STDOUT int pfd = open(file, O_WRONLY | O_CREAT, 0777); // now pfd is descriptor to &quot;bin/.gconsole_tmp_out&quot; saved = dup(1); // now 1 and saved both are descriptor to STDOUT // int dup2(int oldfd, int newfd); dup2(pfd, 1); // would close descriptor 1 first, then now 1 and pfd both are descriptor to &quot;bin/.gconsole_tmp_out&quot;(pfd previously pointed to) close(pfd); // close descriptor pfd redirected_success = 1; ++success_instance_count; &#125; // fflush and restore stdout ~RedirectStdout() &#123; if (redirected_success) &#123; --success_instance_count; // TODO: check these syscall&#39;s return value fflush(stdout); // NOTE that flush the buffer is necessary to indeed push content into file dup2(saved, 1); // would close descriptor 1 first, then now 1 and saved both are descriptor to STDOUT(saved previously pointed to) close(saved); // close descriptor saved&#125; &#125; &#125; &#125;; int RedirectStdout::success_instance_count = 0; // init to 0 int main() &#123; &#123; RedirectStdout ins1(&quot;1&quot;); // success, stdout is redirected to file&quot;1&quot; cout &lt;&lt; ins1.is_success() &lt;&lt; endl; // success, print to file&quot;1&quot; cout &lt;&lt; &quot;This goes into file&quot; &lt;&lt; endl; // print to file&quot;1&quot; RedirectStdout ins2(&quot;2&quot;); // fail, fail msg print to file&quot;1&quot; cout &lt;&lt; ins2.is_success() &lt;&lt; endl; // print to file&quot;1&quot; RedirectStdout ins3(&quot;3&quot;); // fail, fail msg print to file&quot;1&quot; cout &lt;&lt; ins3.is_success() &lt;&lt; endl; // print to file&quot;1&quot; &#125; // destruct: restore stdout cout &lt;&lt; &quot;This goes into console&quot; &lt;&lt; endl; return 0; &#125; 栈式重定向#include &lt;iostream&gt; #include &lt;fstream&gt; #include &lt;stack&gt; #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; using namespace std; template &lt;typename T&gt; void print_stk(stack&lt;T&gt; arr) &#123; cout &lt;&lt; &quot;[sz:&quot; &lt;&lt; arr.size() &lt;&lt; &quot;] &quot;; while (arr.empty() == 0) &#123; cout &lt;&lt; arr.top() &lt;&lt; &quot; &quot;; arr.pop(); &#125; cout &lt;&lt; endl; &#125; // if &lt;des&gt; is descriptor to &lt;file&gt;, then we call &lt;des&gt;&#39;s refer is &lt;file&gt; // construct: redirect descriptor 1&#39;s refer ori_file to file(constructor&#39;s param)(and push ori_file to static stk top) // destruct: restore descriptor 1&#39;s refer to stk top(and pop stk) // static stk design ensures when there&#39;s no RedirectStdout instance, descriptor 1&#39;s refer is stdout class RedirectStdout &#123; public: static stack&lt;int&gt; ori_file_stk; /* redirect descriptor 1&#39;s refer ori_file to file(and push ori_file to static stk top) */ // append: if set, then open file with |O_APPEND RedirectStdout(const char *file, int append = 0) &#123; // TODO: check these syscall&#39;s return value // now 1 is descriptor to ori_file(if stk is empty, ori_file is STDOUT; else ori_file is stk.top()) int pfd; if (append) &#123; pfd = open(file, O_WRONLY | O_CREAT | O_APPEND, 0777); &#125; else &#123; pfd = open(file, O_WRONLY | O_CREAT | O_TRUNC, 0777); &#125; // now pfd is descriptor to file int saved = dup(1); // now 1 and saved both are descriptor to ori_file(1 previously refer to) // int dup2(int oldfd, int newfd); dup2(pfd, 1); // would close descriptor 1 first, then now 1 and pfd both are descriptor to file(pfd previously refer to) close(pfd); // close descriptor pfd ori_file_stk.push(saved); // now saved(stk.top()) is descriptor to ori_file, 1 is descriptor to file &#125; /* fflush and restore descriptor 1&#39;s refer to stk top(and pop stk) */ ~RedirectStdout() &#123; // TODO: check these syscall&#39;s return value fflush(stdout); // NOTE that flush the buffer is necessary to indeed push content into file int saved = ori_file_stk.top(); ori_file_stk.pop(); dup2(saved, 1); // would close descriptor 1 first, then now 1 and saved both are descriptor to &quot;saved previously refer to&quot; close(saved); // close descriptor saved // now only 1 is descriptor to &quot;saved previously refer to&quot; &#125; &#125;; stack&lt;int&gt; RedirectStdout::ori_file_stk; int main() &#123; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in console: &#123;&#125; // now 1 refer to STDOUT &#123; RedirectStdout ins1(&quot;ins1&quot;); // now 1 refer to &quot;ins1&quot; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in ins1: &#123;des_to_STDOUT&#125; &#123; RedirectStdout ins2(&quot;ins2&quot;); // now 1 refer to &quot;ins2&quot; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in ins2: &#123;des_to_ins1,des_to_STDOUT&#125; &#125; // ins2 destruct: now 1 refer to &quot;ins1&quot; print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in ins1: &#123;des_to_STDOUT&#125; &#125; // ins1 destruct: now 1 refer to STDOUT print_stk&lt;int&gt;(RedirectStdout::ori_file_stk); // print in console: &#123;&#125; return 0; &#125; 文件权限编码 chmod https://digitalfortress.tech/php/difference-file-mode-0777-vs-777/ 如何编码 对于posix接口： parameter you pass to mkdir() is interpreted as decimal if it isn’t preceded by a 0 如果前面有0则是被当作16进制数翻译 因此777 and 0777有区别： 0777 (octal) == binary 0b 111 111 111 == permissions rwxrwxrwx (== decimal 511) 777 (decimal) == binary 0b 1 100 001 001 == permissions sr----x--x (== octal 1411) 对于chmod chmod interprets all numeric arguments as octal，则777 and 0777无区别 一个计算器：https://chmodcommand.com/ dup dup2 https://man7.org/linux/man-pages/man2/dup.2.html dup, dup2, dup3 - duplicate a file descriptor #include &lt;unistd.h&gt; int dup(int oldfd); int dup2(int oldfd, int newfd); dup The dup() system call ++allocates a new file descriptor++ that ++refers to the same open file++ description as the descriptor oldfd. The new file descriptor number is guaranteed to be the lowest-numbered file descriptor that was unused in the calling process. After a successful return, the old and new file descriptors may be used interchangeably（毕竟它们指向相同的文件）.Since the two file descriptors refer to the same open file description, they share file offset and file status flags;（for example, if the file offset is modified by using lseek(2) on one of the file descriptors, the offset is also changed for the other file descriptor.） The two file descriptors do NOT share file descriptor flags (the close-on-exec flag). The close-on-exec flag (FD_CLOEXEC; see fcntl(2)) for the duplicate descriptor is off. dup2++the file descriptor newfd++ is adjusted so that it now ++refers to the same open file description as oldfd.++ If the file descriptor newfd was previously open, it is closedbefore being reused; the close is performed silently (i.e., anyerrors during the close are not reported by dup2()). returnOn success, these system calls return the new file descriptor.On error, -1 is returned, and errno is set to indicate the error.","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"c函数宏定义函数可变参数","slug":"c函数宏定义函数可变参数","date":"2022-07-28T04:33:23.438Z","updated":"2022-12-10T15:13:29.527Z","comments":true,"path":"2022/07/28/c函数宏定义函数可变参数/","link":"","permalink":"http://example.com/2022/07/28/c%E5%87%BD%E6%95%B0%E5%AE%8F%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/","excerpt":"","text":"宏定义函数https://gcc.gnu.org/onlinedocs/gcc-7.3.0/gcc.pdf搜索__VA_ARGS__ #define debug(format, ...) fprintf (stderr, format, __VA_ARGS__) Here ... is a variable argument. In the invocation of such a macro, it represents the zero or more tokens until the closing parenthesis that ends the invocation, including anycommas. This set of tokens replaces the identifier __VA_ARGS__ in the macro body whereverit appears. See the CPP manual for more information. c函数https://blog.csdn.net/qq_16628781/article/details/72717008","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"linux c隐藏输入 termios.h","slug":"linux c隐藏输入 termiosh","date":"2022-07-27T08:27:11.661Z","updated":"2022-12-10T15:13:23.096Z","comments":true,"path":"2022/07/27/linux c隐藏输入 termiosh/","link":"","permalink":"http://example.com/2022/07/27/linux%20c%E9%9A%90%E8%97%8F%E8%BE%93%E5%85%A5%20termiosh/","excerpt":"","text":"参考教程https://terminalroot.com/how-to-hide-input-via-cli-with-cpp/?ref=morioh.com&amp;utm_source=morioh.com man信息#include &lt;termios.h&gt;https://pubs.opengroup.org/onlinepubs/7908799/xsh/termios.h.html 举例#include &lt;iostream&gt; #include &lt;termios.h&gt; #include &lt;unistd.h&gt; /* https://man7.org/linux/man-pages/man0/termios.h.0p.html The &lt;termios.h&gt; header shall contain the definitions used by the terminal I/O interfaces (see Chapter 11, General Terminal Interface for the structures and names defined).*/ using namespace std; int main() &#123; string pswd; string stdpswd = &quot;1234&quot;; // set attribute of stdin: hide input pswd termios oldt; tcgetattr(STDIN_FILENO, &amp;oldt); termios newt = oldt; newt.c_lflag &amp;= ~ECHO; // ECHO bit: Enables echo. If this flag is set, characters are echoed as they are received. tcsetattr(STDIN_FILENO, TCSANOW, &amp;newt); // TCSANOW: Change attributes immediately. while (1) &#123; cout &lt;&lt; &quot;Enter password: &quot;; char c; while ((c = getchar()) != EOF &amp;&amp; c != &#39;\\n&#39; &amp;&amp; c != &#39;\\r&#39;) &#123; pswd.push_back(c); &#125; if (feof(stdin)) &#123; cout &lt;&lt; &quot;End of stdin!&quot; &lt;&lt; endl; return 0; &#125; cout &lt;&lt; endl; if (pswd == stdpswd) &#123; break; &#125; pswd.clear(); cout &lt;&lt; &quot;Wrong password.&quot; &lt;&lt; endl; &#125; // recover attribute tcsetattr(STDIN_FILENO, TCSANOW, &amp;oldt); cout &lt;&lt; pswd &lt;&lt; endl; return 0; &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"GNU readline","slug":"GNU readline","date":"2022-07-27T01:49:47.895Z","updated":"2022-12-10T15:13:47.398Z","comments":true,"path":"2022/07/27/GNU readline/","link":"","permalink":"http://example.com/2022/07/27/GNU%20readline/","excerpt":"","text":"自动补全，添加历史https://blog.51cto.com/u_3078781/3287204 自定义换行符https://www.igiftidea.com/article/12962763210.html 官方文档https://web.mit.edu/gnu/doc/html/rlman_2.html 快捷键使用（该库支持的）https://flyyang.me/2017/05/03/GNU-Readline-%E8%AE%A9%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%BE%91%E5%80%8D%E9%80%9F%E6%8F%90%E5%8D%87/","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"git配置","slug":"git配置","date":"2022-07-26T06:20:26.123Z","updated":"2022-12-10T15:13:57.455Z","comments":true,"path":"2022/07/26/git配置/","link":"","permalink":"http://example.com/2022/07/26/git%E9%85%8D%E7%BD%AE/","excerpt":"","text":"写得非常好的官方文档 https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%88%9D%E6%AC%A1%E8%BF%90%E8%A1%8C-Git-%E5%89%8D%E7%9A%84%E9%85%8D%E7%BD%AE 设置当前git仓库提交的用户名和邮箱git config user.name yuanzhiqiu git config user.email zhiqiuyuan@qq.com 检查是否设置成功 git config user.name git config user.email 设置之后则在当前仓库commit的用户名和邮箱即是你设置的这个（这是优先级最高的配置，覆盖比如全局的配置） 查看所有git配置git config --list","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python3调用c++","slug":"python3调用c++","date":"2022-07-25T08:30:57.293Z","updated":"2022-12-10T15:14:32.151Z","comments":true,"path":"2022/07/25/python3调用c++/","link":"","permalink":"http://example.com/2022/07/25/python3%E8%B0%83%E7%94%A8c++/","excerpt":"","text":"https://blog.csdn.net/springlustre/article/details/101177282","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"language","slug":"python/language","permalink":"http://example.com/categories/python/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"linux源码编译安装gcc并添加环境变量","slug":"linux源码编译安装gcc并添加环境变量","date":"2022-07-22T02:00:48.489Z","updated":"2022-12-10T15:15:05.031Z","comments":true,"path":"2022/07/22/linux源码编译安装gcc并添加环境变量/","link":"","permalink":"http://example.com/2022/07/22/linux%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85gcc%E5%B9%B6%E6%B7%BB%E5%8A%A0%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"本例中，下载源码到/home/yuanzhiqiu/built_src/目录下，安装到/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0目录下 1. 获取源码在预计放源码的目录下，比如/home/yuanzhiqiu/built_src/ wget -c http://ftp.gnu.org/gnu/gcc/gcc-9.2.0/gcc-9.2.0.tar.gz tar xzxvf gcc-9.2.0.tar.gz cd gcc-9.2.0 2. 下载依赖gcc源码中提供了可执行文件./contrib/download_prerequisites来干这个事情，./contrib/download_prerequisites --help可以查看使用方法 ./contrib/download_prerequisites # 下载到当前目录下 3. 编译创建和源码目录同级的编译目录gcc-build-9.2.0（创建之后gcc-build-9.2.0和gcc-9.2.0源码目录是同级目录，本例中及都在/home/yuanzhiqiu/built_src/下），在其中执行configure # 目前在gcc-9.2.0源码目录下 mkdir ../gcc-build-9.2.0 # 进入编译目录 cd ../gcc-build-9.2.0 ../gcc-9.2.0/configure --prefix=/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0 --enable-checking=release --enable-languages=c,c++ --disable-multilib # prefix指定你想要安装到的目录 make -j4 &amp;&amp; make install # -j4表示允许4个编译命令同时执行，加速编译过程 4. 配置环境变量在~/.bashrc（/home/yuanzhiqiu/.bashrc）中添加 # 添加到PATH export PATH=/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0/bin:/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0/lib64:$PATH # 添加到LD_LIBRARY_PATH export LD_LIBRARY_PATH=/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0/lib64:/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0/lib:$LD_LIBRARY_PATH # 添加到LD_PRELOAD export LD_PRELOAD=/home/yuanzhiqiu/.local/usr/local/gcc-9.2.0/lib64/libstdc++.so.6 使得在当前shell生效则可以执行： source ~/.bashrc cmake不生效 指定指定版本gcc给cmake命令-D指明变量值： cmake -D CMAKE_C_COMPILER=/home/yuanzhiqiu/.local/usr/local/gcc-9.3.0/bin/gcc -D CMAKE_CXX_COMPILER=/home/yuanzhiqiu/.local/usr/local/gcc-9.3.0/bin/g++ .. 修改CMakeLists.txt定义俩变量似乎没有效果： SET(CMAKE_C_COMPILER /home/yuanzhiqiu/.local/usr/local/gcc-9.3.0/bin/gcc) SET(CMAKE_CXX_COMPILER /home/yuanzhiqiu/.local/usr/local/gcc-9.3.0/bin/g++)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"linux源码编译安装boost库1.56版本","slug":"linux源码编译安装boost库156版本","date":"2022-07-21T05:46:42.173Z","updated":"2022-12-10T15:15:18.668Z","comments":true,"path":"2022/07/21/linux源码编译安装boost库156版本/","link":"","permalink":"http://example.com/2022/07/21/linux%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85boost%E5%BA%93156%E7%89%88%E6%9C%AC/","excerpt":"","text":"1. 获取源码wget -c --no-check-certificate http://sourceforge.net/projects/boost/files/boost/1.56.0/boost_1_56_0.tar.gz #下载源码 tar -xzvf boost_1_56_0.tar.gz #解压源码 cd boost_1_56_0 #进入源码目录 2. 修改bootstrap.sh中的prefix把bootstrap.sh中的 PREFIX=/usr/local 修改为 PREFIX=/home/yuanzhiqiu/.local/usr/local #你希望安装在的目录 3. b2指定prefix./bootstrap.sh ./b2 --prefix=/home/yuanzhiqiu/.local/usr/local/ ./b2 --prefix=/home/yuanzhiqiu/.local/usr/local/ install 可以./b2 --help查看b2的使用方法 4. 修改动态链接库和头文件路径（添加环境变量）安装成功后， 修改动态链接库路径：假设 boost 的动态链接库在/prefix/lib路径下（prefix即上文的在bootstrap.sh中指定的PREFIX和给b2传入的--prefix，与上文一致的举例则为home/yuanzhiqiu/.local/usr/local）：在~/.bashrc中添加如下内容： export LD_LIBRARY_PATH=/prefix/lib:$LD_LIBRARY_PATH 举例： export LD_LIBRARY_PATH=/home/yuanzhiqiu/.local/usr/local/lib:$LD_LIBRARY_PATH 修改头文件路径：假设 boost 的头文件在/prefix/include路径下，则需要执行以下命令： export CPATH=/prefix/include:$CPATH 举例： export CPATH=/home/yuanzhiqiu/.local/usr/local/include:$CPATH","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}]},{"title":"ssh登录退出服务器 跳板服务器 vscode","slug":"ssh登录退出服务器 跳板服务器 vscode","date":"2022-07-20T05:05:07.723Z","updated":"2022-12-10T15:15:30.310Z","comments":true,"path":"2022/07/20/ssh登录退出服务器 跳板服务器 vscode/","link":"","permalink":"http://example.com/2022/07/20/ssh%E7%99%BB%E5%BD%95%E9%80%80%E5%87%BA%E6%9C%8D%E5%8A%A1%E5%99%A8%20%E8%B7%B3%E6%9D%BF%E6%9C%8D%E5%8A%A1%E5%99%A8%20vscode/","excerpt":"","text":"ssh登录退出服务器登录在本机上，想登录服务器 密码登录 ssh &lt;username&gt;@&lt;server_ip&gt; 免密登录（需要先本机生成ssh密匙，然后把其中的公匙传入的~&#x2F;.ssh&#x2F;authorized_keys文件中）（注意，本机是跳板服务器的话，不推荐） ssh -o &quot;PasswordAuthentication no&quot; &lt;username&gt;@&lt;server_ip&gt; 退出已经登录上服务器 logout 退出到登录上服务器的本机 跳板机登录服务器就是ssh登录退出服务器 跳板机免密登录服务器 https://cloud.tencent.com/developer/article/1501977 vscode通过跳板服务器登录服务器 https://blog.51cto.com/u_15127533/4182090","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[]},{"title":"c++并发编程实践2ed：4.3 限时等待","slug":"c++并发编程实践2ed：43 限时等待","date":"2022-07-16T13:27:10.498Z","updated":"2022-12-10T15:15:58.142Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：43 限时等待/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A43%20%E9%99%90%E6%97%B6%E7%AD%89%E5%BE%85/","excerpt":"","text":"4.3 限时等待阻塞调用会将线程挂起一段(不确定的)时间，直到相应的事件发生。通常情况下，这样的方式很不错，但是在一些情况下，需要限定线程等待的时间。可以发送一些类似“我还存活”的信息，无论是对交互式用户，或是其他进程，亦或当用户放弃等待，也可以按下“取消”键终止等待。 这里介绍两种指定超时方式：一种是“时间段”，另一种是“时间点”。第一种方式，需要指定一段时间(例如，30毫秒)。第二种方式，就是指定一个时间点(例如，世界标准时间[UTC]17:30:15.045987023，2011年11月30日)。多数等待函数提供变量，对两种超时方式进行处理。处理持续时间的变量以_for作为后缀，处理绝对时间的变量以_until作为后缀。 所以，std::condition_variable的两个成员函数wait_for()和wait_until()成员函数分别有两个重载，这两个重载都与wait()成员函数的重载相关——其中一个只是等待信号触发，或超期，亦或伪唤醒，并且醒来时会使用谓词检查锁，并且只有在校验为true时才会返回(这时条件变量的条件达成)，或直接超时。 观察使用超时函数的细节前，我们来检查一下在C++中指定时间的方式，就从“时钟”开始吧！ 4.3.1 时钟 std::chrono对于C++标准库来说，时钟就是时间信息源。并且，时钟是一个类，提供了四种不同的信息： 当前时间 时间类型 时钟节拍 稳定时钟 当前时间可以通过静态成员函数now()从获取。例如，**std::chrono::system_clock::now()会返回系统的当前时间。特定的时间点可以通过time_point**的typedef成员来指定，所以some_clock::now()的类型就是some_clock::time_point。 时钟节拍被指定为1&#x2F;x(x在不同硬件上有不同的值)秒，这是由时间周期所决定——一个时钟一秒有25个节拍，因此一个周期为std::ratio&lt;1, 25&gt;，当一个时钟的时钟节拍每2.5秒一次，周期就可以表示为std::ratio&lt;5, 2&gt;。当时钟节拍在运行时获取时，可以使用给定的应用程序运行多次，用执行的平均时间求出，其中最短的时间可能就是时钟节拍，或者是写在手册当中，这就不保证在给定应用中观察到的节拍周期与指定的时钟周期是否相匹配。 当时钟节拍均匀分布(无论是否与周期匹配)，并且不可修改，这种时钟就称为稳定时钟。is_steady静态数据成员为true时，也表明这个时钟就是稳定的。通常情况下，因为std::chrono::system_clock可调，所以是不稳定的。这可调可能造成首次调用now()返回的时间要早于上次调用now()所返回的时间，这就违反了节拍频率的均匀分布。稳定闹钟对于计算超时很重要，所以C++标准库提供一个稳定时钟std::chrono::steady_clock。C++标准库提供的其他时钟可表示为std::chrono::system_clock，代表了系统时钟的“实际时间”，并且提供了函数，可将时间点转化为time_t类型的值。std::chrono::high_resolution_clock 可能是标准库中提供的具有最小节拍周期(因此具有最高的精度)的时钟。它实际上是typedef的另一种时钟，这些时钟和与时间相关的工具，都在**&lt;chrono&gt;库**头文件中定义。 我们先看一下时间段是怎么表示的。 4.3.2 时间段 std::chrono时间部分最简单的就是时间段，std::chrono::duration&lt;&gt;函数模板能够对时间段进行处理(线程库使用到的所有C++时间处理工具，都在std::chrono命名空间内)。第一个模板参数是一个类型表示(比如，int，long或double)，第二个模板参数是定制部分，表示每一个单元所用秒数。例如，当几分钟的时间要存在short类型中时，可以写成std::chrono::duration&lt;short, std::ratio&lt;60, 1&gt;&gt;(60s累加1次)，因为60秒是才是1分钟，所以第二个参数写成std::ratio&lt;60, 1&gt;。当需要将毫秒级计数存在double类型中时，可以写成std::chrono::duration&lt;double, std::ratio&lt;1, 1000&gt;&gt;(1s累加1000次)，因为1秒等于1000毫秒。 标准库在std::chrono命名空间内为时间段变量提供一系列预定义类型：**nanoseconds[纳秒] , microseconds[微秒] , milliseconds[毫秒] , seconds[秒] , minutes[分]和hours[时]**。比如，你要在一个合适的单元表示一段超过500年的时延，预定义类型可充分利用了大整型，来表示所要表示的时间类型。当然，这里也定义了一些国际单位制(SI, [法]le Système international d’unités)分数，可从std::atto(10^(-18))到std::exa(10^(18))(题外话：当你的平台支持128位整型)，也可以指定自定义时延类型。例如：std::duration&lt;double, std::centi&gt;，就可以使用一个double类型的变量表示1&#x2F;100。 方便起见，C++14中**std::chrono_literals命名空间中有许多预定义的后缀操作符**用来表示时长。下面的代码就是使用硬编码的方式赋予变量具体的时长： using namespace std::chrono_literals; auto one_day=24h; auto half_an_hour=30min; auto max_time_between_messages=30ms; 使用整型字面符时，15ns和std::chrono::nanoseconds(15)就是等价的。不过，当使用浮点字面量时，且未指明表示类型时，数值上会对浮点时长进行适当的缩放。因此，2.5min会被表示为std::chrono::duration&lt;some-floating-point-type,std::ratio&lt;60,1&gt;&gt;。如果非常关心所选的浮点类型表示的范围或精度，就需要构造相应的对象来保证表示范围或精度，而不是去苛求字面值来对范围或精度进行表达。 当不要求截断值（即会舍入）的情况下(时转换成秒是没问题，但是秒转换成时就不行)时间段的转换是隐式的，显示转换可以由**std::chrono::duration_cast&lt;&gt;**来完成。 std::chrono::milliseconds ms(54802); std::chrono::seconds s= std::chrono::duration_cast&lt;std::chrono::seconds&gt;(ms); 这里的结果就是截断的，而不是进行了舍入，所以s最后的值为54。 时间值支持四则运算，所以能够对两个时间段进行加减，或者是对一个时间段乘除一个常数(模板的第一个参数)来获得一个新时间段变量。例如，5seconds(1)与seconds(5)或minutes(1)-seconds(55)是一样。在时间段中可以通过count()成员函数获得单位时间的数量。例如，*std::chrono::milliseconds(1234).count()就是1234**。 基于时间段的等待可由std::chrono::duration&lt;&gt;来完成。例如：等待future状态变为就绪需要35毫秒： std::future&lt;int&gt; f=std::async(some_task); if(f.wait_for(std::chrono::milliseconds(35))==std::future_status::ready) do_something_with(f.get()); 等待函数会返回状态值，表示是等待是超时，还是继续等待。等待future时，超时时会返回std::future_status::timeout。当future状态改变，则会返回std::future_status::ready。当与future相关的任务延迟了，则会返回std::future_status::deferred。基于时间段的等待使用稳定时钟来计时，所以这里的35毫秒不受任何影响。当然，系统调度的不确定性和不同操作系统的时钟精度意味着：线程调用和返回的实际时间间隔可能要比35毫秒长。 现在，来看看“时间点”如何工作。 4.3.3 时间点时间点可用**std::chrono::time_point&lt;&gt;来表示，第一个参数用来指定使用的时钟，第二个函数参数用来表示时间单位**(特化的std::chrono::duration&lt;&gt;)。时间点就是时间戳，而时间戳是时钟的基本属性，不可以直接查询，其在C++标准中已经指定。通常，UNIX时间戳表示1970年1月1日 00:00。时钟可能共享一个时间戳，或具有独立的时间戳。当两个时钟共享一个时间戳时，其中一个time_point类型可以与另一个时钟类型中的time_point相关联。虽然不知道UNIX时间戳的具体值，但可以通过对指定time_point类型使用time_since_epoch()来获取时间戳，该成员函数会返回一个数值，这个数值是指定时间点与UNIX时间戳的时间间隔。 例如，指定一个时间点std::chrono::time_point&lt;std::chrono::system_clock, std::chrono::minutes&gt;，这就与系统时钟有关，且实际中的一分钟与系统时钟精度应该不相同(通常差几秒)。 可以通过对std::chrono::time_point&lt;&gt;实例进行加&#x2F;减，来获得一个新的时间点，所以std::chrono::hight_resolution_clock::now() + std::chrono::nanoseconds(500)将得到500纳秒后的时间，这对于计算绝对时间来说非常方便。 也可以减去一个时间点(二者需要共享同一个时钟)，结果是两个时间点的时间差。这对于代码块的计时是很有用的，例如： auto start=std::chrono::high_resolution_clock::now(); do_something(); auto stop=std::chrono::high_resolution_clock::now(); std::cout&lt;&lt;&quot;do_something() took &quot; &lt;&lt;std::chrono::duration&lt;double,std::chrono::seconds&gt;(stop-start).count() &lt;&lt;&quot; seconds&quot;&lt;&lt;std::endl; std::chrono::time_point&lt;&gt;的时钟参数不仅能够指定UNIX时间戳。当等待函数(绝对时间超时)传递时间点时，时间点参数就可以用来测量时间。当时钟变更时，会产生严重的后果，因为等待轨迹随着时钟的改变而改变，并且直到调用now()成员函数时，才能返回一个超过超时时间的值。 后缀为_unitl的(等待函数的)变量会使用时间点。通常是使用时钟的::now()(程序中一个固定的时间点)作为偏移，虽然时间点与系统时钟有关，可以使用std::chrono::system_clock::to_time_point()静态成员函数，对时间点进行操作。 代码4.11 等待条件变量满足条件——有超时功能 #include &lt;condition_variable&gt; #include &lt;mutex&gt; #include &lt;chrono&gt; std::condition_variable cv; bool done; std::mutex m; bool wait_loop() &#123; auto const timeout= std::chrono::steady_clock::now()+ std::chrono::milliseconds(500); std::unique_lock&lt;std::mutex&gt; lk(m); while(!done) &#123; if(cv.wait_until(lk,timeout)==std::cv_status::timeout) break; &#125; return done; &#125; 当没有什么可以等待时，可在一定时限中等待条件变量。这种方式中，循环的整体长度有限。4.1.1节中当使用条件变量时，就使用了循环，这是为了处理假唤醒。当循环中使用wait_for()时，可能在等待了足够长的时间后结束等待(在假唤醒之前)，且下一次等待又开始了。这可能重复很多次，出现无限等待的情况。 至此，有关时间点的基本知识已经了解差不多了。现在，让我们来了解一下如何在函数中使用超时。 4.3.4 使用超时使用超时的最简单方式，就是对特定线程添加延迟处理。当线程无所事事时，就不会占用其他线程的处理时间。4.1节中的例子，循环检查“done”标志，两个处理函数分别是**std::this_thread::sleep_for()和std::this_thread::sleep_until()**。它们的工作就像一个简单的闹钟：当线程因为指定时长而进入睡眠时，可使用sleep_for()唤醒，可指定休眠的时间点，之后可使用sleep_until唤醒。sleep_for()的使用和4.1节一样，有些事必须在指定时间内完成，所以耗时就很敏感。另一方面，sleep_until()允许在某个特定时间点将调度线程唤醒。可能在晚间备份或在早上6:00打印工资条时使用，亦或挂起线程直到下一帧刷新时进行视频播放。 当然，休眠只是超时处理的一种形式，超时可以配合条件变量和future一起使用。超时甚至可以在获取互斥锁时(当互斥量支持超时时)使用。std::mutex和std::recursive_mutex都不支持超时，而std::timed_mutex和std::recursive_timed_mutex支持超时。这两种类型也有try_lock_for()和try_lock_until()成员函数，可以在一段时期内尝试获取锁，或在指定时间点前获取互斥锁。表4.1展示了C++标准库中支持超时的函数。参数列表为“延时”(duration)必须是std::duration&lt;&gt;的实例，并且列出为时间点(time_point)必须是std::time_point&lt;&gt;的实例。 表4.1 可接受超时的函数 类型/命名空间 函数 返回值 std::this_thread 命名空间 sleep_for(duration) N/A sleep_until(time_point) std::condition_variable 或 std::condition_variable_any wait_for(lock, duration) std::cv_status::time_out 或 std::cv_status::no_timeout wait_until(lock, time_point) wait_for(lock, duration, predicate) bool —— 当唤醒时，返回谓词的结果 wait_until(lock, duration, predicate) std::timed_mutex 或 std::recursive_timed_mutex try_lock_for(duration) bool —— 获取锁时返回true，否则返回fasle try_lock_until(time_point) std::unique_lock&lt;TimedLockable&gt; unique_lock(lockable, duration) N/A —— 对新构建的对象调用owns_lock(); unique_lock(lockable, time_point) 当获取锁时返回true，否则返回false try_lock_for(duration) bool —— 当获取锁时返回true，否则返回false try_lock_until(time_point) std::future&lt;ValueType&gt;或std::shared_future&lt;ValueType&gt; wait_for(duration) 当等待超时，返回std::future_status::timeout wait_until(time_point) 当期望值准备就绪时，返回std::future_status::ready 当期望值持有一个为启动的延迟函数，返回std::future_status::deferred 现在，我们讨论过的机制有：条件变量、future、promise，还有打包任务。是时候从更高的角度去看待这些机制，以及如何使用这些机制简化线程的同步操作。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：4.2 使用future","slug":"c++并发编程实践2ed：42 使用future","date":"2022-07-16T13:25:51.790Z","updated":"2022-12-10T15:16:10.360Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：42 使用future/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A42%20%E4%BD%BF%E7%94%A8future/","excerpt":"","text":"4.2 使用futurestd::future &#96;头文件 std::future&lt;&gt; 可移动不可拷贝（构造函数和赋值重载操作符） An asynchronous operation (created via std::async, std::packaged_task, or std::promise) can provide a std::future object to the creator of that asynchronous operation. The creator of the asynchronous operation can then use a variety of methods to query, wait for, or extract a value from the std::future. These methods may block if the asynchronous operation has not yet provided a value. When the asynchronous operation is ready to send a result to the creator, it can do so by modifying shared state (e.g. std::promise::set_value) that is linked to the creator’s std::future. 假设你要乘飞机去国外度假，当到达机场办理完各种登机手续后，还需要等待机场广播通知登机。这段时间内，你可能会在候机室里面找一些事情来打发时间，比如：读书，上网，或者来一杯咖啡。不过，你就在等待一件事情：机场广播通知登机。 C++标准库将这种事件称为future。当线程需要等待特定事件时，某种程度上来说就需要知道期望的结果。之后，线程会周期性(较短的周期)的等待或检查事件是否触发(检查信息板)，检查期间也会执行其他任务(品尝昂贵的咖啡)。另外，等待任务期间也可以先执行另外的任务，直到对应的任务触发，而后等待future的状态会变为就绪状态。future可能是和数据相关(比如，登机口编号)，也可能不是。当事件发生时(状态为就绪)，这个future就不能重置了。 C++标准库中有两种future，声明在**&lt;future&gt;头文件**中: unique future(std::future&lt;&gt;)和shared futures(std::shared_future&lt;&gt;)，与了std::unique_ptr和std::shared_ptr非常类似。std::future只能与指定事件相关联，而std::shared_future就能关联多个事件。后者的实现中，所有实例会在同时变为就绪状态，并且可以访问与事件相关的数据。这种关联与模板有关，比如std::unique_ptr 和std::shared_ptr的模板参数就是相关的数据类型。与数据无关处的，可以使用std::future&lt;void&gt;与std::shared_future&lt;void&gt;的特化模板。虽然，我倾向于线程通讯，但future对象本身并不提供同步访问。当多个线程需要访问一个独立future对象时，必须使用互斥量或类似同步机制进行保护。不过，当多个线程对一个std::shared_future&lt;&gt;副本进行访问，即使同一个异步结果，也不需要同步future。 并行技术规范将这两个模板类在std::experimental命名空间中进行了扩展：std::experimental::future&lt;&gt;和std::experimental::shared_future&lt;&gt; 。这个命名空间是为了将其与std命名空间中的模板类进行区分，实验命名空间中为这两个模板类添加了更多的功能。尤其是std::experimental中的内容与代码质量无关(我希望这里也会有较高质量的实现)，需要强调的是这个命名空间提供的都不是标准类和函数，这个命名空间中类和函数的语法和语义，很可能与纳入C++标准(也就是std命名空间)后有所不同。如果想要使用这两个试验性的模板类，需要包含&lt;experimental/future&gt;头文件。 最简单的事件，就是在后台运行的计算操作。第2章中已经清楚了std::thread 执行的任务不能有返回值，不过这个问题能使用future进行解决。 4.2.1 后台任务的返回值 std::async std::async 模板函数 构造函数：（六个，两种） async( Function&amp;&amp; f, Args&amp;&amp;… args ); async( std::launch policy, Function&amp;&amp; f, Args&amp;&amp;… args ); 概述：runs the function f asynchronously (potentially in a separate thread which might be a part of a thread pool) and returns a std::future that will eventually hold the result of that function call. policy： std::launch::async：executes the callable object f on a new thread of execution (with all thread-locals initialized) as if spawned by std::thread(std::forward(f), std::forward(args)…), except that if the function f returns a value or throws an exception, it is stored in the shared state accessible through the std::future that async returns to the caller. If the deferred flag is set (i.e. (policy &amp; std::launch::deferred) !&#x3D; 0)：converts f and args... the same way as by std::thread constructor, but does not spawn a new thread of execution. Instead, lazy evaluation is performed: the first call to a non-timed wait function on the std::future that async returned to the caller will cause the copy of f to be invoked (as an rvalue) with the copies of args... (also passed as rvalues) in the current thread（对这个std::future调用non-timed wait function的线程） (which does not have to be the thread that originally called std::async). The result or exception is placed in the shared state associated with the future and only then it is made ready. All further accesses to the same std::future will return the result immediately. If more than one flag is set, it is implementation-defined which policy is selected. For the default (both the std::launch::async and std::launch::deferred flags are set in policy), standard recommends (but doesn’t require) utilizing available concurrency, and deferring any additional tasks. 关于其中std::future的析构： If the std::future obtained from std::async is not moved from or bound to a reference, the destructor of the std::future will block at the end of the full expression until the asynchronous operation completes, essentially making code such as the following synchronous: std::async(std::launch::async, []&#123; f(); &#125;); // temporary&#39;s dtor waits for f() std::async(std::launch::async, []&#123; g(); &#125;); // does not start until f() completes 假设有一个需要长时间的运算，需要计算出一个有效值，但并不迫切需要这个值。你可以启动新线程来执行这个计算，你需要计算的结果，而std::thread并不提供直接接收返回值的机制。这里就需要**std::async函数模板(也是在头文件&lt;future&gt;**)。 当不着急让任务结果时，可以使用**std::async启动一个异步任务。与std::thread对象等待的方式不同，std::async会返回一个std::future对象，这个对象持有最终计算出来的结果。当需要这个值时，只需要调用这个对象的get()成员函数，就会阻塞（调用）线程直到future为就绪为止**，并返回计算结果。 代码4.6 std::future从异步任务中获取返回值 #include &lt;future&gt; #include &lt;iostream&gt; int find_the_answer_to_ltuae(); void do_other_stuff(); int main() &#123; std::future&lt;int&gt; the_answer=std::async(find_the_answer_to_ltuae); do_other_stuff(); std::cout&lt;&lt;&quot;The answer is &quot;&lt;&lt;the_answer.get()&lt;&lt;std::endl; &#125; 与std::thread方式一样，std::async允许通过添加额外的调用参数，向函数传递额外的参数。第一个参数是指向成员函数的指针，第二个参数提供这个函数成员类的具体对象(是通过指针，也可以包装在std::ref中)，剩余的参数可作为函数的参数传入。否则，第二个和随后的参数将作为函数的参数，或作为指定可调用对象的第一个参数。和std::thread一样，当参数为右值时，拷贝操作将使用移动的方式转移原始数据，就可以使用“只移动”类型作为函数对象和参数。 代码4.7 使用std::async向函数传递参数 #include &lt;string&gt; #include &lt;future&gt; struct X &#123; void foo(int,std::string const&amp;); std::string bar(std::string const&amp;); &#125;; X x; auto f1=std::async(&amp;X::foo,&amp;x,42,&quot;hello&quot;); // 调用p-&gt;foo(42, &quot;hello&quot;)，p是指向x的指针 auto f2=std::async(&amp;X::bar,x,&quot;goodbye&quot;); // 调用tmpx.bar(&quot;goodbye&quot;)， tmpx是x的拷贝副本 struct Y &#123; double operator()(double); &#125;; Y y; auto f3=std::async(Y(),3.141); // 调用tmpy(3.141)，tmpy通过Y的移动构造函数得到 auto f4=std::async(std::ref(y),2.718); // 调用y(2.718) X baz(X&amp;); std::async(baz,std::ref(x)); // 调用baz(x) class move_only &#123; public: move_only(); move_only(move_only&amp;&amp;) move_only(move_only const&amp;) = delete; move_only&amp; operator=(move_only&amp;&amp;); move_only&amp; operator=(move_only const&amp;) = delete; void operator()(); &#125;; auto f5=std::async(move_only()); // 调用tmp()，tmp是通过std::move(move_only())构造得到 future的等待取决于std::async是否启动一个线程，或是否有任务在进行同步。大多数情况下，也可以在函数调用之前向std::async传递一个额外参数，这个参数的类型是std::launch，还可以是std::launch::defered，表明函数调用延迟到wait()或get()函数调用时才执行，**std::launch::async表明函数必须在独立线程上执行，std::launch::deferred | std::launch::async表明实现可以选择这两种方式的一种**（“ If more than one flag is set, it is implementation-defined which policy is selected.”）。最后一个选项（std::launch::deferred | std::launch::async）是默认的，当函数调用延迟，就可能不会再运行了。如下所示： auto f6=std::async(std::launch::async,Y(),1.2); // 在新线程上执行 auto f7=std::async(std::launch::deferred,baz,std::ref(x)); // 在wait()或get()调用时执行 auto f8=std::async( std::launch::deferred | std::launch::async, baz,std::ref(x)); // 实现选择执行方式 auto f9=std::async(baz,std::ref(x)); f7.wait(); // 调用延迟函数 本章的后续小节和第8章中，会再次看到这段程序，使用std::async会将算法分割到各个任务中，这样程序就能并发了。不过，这不是让std::future与任务实例相关联的唯一方式，也可以将任务包装入std::packaged_task&lt;&gt;中，或通过编写代码的方式，使用std::promise&lt;&gt;模板显式设置值。与std::promise&lt;&gt;相比，std::packaged_task&lt;&gt;具有更高的抽象，所以我们从“高抽象”模板说起。 4.2.2 future与任务关联 std::packaged_task std::packaged_task&lt;&gt; 可移动不可拷贝 概述：The class template std::packaged_task wraps any Callable target (function, lambda expression, bind expression, or another function object) so that it can be invoked asynchronously. Its return value or exception thrown is stored in a shared state which can be accessed through std::future objects. (args)重载函数：Calls the stored task with args as the arguments（在调用这个重载函数的线程中执行）. The return value of the task or any exceptions thrown are stored in the shared state. The shared state is made ready and any threads waiting for this are unblocked. std::packaged_task&lt;&gt;会将future与函数或可调用对象进行绑定。当调用std::packaged_task&lt;&gt;对象时，就会调用相关函数或可调用对象，（并且返回值作为异步结果存储在std::future中）当future状态为就绪时，会存储返回值。这可以用在构建线程池(可见第9章)或其他任务的管理中，比如：在任务所在线程上运行其他任务，或将它们串行运行在一个特殊的后台线程上。当粒度较大的操作被分解为独立的子任务时，每个子任务都可以包含在std::packaged_task&lt;&gt;实例中，之后将实例传递到任务调度器或线程池中。对任务细节进行抽象，调度器仅处理std::packaged_task&lt;&gt;实例，而非处理单独的函数。 std::packaged_task&lt;&gt;的模板参数是一个函数签名，比如void()就是一个没有参数也没有返回值的函数，或int(std::string&amp;, double*)就是有一个非const引用的std::string参数和一个指向double类型的指针参数，并且返回类型是int。构造std::packaged_task&lt;&gt;实例时，就必须传入函数或可调用对象。这个函数或可调用的对象，需要能接收指定的参数和返回(可转换为指定返回类型的)值。类型可以不完全匹配，因为这里类型可以隐式转换，可以用int类型参数和返回float类型的函数，来构建std::packaged_task&lt;double(double)&gt;实例。 函数签名的返回类型可以用来标识从get_future()返回的std::future&lt;&gt;的类型，而函数签名的参数列表，可用来指定packaged_task的函数调用操作符。例如，模板偏特化std::packaged_task&lt;std::string(std::vector&lt;char&gt;*,int)&gt;会在下面的代码中使用到。 代码4.8 std::packaged_task&lt;&gt;的偏特化 template&lt;&gt; class packaged_task&lt;std::string(std::vector&lt;char&gt;*,int)&gt; &#123; public: template&lt;typename Callable&gt; explicit packaged_task(Callable&amp;&amp; f); std::future&lt;std::string&gt; get_future(); void operator()(std::vector&lt;char&gt;*,int); &#125;; std::packaged_task是个可调用对象，可以封装在std::function对象中，从而作为线程函数传递到std::thread对象中，或作为可调用对象传递到另一个函数中或直接调用。当std::packaged_task作为函数调用时，实参将由函数调用操作符传递至底层函数，并且返回值作为异步结果存储在std::future中，并且**可通过get_future()获取(获取future对象)**。因此可以用std::packaged_task对任务进行打包，并适时的取回future。当异步任务需要返回值时，可以等待future状态变为“就绪”。 线程间传递任务 很多图形架构需要特定的线程去更新界面，所以当线程对界面更新时，需要发出一条信息给正确的线程，让相应的线程来做界面更新。std::packaged_task提供了这种功能，且不需要发送一条自定义信息给图形界面线程。 代码4.9 使用std::packaged_task执行一个图形界面线程 #include &lt;deque&gt; #include &lt;mutex&gt; #include &lt;future&gt; #include &lt;thread&gt; #include &lt;utility&gt; std::mutex m; std::deque&lt;std::packaged_task&lt;void()&gt; &gt; tasks; bool gui_shutdown_message_received(); void get_and_process_gui_message(); void gui_thread() // 1 &#123; //没有关闭gui的情况下，不断尝试从队首取任务 while(!gui_shutdown_message_received()) // 2 &#123; get_and_process_gui_message(); // 3 std::packaged_task&lt;void()&gt; task; &#123; //这里设置一个scope的目的是std::lock_guard&lt;std::mutex&gt;对象离开作用域时析构解锁 std::lock_guard&lt;std::mutex&gt; lk(m); if(tasks.empty()) // 4 continue; //对于while循环的continue task=std::move(tasks.front()); // 5 调用std::packaged_task&lt;void()&gt;的移动赋值重载函数 tasks.pop_front(); &#125; task(); // 6 &#125; &#125; std::thread gui_bg_thread(gui_thread); //将任务传入队列 template&lt;typename Func&gt; std::future&lt;void&gt; post_task_for_gui_thread(Func f) &#123; std::packaged_task&lt;void()&gt; task(f); // 7 std::future&lt;void&gt; res=task.get_future(); // 8 std::lock_guard&lt;std::mutex&gt; lk(m); tasks.push_back(std::move(task)); // 9 return res; // 10 &#125; 代码十分简单：图形界面线程①循环直到收到一条关闭图形界面的信息后关闭界面②。关闭界面前，进行轮询界面消息处理③，例如：用户点击和执行在队列中的任务。当队列中没有任务④时，循环将继续。除非能在队列中提取出一个任务⑤，释放队列上的锁，并且执行任务⑥。这里future与任务相关，当任务执行完时，其状态会置为“就绪”。 将任务传入队列：提供的函数⑦可以提供一个打包好的任务，通过这个任务⑧调用get_future()成员函数获取future对象，并且在任务推入列表⑨之前，future将返回调用函数⑩。 例子中使用std::packaged_task&lt;void()&gt;创建任务，其中包含了一个无参数无返回值的函数或可调用对象(如果当这个调用有返回值时，返回值会被丢弃)。这可能是最简单的任务，std::packaged_task也可以用于复杂的情况——通过指定不同的函数签名作为模板参数，不仅可以改变其返回类型(因此该类型的数据会存在期望相关的状态中)，也可以改变函数操作符的参数类型。这个例子可以简单的扩展成允许任务运行在图形界面线程上，并且接受传参，还可以通过std::future获取返回值。 这些任务能作为简单的函数调用来表达吗？还有，任务的结果能从很多地方得到吗？这些问题可以使用第三种方法创建future来解决：使用std::promise对值进行显示设置。 4.2.3 使用std::promise std::promise 可移动不可拷贝 A promise may do three things with the shared state（那个与这个promise对象相关联的std::future）: make ready: the promise stores the result or the exception in the shared state. Marks the state ready and unblocks any thread waiting on a future associated with the shared state. release: the promise gives up its reference to the shared state. If this was the last such reference, the shared state is destroyed. Unless this was a shared state created by std::async which is not yet ready, this operation does not block. abandon: the promise stores the exception of type std::future_error with error code std::future_errc::broken_promise, makes the shared state ready, and then releases it. The promise is the “push” end of the promise-future communication channel: the operation that stores a value in the shared state synchronizes-with (as defined in std::memory_order) the successful return from any function that is waiting on the shared state (such as std::future::get). Concurrent access to the same shared state may conflict otherwise: for example multiple callers of std::shared_future::get must either all be read-only or provide external synchronization. 当需要处理很多网络连接时，会使用不同线程尝试连接每个接口，能使网络尽早联通。不幸的是，随着连接数量的增长，这种方式变的越来越不合适。因为大量的线程会消耗大量的系统资源，还有可能造成线程上下文频繁切换(当线程数量超出硬件可接受的并发数时)，这都会对性能有影响。最极端的例子：线程会将系统资源消耗殆尽，系统连接网络的能力会变的极差。因此通过少数线程处理网络连接，每个线程同时处理多个连接，对需要处理大量网络连接的应用而言，这是一种比较普遍的做法。 当线程处理多个连接事件，来自不同的端口连接的数据包基本上以乱序方式进行处理。同样的，数据包也将以乱序的方式进入队列。很多情况下，一些应用不是等待数据成功的发送，就是等待(新的)指定网络接口数据的接收成功。 std::promise&lt;T&gt;提供设定值的方式(类型为T)，这个类型会和后面看到的std::future&lt;T&gt;对象相关联。std::promise/std::future对提供一种机制：future可以阻塞等待线程，提供数据的线程可以使用promise对相关值进行设置，并将future的状态置为“就绪”。 可以通过给定的**std::promise的get_future()成员函数来获取与之相关的std::future对象，与std::packaged_task的用法类似。当promise设置完毕(使用set_value()成员函数)时，对应的future状态就变为“就绪”，并且可用于检索已存储的值。当设置值之前销毁std::promise，将会存储一个异常**。在4.2.4节中，会详细描述异常是如何传送到线程的。 代码4.10中是单线程处理多接口的实现，这个例子中，可以使用一对std::promise&lt;bool&gt;/std::future&lt;bool&gt;找出传出成功的数据块，与future相关的只是简单的“成功&#x2F;失败”标识。对于传入包，与future相关的数据就是数据包的有效负载。 代码4.10 使用promise解决单线程多连接问题 #include &lt;future&gt; void process_connections(connection_set&amp; connections) &#123; while(!done(connections)) // 1 &#123; //依次的检查每个连接 for(connection_iterator // 2 connection=connections.begin(),end=connections.end(); connection!=end; ++connection) &#123; if(connection-&gt;has_incoming_data()) // 3 &#123; data_packet data=connection-&gt;incoming(); std::promise&lt;payload_type&gt;&amp; p= connection-&gt;get_promise(data.id); // 4 获取引用 p.set_value(data.payload); //set_value &#125; if(connection-&gt;has_outgoing_data()) // 5 &#123; outgoing_packet data= connection-&gt;top_of_outgoing_queue(); connection-&gt;send(data.payload); data.promise.set_value(true); // 6 表明传输成功 set_value &#125; &#125; &#125; &#125; process_connections()中(直到done()返回true①为止)每一次循环，都会依次的检查每个连接②，检索是否有数据③或正在发送已入队的传出数据⑤。假设输入数据包是具有ID和有效负载的(有实际的数在其中)，一个ID映射到一个std::promise(可能是在相关容器中进行的依次查找)④，并且值是在包的有效负载中。传出包是在传出队列中检索，从接口直接发送出去。当发送完成，传出数据相关的promise将置为true，来表明传输成功⑥。是否能映射到实际网络协议上，取决于所用协议。 上面的代码不理会异常，一切工作都会很好的执行，但有悖常理。有时候磁盘满载，有时候会找不到东西，有时候网络会断，还有时候数据库会崩溃。当需要某个操作的结果时，就需要在对应的线程上执行这个操作，因为代码可以通过异常来报告错误。不过，这会对使用std::packaged_task或std::promise带来一些不必要的限制。因此，C++标准库提供了一种在以上情况下清理异常的方法，并且允许将异常存储为相关结果的一部分。 4.2.4 将异常存与future中看完下面的代码段，思考一下：当你传递-1到square_root()中时，它将抛出一个异常，并且你想让调用者看到这个异常： double square_root(double x) &#123; if(x&lt;0) &#123; throw std::out_of_range(&quot;x&lt;0&quot;); &#125; return sqrt(x); &#125; 假设调用square_root()函数不是当前线程， double y=square_root(-1); 将调用改为异步调用： std::future&lt;double&gt; f=std::async(square_root,-1); double y=f.get(); 当y获得函数调用的结果，线程调用f.get()时，就能再看到异常了。 函数作为**std::async的一部分时，当调用抛出一个异常时，这个异常就会存储到future中，之后future的状态置为“就绪”，之后调用get()会抛出已存储的异常**(注意：标准级别没有指定重新抛出的这个异常是原始的异常对象，还是一个拷贝。不同的编译器和库将会在这方面做出不同的选择)。将函数打包入std::packaged_task任务包后，当任务调用时，同样的事情也会发生。打包函数抛出一个异常，这个异常将存储在future中，在get()调用时会再次抛出。 当然，通过函数的显式调用，std::promise也能提供同样的功能。当存入的是异常而非数值时，就需要调用set_exception()成员函数，而非set_value()。这通常是用在一个catch块中，并作为算法的一部分。为了捕获异常，这里使用异常填充promise： extern std::promise&lt;double&gt; some_promise; try &#123; some_promise.set_value(calculate_value()); &#125; catch(...) &#123; some_promise.set_exception(std::current_exception()); //set_exception &#125; 这里使用std::current_exception()来检索抛出的异常，可用std::copy_exception()作为替代方案，std::copy_exception()会直接存储新的异常而不抛出： some_promise.set_exception(std::copy_exception(std::logic_error(&quot;foo &quot;))); 这比使用try&#x2F;catch块更加清晰，当异常类型已知，就应该优先使用。不是因为代码实现简单，而是给编译器提供了极大的优化空间。 另一种向future中存储异常的方式，在没有调用promise上的任何设置函数前，或正在调用包装好的任务时，销毁与std::promise或std::packaged_task相关的future对象。任何情况下，当future的状态还不是“就绪”时，调用std::promise或std::packaged_task的析构函数，将会存储一个与std::future_errc::broken_promise错误状态相关的std::future_error异常。通过创建一个future，可以构造一个promise为其提供值或异常，也可以通过销毁值和异常源，去违背promise。这种情况下，编译器没有在future中存储任何东西，线程可能会永远的等下去。 现在，例子中都在用std::future，不过std::future也有局限性。很多线程在等待的时候，只有一个线程能获取结果。当多个线程等待相同事件的结果时，就需要使用std::shared_future来替代std::future了。 4.2.5 多个线程的等待 std::shared_future std::shared_future 可拷贝 虽然std::future可以处理所有在线程间数据转移的同步，但是调用某一特殊 std::future对象的成员函数，就会让这个线程的数据和其他线程的数据不同步。多线程在没有额外同步的情况下，访问独立std::future对象时，就会有数据竞争和未定义行为。因为std::future独享同步结果，并且通过调用get()函数，一次性的获取数据，这就让并发访问变的毫无意义。 如果并行代码没办法让多个线程等待同一个事件，std::shared_future可以帮你解决这个问题。因为**std::future是只移动的，所以其所有权可以在不同的实例中互相传递，但只有一个实例可以获得特定的同步结果，而std::shared_future实例是可拷贝的**，所以多个对象可以引用同一关联期望值的结果。 每一个std::shared_future的独立对象上，成员函数调用返回的结果还是不同步的，所以为了在多个线程访问一个独立对象时避免数据竞争，必须使用锁来对访问进行保护。优先使用的办法：为了替代只有一个拷贝对象的情况，可以让每个线程都拥有自己对应的拷贝对象。这样，当每个线程都通过自己拥有的std::shared_future对象获取结果，那么多个线程访问共享同步结果就是安全的。可见图4.1。 图4.1 使用多个std::shared_future对象来避免数据竞争 可能会使用std::shared_future的场景，例如：实现类似于复杂的电子表格的并行执行，每一个单元格有唯一终值，这个终值可能由其他单元格中的数据通过公式计算得到。公式计算得到的结果依赖于其他单元格，然后可以使用std::shared_future对象引用第一个单元格的数据。当每个单元格内的所有公式并行执行后，任务会以期望的方式完成工作。不过，当其中有计算需要依赖其他单元格的值时就会阻塞，直到依赖单元格的数据准备就绪。这可以让系统在最大程度上使用硬件并发。 std::shared_future的实例同步std::future实例的状态。当std::future对象没有与其他对象共享同步状态所有权，那么所有权必须使用std::move将所有权传递到std::shared_future，其默认构造函数如下： std::promise&lt;int&gt; p; std::future&lt;int&gt; f(p.get_future()); //把p内部的future转移给f，即f现在是p内部的future assert(f.valid()); // 1 期望值 f 是合法的 std::shared_future&lt;int&gt; sf(std::move(f)); //移动语义的std::shared_future&lt;int&gt;的构造函数 assert(!f.valid()); // 2 期望值 f 现在是不合法的 assert(sf.valid()); // 3 sf 现在是合法的 期望值f开始是合法的①，因为引用的是promise p的同步状态，但是在转移sf的状态后，f就不合法了②，而sf就是合法的了③。 如其他可移动对象一样，转移所有权是对右值的隐式操作，所以可以通过std::promise对象的成员函数get_future()的返回值，直接构造一个std::shared_future对象，例如： std::promise&lt;std::string&gt; p; std::shared_future&lt;std::string&gt; sf(p.get_future()); // 1 隐式转移所有权 调用std::shared_future&lt;std::string&gt;移动语义的构造函数 转移所有权是隐式的，用右值构造std::shared_future&lt;&gt;，得到std::future&lt;std::string&gt;类型的实例①。 std::future的这种特性，可促进std::shared_future的使用，容器可以自动的对类型进行推断，从而初始化该类型的变量(详见附录A，A.6节)。**std::future有一个share()成员函数，可用来创建新的std::shared_future ，并且可以直接转移future的所有权**。这样也就能保存很多类型，并且使得代码易于修改： std::promise&lt; std::map&lt; SomeIndexType, SomeDataType, SomeComparator, SomeAllocator&gt;::iterator&gt; p; auto sf=p.get_future().share(); 这个例子中，sf的类型推导为std::shared_future&lt;std::map&lt;SomeIndexType, SomeDataType, SomeComparator, SomeAllocator&gt;::iterator&gt;，还真的长。当比较器或分配器有所改动，只需要对promise的类型进行修改即可。future的类型会自动与promise的修改进行匹配。 有时需要限定等待事件的时间，不论是因为时间上有硬性规定(一段指定的代码需要在某段时间内完成)，还是因为在事件没有很快的触发，或是有工作需要特定线程来完成，为了处理这种情况，需要等待函数能对超时进行指定。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：4.1 等待事件或条件","slug":"c++并发编程实践2ed：41 等待事件或条件","date":"2022-07-16T13:24:25.763Z","updated":"2022-12-10T15:16:25.384Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：41 等待事件或条件/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A41%20%E7%AD%89%E5%BE%85%E4%BA%8B%E4%BB%B6%E6%88%96%E6%9D%A1%E4%BB%B6/","excerpt":"","text":"4.1 等待事件或条件假设你正在一辆在夜间运行的火车上，在夜间如何在正确的站点下车呢？有一种方法是整晚都要醒着，每停一站都能知道，这样就不会错过你要到达的站点，但会很疲倦。另外，可以看一下时间表，估计一下火车到达目的地的时间，然后在一个稍早的时间点上设置闹铃，然后安心的睡会。这个方法听起来也很不错，也没有错过你要下车的站点，但是当火车晚点时，就要被过早的叫醒了。当然，闹钟的电池也可能会没电了，并导致你睡过站。理想的方式是，无论是早或晚，只要当火车到站的时候，有人或其他东西能把你叫醒就好了。 这和线程有什么关系呢？当一个线程等待另一个线程完成时，可以持续的检查共享数据标志(用于做保护工作的互斥量)，直到另一线程完成工作时对这个标识进行重置。不过，这种方式会消耗线程的执行时间检查标识，并且当互斥量上锁后，其他线程就没有办法获取锁，就会持续等待。因为对等待线程资源的限制，并且在任务完成时阻碍对标识的设置。类似于保持清醒状态和列车驾驶员聊了一晚上：驾驶员不得不缓慢驾驶，因为你分散了他的注意力，所以火车需要更长的时间，才能到站。同样，等待的线程会等待更长的时间，也会消耗更多的系统资源。 另外，在等待线程在检查间隙，使用std::this_thread::sleep_for()进行周期性的间歇(详见4.3节)： bool flag; std::mutex m; void wait_for_flag() &#123; std::unique_lock&lt;std::mutex&gt; lk(m); while(!flag) &#123; lk.unlock(); // 1 解锁互斥量 // 所以另外的线程就有机会获取锁并设置标识 std::this_thread::sleep_for(std::chrono::milliseconds(100)); // 2 休眠100ms lk.lock(); // 3 再锁互斥量 &#125; &#125; 循环中，休眠前②函数对互斥量进行解锁①，并且在休眠结束后再对互斥量上锁，所以另外的线程就有机会获取锁并设置标识。 这个实现就进步很多，当线程休眠时没有浪费执行时间，但很难确定正确的休眠时间。太短的休眠和没有一样，都会浪费执行时间。太长的休眠时间，可能会让任务等待时间过久。休眠时间过长比较少见，这会影响到程序的行为，在高节奏的游戏中，就意味着丢帧或错过了一个时间片。 第三个选择(也是优先选择的)，使用C++标准库提供的工具去等待事件的发生。通过另一线程触发等待事件的机制是最基本的唤醒方式(例如：流水线上存在额外的任务时)，这种机制就称为“条件变量”。从概念上来说，条件变量会与多个事件或其他条件相关，并且一个或多个线程会等待条件的达成。当某些线程被终止时，为了唤醒等待线程(允许等待线程继续执行)，终止线程将会向等待着的线程广播“条件达成”的信息。 4.1.1 等待条件达成C++标准库对条件变量有两套实现：**std::condition_variable和std::condition_variable_any，这两个实现都包含在&lt;condition_variable&gt;头文件**的声明中。两者都需要与互斥量一起才能工作(互斥量是为了同步)，前者仅能与std::mutex一起工作，而后者可以和合适的互斥量一起工作，从而加上了_any的后缀。因为** std::condition_variable_any更加通用，不过在性能和系统资源的使用方面会有更多的开销**，所以通常会将std::condition_variable作为首选类型。当对灵活性有要求时，才会考虑std::condition_variable_any。 所以，使用std::condition_variable去处理之前提到的情况——当有数据需要处理时，如何唤醒休眠中的线程？以下代码展示了使用条件变量唤醒线程的方式。 代码4.1 使用std::condition_variable处理数据等待 std::mutex mut; // 所有线程只有这一个互斥量，这个互斥量用于对data_queue的互斥访问 std::queue&lt;data_chunk&gt; data_queue; // 1 std::condition_variable data_cond; // 条件变量，用来通知data准备好的事件 void data_preparation_thread() &#123; while(more_data_to_prepare()) &#123; data_chunk const data=prepare_data(); std::lock_guard&lt;std::mutex&gt; lk(mut); // lock 对mut上锁 data_queue.push(data); // 2 data_cond.notify_one(); // 3 对等待的线程(如果有等待线程)进行通知 // unlock &#125; &#125; void data_processing_thread() &#123; while(true) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); // 4 对mut上锁 data_cond.wait( // 传递一个锁和一个Lambda表达式作为等待的条件 lk,[]&#123;return !data_queue.empty();&#125;); // 5 data_chunk data=data_queue.front(); data_queue.pop(); lk.unlock(); // 6 process(data); if(is_last_chunk(data)) break; &#125; &#125; 首先，队列中中有两个线程，两个线程之间会对数据进行传递①。数据准备好时，使用std::lock_guard锁定队列，将准备好的数据压入队列②之后，线程会对队列中的数据上锁，并调用std::condition_variable的notify_one()成员函数，对等待的线程(如果有等待线程)进行通知③。 另外的一个线程正在处理数据，线程首先对互斥量上锁(这里使用std::unique_lock要比std::lock_guard④更加合适)。之后会调用std::condition_variable的成员函数wait()，**传递一个锁和一个Lambda表达式(作为等待的条件**⑤)。Lambda函数是C++11添加的新特性，可以让一个匿名函数作为其他表达式的一部分，并且非常合适作为标准函数的谓词。例子中，简单的Lambda函数[]&#123;return !data_queue.empty();&#125;会去检查data_queue是否为空，当data_queue不为空，就说明数据已经准备好了。附录A的A.5节有Lambda函数更多的信息。 wait()会去检查这些条件(通过Lambda函数)，当条件满足(Lambda函数返回true)时返回。如果条件不满足(Lambda函数返回false)，wait()将解锁互斥量，并且将线程(处理数据的线程)置于阻塞或等待状态（放到这个条件变量相关的等待线程队列中）。当准备数据的线程调用notify_one()通知条件变量时，（**从等待在这个条件变量上的所有线程中选一个来唤醒，比如这个处理数据的线程）处理数据的线程从睡眠中苏醒，重新获取互斥锁，并且再次进行条件检查。在条件满足的情况下，从wait()返回并继续持有锁。当条件不满足时，线程将对互斥量解锁，并重新等待**。这就是为什么用std::unique_lock而不使用std::lock_guard的原因——等待中的线程必须在等待期间解锁互斥量，并对互斥量再次上锁，而std::lock_guard没有这么灵活。如果互斥量在线程休眠期间保持锁住状态，准备数据的线程将无法锁住互斥量，也无法添加数据到队列中。同样，等待线程也永远不会知道条件何时满足。 代码4.1使用了简单的Lambda函数用于等待⑤(用于检查队列何时不为空)，不过任意的函数和可调用对象都可以传入wait()。当写好函数做为检查条件时，不一定非要放在一个Lambda表达式中，也可以直接将这个函数传入wait()。调用wait()的过程中，在互斥量锁定时，可能会去检查条件变量若干次，当提供测试条件的函数返回true就会立即返回。当等待线程重新获取互斥量并检查条件变量时，并非直接响应另一个线程的通知，就是所谓的伪唤醒(spurious wakeup)。因为任何伪唤醒的数量和频率都是不确定的，所以不建议使用有副作用的函数做条件检查。 本质上， std::condition_variable::wait是“忙碌-等待”的优化。下面用简单的循环实现了一个“忙碌-等待”： template&lt;typename Predicate&gt; void minimal_wait(std::unique_lock&lt;std::mutex&gt;&amp; lk, Predicate pred)&#123; while(!pred())&#123; lk.unlock(); lk.lock(); &#125; &#125; 为wait()准备一个最小化实现，只需要notify_one()或notify_all()。 std::unique_lock的灵活性，不仅适用于对wait()的调用，还可以用于待处理的数据⑥。处理数据可能是耗时的操作，并且长时间持有锁是个糟糕的主意。 **使用队列在多个线程中转移数据(如代码4.1)**很常见。做得好的话，同步操作可以在队列内部完成，这样同步问题和条件竞争出现的概率也会降低。鉴于这些好处，需要从代码4.1中提取出一个通用线程安全的队列。 4.1.2 构建线程安全队列设计通用队列时，就要花时间想想，哪些操作需要添加到队列实现中去，就如之前在3.2.3节看到的线程安全的栈。可以看一下C++标准库提供的实现，找找灵感。std::queue&lt;&gt;容器的接口展示如下： 代码4.2 std::queue接口 template &lt;class T, class Container = std::deque&lt;T&gt; &gt; class queue &#123; public: explicit queue(const Container&amp;); explicit queue(Container&amp;&amp; = Container()); template &lt;class Alloc&gt; explicit queue(const Alloc&amp;); template &lt;class Alloc&gt; queue(const Container&amp;, const Alloc&amp;); template &lt;class Alloc&gt; queue(Container&amp;&amp;, const Alloc&amp;); template &lt;class Alloc&gt; queue(queue&amp;&amp;, const Alloc&amp;); void swap(queue&amp; q); bool empty() const; size_type size() const; T&amp; front(); const T&amp; front() const; T&amp; back(); const T&amp; back() const; void push(const T&amp; x); void push(T&amp;&amp; x); void pop(); template &lt;class... Args&gt; void emplace(Args&amp;&amp;... args); &#125;; 忽略构造、赋值以及交换操作，剩下了三组操作： 对整个队列的状态进行查询(empty()和size()) 查询在队列中的各个元素(front()和back()) 修改队列的操作(push(), pop()和emplace()) 和3.2.3中的栈一样，也会遇到接口上的条件竞争。因此，需要将front()和pop()合并成一个函数调用，就像之前在栈实现时合并top()和pop()一样。与代码4.1不同的是，当队列在多个线程中传递数据时，接收线程通常需要等待数据的压入。这里提供pop()函数的两个变种：try_pop()和wait_and_pop()。 try_pop() ，尝试从队列中弹出数据，即使没有值可检索，也会直接返回。立即返回 wait_and_pop()，将会等待有值可检索的时候才返回。 当使用之前栈的方式来实现队列，接口可能会是下面这样： 代码4.3 线程安全队列的接口 #include &lt;memory&gt; // 为了使用std::shared_ptr template&lt;typename T&gt; class threadsafe_queue &#123; public: threadsafe_queue(); threadsafe_queue(const threadsafe_queue&amp;); threadsafe_queue&amp; operator=( const threadsafe_queue&amp;) = delete; // 不允许简单的赋值 void push(T new_value); bool try_pop(T&amp; value); // 1 在引用变量中返回检索值 std::shared_ptr&lt;T&gt; try_pop(); // 2 返回检索值 void wait_and_pop(T&amp; value); std::shared_ptr&lt;T&gt; wait_and_pop(); bool empty() const; &#125;; 就像之前的栈，裁剪了很多构造函数，并禁止简单赋值。需要提供两个版本的try_pop()和wait_for_pop()。第一个重载的try_pop()①在引用变量中存储着检索值，可以用来返回队列中值的状态。当检索到一个变量时，将返回true，否则返回false(详见A.2节)。第二个重载②就不行了，因为它是用来直接返回检索值的，当没有值可检索时，这个函数返回NULL。 那么问题来了，如何将以上这些和代码4.1相关联呢？从之前的代码中提取push()和wait_and_pop()，如以下代码所示。 代码4.4 从代码4.1中提取push()和wait_and_pop() #include &lt;queue&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; template&lt;typename T&gt; class threadsafe_queue &#123; private: std::mutex mut; std::queue&lt;T&gt; data_queue; std::condition_variable data_cond; public: void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); //lock mut data_queue.push(new_value); data_cond.notify_one(); //notify_one //unlock mut &#125; void wait_and_pop(T&amp; value) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); //lock mut // wait for condition and notify data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); // 执行到这里时检查条件是否满足，如果不满足就释放锁，并被挂起到data_cond相关的等待队列中（当前线程），直到有线程对data_cond调用notify，则会从data_cond相关的等待队列中选择一个线程被唤醒：这个线程先获取锁，然后检查条件是否满足，如果满足则这个线程会从wait()返回继续执行后面的，如果不满足则释放锁，并挂起到data_cond相关的等待队列中 value=data_queue.front(); data_queue.pop(); //unlock mut &#125; &#125;; threadsafe_queue&lt;data_chunk&gt; data_queue; // 1 void data_preparation_thread() &#123; while(more_data_to_prepare()) &#123; data_chunk const data=prepare_data(); data_queue.push(data); // 2 &#125; &#125; void data_processing_thread() &#123; while(true) &#123; data_chunk data; data_queue.wait_and_pop(data); // 3 process(data); if(is_last_chunk(data)) break; &#125; &#125; 线程队列中有互斥量和条件变量，所以独立的变量就不需要了①，并且push()不需要外部同步②。当然，wait_and_pop()还要兼顾条件变量的等待③。 另一个wait_and_pop()的重载写起来就很琐碎，剩下的函数就像从代码3.5实现的栈中粘过来一样。 代码4.5 使用条件变量的线程安全队列(完整版) #include &lt;queue&gt; #include &lt;memory&gt; #include &lt;mutex&gt; #include &lt;condition_variable&gt; template&lt;typename T&gt; class threadsafe_queue &#123; private: mutable std::mutex mut; // 1 互斥量必须是可变的 std::queue&lt;T&gt; data_queue; std::condition_variable data_cond; public: threadsafe_queue() &#123;&#125; threadsafe_queue(threadsafe_queue const&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lk(other.mut); // lock other.mut // 这个对象还在构造中，因此不用担心其他线程会来通过这个对象访问其中的队列数据，因此不用对mut上锁 data_queue=other.data_queue; // unlock other.mut &#125; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut data_queue.push(new_value); data_cond.notify_one(); // data_cond.notify // unlock mut &#125; void wait_and_pop(T&amp; value) &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); // lock mut (unique_lock 因为wait要能够unlock和lock锁) data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); // wait on data_cond value=data_queue.front(); data_queue.pop(); // unlock mut &#125; std::shared_ptr&lt;T&gt; wait_and_pop() &#123; std::unique_lock&lt;std::mutex&gt; lk(mut); // lock mut (unique_lock) data_cond.wait(lk,[this]&#123;return !data_queue.empty();&#125;); // wait on data_cond std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front())); data_queue.pop(); return res; // unlock mut &#125; bool try_pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut if(data_queue.empty()) return false; // unlock mut value=data_queue.front(); data_queue.pop(); return true; // unlock mut &#125; std::shared_ptr&lt;T&gt; try_pop() &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut if(data_queue.empty()) return std::shared_ptr&lt;T&gt;(); // unlock mut std::shared_ptr&lt;T&gt; res(std::make_shared&lt;T&gt;(data_queue.front())); data_queue.pop(); return res; // unlock mut &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lk(mut); // lock mut return data_queue.empty(); // unlock mut &#125; &#125;; empty()是一个const成员函数，并且传入拷贝构造函数的other形参是一个const引用（这个引用不可变，不是说指向的对象不可变）。因为其他线程可能有非const引用对象，并调用变种成员函数，所以这里有必要对互斥量上锁。又因为锁住互斥量是个可变操作，所以互斥量成员必须为mutable①才能在empty()和拷贝构造函数中进行上锁。 条件变量在多个线程等待同一个事件时也很有用。当线程用来分解工作负载，并且只有一个线程可以对通知做出反应时，与代码4.1中结构完全相同。当数据准备完成时，调用notify_one()将会唤醒一个正在wait()的线程，检查条件和wait()函数的返回状态(因为仅是向data_queue添加了一个数据项)。 这里不保证线程一定会被通知到，即使只有一个等待线程收到通知，其他处理线程也有可能因为在处理数据，而忽略了这个通知。 另一种可能是，很多线程等待同一事件。对于通知，都需要做出回应。这会发生在共享数据初始化的时候，当处理线程使用同一数据时，就要等待数据被初始化，或等待共享数据的更新，比如：周期性初始化(periodic reinitialization)。这些情况下，线程准备好数据时，就会通过条件变量调用notify_all()，而非调用notify_one()。顾名思义，这就是全部线程在都去执行wait()(检查他们等待的条件是否满足)的原因。 当条件为true时，等待线程只等待一次，就不会再等待条件变量了，所以尤其是在等待一组可用的数据块时，一个条件变量并非同步操作最好的选择。 接下来就来了解一下future，对于条件变量的补足。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：3.3 保护共享数据的方式","slug":"c++并发编程实践2ed：33 保护共享数据的方式","date":"2022-07-16T13:22:56.918Z","updated":"2022-12-10T15:16:37.146Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：33 保护共享数据的方式/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A33%20%E4%BF%9D%E6%8A%A4%E5%85%B1%E4%BA%AB%E6%95%B0%E6%8D%AE%E7%9A%84%E6%96%B9%E5%BC%8F/","excerpt":"","text":"3.3 保护共享数据的方式互斥量是一种通用的机制，但其并非保护共享数据的唯一方式。有很多方式可以在特定情况下，对共享数据提供合适的保护。 一个特别极端的情况就是，共享数据在并发访问和初始化时(都需要保护)，需要进行隐式同步。这可能是因为数据作为只读方式创建，所以没有同步问题，或者因为必要的保护作为对数据操作的一部分。任何情况下，数据初始化后锁住一个互斥量，纯粹是为了保护其初始化过程，并且会给性能带来不必要的影响。 出于以上的原因，C++标准提供了一种纯粹保护共享数据初始化过程的机制。 3.3.1 保护共享数据的初始化过程假设有一个共享源，构建代价很昂贵，它可能会打开一个数据库连接或分配出很多的内存。 以下两种初始化方式可能存在竞争条件问题： 延迟初始化延迟初始化(Lazy initialization)在单线程代码很常见——每一个操作都需要先对源进行检查，为了了解数据是否被初始化，然后在其使用前决定，数据是否需要初始化： std::shared_ptr&lt;some_resource&gt; resource_ptr; void foo() &#123; if(!resource_ptr) &#123; resource_ptr.reset(new some_resource); // 1 &#125; resource_ptr-&gt;do_something(); &#125; 转为多线程代码时，只有①处需要保护，这样共享数据对于并发访问就是安全的。但是下面天真的转换会使得线程资源产生不必要的序列化，为了确定数据源已经初始化，每个线程必须等待互斥量。 代码3.11 使用延迟初始化(线程安全)的过程 std::shared_ptr&lt;some_resource&gt; resource_ptr; std::mutex resource_mutex; void foo() &#123; std::unique_lock&lt;std::mutex&gt; lk(resource_mutex); // 所有线程在此序列化 if(!resource_ptr) &#123; resource_ptr.reset(new some_resource); // 只有初始化过程需要保护 &#125; lk.unlock(); resource_ptr-&gt;do_something(); &#125; 这段代码相当常见了，也足够表现出没必要的线程化问题，很多人能想出更好的一些的办法来做这件事，包括声名狼藉的“双重检查锁模式”： void undefined_behaviour_with_double_checked_locking() &#123; if(!resource_ptr) // 1 &#123; std::lock_guard&lt;std::mutex&gt; lk(resource_mutex); if(!resource_ptr) // 2 &#123; resource_ptr.reset(new some_resource); // 3 &#125; &#125; resource_ptr-&gt;do_something(); // 4 &#125; 指针第一次读取数据不需要获取锁①，并且只有在指针为空时才需要获取锁。然后，当获取锁之后，会再检查一次指针② (这就是双重检查的部分)，避免另一线程在第一次检查后再做初始化，并且让当前线程获取锁。 这个模式为什么声名狼藉呢？因为有潜在的条件竞争。未被锁保护的读取操作①没有与其他线程里被锁保护的写入操作③进行同步（*举例？没想出来*），因此就会产生条件竞争，这个条件竞争不仅覆盖指针本身，还会影响到其指向的对象；即使一个线程知道另一个线程完成对指针进行写入，它可能没有看到新创建的some_resource实例，然后调用do_something()④后，得到不正确的结果。这个例子是在一种典型的条件竞争——数据竞争，C++标准中指定为“未定义行为”，这种竞争是可以避免的。阅读第5章时，那里有更多对内存模型的讨论，也包括数据竞争的构成。(译者注：著名的《C++和双重检查锁定模式(DCLP)的风险》可以作为补充材料供大家参考 英文版 中文版) C++标准委员会也认为条件竞争的处理很重要，所以C++标准库提供了std::once_flag和std::call_once来处理这种情况。比起锁住互斥量并显式的检查指针，每个线程只需要使用std::call_once就可以，在std::call_once的结束时，就能安全的知晓指针已经被其他的线程初始化了。使用std::call_once比显式使用互斥量消耗的资源更少，特别是当初始化完成后。下面的例子展示了与代码3.11中的同样的操作，这里使用了std::call_once。这种情况下，初始化通过调用函数完成，这样的操作使用类中的函数操作符来实现同样很简单。如同大多数在标准库中的函数一样，或作为函数被调用，或作为参数被传递，std::call_once可以和任何函数或可调用对象一起使用。 使用std::call_once延迟初始化(线程安全) std::shared_ptr&lt;some_resource&gt; resource_ptr; std::once_flag resource_flag; // 1 void init_resource() &#123; resource_ptr.reset(new some_resource); &#125; void foo() &#123; std::call_once(resource_flag,init_resource); // 可以完整的进行一次初始化 resource_ptr-&gt;do_something(); &#125; 这个例子中，std::once_flag①和初始化好的数据都是命名空间区域的对象，但std::call_once()可仅作为延迟初始化的类型成员，如同下面的例子一样： 代码3.12 使用std::call_once作为类成员的延迟初始化(线程安全) class X &#123; private: connection_info connection_details; connection_handle connection; std::once_flag connection_init_flag; void open_connection() &#123; connection=connection_manager.open(connection_details); &#125; public: X(connection_info const&amp; connection_details_): connection_details(connection_details_) &#123;&#125; void send_data(data_packet const&amp; data) // 1 &#123; std::call_once(connection_init_flag,&amp;X::open_connection,this); // 2 connection.send_data(data); &#125; data_packet receive_data() // 3 &#123; std::call_once(connection_init_flag,&amp;X::open_connection,this); // 2 return connection.receive_data(); &#125; &#125;; 例子中第一次调用send_data()①或receive_data()③的线程完成初始化过程。使用成员函数open_connection()去初始化数据，也需要将this指针传进去。和标准库中的函数一样，接受可调用对象，比如std::thread的构造函数和std::bind()，通过向std::call_once()②传递一个额外的参数来完成这个操作。 值得注意的是，**std::mutex和std::once_flag的实例不能拷贝和移动**，需要通过显式定义相应的成员函数，对这些类成员进行操作。 static类型的局部变量 c++11编译器会阻止这种竞争还有一种初始化过程中潜存着条件竞争：其中一个局部变量为static类型（static类型的变量会存放在进程地址空间的data区，这个区是为一个进程的多个线程所共享的），这种变量的在声明后就已经完成初始化。对于多线程调用的函数，这就意味着这里有条件竞争——抢着去定义这个变量。很多在不支持C++11标准的编译器上，在实践过程中，这样的条件竞争是确实存在的，因为在多线程中，每个线程都认为他们是第一个初始化这个变量线程，或一个线程对变量进行初始化，而另外一个线程要使用这个变量时，初始化过程还没完成。在C++11标准中，这些问题都被解决了：初始化及定义完全在一个线程中发生，并且没有其他线程可在初始化完成前对其进行处理，条件竞争终止于初始化阶段，这样比在之后再去处理好的多。在只需要一个全局实例情况下，这里提供一个std::call_once的替代方案 class my_class; my_class&amp; get_my_class_instance() &#123; static my_class instance; // 线程安全的初始化过程 return instance; &#125; 多线程可以安全的调用get_my_class_instance()①函数，不用为数据竞争而担心。 对于很少有更新的数据结构来说，只在初始化时保护数据。大多数情况下，这种数据结构是只读的，并且多线程对其并发的读取也是很愉快的，不过一旦数据结构需要更新就会产生竞争。 3.3.2 保护不常更新的数据结构 读者-作者锁c++17试想为了将域名解析为其相关IP地址，在缓存中的存放了一张DNS入口表。通常，给定DNS数目在很长的时间内保持不变。虽然，用户访问不同网站时，新的入口可能会被添加到表中，但是这些数据可能在其生命周期内保持不变。所以定期检查缓存中入口的有效性就变的十分重要。但也需要一次更新，也许这次更新只是对一些细节做了改动。 虽然更新频度很低，但也有可能发生，并且当缓存多个线程访问时，这个缓存就需要保护更新时状态的状态，也是为了确保每个线程读到都是有效数据。 没有使用专用数据结构时，这种方式是符合预期的，并为并发更新和读取进行了特别设计(更多的例子在第6和第7章中介绍)。这样的更新要求线程独占数据结构的访问权，直到更新操作完成。当完成更新时，数据结构对于并发多线程的访问又会是安全的。使用std::mutex来保护数据结构，感觉有些反应过度(因为在没有发生修改时，它将削减并发读取数据的可能性)。这里需要另一种不同的互斥量，这种互斥量常被称为“读者-作者锁”，因为其允许两种不同的使用方式：一个“作者”线程独占访问和共享访问，让多个“读者”线程并发访问。 C++17标准库提供了两种非常好的互斥量——**std::shared_mutex和std::shared_timed_mutex。C++14只提供了std::shared_timed_mutex，并且在C++11中并未提供任何互斥量类型。如果还在用支持C++14标准之前的编译器，可以使用Boost库中的互斥量。std::shared_mutex和std::shared_timed_mutex的不同点在于，std::shared_timed_mutex支持更多的操作方式(参考4.3节)，std::shared_mutex有更高的性能优势**，但支持的操作较少。 第8章中会看到，这种锁的也不能包治百病，其性能依赖于参与其中的处理器数量，同样也与读者和作者线程的负载有关。为了确保增加复杂度后还能获得性能收益，目标系统上的代码性能就很重要。 比起使用std::mutex实例进行同步，不如使用std::shared_mutex来做同步。 对于更新操作，可以使用**std::lock_guard&lt;std::shared_mutex&gt;和std::unique_lock&lt;std::shared_mutex&gt;上锁**。作为std::mutex的替代方案，与std::mutex所做的一样，这就能保证更新线程的独占访问。 那些无需修改数据结构的线程，可以使用**std::shared_lock&lt;std::shared_mutex&gt;获取访问权。这种RAII类型模板是在C++14中的新特性，这与使用std::unique_lock一样，除了多线程可以同时获取同一个std::shared_mutex的共享锁。唯一的限制：当有线程拥有共享锁时，尝试获取独占锁的线程会被阻塞，直到所有其他线程放弃锁。当任一线程拥有一个独占锁时，其他线程就无法获得共享锁或独占锁**，直到第一个线程放弃其拥有的锁。 如同之前描述的那样，下面的代码清单展示了一个简单的DNS缓存，使用std::map持有缓存数据，使用std::shared_mutex进行保护。 代码3.13 **使用std::shared_mutex**对数据结构进行保护 #include &lt;map&gt; #include &lt;string&gt; #include &lt;mutex&gt; #include &lt;shared_mutex&gt; class dns_entry; class dns_cache &#123; std::map&lt;std::string,dns_entry&gt; entries; mutable std::shared_mutex entry_mutex; // std::shared_mutex public: dns_entry find_entry(std::string const&amp; domain) const &#123; std::shared_lock&lt;std::shared_mutex&gt; lk(entry_mutex); // 1 读者，shared_lock std::map&lt;std::string,dns_entry&gt;::const_iterator const it= entries.find(domain); return (it==entries.end())?dns_entry():it-&gt;second; &#125; void update_or_add_entry(std::string const&amp; domain, dns_entry const&amp; dns_details) &#123; std::lock_guard&lt;std::shared_mutex&gt; lk(entry_mutex); // 2 写者，lock_guard entries[domain]=dns_details; &#125; &#125;; 代码3.13中，find_entry()使用std::shared_lock&lt;&gt;来保护共享和只读权限①。这就使得多线程可以同时调用find_entry()，且不会出错。另一方面，update_or_add_entry()使用std::lock_guard&lt;&gt;实例，当表格需要更新时②，为其提供独占访问权限。update_or_add_entry()函数调用时，独占锁会阻止其他线程对数据结构进行修改，并且阻止线程调用find_entry()。 3.3.3 嵌套锁线程对已经获取的std::mutex(已经上锁)再次上锁是错误的，尝试这样做会导致未定义行为。在某些情况下，一个线程会尝试在释放一个互斥量前多次获取。因此，C++标准库提供了**std::recursive_mutex类。除了可以在同一线程的单个实例上多次上锁，其他功能与std::mutex相同。其他线程对互斥量上锁前，当前线程必须释放拥有的所有锁**，所以如果你调用lock()三次，也必须调用unlock()三次。正确使用std::lock_guard&lt;std::recursive_mutex&gt;和std::unique_lock&lt;std::recursive_mutex&gt;可以帮你处理这些问题。 使用嵌套锁时，要对代码设计进行改动。嵌套锁一般用在可并发访问的类上，所以使用互斥量保护其成员数据。每个公共成员函数都会对互斥量上锁，然后完成对应的操作后再解锁互斥量。不过，有时成员函数会调用另一个成员函数，这种情况下，第二个成员函数也会试图锁住互斥量，这就会导致未定义行为的发生。“变通的”解决方案会将互斥量转为嵌套锁，第二个成员函数就能成功的进行上锁，并且函数能继续执行。 但是这种方式过于草率和不合理，所以不推荐这样的使用方式。特别是，对应类的不变量通常会被破坏。这意味着，当不变量被破坏时，第二个成员函数还需要继续执行。一个比较好的方式是，从中提取出一个函数作为类的私有成员，**这个私有成员函数不会对互斥量进行上锁(调用前必须获得锁)**。然后，需要仔细考虑一下，这种情况调用新函数时数据的状态。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：3.2 使用互斥量","slug":"c++并发编程实践2ed：32 使用互斥量","date":"2022-07-16T13:19:19.631Z","updated":"2022-12-10T15:16:46.157Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：32 使用互斥量/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A32%20%E4%BD%BF%E7%94%A8%E4%BA%92%E6%96%A5%E9%87%8F/","excerpt":"","text":"竞争条件一个来源：指令级并发 std::lock_guard和std::unique_lock对象，都是为构造它们时传入的第一个参数提供锁服务的，这两种类型的对象**拥有的资源是对 构造函数传递给他们的第一个参数这个资源 的关联，以及如果他们拥有的这个资源上了锁的话，上的这把锁（这把锁其实是那个资源类内部实现的）也是**（移动语义即转移这俩给别的对象） 资源类有lock() unlock() try_lock()成员函数 lock_guard：std::lock_guard&lt;std::mutex&gt; guard(some_mutex); 则guard对象提供对std::mutex类型的实例some_mutex提供锁保护，具体而言是在构造guard对象后就对some_mutex上锁（会构造一把锁然后上锁），guard析构时释放锁 如果传入**第二个参数std::adopt_lock**则告诉guard使用some_mutex上面已经加的锁，并且将该锁的管理交给guard unique_lock：std::unique_lock&lt;std::mutex&gt; ulock(some_mutex); 则ulock对象提供对std::mutex类型的实例some_mutex提供锁保护，具体而言是在构造ulock对象后就对some_mutex上锁，ulock析构时释放锁（如果ulock相关联的资源some_mutex有锁的话） 如果传入**第二个参数std::adopt_lock**则告诉ulock使用some_mutex上面已经加的锁，而不用另外构建锁（如果没有传入第二个参数，则在ulock构造函数中会构造对some_mutex的锁然后上锁），并且将该锁的管理交给ulock 如果传入**第二个参数std::defer_lock**则ulock与资源some_mutex相关联，但是不新构造对some_mutex的锁也不上锁 ulock有**成员函数lock()和unlock()和try_lock()**来在std::unique_lock类型对象构造后销毁前进行锁申请和锁释放（这个lock_guard类型没有，也因为要实现这个，unique_lock类型比lock_guard类型占用内存更大（比如一些对于锁状态记录的标志），开销也更多一点（比如一些对于锁状态的检查）） 3.2 使用互斥量你肯定不想让共享数据陷入条件竞争，或是出现破坏不变量的情况。将所有访问共享数据的代码标记为互斥是否是一种更好的办法呢？这样，任何一个线程在执行时，其他线程就必须进行等待。除非该线程在修改共享数据，否则任何线程都不可能会看到不变量的中间状态。 访问共享数据前，将数据锁住，在访问结束后，再将数据解锁。线程库需要保证，当线程使用互斥量锁住共享数据时，其他的线程都必须等到之前那个线程对数据进行解锁后，才能进行访问数据。 互斥量是C++保护数据最通用的机制，但也需要编排代码来保护数据的正确性(见3.2.2节)，并避免接口间的条件竞争(见3.2.3节)也非常重要。不过，互斥量也会造成死锁(见3.2.4节)，或对数据保护的太多(或太少)(见3.2.8节)。 3.2.1 互斥量通过实例化**std::mutex创建互斥量实例，成员函数lock()可对互斥量上锁，unlock()为解锁。不过，不推荐直接去调用成员函数，调用成员函数就意味着，必须在每个函数出口都要去调用unlock()(包括异常的情况)。C++标准库为互斥量提供了RAII模板类std::lock_guard，在构造时（对互斥量上锁**）就能提供已锁的互斥量，并在析构时进行解锁，从而保证了互斥量能被正确解锁。下面的代码中，展示了如何在多线程应用中，使用std::mutex构造的std::lock_guard实例，对列表进行访问保护。(std::mutex和std::lock_guard都在**&lt;mutex&gt;头文件**中声明。) 代码3.1 使用互斥量保护列表 不是 直接锁住要控制为互斥访问的资源some_list，而是锁住some_mutex，这个互斥量对于所有竞争线程只有一个，因此一个线程占有some_mutex时，其他线程无法占有，而对于some_list的操作一定在some_mutex被锁住之后到被解锁之前，由此提供对some_list的互斥访问 #include &lt;list&gt; #include &lt;mutex&gt; #include &lt;algorithm&gt; std::list&lt;int&gt; some_list; // 1 std::mutex some_mutex; // 2 void add_to_list(int new_value) &#123; std::lock_guard&lt;std::mutex&gt; guard(some_mutex); // 3 构造时对some_mutex上锁 some_list.push_back(new_value); // guard析构时对some_mutex解锁 &#125; bool list_contains(int value_to_find) &#123; std::lock_guard&lt;std::mutex&gt; guard(some_mutex); // 4 构造时对some_mutex上锁 return std::find(some_list.begin(),some_list.end(),value_to_find) != some_list.end(); // guard析构时对some_mutex解锁 &#125; 代码3.1中有一个全局变量①，这个全局变量被一个全局的互斥量保护②。add_to_list()③和list_contains()④函数中使用std::lock_guard&lt;std::mutex&gt;，使得这两个函数中对数据的访问是互斥的：list_contains()不可能看到正在被add_to_list()修改的列表。 C++17中添加了一个新特性，称为模板类参数推导，类似std::lock_guard这样简单的模板类型，其模板参数列表可以省略。③和④的代码可以简化成： std::lock_guard guard(some_mutex); 具体的模板参数类型推导则交给C++17的编译器完成。3.2.4节中，会介绍C++17中的一种加强版数据保护机制——std::scoped_lock，所以在C++17的环境下，上面的这行代码也可以写成： std::scoped_lock guard(some_mutex); 为了让代码更加清晰，并且兼容只支持C++11标准的编译器，我会继续使用std::lock_guard，并在代码中写明模板参数的类型。 某些情况下使用全局变量没问题，但大多数情况下，互斥量通常会与需要保护的数据放在同一类中，而不是定义成全局变量。这是面向对象设计的准则：将其放在一个类中，就可让他们联系在一起，也可对类的功能进行封装，并进行数据保护。这种情况下，函数add_to_list和list_contains可以作为这个类的成员函数。互斥量和需要保护的数据，在类中都定义为private成员，这会让代码更清晰，并且方便了解什么时候对互斥量上锁。所有成员函数都会在调用时对数据上锁，结束时对数据解锁，这就保证了访问时数据不变量的状态稳定。 当然，也不是总能那么理想：当其中一个成员函数返回的是保护数据的指针或引用时，也会破坏数据。具有访问能力的指针或引用可以访问(并可能修改)保护数据，而不会被互斥锁限制。这就需要对接口谨慎设计，要确保互斥量能锁住数据访问，并且不留后门。 3.2.2 保护共享数据使用互斥量来保护数据，并不是在每一个成员函数中加入一个std::lock_guard对象那么简单。一个指针或引用，也会让这种保护形同虚设。不过，检查指针或引用很容易，只要没有成员函数通过返回值或者输出参数的形式，向其调用者返回指向受保护数据的指针或引用，数据就是安全的。确保成员函数不会传出指针或引用的同时，检查成员函数是否通过指针或引用的方式来调用也是很重要的(尤其是这个操作不在你的控制下时)。函数可能没在互斥量保护的区域内存储指针或引用，这样就很危险。更危险的是：将保护数据作为一个运行时参数，如同下面代码中所示。 代码3.2 无意中传递了保护数据的引用 class some_data &#123; int a; std::string b; public: void do_something(); &#125;; class data_wrapper &#123; private: some_data data; std::mutex m; public: template&lt;typename Function&gt; void process_data(Function func) &#123; std::lock_guard&lt;std::mutex&gt; l(m); func(data); // 1 传递“保护”数据给用户函数 &#125; &#125;; some_data* unprotected; void malicious_function(some_data&amp; protected_data) &#123; unprotected=&amp;protected_data; &#125; data_wrapper x; void foo() &#123; x.process_data(malicious_function); // 2 传递一个恶意函数 unprotected-&gt;do_something(); // 3 在无保护的情况下访问保护数据 &#125; 例子中process_data看起来没有问题，std::lock_guard对数据做了很好的保护，但调用用户提供的函数func①，就意味着foo能够绕过保护机制将函数malicious_function传递进去②，可以在没有锁定互斥量的情况下调用do_something()。 这段代码的问题在于根本没有保护，只是将所有可访问的数据结构代码标记为互斥。函数foo()中调用unprotected-&gt;do_something()的代码未能被标记为互斥。这种情况下，C++无法提供任何帮助，只能由开发者使用正确的互斥锁来保护数据。从乐观的角度上看，还是有方法的：**切勿将受保护数据的指针或引用传递到互斥锁作用域之外**。 虽然，这是使用互斥量保护共享数据时常犯的错误，但绝不仅仅是一个潜在的陷阱。下一节中，即便是使用了互斥量对数据进行保护，条件竞争可能依旧存在。 3.2.3 接口间的条件竞争问题使用了互斥量或其他机制保护了共享数据，就不必再为条件竞争所担忧吗？并不是，依旧需要确定数据是否受到了保护。回想之前双链表的例子，为了能让线程安全地删除一个节点，需要确保防止对这三个节点(待删除的节点及其前后相邻的节点)的并发访问。如果只对指向每个节点的指针进行访问保护，那就和没有使用互斥量一样，条件竞争仍会发生——除了指针，整个数据结构和整个删除操作需要保护。这种情况下最简单的解决方案就是使用互斥量来保护整个链表，如代码3.1所示。 尽管链表的个别操作是安全的，但依旧可能遇到条件竞争。例如，构建一个类似于std::stack的栈(代码3.3)，除了构造函数和swap()以外，需要对std::stack提供五个操作：push()一个新元素进栈，pop()一个元素出栈，top()查看栈顶元素，empty()判断栈是否是空栈，size()了解栈中有多少个元素。即使修改了top()，返回一个拷贝而非引用(即遵循了3.2.2节的准则)，这个接口仍存在条件竞争。这个问题不仅存在于互斥量实现接口中，在无锁实现接口中，也会产生条件竞争。这是接口的问题，与实现方式无关。 代码3.3 std::stack容器的实现 template&lt;typename T,typename Container=std::deque&lt;T&gt; &gt; class stack &#123; public: explicit stack(const Container&amp;); explicit stack(Container&amp;&amp; = Container()); template &lt;class Alloc&gt; explicit stack(const Alloc&amp;); template &lt;class Alloc&gt; stack(const Container&amp;, const Alloc&amp;); template &lt;class Alloc&gt; stack(Container&amp;&amp;, const Alloc&amp;); template &lt;class Alloc&gt; stack(stack&amp;&amp;, const Alloc&amp;); bool empty() const; size_t size() const; T&amp; top(); T const&amp; top() const; void push(T const&amp;); void push(T&amp;&amp;); void pop(); void swap(stack&amp;&amp;); template &lt;class... Args&gt; void emplace(Args&amp;&amp;... args); // C++14的新特性 &#125;; 虽然empty()和size()可能在返回时是正确的，但结果不可靠。当返回后，其他线程就可以自由地访问栈，并且可能push()多个新元素到栈中，也可能pop()一些已在栈中的元素。这样的话，之前从empty()和size()得到的数值就有问题了。 非共享的栈对象，如果栈非空，使用empty()检查再调用top()访问栈顶部的元素是安全的。如下代码所示： stack&lt;int&gt; s; if (! s.empty())&#123; // 1 int const value = s.top(); // 2 s.pop(); // 3 do_something(value); &#125; 不仅在单线程代码中安全，而且在空堆栈上调用top()是未定义的行为也符合预期。对于共享的栈对象，这样的调用顺序就不再安全，因为**在调用empty()①和调用top()②之间，可能有来自另一个线程的pop()调用并删除了最后一个元素**。这是一个经典的条件竞争，使用互斥量对栈内部数据进行保护，但依旧不能阻止条件竞争的发生，这就是接口固有的问题。 怎么解决呢？问题发生在接口设计上，所以解决的方法就是变更接口设计。怎么改？这个简单的例子中调用top()时，发现栈已经是空，就抛出异常。这能直接解决这个问题，但这是一个笨拙的解决方案，这样的话，即使empty()返回false的情况下，也需要进行异常捕获。本质上，这会让empty()成为一个多余函数。 仔细的观察之前的代码段，在调用top()②和pop()③之间会发现另一个潜在的条件竞争。假设两个线程运行着前面的代码，并且都引用同一个栈对象。当为性能而使用线程时，多个线程在不同的数据上执行相同的操作很正常，并且共享栈可以将工作进行分摊。假设，一开始栈中只有两个元素，这时任一线程上的empty()和top()都存在竞争，只需要考虑可能的执行顺序即可。 内部互斥量保护栈时，只有一个线程可以调用栈的成员函数，所以调用可以很好地交错，并且do_something()是可以并发运行的。在表3.1中，展示一种可能的执行顺序。 表3.1 一种可能执行顺序 Thread A Thread B if (!s.empty); if(!s.empty); int const value &#x3D; s.top(); int const value &#x3D; s.top(); s.pop(); do_something(value); s.pop(); do_something(value); 当线程运行时，调用两次top()，没修改栈，所以每个线程能得到同样的值。不仅是这样，调用top()的过程中(两次)，都没有调用pop()函数。这样，在其中一个值再读取的时候，虽然不会出现“写后读”的情况，但其值已处理了两次。这种条件竞争，比未定义的empty()&#x2F;top()竞争更加严重。虽然结果依赖于do_something()的结果，但因为看起来没有任何错误，就会让这个Bug更难定位。 这就需要接口设计上有较大的改动，提议之一就是使用同一互斥量来保护top()和pop()。Tom Cargill[1]指出当拷贝构造函数在栈中抛出一个异常，这样的处理方式就会有问题。在Herb Sutter[2]看来，这个问题可以从“异常安全”的角度完美解决，不过潜在的条件竞争，可能会组成一些新的组合。 说一些大家没有意识到的问题：假设有一个stack&lt;vector&lt;int&gt;&gt;，vector是一个动态容器，当拷贝一个vector，标准库会从堆上分配很多内存来完成这次拷贝。当这个系统处在重度负荷，或有严重的资源限制的情况下，这种内存分配就会失败，所以vector的拷贝构造函数可能会抛出一个std::bad_alloc异常。当vector中存有大量元素时，这种情况发生的可能性更大。当pop()函数返回“弹出值”时(也就是从栈中将这个值移除)，会有一个潜在的问题：这个值返回到调用函数的时候，栈才被改变（比如元素计数）。但拷贝数据的时候，调用函数抛出一个异常会怎么样？ 如果真的发生了，要弹出的数据将会丢失，它的确从栈上移出了，但是拷贝失败了！std::stack的设计人员将这个操作分为两部分：先获取顶部元素(top())，然后从栈中移除(pop())。这样，在不能安全的将元素拷贝出去的情况下，栈中的这个数据还依旧存在，没有丢失。当问题是堆空间不足，应用可能会释放一些内存，然后再进行尝试。 不幸的是，这样的分割却制造了本想避免的条件竞争。幸运的是，我们还有的别的选项，但使用每个选项都有相应的代价。 选项1： 传入一个引用 选项1的意思：修改pop函数的接口设计为 通过引用参数返回栈顶元素 第一个选项是将变量的引用作为参数，传入pop()函数中获取“弹出值”： std::vector&lt;int&gt; result; some_stack.pop(result); 这种方式还不错，缺点也很明显：需要构造出一个栈中类型的实例，用于接收目标值。对于一些类型，这样做是不现实的，因为临时构造一个实例，从时间和资源的角度上来看都不划算。对于其他的类型，这样也不总行得通，因为构造函数需要的参数，在这个阶段不一定可用。最后，需要可赋值的存储类型，这是一个重大限制：即使支持移动构造，甚至是拷贝构造(从而允许返回一个值)，很多用户自定义类型可能都不支持赋值操作。 选项2：无异常抛出的拷贝构造函数或移动构造函数 选项2的意思：使用有返回值的pop接口设计（删除栈顶元素，返回栈顶元素）（这样的接口设计可以解决“top()和无返回值和引用参数的pop()的接口设计”产生的竞争条件问题（一个线程调用top之后，在其调用pop之前，可能其他线程删除了栈顶）），则同时要求 栈中元素类型 有无异常抛出的拷贝构造函数或移动构造函数，这样在pop返回值的时候，不会因为在构造返回值的过程中（通过拷贝构造函数或移动构造函数进行的）抛出异常，而导致已经删除了栈顶元素却无法获取栈顶元素即栈顶元素丢失的情况 对于有返回值的pop()函数来说，只有“异常安全”方面的担忧(当返回值时可以抛出一个异常)。很多类型都有拷贝构造函数，它们不会抛出异常，并且随着新标准中对“右值引用”的支持(详见附录A，A.1节)，很多类型都将会有一个移动构造函数，即使他们和拷贝构造函数做着相同的事情，也不会抛出异常。一个有用的选项可以限制对线程安全栈的使用，并且能让栈安全的返回所需的值，而不抛出异常。 虽然安全，但非可靠。尽管能在编译时可使用std::is_nothrow_copy_constructible和std::is_nothrow_move_constructible，让拷贝或移动构造函数不抛出异常，但是这种方式的局限性太强。用户自定义的类型中，会有不抛出异常的拷贝构造函数或移动构造函数的类型， 那些有抛出异常的拷贝构造函数，但没有移动构造函数的类型往往更多(这种情况会随着人们习惯于C++11中的右值引用而有所改变)。如果这些类型不能存储在线程安全的栈中，那将是多么的不幸。 选项3：返回指向弹出值的指针第三个选择是返回一个指向弹出元素的指针，而不是直接返回值。指针的优势是自由拷贝，并且不会产生异常，这样就能避免Cargill提到的异常问题了。缺点就是返回指针需要对对象的内存分配进行管理，对于简单数据类型(比如:int)，内存管理的开销要远大于直接返回值。对于这个方案，使用std::shared_ptr是个不错的选择，不仅能避免内存泄露(因为当对象中指针销毁时，对象也会被销毁)，而且标准库能够完全控制内存分配方案，就不需要new和delete操作。这种优化是很重要的：因为堆栈中的每个对象，都需要用new进行独立的内存分配，相较于非线程安全版本，这个方案的开销相当大。 选项4：“选项1 + 选项2”或 “选项1 + 选项3”对于通用的代码来说，灵活性不应忽视。当已经选择了选项2或3时，再去选择1也是很容易的。这些选项提供给用户，让用户自己选择最合适，最经济的方案。 举例例：定义线程安全的堆栈 代码3.4中是一个接口没有条件竞争的堆栈类定义，它实现了选项1和选项3：重载了pop()，使用局部引用去存储弹出值，并返回std::shared_ptr&lt;&gt;对象。它有一个简单的接口，只有两个函数：push()和pop(); 代码3.4 线程安全的堆栈类定义(概述) #include &lt;exception&gt; #include &lt;memory&gt; // For std::shared_ptr&lt;&gt; struct empty_stack: std::exception &#123; const char* what() const throw(); &#125;; template&lt;typename T&gt; class threadsafe_stack &#123; public: threadsafe_stack(); threadsafe_stack(const threadsafe_stack&amp;); threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; // 1 赋值操作被删除 void push(T new_value); std::shared_ptr&lt;T&gt; pop(); void pop(T&amp; value); bool empty() const; &#125;; 削减接口可以获得最大程度的安全,甚至限制对栈的一些操作。栈是不能直接赋值的，因为赋值操作已经删除了①(详见附录A，A.2节)，并且这里没有swap()函数。当栈为空时，pop()函数会抛出一个empty_stack异常，所以在empty()函数被调用后，其他部件还能正常工作。如选项3描述的那样，使用std::shared_ptr可以避免内存分配管理的问题，并避免多次使用new和delete操作。堆栈中的五个操作，现在就剩下三个：push(), pop()和empty()(这里empty()都有些多余)。简化接口更有利于数据控制，可以保证互斥量将操作完全锁住。下面的代码展示了一个简单的实现——封装std::stack&lt;&gt;的线程安全堆栈。 代码3.5 扩充(线程安全)堆栈 #include &lt;exception&gt; #include &lt;memory&gt; #include &lt;mutex&gt; #include &lt;stack&gt; struct empty_stack: std::exception &#123; const char* what() const throw() &#123; return &quot;empty stack!&quot;; &#125;; &#125;; template&lt;typename T&gt; class threadsafe_stack &#123; private: std::stack&lt;T&gt; data; mutable std::mutex m; public: threadsafe_stack() : data(std::stack&lt;T&gt;())&#123;&#125; threadsafe_stack(const threadsafe_stack&amp; other) &#123; std::lock_guard&lt;std::mutex&gt; lock(other.m); data = other.data; // 1 在构造函数体中的执行拷贝 &#125; threadsafe_stack&amp; operator=(const threadsafe_stack&amp;) = delete; void push(T new_value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); data.push(new_value); &#125; std::shared_ptr&lt;T&gt; pop() &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); // 在调用pop前，检查栈是否为空 std::shared_ptr&lt;T&gt; const res(std::make_shared&lt;T&gt;(data.top())); // 在修改堆栈前，分配出返回值 data.pop(); return res; &#125; void pop(T&amp; value) &#123; std::lock_guard&lt;std::mutex&gt; lock(m); if(data.empty()) throw empty_stack(); value=data.top(); data.pop(); &#125; bool empty() const &#123; std::lock_guard&lt;std::mutex&gt; lock(m); return data.empty(); &#125; &#125;; 堆栈可以拷贝——拷贝构造函数对互斥量上锁，再拷贝堆栈。构造函数体中①的拷贝使用互斥量来确保复制结果的正确性，这样的方式比成员初始化列表好。 之前对top()和pop()函数的讨论中，因为锁的粒度太小，恶性条件竞争已经出现，需要保护的操作并未全覆盖到。不过，锁的颗粒度过大同样会有问题。还有一个问题，一个全局互斥量要去保护全部共享数据，在一个系统中存在有大量的共享数据时，线程可以强制运行，甚至可以访问不同位置的数据，抵消了并发带来的性能提升。第一版为多处理器系统设计Linux内核中，就使用了一个全局内核锁。这个锁能正常工作，但在双核处理系统的上的性能要比两个单核系统的性能差很多，四核系统就更不能提了。太多请求去竞争占用内核，使得依赖于处理器运行的线程没有办法很好的工作。随后修正的Linux内核加入了一个细粒度锁方案，因为少了很多内核竞争，这时四核处理系统的性能就和单核处理的四倍差不多了。 使用多个互斥量保护所有的数据，细粒度锁也有问题。如前所述，当增大互斥量覆盖数据的粒度时，只需要锁住一个互斥量。但这种方案并非放之四海皆准，互斥量保护一个独立类的实例，锁的状态的下一个阶段，不是离开锁定区域将锁定区域还给用户，就是有独立的互斥量去保护这个类的全部实例，两种方式都不怎么好。 一个给定操作需要两个或两个以上的互斥量时，另一个潜在的问题将出现：死锁。与条件竞争完全相反——不同的两个线程会互相等待，从而什么都没做。 3.2.4 死锁：问题描述及解决方案试想有一个玩具，这个玩具由两部分组成，必须拿到这两个部分，才能够玩。例如玩具鼓，需要鼓锤和鼓才能玩。有两个小孩，他们都很喜欢玩这个玩具。当其中一个孩子拿到了鼓和鼓锤时，那就可以尽情的玩耍了。当另一孩子想要玩，他就得等待另一孩子玩完才行。再试想，鼓和鼓锤被放在不同的玩具箱里，并且两个孩子在同一时间里都想要去敲鼓。之后，他们就去玩具箱里面找这个鼓。其中一个找到了鼓，并且另外一个找到了鼓锤。现在问题就来了，除非其中一个孩子决定让另一个先玩，他可以把自己的那部分给另外一个孩子。但当他们都紧握着自己所有的部分，那么这个鼓谁都没法玩。 现在没有孩子去争抢玩具，但线程有对锁的竞争：一对线程需要对他们所有的互斥量做一些操作，其中每个线程都有一个互斥量，且等待另一个解锁。因为他们都在等待对方释放互斥量，没有线程能工作。这种情况就是死锁，它的问题就是由两个或两个以上的互斥量进行锁定。 避免死锁的一般建议，就是让两个互斥量以相同的顺序上锁：总在互斥量B之前锁住互斥量A，就永远不会死锁。某些情况下是可以这样用，因为不同的互斥量用于不同的地方。不过，当有多个互斥量保护同一个类的独立实例时，一个操作对同一个类的两个不同实例进行数据的交换操作，为了保证数据交换操作的正确性，就要避免并发修改数据，并确保每个实例上的互斥量都能锁住自己要保护的区域。不过，选择一个固定的顺序(例如，实例提供的第一互斥量作为第一个参数，提供的第二个互斥量为第二个参数)，可能会适得其反：在参数交换了之后，两个线程试图在相同的两个实例间进行数据交换时，程序又死锁了！ 很幸运，C++标准库有办法解决这个问题，**std::lock()——可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险)**。下面的程序代码中，就来看一下怎么在一个简单的交换操作中使用std::lock。 代码3.6 交换操作中使用std::lock()和std::lock_guard // 这里的std::lock()需要包含&lt;mutex&gt;头文件 class some_big_object; void swap(some_big_object&amp; lhs,some_big_object&amp; rhs); class X &#123; private: some_big_object some_detail; std::mutex m; public: X(some_big_object const&amp; sd):some_detail(sd)&#123;&#125; friend void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; std::lock(lhs.m,rhs.m); // 1 std::lock_guard&lt;std::mutex&gt; lock_a(lhs.m,std::adopt_lock); // 2 std::lock_guard&lt;std::mutex&gt; lock_b(rhs.m,std::adopt_lock); // 3 swap(lhs.some_detail,rhs.some_detail); &#125; &#125;; 首先检查参数，因为操作试图获取std::mutex对象上的锁，所以结果很难预料。(互斥量可以在同一线程上多次上锁，标准库中std::recursive_mutex提供这样的功能。详情见3.3.3节)。然后，调用std::lock()①锁住两个互斥量，并且创建两个std:lock_guard实例②③。 提供**std::adopt_lock参数除了表示std::lock_guard可获取锁之外，还将锁（std::lock对lhs.m,rhs.m已经上的锁）交由std::lock_guard管理，就不需要std::lock_guard再去构建新的锁**了。 这样，就能保证在大多数情况下【为啥说是大多数情况下？】，函数退出时互斥量能解锁(保护操作可能会抛出一个异常)，也允许使用一个简单的“return”作为返回。当使用std::lock去锁lhs.m或rhs.m时，可能会抛出异常，异常会传播到std::lock之外。当std::lock获取互斥锁时，并尝试从另一个互斥量上再获取锁时，就会有异常抛出，第一个锁也会随着异常而自动释放，所以**std::lock要么将两个锁都锁住，要不一个都不锁**。 C++17对这种情况提供了支持，std::scoped_lock&lt;&gt;是一种新的RAII模板类型，与 std::lock_guard&lt;&gt;的功能相同，这个新类型能接受不定数量的互斥量类型作为模板参数，以及相应的互斥量(数量和类型)作为构造参数。互斥量支持构造时上锁，与std::lock的用法相同，解锁在析构中进行。代码3.6中swap()操作可以重写如下： void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; std::scoped_lock guard(lhs.m,rhs.m); // 1 swap(lhs.some_detail,rhs.some_detail); &#125; 这里使用了C++17的另一个特性：自动推导模板参数。如果有支持C++17的编译器(就能使用std::scoped_lock了，因为其是C++17标准库中的一个工具)，C++17可以通过隐式参数模板类型推导机制， 通过传递的对形象类型来构造实例①。这行代码等价于下面全给参数的版本： std::scoped_lock&lt;std::mutex,std::mutex&gt; guard(lhs.m,rhs.m); std::scoped_lock的好处在于，可以将所有std::lock替换掉，从而减少错误的发生。 虽然std::lock(和std::scoped_lock&lt;&gt;)可以在这情况下(获取两个以上的锁)避免死锁，但它没办法帮助你获取其中一个锁。这需要依赖开发者的纪律性(译者：也就是经验)，来确保程序不会死锁。 死锁是多线程编程中令人相当头痛的问题，并且死锁经常是不可预见的，因为在大部分时间里，所有工作都能很好的完成。不过，一些相对简单的规则能帮助写出“无死锁”的代码。 3.2.5 避免死锁的进阶指导死锁通常是对锁的使用不当造成。无锁的情况下，仅需要两个线程std::thread对象互相调用join()就能产生死锁。这种情况下，没有线程可以继续运行，因为他们正在互相等待。这种情况很常见，一个线程会等待另一个线程，其他线程同时也会等待第一个线程结束，所以三个或更多线程的互相等待也会发生死锁。为了避免死锁，这里意见：不要谦让。以下提供一些个人建议。 避免嵌套锁第一个建议往往是最简单的：线程获得一个锁时，就别再去获取第二个。每个线程只持有一个锁，就不会产生死锁。**当需要获取多个锁，使用std::lock**来做这件事(对获取锁的操作上锁)，避免产生死锁。 避免在持有锁时调用外部代码第二个建议是次简单的：因为代码是外部提供的，所以没有办法确定外部要做什么。外部程序可能做任何事情，包括获取锁。在持有锁的情况下，如果用外部代码要获取一个锁，就会违反第一个指导意见，并造成死锁(有时这是无法避免的)。当写通用代码时(例如3.2.3中的栈)，每一个操作的参数类型，都是外部提供的定义，这就需要其他指导意见来帮助你了。 使用固定顺序获取锁当硬性要求获取两个或两个以上的锁，并且不能使用std::lock单独操作来获取它们时，最好在每个线程上，用固定的顺序获取它们(锁)。3.2.4节中提到，当需要获取两个互斥量时，需要以一定的顺序获取锁。一些情况下，这种方式相对简单。比如，3.2.3节中的栈——每个栈实例中都内置有互斥量，但是对数据成员存储的操作上，栈就需要调用外部代码。虽然，可以添加一些约束，对栈上存储的数据项不做任何操作，但对数据项的处理仅限于栈自身。这会让使用通用栈的难度有所增加，但是一个容器很少去访问另一个容器中存储的数据，即使发生了也会很显眼，所以这对于通用栈来说并不是一个特别重的负担。 其他情况下，这就没那么简单了(例如：3.2.4节中的交换操作)，这时可能同时锁住多个互斥量(有时不会发生)。3.1节中那个链表连接例子中，列表中的每个节点都会有一个互斥量保护。为了访问链表，线程必须获取感兴趣节点上的互斥锁。当一个线程删除一个节点，就必须获取三个节点上的互斥锁：将要删除的节点，两个邻接节点。为了遍历链表，线程必须保证在获取当前节点的互斥锁前提下，获得下一个节点的锁，要保证指向下一个节点的指针不会同时被修改。当下一个节点上的锁被获取，第一个节点的锁就可以释放了。 这种“手递手”的模式允许多个线程访问链表，为每一个访问的线程提供不同的节点。为了避免死锁，节点必须以固定的顺序上锁：如果两个线程试图用互为反向的顺序，在使用“手递手”遍历列表时，执行到链表中间部分时会发生死锁。当节点A和B在列表中相邻，当前线程可能会同时尝试获取A和B上的锁。另一个线程可能已经获取了节点B上的锁，并试图获取节点A上的锁——经典的死锁场景，如图3.2所示。 线程1 线程2 锁住主入口的互斥量 读取头结点指针 锁住头结点互斥量 解锁主入口互斥量 锁住主入口互斥量 读取head-&gt;next指针 锁住尾结点互斥量 锁住next结点的互斥量 读取tail-&gt;prev指针 读取next-&gt;next指针 解锁尾结点的互斥量 … … 锁住A结点的互斥量 锁住C结点的互斥量 读取A-&gt;next指针(也就是B结点) 读取C-&gt;next指针(也就是B结点) 锁住B结点互斥量 阻塞，尝试锁住B结点的互斥量 解锁C结点互斥量 读取B-&gt;prev指针(也就是A结点) 阻塞，尝试锁住A结点的互斥量 死锁！ 图3.2 不同线程以相反顺序访问列表所造成的死锁 当A、C节点中间的B节点删除时，有线程在已获取A和C上的锁后，还要获取B节点上的锁时，就可能发生死锁。线程可能会试图先锁住A节点或C节点(根据遍历的方向)，但是发现无法获得B上的锁，因为执行删除任务的线程，已经获取了B上的锁。 这里提供一种避免死锁的方式，定义遍历的顺序，一个线程必须先锁住A才能获取B的锁，在锁住B之后才能获取C的锁。这将消除死锁，不允许反向遍历链表。类似的约定常用于建立其他的数据结构。 使用层次锁结构虽然，定义锁的顺序是一种特殊情况，但层次锁的意义在于，在运行时会约定是否进行检查。这个建议需要对应用进行分层，并且识别在给定层上所有互斥量。当代码试图对互斥量上锁，而低层已持有该层锁时，不允许锁定。可以通过每个互斥量对应的层数，以及每个线程使用的互斥量，在运行时检查锁定操作是否可以进行。下面的代码列表中，展示两个线程如何使用进行分层互斥的。 代码3.7 使用层次锁来避免死锁 hierarchical_mutex high_level_mutex(10000); // 1 hierarchical_mutex low_level_mutex(5000); // 2 hierarchical_mutex other_mutex(6000); // 3 int do_low_level_stuff(); int low_level_func() &#123; std::lock_guard&lt;hierarchical_mutex&gt; lk(low_level_mutex); // 4 return do_low_level_stuff(); &#125; void high_level_stuff(int some_param); void high_level_func() &#123; std::lock_guard&lt;hierarchical_mutex&gt; lk(high_level_mutex); // 6 high_level_stuff(low_level_func()); // 5 &#125; void thread_a() // 7 &#123; high_level_func(); &#125; void do_other_stuff(); void other_stuff() &#123; high_level_func(); // 10 do_other_stuff(); &#125; void thread_b() // 8 在运行时会失败 &#123; std::lock_guard&lt;hierarchical_mutex&gt; lk(other_mutex); // 9 other_stuff(); &#125; 这段代码有三个hierarchical_mutex实例(①，②和③)，其通过逐渐递减的层级进行构造。根据已经定义好的机制，如将一个hierarchical_mutex实例进行上锁，那么只能获取更低层级实例上的锁，这就会对代码进行一些限制。 假设do_low_level_stuff不会对任何互斥量进行上锁，low_level_func为层级最低的函数，并且会对low_level_mutex④进行上锁。high_level_func调用low_level_func⑤的同时，也持有high_level_mutex⑥上的锁，这也没什么问题，因为high_level_mutex(①：10000)要比low_level_mutex(②：5000)更高级。 thread_a()⑦遵守规则，所以运行没问题。 另一方面，thread_b()⑧无视规则，因此在运行时会失败。 首先，thread_b锁住了other_mutex⑨，这个互斥量的层级值只有6000③。这就意味着，中层级的数据已被保护。当other_stuff()调用high_level_func()⑧时，就违反了层级结构：high_level_func()试图获取high_level_mutex，这个互斥量的层级值是10000，要比当前层级值6000大很多。因此hierarchical_mutex将会产生一个错误，可能会是抛出一个异常或直接终止程序。层级互斥量不可能死锁，因为互斥量本身会严格遵循约定进行上锁。当多个互斥量在是在同一级上时，不能同时持有多个锁，所以“手递手”的方案需要每个互斥量在一条链上，并且每个互斥量都比前一个有更低的层级值，这在某些情况下无法实现。 例子也展示了std::lock_guard&lt;&gt;模板与用户自定义的互斥量类型如何一起使用。虽然hierarchical_mutex不是C++标准的一部分，但是写起来很容易，代码3.8中有一个简单的实现。尽管它是一个用户定义类型，可用于std::lock_guard&lt;&gt;模板中，为了满足互斥量操作，其有三个成员函数：lock(), unlock() 和 try_lock()。try_lock()使用起来很简单：当互斥量上的锁被一个线程持有，它将返回false，而不是等待调用的线程，直到能够获取互斥量上的锁为止；如果互斥量上的锁没有被持有，则获取锁并返回true。std::lock()的内部实现中，try_lock()作为避免死锁算法的一部分。 代码3.8 简单的层级互斥量实现 class hierarchical_mutex &#123; std::mutex internal_mutex; unsigned long const hierarchy_value; //这个锁的层级，构造函数中传入进行设定 unsigned long previous_hierarchy_value; //当前线程获得这把锁前获取的上一把锁的层级（这个应该是thread_local的吗？不需要，这把锁一个时刻只能被一个线程占有，这把锁的上一把锁是well-defined的，即只有一个或者没有，这把锁不会出现有多把上一把锁的情况） static thread_local unsigned long this_thread_hierarchy_value; // 1 当前线程的层级（可以获取的锁必须层级&lt;=这个级别） //检查当前线程的层级是否不低于这把锁的层级，不低于的话当前线程才允许获取这把锁 void check_for_hierarchy_violation() &#123; if(this_thread_hierarchy_value &lt;= hierarchy_value) // 2 &#123; throw std::logic_error(&quot;mutex hierarchy violated&quot;); &#125; &#125; void update_hierarchy_value() &#123; previous_hierarchy_value=this_thread_hierarchy_value; // 3 记录当前线程在获取这把锁之前的层级 this_thread_hierarchy_value=hierarchy_value; //更新当前线程的层级为这把锁的层级（其实是更新为std::min(this_thread_hierarchy_value, hierarchy_value)，不过能够执行更新函数一定有hierarchy_value&lt;=this_thread_hierarchy_value，所以这个直接赋值即可，一定是向下或不变地更新当前线程的层级） &#125; public: //构造函数，设定这个锁的层级 explicit hierarchical_mutex(unsigned long value): hierarchy_value(value), previous_hierarchy_value(0) &#123;&#125; void lock() &#123; check_for_hierarchy_violation(); internal_mutex.lock(); // 4 update_hierarchy_value(); // 5 &#125; void unlock() &#123; //当前线程的层级!=这把锁的层级，说明当前线程在获取这把锁之后获取了其他的锁（必须是层级低于这把锁的），而其他锁尚未解锁，或者当前线程尚未获取这把锁 if(this_thread_hierarchy_value!=hierarchy_value) throw std::logic_error(&quot;mutex hierarchy violated&quot;); // 9 this_thread_hierarchy_value=previous_hierarchy_value; // 6 释放这把锁，更新当前线程的层级为它获得的上一把锁的层级 internal_mutex.unlock(); &#125; bool try_lock() &#123; check_for_hierarchy_violation(); if(!internal_mutex.try_lock()) // 7 return false; //对internal_mutex lock了，更新层级 update_hierarchy_value(); return true; &#125; &#125;; thread_local unsigned long hierarchical_mutex::this_thread_hierarchy_value(ULONG_MAX); // 8 在构造函数中指定这把锁的层级（所以我们可以创建多个同层次的不同锁） 这里重点是使用了thread_local的值来代表当前线程的层级值：this_thread_hierarchy_value①，初始化为最大值⑧，所以最初所有线程都能被锁住。因为声明中有thread_local，所以每个线程都有其副本，这样线程中变量状态完全独立，当从另一个线程进行读取时，变量的状态也完全独立。 所以，线程第一次锁住一个hierarchical_mutex时，this_thread_hierarchy_value的值是ULONG_MAX。由于其本身的性质，这个值会大于其他任何值，所以通过了check_for_hierarchy_vilation()②的检查。这种检查下，lock()代表内部互斥锁已锁住④。一旦成功锁住，就可以更新层级值了⑤。 当持有第一个锁的同时，还锁住了另一个hierarchical_mutex，this_thread_hierarchy_value的值将会显示第一个互斥量的层级值。第二个互斥量的层级值必须小于已持有互斥量，检查函数②才能通过。 现在，最重要的是为当前线程赋予之前的层级值，可以调用unlock()⑥对层级值进行保存。否则，就锁不住任何互斥量(第二个互斥量的层级数高于第一个互斥量)，即使线程没有持有任何锁。因为保存了之前的层级值，只有当持有internal_mutex③，且在解锁内部互斥量⑥之前存储它的层级值时，需要内部互斥量对hierarchical_mutex实例进行保护，才能安全的将hierarchical_mutex存储。为了避免无序解锁造成层次混乱，不是解锁最近上锁的那个互斥量，就需要抛出异常⑨。其他机制也能做到这点，但目前这是最简单的。 try_lock()与lock()的功能相似，除了在调用internal_mutex的try_lock()⑦失败时，不能持有对应锁，所以不必更新层级值，并直接返回false。 虽然是运行时检测，但无时间依赖性——不必去等待构成死锁的条件出现。同时，设计过程需要拆分应用，互斥量在这种情况下可以消除死锁的可能性。这样的练习很有必要去做一下，即使你之后没有去做，代码也会在运行时检查。 超越锁的延伸扩展死锁不仅仅会发生在锁之间，也会发生在同步构造中(可能会产生一个等待循环)，这也需要有指导意见，例如：获取嵌套锁，等待一个持有锁的线程，都是很糟糕的决定(因为线程为了能继续运行可能需要获取对应的锁)。如果去等待一个线程结束，应该确定这个线程的层级，这样一个线程只需要等待比其层级低的线程结束即可。用一个简单的办法便可确定，添加的线程是否在同一函数中启动，如同在3.1.2节和3.3节中描述的那样。 代码已能规避死锁，std::lock()和std::lock_guard可组成简单的锁，并覆盖大多数情况，但有时需要更多的灵活性，可以使用标准库提供的std::unique_lock模板。如 std::lock_guard，这是一个参数化的互斥量模板类，它提供很多RAII类型锁用来管理std::lock_guard类型，可以让代码更加灵活。 3.2.6 std::unique_lock——灵活的锁std::unqiue_lock使用起来更为自由，**std::unique_lock实例不会总与互斥量的数据类型相关，使用起来要比std:lock_guard更加灵活。首先，可将std::adopt_lock作为第二个参数传入构造函数，对互斥量进行管理（意思是这传入这个参数之后，就不是用std::unqiue_lock内部申请的锁，不是由std::unqiue_lock类来进行锁管理，而是由用户代码进行锁管理）。也可以将std::defer_lock作为第二个参数传递进去，表明互斥量应保持解锁状态（构造对象的时候不是直接上锁）。这样就可以让std::unique_lock对象(不是互斥量)的lock()所获取，或传递std::unique_lock对象到std::lock()中。代码3.6可以轻易的转换为代码3.9，使用std::unique_lock和std::defer_lock①，而非std::lock_guard和std::adopt_lock。代码长度相同，几乎等价，唯一不同的就是：std::unique_lock会占用比较多的空间，并且比std::lock_guard稍慢一些**。保证灵活性要付出代价，这个代价就是允许std::unique_lock实例不带互斥量：信息已存储，且已更新。 代码3.9 交换操作中std::lock()和std::unique_lock的使用 class some_big_object; void swap(some_big_object&amp; lhs,some_big_object&amp; rhs); class X &#123; private: some_big_object some_detail; std::mutex m; public: X(some_big_object const&amp; sd):some_detail(sd)&#123;&#125; friend void swap(X&amp; lhs, X&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return; //unique_lock的模板参数类型为 其上锁的类型（对什么上锁，比如这里是对std::mutex类型的实例上锁，这个类型与构造函数传入的第一个参数的类型一致） std::unique_lock&lt;std::mutex&gt; lock_a(lhs.m,std::defer_lock); // 1 std::unique_lock&lt;std::mutex&gt; lock_b(rhs.m,std::defer_lock); // 1 std::defer_lock 留下未上锁的互斥量 std::lock(lock_a,lock_b); // 2 互斥量在这里上锁 swap(lhs.some_detail,rhs.some_detail); &#125; &#125;; 代码3.9中，因为**std::unique_lock支持lock(), try_lock()和unlock()成员函数，所以能将std::unique_lock对象传递到std::lock()②。这些同名成员函数在低层做着实际的工作，并且仅更新std::unique_lock实例中的标志，来确定该实例是否拥有特定的互斥量，这个标志是为了确保unlock()在析构函数中正确调用。如果实例拥有互斥量，那么析构函数必须调用unlock()。但当实例中没有互斥量时，析构函数就不能去调用unlock()，这个标志可以通过owns_lock()成员变量进行查询**。除非想将std::unique_lock的所有权进行转让，最好使用C++17中提供的std::scoped_lock(详见3.2.4节)。 如期望的那样，这个标志存储在了某个地方。因此，std::unique_lock实例的体积通常要比std::lock_guard实例大，当使用std::unique_lock替代std::lock_guard，会对标志进行更新或检查，就会有一些轻微的性能惩罚。当std::lock_guard已经能够满足需求时，建议继续使用。当需要更加灵活的锁时，最好选择std::unique_lock，因为它更适合于你的任务。我们已经看到一个递延锁的例子，另外一种情况是锁的所有权从一个域转到另一个域。 3.2.7 不同域中互斥量的传递std::unique_lock实例没有与自身相关的互斥量，互斥量的所有权可以通过移动操作，在不同的实例中进行传递。某些情况下，这种转移是自动发生的，例如：当函数返回一个实例。另一种情况下，需要显式的调用std::move()来执行移动操作。本质上来说，需要依赖于源值是否是左值——一个实际的值或是引用——或一个右值——一个临时类型。当源值是一个右值，为了避免转移所有权过程出错，就必须显式移动成左值。**std::unique_lock是可移动，但不可赋值**的类型。 一种使用可能是允许函数去锁住一个互斥量，并且将所有权移到调用者上，所以调用者可以在这个锁保护的范围内执行额外的动作。 下面的程序片段展示了：函数get_lock()锁住了互斥量，然后准备数据，返回锁的调用函数。 std::unique_lock&lt;std::mutex&gt; get_lock() &#123; extern std::mutex some_mutex; std::unique_lock&lt;std::mutex&gt; lk(some_mutex); //构造函数没有传入第二个参数，则是构造函数中就对互斥量std::mutex some_mutex上锁 prepare_data(); return lk; // 1 编译器会调用移动构造函数来构造返回值（一个临时的类型为std::unique_lock&lt;std::mutex&gt;的变量） &#125; void process_data() &#123; std::unique_lock&lt;std::mutex&gt; lk(get_lock()); // 2 get_lock()返回临时对象，然后lk的构造是调用移动构造函数，把get_lock()返回的临时对象关联的锁移动给lk do_something(); &#125; lk在函数中被声明为自动变量，它不需要调用std::move()，可以直接返回①(编译器负责调用移动构造函数)。process_data()函数直接转移std::unique_lock实例的所有权②，调用do_something()可使用的正确数据(数据没有受到其他线程的修改)。 通常这种模式会用于已锁的互斥量，其依赖于当前程序的状态，或依赖于传入返回类型为std::unique_lock的函数(或以参数返回)。这样不会直接返回锁，不过网关类的数据成员可用来确认，是否已经对保护数据的访问权限进行上锁。这种情况下，所有的访问都必须通过网关类：当你想要访问数据，需要获取网关类的实例(如同前面的例子，通过调用get_lock()之类函数)来获取锁。之后就可以通过网关类的成员函数对数据进行访问，完成访问时可以销毁这个网关类对象，将锁进行释放，让别的线程来访问保护数据。这样的一个网关类可能是可移动的(所以可以从函数进行返回)，这种情况下锁对象的数据必须可移动。 std::unique_lock的灵活性同样也允许实例在销毁之前放弃拥有的锁。可以使用unlock()来做这件事，如同一个互斥量：std::unique_lock的成员函数提供类似于锁定和解锁的功能。std::unique_lock实例有在销毁前释放锁的能力，当没有必要在持有锁的时候，可以在特定的代码分支对锁进行选择性释放。这对于应用的性能来说非常重要，因为持有锁的时间增加会导致性能下降，其他线程会等待这个锁的释放，避免超越操作。 3.2.8 锁的粒度3.2.3节中，已经对锁的粒度有所了解：锁的粒度是一个华而不实的术语(hand-waving term)，用来描述通过一个锁保护着的数据量大小。一个细粒度锁(a fine-grained lock)能够保护较小的数据量，一个粗粒度锁(a coarse-grained lock)能够保护较多的数据量。粒度对于锁来说很重要，为了保护对应的数据，保证锁有能力保护这些数据也很重要。 在超市等待结账的时候，正在结账的顾客突然意识到忘了拿蔓越莓酱，然后离开柜台去拿，并让其他的人都等待他回来。或者当收银员，准备收钱时，顾客才去翻钱包拿钱，这样的情况都会让等待的顾客很无奈。当每个人都检查了自己要拿的东西，且能随时为拿到的商品进行支付时，每件事都会进行得很顺利。 道理同样适用于线程：如果很多线程正在等待同一个资源(等待收银员对自己拿到的商品进行清点)，当有线程持有锁的时间过长，这就会增加等待的时间(别等到结账的时候，才想起来蔓越莓酱没拿)。可能的情况下，锁住互斥量的同时只能对共享数据进行访问，试图对锁外数据进行处理。特别是做一些费时的动作，比如：对文件的输入&#x2F;输出操作进行上锁。文件输入&#x2F;输出通常要比从内存中读或写同样长度的数据慢成百上千倍，所以除非锁已经打算去保护对文件的访问，要么执行输入&#x2F;输出操作将会将延迟其他线程执行的时间，这没有必要(因为文件锁阻塞住了很多操作)，这样多线程带来的性能效益会被抵消。 std::unique_lock在这种情况下工作正常，调用unlock()时，代码不需要再访问共享数据。当再次需要对共享数据进行访问时，再调用lock()就可以了。 void get_and_process_data() &#123; std::unique_lock&lt;std::mutex&gt; my_lock(the_mutex); //std::unique_lock对象与对the_mutex的锁相关联，或者说这个std::unique_lock对象提供对the_mutex实例的锁服务 some_class data_to_process=get_next_data_chunk(); my_lock.unlock(); // 1 不要让锁住的互斥量越过process()函数的调用 result_type result=process(data_to_process); my_lock.lock(); // 2 为了写入数据，对互斥量再次上锁 write_result(data_to_process,result); &#125; 不需要让锁住的互斥量越过对process()函数的调用，所以可以在函数调用①前对互斥量进行手动解锁，之后对其再次上锁②。 这表示只有一个互斥量保护整个数据结构时的情况，不仅会有更多对锁的竞争，也会增加持锁的时长。较多的操作步骤需要获取同一个互斥量上的锁，所以持有锁的时间会更长。成本上的双重打击也算是为了向细粒度锁转移提供了激励和可能。 如同上面的例子，锁不仅是能 锁住合适粒度的数据，还要控制锁的持有时间，以及哪些操作在执行的同时能够拥有锁。一般情况下，尽可能将持有锁的时间缩减到最小。 代码3.6和3.9中，交换操作需要锁住两个互斥量，其明确要求并发访问两个对象。假设用来做比较的是一个简单的数据类型(比如：int类型)，将会有什么不同么？int的拷贝很廉价，所以可以进行数据复制，并且每个比较的对象都持有该对象的锁，在比较之后进行数据拷贝。在最短时间内持有每个互斥量，并且不会在持有一个锁的同时再去获取另一个。下面的代码中展示了这样情景中的Y类，并且展示了一个相等比较运算符的等价实现。 代码3.10 比较操作符中一次锁住一个互斥量 class Y &#123; private: int some_detail; mutable std::mutex m; int get_detail() const &#123; std::lock_guard&lt;std::mutex&gt; lock_a(m); // 1 return some_detail; &#125; public: Y(int sd):some_detail(sd)&#123;&#125; friend bool operator==(Y const&amp; lhs, Y const&amp; rhs) &#123; if(&amp;lhs==&amp;rhs) return true; int const lhs_value=lhs.get_detail(); // 2 int const rhs_value=rhs.get_detail(); // 3 return lhs_value==rhs_value; // 4 &#125; &#125;; 例子中，比较操作符首先通过调用get_detail()成员函数检索要比较的值②③，函数在索引时被锁保护着①。比较操作符会在之后比较索引出来的值④。注意：虽然锁只持有一次的操作能减少锁持有的时间(这样能消除死锁的可能性)，但这里有一个微妙的语义操作同时对两个锁住的值进行比较。 代码3.10中，当操作符返回true时，就意味着在这个时间点上的lhs.some_detail与另一个时间点的rhs.some_detail相同。这两个值在读取之后，可能会以任意方式修改。两个值会在②和③处进行交换，这样就会失去了比较的意义。比较可能会返回true，表明这两个值是相等的，实际上这两个值相等的情况可能就发生在一瞬间。这样的变化必须要小心，语义操作是无法改变比较方式的：当持有锁的时间没有达到整个操作时间，就会让自己处于条件竞争的状态。 有时可能找不到一个合适的粒度级别，因为并不是所有对数据结构的访问都需要同一级的保护。这个例子中，就需要寻找一个合适的机制，去替换std::mutex。 [1] Tom Cargill, “Exception Handling: A False Sense of Security,” in C++ Report 6, no. 9 (November–December 1994). Also available at http://www.informit.com/content/images/020163371x/supplements/Exception_Handling_Article.html. [2] Herb Sutter, Exceptional C++: 47 Engineering Puzzles, Programming Problems, and Solutions (Addison Wesley Pro-fessional, 1999).","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.5 线程标识","slug":"c++并发编程实践2ed：25 线程标识","date":"2022-07-16T13:17:37.923Z","updated":"2022-12-10T15:17:02.975Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：25 线程标识/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A25%20%E7%BA%BF%E7%A8%8B%E6%A0%87%E8%AF%86/","excerpt":"","text":"2.5 线程标识线程标识为**std::thread::id类型，可以通过两种方式进行检索。第一种，可以通过调用std::thread对象**的成员函数get_id()来直接获取。如果std::thread对象没有与任何执行线程相关联，get_id()将返回std::thread::type默认构造值，这个值表示“无线程”。第二种，**当前线程中调用std::this_thread::get_id()**(这个函数定义在&lt;thread&gt;头文件中)也可以获得线程标识。 std::thread::id对象可以自由的拷贝和对比，因为标识符可以复用。如果两个对象的std::thread::id相等，那就是同一个线程，或者都“无线程”。如果不等，那么就代表了两个不同线程，或者一个有线程，另一没有线程。 C++线程库不会限制你去检查线程标识是否一样，std::thread::id类型对象提供了相当丰富的对比操作。比如，为不同的值进行排序。这意味着开发者可以将其当做为容器的键值做排序，或做其他比较。按默认顺序比较不同的std::thread::id：当a&lt;b，b&lt;c时，得a&lt;c，等等。标准库也提供std::hash&lt;std::thread::id&gt;容器，std::thread::id也可以作为无序容器的键值。 std::thread::id实例常用作检测线程是否需要进行一些操作。比如：当用线程来分割一项工作(如代码2.9)，主线程可能要做一些与其他线程不同的工作，启动其他线程前，可以通过std::this_thread::get_id()得到自己的线程ID。每个线程都要检查一下，其拥有的线程ID是否与初始线程的ID相同。 std::thread::id master_thread; void some_core_part_of_algorithm() &#123; if(std::this_thread::get_id()==master_thread) &#123; do_master_thread_work(); &#125; do_common_work(); &#125; 另外，当前线程的std::thread::id将存储到数据结构中。之后这个结构体对当前线程的ID与存储的线程ID做对比，来决定操作是“允许”，还是“需要”(permitted&#x2F;required)。 同样，作为线程和本地存储不适配的替代方案，线程ID在容器中可作为键值。例如，容器可以存储其掌控下每个线程的信息，或在多个线程中互传信息。 std::thread::id可以作为线程的通用标识符，当标识符只与语义相关(比如，数组的索引)时，就需要这个方案了。也可以使用输出流(std::cout)来记录一个std::thread::id对象的值。 std::cout&lt;&lt;std::this_thread::get_id(); 具体的输出结果是严格依赖于具体实现的，C++标准的要求就是保证ID相同的线程必须有相同的输出。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.4 确定线程数量","slug":"c++并发编程实践2ed：24 确定线程数量","date":"2022-07-16T13:16:43.074Z","updated":"2022-12-10T15:17:13.000Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：24 确定线程数量/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A24%20%E7%A1%AE%E5%AE%9A%E7%BA%BF%E7%A8%8B%E6%95%B0%E9%87%8F/","excerpt":"","text":"2.4 确定线程数量std::thread::hardware_concurrency()在新版C++中非常有用，其会返回并发线程的数量。例如，多核系统中，返回值可以是CPU核芯的数量。返回值也仅仅是一个标识，当无法获取时，函数返回0。 代码2.9实现了并行版的std::accumulate。代码将整体工作拆分成小任务，交给每个线程去做，并设置最小任务数，避免产生太多的线程，程序会在操作数量为0时抛出异常。比如，std::thread无法启动线程，就会抛出异常。 代码2.9 并行版的std::accumulate template&lt;typename Iterator,typename T&gt; struct accumulate_block &#123; void operator()(Iterator first,Iterator last,T&amp; result) &#123; result=std::accumulate(first,last,result); &#125; &#125;; template&lt;typename Iterator,typename T&gt; T parallel_accumulate(Iterator first,Iterator last,T init) &#123; unsigned long const length=std::distance(first,last); if(!length) // 1 return init; unsigned long const min_per_thread=25; unsigned long const max_threads= (length+min_per_thread-1)/min_per_thread; // 2 unsigned long const hardware_threads= std::thread::hardware_concurrency(); unsigned long const num_threads= // 3 std::min(hardware_threads != 0 ? hardware_threads : 2, max_threads); unsigned long const block_size=length/num_threads; // 4 std::vector&lt;T&gt; results(num_threads); std::vector&lt;std::thread&gt; threads(num_threads-1); // 5 Iterator block_start=first; for(unsigned long i=0; i &lt; (num_threads-1); ++i) &#123; Iterator block_end=block_start; std::advance(block_end,block_size); // 6 threads[i]=std::thread( // 7 accumulate_block&lt;Iterator,T&gt;(), block_start,block_end,std::ref(results[i])); block_start=block_end; // 8 &#125; //最终块可能没有block_size个元素，其end用last accumulate_block&lt;Iterator,T&gt;()( block_start,last,results[num_threads-1]); // 9 for (auto&amp; entry : threads) entry.join(); // 10 return std::accumulate(results.begin(),results.end(),init); // 11 &#125; 函数看起来很长，但不复杂。如果输入的范围为空①，就会得到init的值。如果范围内的元素多于一个时，需要用范围内元素的总数量除以线程(块)中最小任务数，从而确定启动线程的最大数量②。 因为上下文频繁切换会降低线程的性能，所以计算量的最大值和硬件支持线程数，较小的值为启动线程的数量③。std::thread::hardware_concurrency()返回0时，可以选择一个合适的数字。在本例中，我选择了”2”。 每个线程中处理的元素数量，是范围中元素的总量除以线程的个数得出的④，分配是否得当会在后面讨论。 现在，确定了线程个数，创建一个std::vector&lt;T&gt;容器存放中间结果，并为线程创建一个std::vector&lt;std::thread&gt;容器⑤。因为**在启动之前已经有了一个线程(主线程)**，所以启动的线程数必须比num_threads少1。 使用循环来启动线程：block_end迭代器指向当前块的末尾⑥，并启动一个新线程为当前块累加结果⑦。当迭代器指向当前块的末尾时，启动下一个块⑧。 启动所有线程后，⑨中的线程会处理最终块的结果。因为知道最终块是哪一个，所以最终块中有多少个元素就无所谓了。 累加最终块的结果后，可等待std::for_each⑩joint线程(如同在代码2.8中做的那样)，之后使用std::accumulate将所有结果进行累加⑪。 结束这个例子之前，需要明确：T类型的加法不满足结合律(比如，对于float型或double型，在进行加法操作时，系统很可能会做截断操作)，因为对范围中元素的分组，会导致parallel_accumulate得到的结果可能与std::accumulate的结果不同。同样的，这里对迭代器的要求更加严格：必须是前向迭代器。对于results容器，需要保证T有默认构造函数。可以需要根据算法本身的特性，选择不同的并行方式。算法并行会在第8章更加深入的进行讨论，并在第10章中会介绍C++17中支持的并行算法(其中std::reduce操作等价于这里的parallel_accumulate)。因为不能直接从一个线程中返回值，所以需要传递results容器的引用到线程中去。另一个办法，通过地址来获取线程执行的结果(第4章中，我们将使用future完成这种方案)。 当线程运行时，所有必要的信息都需要传入到线程中去，包括存储计算结果的位置。有时候可以传递一个标识数，例如代码2.8中的i。不过，需要标识的函数（的标识数参数）在调用栈的底层，同时其他线程也可调用该函数（这样其实本来只是想标识线程，但是现在由于设计了标识数这个参数，每次谁调用这个函数都会在栈上有这个参数占的内存），那么标识数就会变成累赘。好消息是在设计C++的线程库时，就有预见了这种情况，实现中给每个线程附加了唯一标识符。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.2 传递参数","slug":"c++并发编程实践2ed：22 传递参数","date":"2022-07-16T13:12:10.634Z","updated":"2022-12-10T15:17:24.687Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：22 传递参数/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A22%20%E4%BC%A0%E9%80%92%E5%8F%82%E6%95%B0/","excerpt":"","text":"2.2 传递参数：std::thread构造函数规则如代码2.4所示，向可调用对象或函数传递参数很简单，只需要将这些参数作为 std::thread构造函数的附加参数即可。需要注意的是，这些参数会**拷贝至新线程的内存空间中(同临时变量一样)。即使函数中的参数是引用的形式**，拷贝操作也会执行。 事实上，以附加参数传入的参数，其在线程函数中的类型只能是值传递或者const引用传递（const引用可以是因为可以const引用右值），否则会编译错误 cppreference thread() noexcept; (1) (since C++11) thread( thread&amp;&amp; other ) noexcept; 移动构造函数，1.参数类型thread&amp;&amp;右值引用类型暗示实现是移动语义（即浅拷贝+源指针置空） 2.noexcept则一旦在其上下文中抛出异常，异常处理机制将直接调用std::terminate() (2) (since C++11) template&lt; class Function, class… Args &gt; explicit thread( Function&amp;&amp; f, Args&amp;&amp;… args ); 构造函数 (3) (since C++11) thread( const thread&amp; ) &#x3D; delete; 拷贝构造函数，不允许编译器生成 (4) (since C++11) Constructs new thread object. \\1) Creates new thread object which does not represent a thread. \\2) Move constructor. Constructs the thread object to represent the thread of execution that was represented by other. After this call other no longer represents a thread of execution. \\3) Creates new std::thread object and associates it with a thread of execution. The new thread of execution starts executing &#x2F;*INVOKE*&#x2F;(std::move(f_copy), std::move(args_copy)…), where &#x2F;*INVOKE*&#x2F; performs the *INVOKE* operation specified in Callable f_copy is an object of type std::decay::type and constructed from std::forward(f), and 如果Function类型为左值引用类型，则f_copy为左值，否则f_copy类型为右值 args_copy... are objects of types std::decay::type… and constructed from std::forward(args)…. Constructions of these objects are executed in the context of the caller, so that any exceptions thrown during evaluation and copying&#x2F;moving of the arguments are thrown in the current thread, without starting the new thread. The program is ill-formed if any construction or the *INVOKE* operation is invalid. This constructor does not participate in overload resolution if std::decay::type is the same type as thread. The completion of the invocation of the constructor synchronizes-with (as defined in std::memory_order) the beginning of the invocation of the copy of f on the new thread of execution. \\4) The copy constructor is deleted; threads are not copyable. No two std::thread objects may represent the same thread of execution. 来看一个例子： void f(int i, std::string const&amp; s); std::thread t(f, 3, &quot;hello&quot;); 替换隐式转换为显示转换代码创建了一个调用f(3, “hello”)的线程。注意，函数f需要一个std::string对象作为第二个参数，但这里使用的是字符串的字面值，也就是char const *类型，线程的上下文完成字面值向std::string的转化。需要特别注意，指向动态变量的指针作为参数的情况，代码如下： void f(int i,std::string const&amp; s); void oops(int some_param) &#123; char buffer[1024]; // 1 sprintf(buffer, &quot;%i&quot;,some_param); std::thread t(f,3,buffer); // 2 t.detach(); &#125; buffer①是一个指针变量，指向局部变量，然后此局部变量通过buffer传递到新线程中②。此时，函数oops可能会在buffer转换成std::string之前结束，从而导致未定义的行为。因为，**无法保证隐式转换的操作和std::thread构造函数的拷贝操作的顺序，有可能std::thread的构造函数拷贝的是转换前的变量(buffer指针)。解决方案就是在传递到std::thread构造函数之前，就将字面值转化为std::string**： void f(int i,std::string const&amp; s); void not_oops(int some_param) &#123; char buffer[1024]; sprintf(buffer,&quot;%i&quot;,some_param); std::thread t(f,3,std::string(buffer)); // 使用std::string，避免悬空指针 t.detach(); &#125; 相反的情形(期望传递一个非常量引用，但复制了整个对象)倒是不会出现，因为会出现编译错误。比如，尝试使用线程更新引用传递的数据结构： void update_data_for_widget(widget_id w,widget_data&amp; data); // 1 void oops_again(widget_id w) &#123; widget_data data; std::thread t(update_data_for_widget,w,data); // 2 display_status(); t.join(); process_widget_data(data); &#125; 虽然update_data_for_widget①的第二个参数期待传入一个引用，但std::thread的构造函数②并不知晓，构造函数无视函数参数类型，盲目地拷贝已提供的变量。不过，内部代码会将拷贝的参数以右值的方式进行传递，这是为了那些只支持移动的类型，而后会尝试以右值为实参调用update_data_for_widget。但因为函数期望的是一个非常量引用作为参数(而非右值)，所以会在编译时出错。 使用std::ref传递引用 std::ref和std::cref事实上是模板函数，返回值是一个std::reference_wrapper对象（该对象有一个数据成员：一个指针），而std::reference_wrapper虽然是一个对象，可是他却能展现出和普通引用类似的效果 对于熟悉std::bind的开发者来说，问题的解决办法很简单：可以使用std::ref将参数转换成引用的形式。因此可将线程的调用改为以下形式： std::thread t(update_data_for_widget,w,std::ref(data)); 这样仍然是发生拷贝，拷贝的std::reference_wrapper对象，这个对象满足函数引用参数类型的要求 这样update_data_for_widget就会收到data的引用，而非data的拷贝副本，这样代码就能顺利的通过编译了。 类的成员函数作为线程函数如果熟悉std::bind，就应该不会对以上述传参的语法感到陌生，因为std::thread构造函数和std::bind的操作在标准库中以相同的机制进行定义。比如，你也可以传递一个成员函数指针作为线程函数，并提供一个合适的对象指针作为第一个参数： class X &#123; public: void do_lengthy_work(); &#125;; X my_x; std::thread t(&amp;X::do_lengthy_work, &amp;my_x); // 1 这段代码中，新线程将会调用my_x.do_lengthy_work()，其中my_x的地址①作为对象指针提供给函数。也可以为成员函数提供参数：std::thread构造函数的第三个参数就是成员函数的第一个参数，以此类推(代码如下，译者自加)。 class X &#123; public: void do_lengthy_work(int); &#125;; X my_x; int num(0); std::thread t(&amp;X::do_lengthy_work, &amp;my_x, num); std::move传递只能移动不能拷贝的类型另一种有趣的情形是，提供的参数仅支持移动(move)，不能拷贝。&#96;&#96;std::unique_ptr&#96;是这种类型 使用移动操作可以将对象转换成函数可接受的实参类型，或满足函数返回值类型要求。 void process_big_object(std::unique_ptr&lt;big_object&gt;); std::unique_ptr&lt;big_object&gt; p(new big_object); p-&gt;prepare_data(42); std::thread t(process_big_object,std::move(p)); //std::move将左值p强制类型转换为右值引用类型 C++标准线程库中和std::unique_ptr在所属权上相似的类有好几种，std::thread为其中之一。虽然，std::thread不像std::unique_ptr能占有动态对象的所有权，但是它能占有其他资源：每个实例都负责管理一个线程。线程的所有权可以在多个std::thread实例中转移，这依赖于**std::thread实例的可移动且不可复制性**。不可复制性表示在某一时间点，一个std::thread实例只能关联一个执行线程。可移动性使得开发者可以自己决定，哪个实例拥有线程实际执行的所有权。","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++11左右值引用 移动语义","slug":"c++11左右值引用 移动语义","date":"2022-07-16T13:11:07.413Z","updated":"2022-12-10T15:17:36.420Z","comments":true,"path":"2022/07/16/c++11左右值引用 移动语义/","link":"","permalink":"http://example.com/2022/07/16/c++11%E5%B7%A6%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%20%E7%A7%BB%E5%8A%A8%E8%AF%AD%E4%B9%89/","excerpt":"","text":"学习自一文读懂C++右值引用和std::move - 知乎 (zhihu.com)，原文真的写得超级好！ 该文文末还讲解了std::forward，暂时未学习 左右值引用左值引用左值引用类型为T&amp; 非const不可以指向右值 int a = 5; int &amp;ref_a = a; // 左值引用指向左值，编译通过 int &amp;ref_a = 5; // 左值引用指向了右值，会编译失败 const左值引用是可以指向右值的： const int &amp;ref_a = 5; // 编译通过 const左值引用不会修改指向值，因此可以指向右值 如std::vector的push_back： void push_back (const value_type&amp; val); 如果没有const，vec.push_back(5)这样的代码就无法编译通过了。 右值引用右值引用类型为T&amp;&amp; 可以指向右值，不能指向左值 可以修改右值 int &amp;&amp;ref_a_right = 5; // ok int a = 5; int &amp;&amp;ref_a_left = a; // 编译不过，右值引用不可以指向左值 ref_a_right = 6; // 右值引用的用途：可以修改右值 右值引用修改右值的实际实现：把右值提升为一个左值，并定义一个右值引用通过std::move指向该左值： int &amp;&amp;ref_a = 5; ref_a = 6; //等同于以下代码： int temp = 5;//只是这个是编译器给准备的一个存储实体，估计这个存储实体是在栈上，和int temp=5;一样是栈上的局部变量，只是我们没有这个变量的名字 int &amp;&amp;ref_a = std::move(temp); ref_a = 6; 右值引用有办法指向左值吗？ std::moveint a = 5; // a是个左值 int &amp;ref_a_left = a; // 左值引用指向左值 int &amp;&amp;ref_a_right = std::move(a); // 通过std::move将左值类型转化为右值，可以被右值引用指向 cout &lt;&lt; a; // 打印结果：5 在上边的代码里，看上去是左值a通过std::move移动到了右值ref_a_right中，那是不是a里边就没有值了？并不是，打印出a的值仍然是5。 std::move是一个非常有迷惑性的函数，不理解左右值概念的人们往往以为它能把一个变量里的内容移动到另一个变量，但事实上std::move没有做移动，唯一的功能是强制类型转换（把左值强制转化为右值），让右值引用可以指向左值。其实现等同于一个类型转换：**static_cast&lt;T&amp;&amp;&gt;(lvalue)**。 结论 从性能上讲，左右值引用没有区别，传参使用左右值引用都可以避免拷贝。 右值引用可以直接指向右值，也可以通过std::move指向左值；而左值引用只能指向左值(const左值引用也能指向右值)。 作为函数形参时，右值引用更灵活。虽然const左值引用也可以做到左右值都接受，但它无法修改，有一定局限性。 std::ref 使用举例见 c++并发编程实践：2.2 传递参数 用于函数接收参数类型为非const左值引用，但是只能拷贝传递的场景下（比如std::thread构造函数中通过附件参数来传参，这些参数都是通过值传递的方式传递的），来包装左值引用 std::ref和std::cref是模板函数，返回值是一个std::reference_wrapper对象（该对象有一个数据成员：一个指针），而std::reference_wrapper虽然是一个对象，可是他却能展现出和普通引用类似的效果 头文件#include 编译参数：-std=c++11 -pthread 其中-pthread 库需要 #include &lt;iostream&gt; #include &lt;thread&gt; #include &lt;functional&gt; void func(int&amp; arg) &#123; std::cout&lt;&lt;arg&lt;&lt;std::endl; &#125; int main()&#123; int a; //想把a的引用传入func中，func作为新线程的线程函数 std::thread th(func, a); //编译器会报错 std::thread th(func, std::ref(a)); //也是值传递std::ref(a)，把std::ref(a)这个对象拷贝到新线程堆栈中（先准备参数，然后是返回地址，然后是旧的栈底指针，然后是栈底...），这个对象中有个指向a的指针 th.join();//等待子线程，因为子线程持有主线程生命周期中的局部变量的引用，所以为了防止未定义行未，主线程得比子线程晚结束 return 0; &#125; 常量引用可以绑定到右值 https://herbsutter.com/2008/01/01/gotw-88-a-candidate-for-the-most-important-const/ Normally, a temporary object lasts only until the end of the full expression in which it appears. However, C++ deliberately specifies that binding a temporary object to a reference to const on the stack lengthens the lifetime of the temporary ++to the lifetime of the reference itself++, and thus avoids what would otherwise be a common dangling-reference error Note this only applies to stack-based references. It doesn’t work for references that are members of objects 右值引用和std::move的应用场景 移动语义实现移动语义 移动语义理解举例class Array &#123; public: Array(int size) : size_(size) &#123; data = new int[size_]; &#125; // 深拷贝构造 Array(const Array&amp; temp_array) &#123; size_ = temp_array.size_; data_ = new int[size_]; for (int i = 0; i &lt; size_; i ++) &#123; data_[i] = temp_array.data_[i]; &#125; &#125; // 深拷贝赋值 Array&amp; operator=(const Array&amp; temp_array) &#123; delete[] data_; size_ = temp_array.size_; data_ = new int[size_]; for (int i = 0; i &lt; size_; i ++) &#123; data_[i] = temp_array.data_[i]; &#125; &#125; ~Array() &#123; delete[] data_; &#125; public: int *data_; int size_; &#125;; 该类的拷贝构造函数、赋值运算符重载函数已经通过使用左值引用传参来避免一次多余拷贝了，但是内部实现要深拷贝，无法避免。 这时，有人提出一个想法：是不是可以提供一个移动构造函数，把被拷贝者的数据移动过来，被拷贝者后边就不要了，这样就可以避免深拷贝了 如： class Array &#123; public: Array(int size) : size_(size) &#123; data = new int[size_]; &#125; // 深拷贝构造 Array(const Array&amp; temp_array) &#123; ... &#125; // 深拷贝赋值 Array&amp; operator=(const Array&amp; temp_array) &#123; ... &#125; // 移动构造函数，可以浅拷贝 Array(const Array&amp; temp_array, bool move) &#123; data_ = temp_array.data_; size_ = temp_array.size_; // 为防止temp_array析构时delete data，提前置空其data_ temp_array.data_ = nullptr; &#125; ~Array() &#123; delete [] data_; &#125; public: int *data_; int size_; &#125;; 这么做有2个问题： 不优雅，表示移动语义还需要一个额外的参数(或者其他方式)。 无法实现！temp_array是个const左值引用，无法被修改，所以temp_array.data_ = nullptr;这行会编译不过。当然函数参数可以改成非const：Array(Array&amp; temp_array, bool move)&#123;...&#125;，这样也有问题，由于左值引用不能接右值，Array a = Array(Array(), true);这种调用方式就没法用了。 可以发现左值引用真是用的很不爽，右值引用的出现解决了这个问题， 在STL的很多容器中，都实现了以右值引用为参数的移动构造函数和移动赋值重载函数，或者其他函数，最常见的如std::vector的push_back和emplace_back。STL的函数中，参数为左值引用意味着拷贝，为右值引用意味着移动（这是个设计上的“convention”） class Array &#123; public: ...... // 优雅 Array(Array&amp;&amp; temp_array) &#123; data_ = temp_array.data_; size_ = temp_array.size_; // 为防止temp_array析构时delete data，提前置空其data_ temp_array.data_ = nullptr; &#125; public: int *data_; int size_; &#125;; 如何使用： int main()&#123; Array a; // 做一些操作 ..... // 左值a，用std::move转化为右值 Array b(std::move(a)); // 这里a.data_是nullptr了，原来的a.data_被赋给b.data_ &#125; 移动语义理解 可以这样理解： 拷贝语义：深拷贝 移动语义：浅拷贝 + 把源指针赋值为空 拷贝语义和移动语义的实际应用：类的构造函数和赋值重载函数的实现 可移动不可拷贝：这种类的“拷贝”构造函数都是移动语义的，赋值重载函数都是移动语义的 实例：vector::push_backint main() &#123; std::string str1 = &quot;aacasxs&quot;; std::vector&lt;std::string&gt; vec; vec.push_back(str1); // 传统方法，copy vec.push_back(std::move(str1)); // 调用移动语义的push_back方法，避免拷贝，str1会失去原有值，变成空字符串 vec.push_back(&quot;axcsddcas&quot;); // 当然可以直接接右值 &#125; // std::vector方法定义 void push_back (const value_type&amp; val); void push_back (value_type&amp;&amp; val); 加个std::move会调用到移动语义函数，避免了深拷贝。 只可移动类型还有些STL类是move-only的，比如unique_ptr，这种类只有移动构造函数，因此只能移动，不能拷贝: std::unique_ptr&lt;A&gt; ptr_a = std::make_unique&lt;A&gt;(); std::unique_ptr&lt;A&gt; ptr_b = std::move(ptr_a); // unique_ptr只有‘移动赋值重载函数‘，参数是&amp;&amp; ，只能接右值，因此必须用std::move转换类型 std::unique_ptr&lt;A&gt; ptr_b = ptr_a; // 编译不通过 建议除非设计不允许移动，STL类大都支持移动语义函数，即可移动的。 另外，编译器会默认在用户自定义的class和struct中生成移动语义函数，但前提是用户没有主动定义该类的拷贝语义函数。 因此，可移动对象在**&lt;需要拷贝且被拷贝者之后不再被需要&gt;的场景，建议使用std::move触发移动语义**，提升性能。 void func(const T&amp;);//参数类型const T&amp;暗示其实现为拷贝（深拷贝） void func(T&amp;&amp;);//参数类型T&amp;&amp;暗示其实现为移动（浅拷贝+把源指针赋值为空） moveable_objecta = moveable_objectb; //调用拷贝赋值重载函数 func(moveable_objectb); //调用参数类型为const T&amp;的func 改为： moveable_objecta = std::move(moveable_objectb); //调用移动赋值重载函数 func(std::move(moveable_objectb)); //调用参数类型为T&amp;&amp;的func std::forwardforward也是仅进行强制类型转换 std::forward(u)有两个参数：T与 u： 当T为左值引用类型时，u将被转换为T类型的左值； 否则u将被转换为T类型右值。 举个例子，有main，A，B三个函数，调用关系为：main-&gt;A-&gt;B，建议先看懂2.3节对左右值引用本身是左值还是右值的讨论再看这里： void B(int&amp;&amp; ref_r) &#123; ref_r = 1; &#125; // A、B的入参是右值引用 // 有名字的右值引用是左值，因此ref_r是左值 void A(int&amp;&amp; ref_r) &#123; B(ref_r); // 错误，B的入参是右值引用，需要接右值，ref_r是左值，编译失败 B(std::move(ref_r)); // ok，std::move把左值转为右值，编译通过 B(std::forward&lt;int&gt;(ref_r)); // ok，std::forward的T是int类型，属于条件b，因此会把ref_r转为右值 &#125; int main() &#123; int a = 5; A(std::move(a)); &#125; 例2： void change2(int&amp;&amp; ref_r) &#123; ref_r = 1; &#125; void change3(int&amp; ref_l) &#123; ref_l = 1; &#125; // change的入参是右值引用 // 有名字的右值引用是 左值，因此ref_r是左值 void change(int&amp;&amp; ref_r) &#123; change2(ref_r); // 错误，change2的入参是右值引用，需要接右值，ref_r是左值，编译失败 change2(std::move(ref_r)); // ok，std::move把左值转为右值，编译通过 change2(std::forward&lt;int &amp;&amp;&gt;(ref_r)); // ok，std::forward的T是右值引用类型(int &amp;&amp;)，符合条件b，因此u(ref_r)会被转换为右值，编译通过 change3(ref_r); // ok，change3的入参是左值引用，需要接左值，ref_r是左值，编译通过 change3(std::forward&lt;int &amp;&gt;(ref_r)); // ok，std::forward的T是左值引用类型(int &amp;)，符合条件a，因此u(ref_r)会被转换为左值，编译通过 // 可见，forward可以把值转换为左值或者右值 &#125; int main() &#123; int a = 5; change(std::move(a)); &#125; 上边的示例在日常编程中基本不会用到，std::forward最主要运于模版编程的参数转发中","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"c++11异常处理","slug":"c++11异常处理","date":"2022-07-16T13:10:25.309Z","updated":"2022-12-10T15:17:47.154Z","comments":true,"path":"2022/07/16/c++11异常处理/","link":"","permalink":"http://example.com/2022/07/16/c++11%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","excerpt":"","text":"学习自C++11异常处理 noexcept_木的情感的博客-CSDN博客_c++11 noexcept C++03 异常处理（throw）c++11也可以用 指定异常规格（语法）C++98中，在函数声明时，我们使用throw指定一个函数可以抛出异常的类型（异常规格（exception specification））。例如： class Ex &#123; public: double getVal(); void display() throw(); void setVal(int i) throw (char*, double); private: int m_val; &#125;;12345678 上述函数的声明指定了该函数可以抛出异常的类型：getVal() 可以抛出任何异常(默认)；display() 不可以抛出任何异常；setVal() 只可以抛出char* 和 double类型异常。 编译器为了遵守C++语言标准，在编译时，只检查部分函数的异常规格（不会递归检查函数内部调用的所有函数抛出的异常类型是否符合异常规格）。 // declaration extern void funAny(void); //May throw ANY exception. void check(void) throw (std::out_of_range); // May throw only std::out_of_range. // implementation void check(void) throw(std::out_of_range) &#123; funAny(); // Compiler does not check if funAny(), or one of its &#125; // subordinates, only throws std::out_of_range! 异常处理过程使用throw指定异常规格的话， 如果函数抛出异常： 异常处理机制会进行栈回退，寻找(一个或多个）catch语句。 此时，检测catch可以捕捉的类型，如果没有匹配的类型，**std::unexpected()**会被调用。 但是std::unexpected()本身也可能抛出异常。如果std::unexpected()抛出的异常对于当前的异常规格是有效的，异常传递和栈回退会像以前那样继续进行。 这意味着，如果使用throw， 编译器几乎没有机会做优化。事实上，编译器甚至会让代码变得更臃肿、庞大：（1）栈必须被保存在回退表中；（2）所有对象的析构函数必须被正确的调用（按照对象构建相反的顺序析构对象）；（3）编译器可能引入新的传播栅栏（propagation barriers）、引入新的异常表入口，使得异常处理的代码变得更庞大；（4）内联函数的异常规格（exception specification）可能无效的。 C++11新增（noexcept）语法void mightThrow(); // could throw any exceptions. void doesNotThrow() noexcept; // does not throw any exceptions 异常处理过程当使用noexcept时，如果在该函数的上下文中抛出异常，std::teminate()函数会被立即调用（终止整个进程）（std::teminate()也可能抛出异常，其是noexcept），而不是调用std::unexpected()；因此，在异常处理的过程中，编译器不会回退栈 比较noexcept和throw()下面两个函数声明的异常规格在语义上是相同的，都表示函数不抛出任何异常。 void old_style() throw(); void new_style() noexcept; 但是throw()的会栈回退，noexcept的不会，这为编译器的优化提供了更大的空间。 建议如果你知道你的函数绝对不会抛出任何异常，应该使用noexcept, 而不是throw().","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"c++并发编程实践2ed：2.1和2.3 thread生命周期","slug":"c++并发编程实践2ed：21和23 thread生命周期","date":"2022-07-16T13:08:25.394Z","updated":"2022-12-10T15:18:01.567Z","comments":true,"path":"2022/07/16/c++并发编程实践2ed：21和23 thread生命周期/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed%EF%BC%9A21%E5%92%8C23%20thread%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","excerpt":"","text":"学习自 第25课 std::thread对象的析构 - 浅墨浓香 - 博客园 (cnblogs.com)和《c++并发编程实践第二版》2.1 一、线程创建std::thread th对象创建时，创建线程，这个线程是主线程的子线程，与主线程并发执行 语法 每个程序有一个执行 main() 函数的主线程，将函数添加为 std::thread 的参数即可创建另一个线程，两个线程并发运行 #include &lt;iostream&gt; #include &lt;thread&gt; void f() &#123; std::cout &lt;&lt; &quot;hello world&quot;; &#125; int main() &#123; std::thread t&#123;f&#125;; t.join(); // 等待新起的线程退出 &#125; std::thread 的参数也可以是函数对象或者 lambda #include &lt;iostream&gt; #include &lt;thread&gt; struct A &#123;//函数对象 void operator()() const &#123; std::cout &lt;&lt; 1; &#125; &#125;; int main() &#123; /*函数对象*/ A a; std::thread t1(a); // （对象申明）会调用 A 的拷贝构造函数 std::thread t2(A()); // （函数申明）most vexing parse，声明 名为 t2 、参数类型为 A 的 函数 std::thread t3&#123;A()&#125;; std::thread t4((A())); /*lambda*/ std::thread t5&#123;[] &#123; std::cout &lt;&lt; 1; &#125;&#125;; t1.join(); t3.join(); t4.join(); t5.join(); &#125; 二、td::thread对象的等待与分离下文中“底层线程”指std::thread对象关联的底层线程。比如创建std::thread th对象时创造的新线程为这个std::thread对象th的底层线程；而在执行th.detach()或th.join()之后，对象th将不与任何底层线程相关联 下文中“线程对象”指类型为std::thread的一个对象 （一）join和detach函数对线程对象执行join或detach之后，都会和底层线程断开联系，joinable()都会变成返回false。其中执行join之后会释放底层线程的内存（所以这显然要断开线程对象和底层线程的联系）；执行detach就是分离底层线程 ### 1. 线程等待&#x2F;联结：join() （1）等待子线程结束，调用线程处于阻塞模式。 （2）join()执行完成之后，底层线程id被设置为0，即joinable()变为false。同时会清理线程相关的存储部分， 这样 std::thread 对象将不再与底层线程有任何关联。这意味着，**只能对一个线程对象使用一次join()**。 ### 2. 线程分离：detach() （1）分离子线程，与当前线程的连接被断开，子线程成为后台线程，被C++运行时库接管。 std::thread 对象将不再与底层线程有任何关联。与join一样，detach也只能调用一次，当detach以后其joinable()为false。 （2）注意事项： ①如果不等待线程，就必须保证线程结束之前，可访问的数据是有效的。**特别是要注意线程函数是否还持有一些局部变量的指针或引用（这些局部变量所在作用域在线程函数返回前可能已经结束了）**。 悬空引用问题： #include &lt;iostream&gt; #include &lt;thread&gt; using namespace std; class FuncObject &#123; void do_something(int&amp; i) &#123; cout &lt;&lt;&quot;do something: &quot; &lt;&lt; i &lt;&lt; endl; &#125; public: int&amp; i; //注意：引用类型 FuncObject(int&amp; i) :i(i) &#123; &#125; //注意：引用类型 void operator()() &#123; for (unsigned int j = 0; j &lt; 1000; ++j) &#123; do_something(i); //可能出现悬空引用的问题。 &#125; &#125; &#125;; void oops() &#123; int localVar = 0; FuncObject fObj(localVar); //注意，fObj的成员i是引用局部变量localVar std::thread t1(fObj); t1.detach(); //主线程调用oops函数,可能出现oops函数执行完了，子线程还在运行的现象。它会去调用do_something，这时会访问到己经被释放的localVar变量，会出现未定义行为！如果这里改成join()则不会发生这种现象。因为主线程会等子线程执行完才退出oops &#125; int main() &#123; oops(); return 0; &#125; ②为防止上述的悬空指针和悬引用的问题，线程对象（std::thread对象）的生命期应尽量长于底层线程（std::thread对象创造时创造的线程）的生命期，或者将局部变量复制传入线程，而不是引用或指针 （3）应用场合 ①适合长时间运行的任务，如后台监视文件系统、对缓存进行清理、对数据结构进行优化等。 ②线程被用于“发送即不管”（fire and forget）的任务，任务完成情况线程并不关心，即安排好任务之后就不管。 （二）联结状态：线程对象的联结状态即std::thread对象是否与某个有效的底层线程关联，可用joinable()函数来判断，内部通过判断线程id是否为0来实现。一个std::thread对象只可能处于可联结或不可联结两种状态之一。 1. **不可联结**： 1. **己调用join或detach的std::thread对象**为不可联结状态。 2. **不带参构造的std::thread对象**为不可联结，因为底层线程还没创建。 3. **己移动的std::thread对象**为不可联结。因为该对象的底层线程id会被设置为0。 可联结：当线程可运行、己运行或处于阻塞时是可联结的 std::thread对象生命周期内的其他情况。注意，如果某个底层线程已经执行完任务，但是没有被join的话，该线程依然会被认为是一个活动的执行线程，该std::thread对象仍然处于joinable状态。 三、std::thread对象的析构（一）std::thread的析构 std::thread对象析构时，会先判断joinable()，如果可联结，则程序会直接被终止（std::thread对象的析构函数中会调用&#96;&#96;std::terminate&#96;函数）。 std::terminate 调用当前安装的 std::terminate_handler 。默认的 std::terminate_handler 调用 std::abort 这好像会终止进程 这意味std::thread对象从其它定义域出去的任何路径，都应为不可联结状态。也意味着创建thread对象以后，要在随后的某个地方显式地调用join或detach以便让std::thread处于不可联结状态。 （二）为什么析构函数中不隐式调用join或detach？ 如果设计成隐式join()：将导致调用线程一直等到子线程结束才返回。如果子线程正在运行一个耗时任务，这可能造成性能低下的问题，而且问题也不容易被发现。 如果设计成隐式detach()：由于detach会将切断std::thread对象与底层线程之间的关联，两个线程从此各自独立运行。如果线程函数是按引用（或指针）方式捕捉的变量，在调用线程退出作用域后这些变量会变为无效，这容易掩盖错误也将使调试更加困难。因此隐式detach，还不如join或者显式调用detach更直观和安全。 标准委员会认为，销毁一个joinable线程的后果是十分可怕的，因此他们通过terminate程序来禁止这种行为。为了避免销毁一个joinable的线程，就得由程序员自己来确保std::thread对象从其定义的作用域出去的任何路径，都处于不可联结状态，最常用的方法就是资源获取即初始化技术（RAII，Resource Acquisition Is Initialization）。 （三）利用RAII技术：保证从std::thread对象定义的作用域出去的任何路径，都处于不可联结状态异常抛出情况下如果主线程（创造std::thread对象的线程）运行后在执行join()之前抛出异常，这样就会跳过join()，即这种情况下主线程可能会比它join的线程先结束，因为它中止在异常抛出的处理中了，而没有走到join，这种情况下主线程在结束的时候析构std::thread对象时，该对象是joinable的，则整个进程会终止 因此，如果在无异常的情况下要使用join()，则需要**在异常处理中也调用join()**，从而避免生命周期的问题。 struct func &#123; int&amp; i; //注意这个是引用 func(int&amp; i_) : i(i_) &#123;&#125; //构造函数的参数是引用类型 void operator() () &#123; for (unsigned j=0 ; j&lt;1000000 ; ++j) &#123; do_something(i); // 1 潜在访问隐患：空引用 &#125; &#125; &#125;; void f() &#123; int some_local_state=0; func my_func(some_local_state); std::thread t(my_func); try &#123; do_something_in_current_thread(); &#125; catch(...) &#123; t.join(); // 1 throw; &#125; t.join(); // 2 &#125; 代码2.2中使用了try/catch块确保(子)线程退出后(主线程的f)函数才结束。当函数正常退出后，会执行到②处。当执行过程中抛出异常，程序会执行到①处。如果线程在函数之前结束——就要查看是否因为线程函数使用了局部变量的引用——而后再确定一下程序可能会退出的途径，无论正常与否，有一个简单的机制，可以解决这个问题。 RAII方案 1. 方案1：自定义的thread_guard类，并将std::thread对象传入其中，同时在构造时选择join或detach策略。当thread_guard对象析构时，会根据析构策略，**调用std::thread的join()或detach()**，确保在任何路径，线程对象都处于unjoinable状态。 2. 方案2：重新封装std::thread类（见下面的代码，类名为joining_thread），在**析构时隐式调用join()**。 #include &lt;iostream&gt; #include &lt;thread&gt; class thread_guard &#123; std::thread t; public: //构造函数 explicit thread_guard(std::thread t_): t(std::move(t_)) &#123;&#125; //析构函数 ~thread_guard() &#123; if(t.joinable()) &#123; t.join(); &#125; &#125; //拷贝语义函数删除 thread_guard(thread_guard const&amp;)=delete; thread_guard&amp; operator=(thread_guard const&amp;)=delete; &#125;; struct func; void f() &#123; int some_local_state=0; func my_func(some_local_state); std::thread t(my_func);//创建新线程 thread_guard g(std::move(t)); //调用thread_guard的构造函数，其中构造参数_t（_t是类型为std::thread的bian&#39;lian）会调用std::thread的移动构造函数（把底层线程所有权给_t），然后t(std::move(_t))也会调用std::thread的移动构造函数（把底层线程所有权给t） do_something_in_current_thread(); //主线程离开这里时，析构thread_guard g对象，调用其析构函数 &#125; 代码尚未阅读//使用RAII等待线程完成：joining_thread类的实现 class joining_thread &#123; std::thread thr; public: joining_thread() noexcept = default; //析构函数 ~joining_thread() &#123; if (joinable()) //对象析构造，会隐式调用join() &#123; join(); &#125; &#125; template&lt;typename Callable, typename... Args&gt; explicit joining_thread(Callable&amp;&amp; func, Args&amp;&amp; ...args): thr(std::forward&lt;Callable&gt;(func), std::forward&lt;Args&gt;(args)...) &#123; &#125; //类型转换构造函数 explicit joining_thread(std::thread t) noexcept : thr(std::move(t)) &#123; &#125; //移动操作 joining_thread(joining_thread&amp;&amp; other) noexcept : thr(std::move(other.thr)) &#123; &#125; joining_thread&amp; operator=(joining_thread&amp;&amp; other) noexcept &#123; if (joinable()) join(); //等待原线程执行完 thr = std::move(other.thr); //将新线程移动到thr中 return *this; &#125; joining_thread&amp; operator=(std::thread other) noexcept &#123; if (joinable()) join(); thr = std::move(other); return *this; &#125; bool joinable() const noexcept &#123; return thr.joinable(); &#125; void join() &#123; thr.join(); &#125; void detach() &#123; thr.detach(); &#125; void swap(joining_thread&amp; other) noexcept &#123; thr.swap(other.thr); &#125; std::thread::id get_id() const noexcept &#123; return thr.get_id(); &#125; std::thread&amp; asThread() noexcept //转化为std::thread对象 &#123; return thr; &#125; const std::thread&amp; asThread() const noexcept &#123; return thr; &#125; &#125;; void doWork(int i) &#123; cout &lt;&lt; i &lt;&lt; endl; &#125; int main() &#123; //3. 测试joining_thread类 std::vector&lt;joining_thread&gt; threads; //joining_thread析构时隐式调用join for (unsigned int i = 0; i &lt; 20; ++i) &#123; threads.push_back(joining_thread(doWork, i)); &#125; std::for_each(threads.begin(), threads.end(), std::mem_fn(&amp;joining_thread::join)); return 0; &#125; 四、std::thread的移动语义创建了两个执行线程，并在std::thread实例之间(t1，t2和t3)转移所有权： void some_function(); void some_other_function(); std::thread t1(some_function); // 1 std::thread t2=std::move(t1); // 2 std::move返回的右值类型触发调用 std::thread的移动赋值重载函数，这个移动语义函数实现底层线程的“所有权”从t1移动到t2 //此时t1无关联线程 t1=std::thread(some_other_function); // 3 临时std::thread对象启动了一个线程，临时对象是一个右值，因此触发调用 std::thread的移动赋值重载函数，将这个新触发的线程移动给t1 //现在t1和刚刚std::thread临时对象启动的线程相关联 std::thread t3; // 4 t3此时没有与任何线程进行关联 t3=std::move(t2); // 5 t1=std::move(t3); // 6 因为t1已经有了一个关联的线程，赋值操作将抛出异常，移动赋值重载函数是noexcept则异常处理机制将直接调用std::terminate() 函数返回std::thread对象： std::thread f() &#123; void some_function(); return std::thread(some_function); //构造返回值std::thread临时对象时是调用std::thread的移动构造函数 &#125; //这个编译器不会报错吗？试了一下不会 std::thread g() &#123; void some_other_function(int); std::thread t(some_other_function,42); return t; //构造返回值std::thread临时对象时是调用std::thread的移动构造函数 //return std::move(t);比较符合我的li &#125; std::thread实例作为参数进行传递： void f(std::thread t); void g() &#123; void some_function(); f(std::thread(some_function)); std::thread t(some_function); f(std::move(t)); &#125;","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"}],"author":"zhiqiuyuan"},{"title":"c++底层 c++STL源码","slug":"c++底层 c++STL源码","date":"2022-07-16T13:00:59.357Z","updated":"2022-12-10T15:18:15.739Z","comments":true,"path":"2022/07/16/c++底层 c++STL源码/","link":"","permalink":"http://example.com/2022/07/16/c++%E5%BA%95%E5%B1%82%20c++STL%E6%BA%90%E7%A0%81/","excerpt":"","text":"用户内存分配和使用的规则（os知识）堆栈查看堆栈总大小每个进程允许的堆栈总大小在linux下可以用ulimit查看 stack size #查看软极限，单个进程的stack size限制 ulimit -a #或者ulimit -aS #查看硬极限，软极限的限制 ulimit -aH 堆栈地址增长方向x86机器上， 栈是向下增长的，即入栈是栈顶指针值变小 堆是向上增长的（这个其实无所谓，看操作系统分配堆内存的机制，会分配给哪些内存） 习惯性思考视图：向下方向是地址变小 使用堆or栈的权衡内存分配消耗： 在堆上创建对象需要追踪内存的可用区域。这个算法是由操作系统提供，通常不会是常量时间的。当内存出现大量碎片，或者几乎用到 100% 内存时，这个过程会变得更久。 与此相比，栈分配是常量时间的。 分配的大小： 栈的大小是固定的，并且远小于堆的大小。 所以，如果你需要分配很大的对象，或者很多很多小对象，一般而言，堆是更好的选择。如果你分配的对象大小超出栈的大小，通常会抛出一个异常。 局部变量栈分配的规则 （小端法）整形和浮点型：低有效位在低地址，视图是：首地址在“下面”，高位字节到低位字节是”向下走“ 比如四字节int型， int a=0x01 02 03 04; 位级表示为0x01 02 03 04的，首字节地址为addr，则内容： addr+3:0x01 addr+2:0x02 addr+1:0x03 addr:0x04 数组：数组下标小的在低地址，视图是：首地址在“下面”，idx(数组下标)++给数组赋值是不断“向上走” 比如char数组 char arr[4]=&#123;1,2,3,4&#125;; 首字节地址为addr，则内容： addr+3:4 addr+2:3 addr+1:2 addr:1 比如int数组 int arr[2]=&#123;0x12345678,0x12345678&#125;; 首字节地址为addr，则内容： addr+7:0x12 addr+6:0x34 addr+5:0x56 addr+4:0x78 addr+3:0x12 addr+2:0x34 addr+1:0x56 addr:0x78 即数组idx++视图是向上走，int元素高位字节到低位字节是向下走 举例： #include&lt;stdio.h&gt; int main() &#123; int i; int a[3]; for (i = 0;i &lt;= 11;++i)&#123; a[i] = 0; printf(&quot;%d\\n&quot;, a[i]); &#125; return 0; &#125; 对应的反汇编objdump -j .text -l -C -S a.out 局部变量i分配在%rbp-4处开始，局部变量数组a分配在%rbp-16处开始，所以其实a[4]是i，所以每次给a[4]&#x3D;0后即把i&#x3D;0，这样又重新i从0到4，然后又把i清零，死循环 0000000000400502 &lt;main&gt;: main(): /home/yuanzhiqiu/tools/c/main.c:3 #include&lt;stdio.h&gt; int main() &#123; 400502: 55 push %rbp 400503: 48 89 e5 mov %rsp,%rbp 400506: 48 83 ec 10 sub $0x10,%rsp /home/yuanzhiqiu/tools/c/main.c:6 int i; int a[3]; for (i = 0;i &lt;= 11;++i)&#123; 40050a: c7 45 fc 00 00 00 00 movl $0x0,-0x4(%rbp) #局部变量i分配在%rbp-4处开始 400511: eb 2b jmp 40053e &lt;main+0x3c&gt; /home/yuanzhiqiu/tools/c/main.c:7 (discriminator 3) a[i] = 0; 400513: 8b 45 fc mov -0x4(%rbp),%eax 400516: 48 98 cltq 400518: c7 44 85 f0 00 00 00 movl $0x0,-0x10(%rbp,%rax,4) #局部变量数组a分配在%rbp-16处开始 40051f: 00 /home/yuanzhiqiu/tools/c/main.c:8 (discriminator 3) printf(&quot;%d\\n&quot;, a[i]); 400520: 8b 45 fc mov -0x4(%rbp),%eax 400523: 48 98 cltq 400525: 8b 44 85 f0 mov -0x10(%rbp,%rax,4),%eax 400529: 89 c6 mov %eax,%esi 40052b: bf d4 05 40 00 mov $0x4005d4,%edi 400530: b8 00 00 00 00 mov $0x0,%eax 400535: e8 c6 fe ff ff callq 400400 &lt;printf@plt&gt; /home/yuanzhiqiu/tools/c/main.c:6 (discriminator 3) for (i = 0;i &lt;= 11;++i)&#123; 40053a: 83 45 fc 01 addl $0x1,-0x4(%rbp) /home/yuanzhiqiu/tools/c/main.c:6 (discriminator 1) 40053e: 83 7d fc 0b cmpl $0xb,-0x4(%rbp) 400542: 7e cf jle 400513 &lt;main+0x11&gt; /home/yuanzhiqiu/tools/c/main.c:10 &#125; return 0; 400544: b8 00 00 00 00 mov $0x0,%eax /home/yuanzhiqiu/tools/c/main.c:11 &#125; 400549: c9 leaveq 40054a: c3 retq 40054b: 0f 1f 44 00 00 nopl 0x0(%rax,%rax,1) c++ new delete https://blog.csdn.net/hazir/article/details/21413833 可以通过反汇编找到相应的汇编代码 newnew 分配内存（堆），获得分配内存的起始地址，这里假设是 0x007da290。 是否会对分配的内存的内容进行修改（比如清空）取决于操作系统机制，通常不会改 在这一块分配的内存上对类对象进行初始化：调用相应的构造函数 返回新分配并构造好的对象的指针，这里 pA 就指向 0x007da290 这块内存，pA 的类型为类 A 对象的指针。 new [] 分配内存 对于数组每个元素的内存调用构造函数 （由于delete []时需要知道要析构和释放多少个元素）C++ 会在分配数组空间时多分配 4 个字节，用于保存数组的大小 deletedelete 调用pA 指向对象的析构函数 释放该对象的内存 释放内存是否会对被释放的内存的内容进行修改取决于操作系统机制，通常不会改 释放这些堆内存之后，操作系统可以把这些堆内存分配给这个进程别的地方了 delete [] 对每个元素调用析构函数（从数组对象指针前面的 4 个字节中取出数组大小，然后从传入的指针开始析构和释放这么多元素） 释放内存（传入的指针是对象指针-4） c++11 range-for Range-based for loop (since C++11) - cppreference.com https://blog.csdn.net/K346K346/article/details/57403750 语法for (range-declaration : range-expression) loop-statement 完整语法： attr(optional) for ( init-statement(optional) range-declaration : range-expression ) loop-statement 编译器生成的代码range-for语法将产生和下述等价的代码： &#123; auto &amp;&amp; __range = range-expression; for (auto __begin = begin_expr, __end = end_expr; __begin != __end; ++__begin) &#123; range-declaration = *__begin; loop_statement &#125; &#125; 其中begin_expr 与 end_expr 是迭代对象的迭代器，根据range-expression的类型，取值有：（1）数组：begin_expr 和 end_expr 分别等于__range和__range + bound；（2）STL 容器：__range.begin()和__range.end()（3）其他类型：begin(__range)和end(__range)。编译器将会通过参数类型找到合适的 begin 和 end 函数。 Temporary range expression If range-expression returns a temporary, its lifetime is extended until the end of the loop, as indicated by binding to the forwarding reference __range, but beware that the lifetime of any temporary within range-expression is not extended 注意到auto &amp;&amp; __range = range-expression在循环之前引用绑定range-expression，循环中是通过__range对迭代对象进行操作，因此如果range-expression返回的是临时对象，则： 不会每一轮循环都evaluate一次range-expression得到临时对象，而是循环开始前evaluate一次 临时对象的生命周期为整个循环，而不是当轮循环 c++ STLc++标准中规定，stl要优先考虑性能，为此，其他的容错性以及更多的功能都可以被舍弃掉 观察下面的STL类实现可以发现，没错，栈上的实体是大小在编译期间就可以确定的，所以可以放在栈上，可以增长的存储部分确实是放堆上的 vector https://segmentfault.com/a/1190000040103598 数据成员和数据结构规则 栈上对象：3个迭代器_First、_Last、_End： _First指向使用空间的头部，_Last指向使用空间大小（size）的尾部，_End指向使用空间容量（capacity）的尾部 堆上存储数据：上面迭代器_First和_End指向的内存范围 所以比如 class A{int x;}; vector&lt;vector&gt; vvs; vvs这个对象在栈上就三个指针，这三个指针指向堆中的数组，这个数组每个元素都是三个指针的vector对象，这个数组中每个元素的三个指针都指向堆中的一个元素为A的数组 源码stl_vector.h template&lt;typename _Tp, typename _Alloc&gt; struct _Vector_base &#123; typedef typename __gnu_cxx::__alloc_traits&lt;_Alloc&gt;::template rebind&lt;_Tp&gt;::other _Tp_alloc_type; typedef typename __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt;::pointer pointer; struct _Vector_impl //栈上的实际存储：这三个数据成员 : public _Tp_alloc_type &#123; pointer _M_start;//容器开始位置 pointer _M_finish;//容器结束位置 pointer _M_end_of_storage;//容器所申请的动态内存最后一个位置的下一个位置 _Vector_impl() : _Tp_alloc_type(), _M_start(), _M_finish(), _M_end_of_storage() //默认构造函数，不进行堆内存申请 &#123; &#125; ... &#125;; public: typedef _Alloc allocator_type; ... _Vector_base() : _M_impl() &#123; &#125; _Vector_base(size_t __n) : _M_impl() &#123; _M_create_storage(__n); &#125; ... public: _Vector_impl _M_impl; pointer _M_allocate(size_t __n) &#123; typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr; return __n != 0 ? _Tr::allocate(_M_impl, __n) : pointer(); &#125; void _M_deallocate(pointer __p, size_t __n) &#123; typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Tr; if (__p) _Tr::deallocate(_M_impl, __p, __n); &#125; private: void _M_create_storage(size_t __n) &#123; this-&gt;_M_impl._M_start = this-&gt;_M_allocate(__n); this-&gt;_M_impl._M_finish = this-&gt;_M_impl._M_start; this-&gt;_M_impl._M_end_of_storage = this-&gt;_M_impl._M_start + __n; &#125; &#125;; 扩充机制：翻倍找空闲空间，拷贝规则vector是动态分配空间，随着元素的不断插入，它会按照自身的一套机制不断扩充自身的容量：按照容器现在容量的一倍进行增长。 vector容器分配的是一块连续的内存空间（堆上），每次容器的增长，并不是在原有连续的内存空间后再进行简单的叠加，而是重新申请一块更大的新内存，并把现有容器中的元素逐个复制过去，然后销毁旧的内存。这时原有指向旧内存空间的迭代器已经失效，所以当操作容器时，迭代器要及时更新 源码push_back void push_back(const value_type&amp; __x) &#123; if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) &#123; _Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish, __x); ++this-&gt;_M_impl._M_finish; &#125; else _M_realloc_insert(end(), __x); &#125; 其中_M_realloc_insert： #if __cplusplus &gt;= 201103L //c++11标准是在2011年3月份发布的，这个表示是c++11及以后 template&lt;typename _Tp, typename _Alloc&gt; template&lt;typename... _Args&gt; void vector&lt;_Tp, _Alloc&gt;:: _M_realloc_insert(iterator __position, _Args&amp;&amp;... __args) #else template&lt;typename _Tp, typename _Alloc&gt; void vector&lt;_Tp, _Alloc&gt;:: _M_realloc_insert(iterator __position, const _Tp&amp; __x) #endif &#123; //_M_check_len函数功能说明：若传入参数为1：只要没有超出stl规定的最大内存大小，每次返回当前容器大小的双倍，初次返回1 const size_type __len = _M_check_len(size_type(1), &quot;vector::_M_realloc_insert&quot;); const size_type __elems_before = __position - begin(); //_M_allocate函数功能说明：根据传入长度申请内存空间 pointer __new_start(this-&gt;_M_allocate(__len)); pointer __new_finish(__new_start); __try &#123; //把x写入相应的位置 _Alloc_traits::construct(this-&gt;_M_impl, __new_start + __elems_before, #if __cplusplus &gt;= 201103L std::forward&lt;_Args&gt;(__args)...); #else __x); #endif __new_finish = pointer(); //这里其实就是把原来数据拷贝到新的内存中来 __new_finish = std::__uninitialized_move_if_noexcept_a (this-&gt;_M_impl._M_start, __position.base(), __new_start, _M_get_Tp_allocator()); ++__new_finish; //这里为什么要再调用一次呢，是针对往vector中间插入元素的情况来的 __new_finish = std::__uninitialized_move_if_noexcept_a (__position.base(), this-&gt;_M_impl._M_finish, __new_finish, _M_get_Tp_allocator()); &#125; __catch(...) &#123; ...; &#125; //这里销毁原来的内存并给成员变量赋新值 std::_Destroy(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_finish, _M_get_Tp_allocator()); _M_deallocate(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_end_of_storage - this-&gt;_M_impl._M_start); this-&gt;_M_impl._M_start = __new_start; this-&gt;_M_impl._M_finish = __new_finish; this-&gt;_M_impl._M_end_of_storage = __new_start + __len; &#125;; 建议 所以如果对于一个空vector不断调用push_back，底层是先分配1个元素的内存，然后分配2个元素的内存（如果原来的起始地址开始没有足够大的连续内存，则要申请一块新内存，把原来的内容拷贝过去），4个元素，8个元素… 所以，如果能确定vector必定会被使用且有数据时，我们应该在声明的时候指定元素个数，避免最开始的时候多次申请动态内存消耗资源，进而影响性能 具体接口底层 上面数据结构和规则的应用+一些线性表简单实现 规律： 扩充机制：push_back、resize（大小增大的调用）、insert（capacity不够的调用） 释放内存：只有析构函数（和c++11及以后的shrink_to_fit）可以主动释放内存，否则只有是扩充的时候发现首地址连续内存不够大，然后换一块会释放原先的内存，其他比如clear\\erase\\resize等都不会释放内存 具体接口： insert：（不够会扩充）把插入位置后面的元素向后移动（拷贝），然后把待插入元素插入到相应的位置 resize：如果是截断的调用，只是对截断后面的元素调用析构函数，不会有内存分配的变化，也不会释放内存 clear：对于所有元素调用析构函数，不会有内存分配的变化，也不会释放内存 delete和erase：会析构被删除元素，会通过拷贝元素来保持连续内存，不会有内存分配的变化，也不会释放内存 swap：交换三个指针 c++11c++11以后vector中增加了一些什么内容呢，我们来看看： 对于迭代器，增加cbegin系列函数，返回常量迭代器，就是只读迭代器； 增加了移动构造函数和移动赋值函数，这一点基本上标准库里面所有类型都增加了； 增加公共成员函数shrink_to_fit，允许释放未使用的内存； 增加公共成员函数emplace和emplace_back，它支持在指定位置原味构造元素，因为它们是以右值引用的方式传递参数，所以它们相比于push_back这一类的函数，少了一个拷贝的动作 释放vector所有元素存储内存 swap vector&lt;int&gt;().swap(v); //想释放v的 v这个vector的三个指针和一个空vector的三个指针进行交换，然后由于这个空vector因为是一个临时变量，它在这行代码结束以后，会自动调用vector的析构函数释放动态内存空间 c++11以后：shrink_to_fit 先调用clear函数，这样所有元素都变成未使用了； 然后调用shrink_to_fit函数把未使用的部分内存释放掉 list数据结构：双向链表有头结点 节点的定义如下： template&lt;typename T,...&gt; struct __List_node&#123; //... __list_node&lt;T&gt;* prev; __list_node&lt;T&gt;* next; T myval; //... &#125; deque STL deque源码实现及分析_FishBear_move_on的博客-CSDN博客 数据结构：首地址数组+多个数组deque 的元素不一定是相邻存储的：典型实现是 多个单独分配的固定大小的相邻元素数组（数组大小：例如 64 位 libstdc++ 上为对象大小的 8 倍空间； 64 位 libc++ 上为对象大小的16 倍或 4096 字节的较大者） 有一个元素的 deque ：也必须为其分配至少一个内存数组 一个数组存储这些空间的首地址（STL中称为map，其中元素称为node） 这表示下标访问必须进行二次指针解引用，与之相比 vector 的下标访问只需要进行一次；迭代器++的时候，可能要换数组，vector只需要迭代器++，而deque还需要从map数组中读取下一个数组的首地址 数据成员迭代器：三个T*指针（指向当前数组），一个T**指针（指向map数组中当前所在数组对应的首地址节点） template &lt;class T, class Ref, class Ptr, size_t buff_size&gt; struct __deque_iterator&#123; typedef __deque_iterator&lt;T, T&amp;, T*, buff_size&gt; iterator; typedef __deque_iterator&lt;T, const T&amp;, const T*, buff_size&gt; const_iterator; static size_t buffer_size() &#123;return __deque_buf_size(buff_size, sizeof(T)); &#125; typedef T value_type; typedef size_t size_type; typedef ptrdiff_t difference_type; typedef T** map_pointer; typedef __deque_iterator self; // 保持与容器的联结 T* cur; // 此迭代器所指之缓冲区中的现行元素 T* first; // 此迭代器所指之缓冲区的头 T* last; // 此迭代器所指之缓冲区的尾（含备用空间） //由于，指针肯会遇到缓冲区边缘，因此需要跳到下一个缓冲区 //于是需要指向map回去下一个缓冲区地址 map_pointer node; // 指向管控中心 &#125; deque类： 栈：两个迭代器（每个迭代器4个指针，即8个指针），一个T**指针（map数组首地址），一个map_size 堆：map数组+多个数组 template&lt;typename T, size_t buff_size = 0&gt; class deque&#123; public: typedef T value_type; typedef T&amp; reference; typedef T* pointer; typedef __deque_iterator&lt;T, T&amp;, T*, buff_size&gt; iterator; typedef size_t size_type; typedef ptrdiff_t difference_type; protected: typedef pointer* map_pointer; // 实际的数据存储，分配器 typedef allocator&lt;value_type&gt; dataAllocator; // map指针分配器 typedef allocator&lt;pointer&gt; mapAllocator; private: //数据成员 iterator start; iterator finish; map_pointer map; size_type map_size; &#125; 扩充机制：新增固定大小数组，无拷贝一旦有必要在deque的前端或尾端增加新空间（当当前数组填满最后一个元素，且当前数组是第一个或者最后一个数组时），便配置一段定量连续空间，串接在整个deque的头端或尾端，不需要复制当前的元素到新内存位置 举例： 初始 push_back0 1 2 push_back3 push_front99 具体接口 deque源码4(deque元素操作:pop_back、pop_front、clear、erase、insert） - ybf&amp;yyj - 博客园 (cnblogs.com) pop 如果不是当前数组最后一个元素，则只是析构这个待删除元素，正确移动迭代器； 如果是最后一个元素，则会释放当前数组，并正确移动迭代器 pop_back void pop_back()&#123; if(finish.cur!=finish.first)&#123; //最后缓冲区至少有一个元素 --finish.cur; //调整指针，相当于排除了最后元素 pop_front这里是++ destory(finish.cur); //将最后元素构析 &#125; else //最后缓冲区没有任何元素 pop_back_aux(); //这里将进行缓冲区的释放工作 &#125; //只有当finish.cur==finish.first时才会被调用 template &lt;class T,class Alloc,size_t BufSize&gt; void deque&lt;T,Alloc,BufSize&gt;::pop_back_aux()&#123; deallocate_node(finish.first); //释放最后一个缓冲区 finish.set_node(finish.node-1); //调整finish的状态，使指向上一个缓冲区的最后一个元素 finish.cur=finish.last-1; destory(finish.cur); //将该元素析构 &#125; clear 存储数组：保留一个存储数组不释放（但是都析构），其余存储数组全部析构和释放 map数组：不释放不析构，只是finish和start迭代器置为相等 template &lt;class T,class Alloc,size_t BufSize&gt; void deque&lt;T,Alloc,BufSize&gt;::clear()&#123; //以下针对头尾以外的每一个缓冲区 for(map_pointer node=start.node+1;node&lt;finish.node;++node)&#123; //将缓冲区内的所有元素析构 destory(*node,*node+buff_size()); //释放缓冲区内存 data_allocator::deallocate(*node,buff_size()); &#125; if(start.node!=finish.node)&#123; //至少有头尾两个缓冲区 destory(start.cur,start.last); //将头缓冲区的目前所有元素析构 destory(finish.first,finish.cur); //将尾缓冲区的目前所有元素析构 //以下释放尾缓冲区，注意，头缓冲区保留 data_allocator::deallocate(finish.first,buffer_size()); &#125; else //只有一个缓冲区 destory(start.cur,finish.cur); //将此唯一缓冲区内所有元素析构，并保留缓冲区 finish=start; //调整状态 &#125; erase和insert 一个存储数组内部需要保持连续存储，因此会有拷贝（待删除元素或者待插入元素哪边元素少就拷贝哪边）（数组定长比较短，就16或者8） //清除pos所指向的元素，pos为清除点 iterator erase(iterator pos)&#123; iterator next=pos; ++next; difference_type index=pos-start; //清除点之前的元素个数 if(index&lt;(size()&gt;&gt;1))&#123; //如果清除点之前的元素比较少 copy_backward(start,pos,next); //就移动清除点之前的元素 pop_front(); //移动完毕，清除最前一个元素 &#125; else&#123; //清除点之后的元素比较少 copy(next,finish,pos); //就移动清除点之后的元素 pop_back(); //移动完毕，清除最后一个元素 &#125; return start+index; &#125; queue和stack：默认底层deque queue和stack底层默认是由deque实现 (multi)map,(multi)set map源码：libstdc++: map.h Source File (gnu.org) 数据结构：红黑树unordered_(multi)map,unordered_(multi)set C++ STL无序容器底层实现原理（深度剖析） (biancheng.net) 数据结构：开链哈希表所有无序容器的底层实现：用“开链法”解决数据存储位置发生冲突的哈希表：（图中Pi 表示存储的各个键值对） 一整块连续的存储空间：存储各个链表的头指针，STL 标准库通常选用 vector。 各个链表的节点：各键值对 在 C++ STL 标准库中，将图 1 中的各个链表称为桶（bucket），每个桶都有自己的编号（从 0 开始）。 所以如果是用vector来存储链表头指针， unordered_map栈上对象应该有个vector对象，这个对象有三个指针 然后比如· class A{int x;}; unordered_map&lt;int, vector&gt; int2vector; int2vector这个对象在栈上有三个指针，这三个指针指向堆中的数组，这个数组每个元素是链表头指针，链表中每个元素至少是“键+三个指针的vector对象+下一个元素的地址”，其中每个指针都指向堆中的一个元素为A的数组 插入新键值当有新键值对存储到无序容器中时，整个存储过程分为如下几步： 将该键值对中键的值带入设计好的哈希函数，会得到一个哈希值（一个整数，用 H 表示）； 将 H 和无序容器拥有桶的数量 n 做取模运算（即 H % n），该结果即表示应将此键值对存储到的桶的编号； 建立一个新节点存储此键值对，同时将该节点链接到相应编号的桶上。 增加桶数重新哈希无序容器中，负载因子的计算方法为： 负载因子 = 容器存储的总键值对 / 桶数 默认情况下，无序容器的最大负载因子为 1.0。如果操作无序容器过程中，使得最大负载因子超过了默认值，则容器会自动增加桶数（翻倍式（8、16、32、…）增加（这个翻倍式增长可能是因为链表头指针时是用vector存储的自然导致的）），并重新进行哈希，以此来减小负载因子的值。需要注意的是，此过程会导致容器迭代器失效，但指向单个键值对的引用或者指针仍然有效。 所以，我们在操作无序容器过程中，键值对的存储顺序有时会“莫名”的发生变动。 管理哈希表的成员方法 成员方法 功能 bucket_count() 返回当前容器底层存储键值对时，使用桶的数量。 比如unordered_map&lt;string, string&gt; umap;初始桶数为8 应用：图邻接表STL选择邻接表：每个顶点一个邻居列表 考虑每个顶点的邻居用vector存，使用场景为： 初始从文件读取构造的图顶点id从0开始，且是连续的整形id； 后面会不断对图做reduce且不需要”回头“（即不会再需要对reduced图进行恢复）：将图规约为仅含当前顶点集的一个子集的导出子图，即实现上（不考虑”假删除“，比如像dancing link那样的链表数据结构，是因为并不需要恢复）表现为将一些顶点的邻居列表清空、将一些顶点的邻居列表中的一些顶点删除，图中实际存在的顶点的id变成可能不是连续的 则整个邻接表用unordered_map还是vector呢？具体来讲： typedef unsigned VID_TYPE; unordered_map&lt;VID_TYPE, vector&lt;VID_TYPE&gt;&gt; g_umap; vector&lt;vector&lt;VID_TYPE&gt;&gt; g_vec; 用g_umap还是g_vec？ 我觉得是g_vec： 底层存储上面举例已经考虑过： g_vec这个对象在栈上就三个指针，这三个指针指向堆中的数组，这个数组每个元素都是三个指针的vector对象，这个数组中每个元素的三个指针都指向堆中的一个元素为VID_TYPE的数组； g_umap这个对象在栈上有三个指针，这三个指针指向堆中的数组，这个数组每个元素是链表头指针，链表中每个元素至少是“键+三个指针的vector对象+下一个元素的地址”，其中每个指针都指向堆中的一个元素为VID_TYPE的数组 考虑g_umap没有出现冲突（可能有增加桶数重新哈希的过程）、每个链表都只有一个元素的最好情况，可以看到g_umap要比g_vec多存储键以及用于链表的指针：顶点数目个指针和键 考虑获取一个顶点的邻居列表 g_umap：需要用顶点id计算哈希值，然后取模得到头指针数组的下标（头指针数组首指针由g_umap这个栈上对象的数据成员得到），从头指针数组中取出链表首地址，如果链表只有一个元素，则由这个地址找到目标邻居列表vector的三个指针，返回这个对象（如果有多个元素，要沿着链表一步步找） g_vec：由顶点id访问元素为vector的数组（这个数组首指针由g_vec这个栈上对象的数据成员得到），得到目标邻居列表vector的三个指针，返回这个对象 可以看到，unordered_map由于链表增加了至少一次访存，并且增加了计算哈希值和取模的步骤 unordered_map可以在reduce删除顶点的时候释放掉已经删除的顶点的键值对从而及时释放存储、所以这点优于vector？这个说法站不住脚： 一方面，邻居列表为空的顶点在g_vec中只是占3个指针的空间 另一方面，unordered_map删除一个键值对，只是键值对删除了（从链表中删除），桶数目不会变（如果桶数目要缩小的话，所有桶的所有键值对都需要重新哈希，这个开销很大） [外加]reduce实现用g_vec，则reduce：原位覆盖+resize+shrink_to_fit： 遍历每个顶点的邻居列表neighbors，一个变量next_new_nbr_idx初始给0，然后如果这个邻居在目标顶点集中，则赋值给neighbors[next_new_nbr_idx++]，遍历结束后neighbors.resize(next_new_nbr_idx); neighbors.shrink_to_fit() resize传入参数若小于当前vector中元素数目，则不会有新的内存分配也不会有释放，只是截断然后析构后面的元素并设置capcity； 然后shrink_to_fit()释放后面的内存 因为在此应用场景下reduce不需要回头，即被从邻居列表中删除掉的顶点不会再重新加入，因此后面邻居列表要占用的内存一定不会比现在释放掉不用的剩下的还多，可以释放掉 [外加]为什么邻居列表不用list呢？list增删元素很快，且本应用场景中不需要随机访问，依次访问邻居即可，那为什么不用list呢？ 我的考虑：因为list底层实现是双向链表，存储的每个元素都多两个指针，在邻居列表存储的实际元素为VID_TYPE仅四个字节的情况下，多存储8个字节的指针，在对于边数为亿级的图感觉不是很合适（10^8个entry，每个12字节，要大约10^9字节，1G） 应用：广度优先搜索的队列用queue还是vector使用算法 用queue：初始时queue中有一个元素（出发点），然后不断从队首取出元素（并删除），并将队首的满足一些性质的邻居加入到队尾 用vector：vector中存储每一层：一个level，一个next_level 初始时一个元素，然后不断：遍历level中所有元素（不用删除），把当前元素的满足一些性质的邻居加入到next_level中，level遍历完成之后，把next_level移动赋值给level（移动赋值：这样即把next_level的存储数据直接给level（即level的三个指针直接赋值为next_level三个指针的值），level原先的数据会被析构和释放） 我觉得用queue更好 分析内存使用考虑队列中元素是原始类型，所以没有析构开销 用queue：初始时queue中有一个元素（出发点），然后不断从队首取出元素（并删除），并将队首的满足一些性质的邻居加入到队尾 queue默认用deque实现： 初始时会有一个map数组和一个存储数组 不断从头部取出和删除元素：由于是从头部删除，则不需要拷贝元素，只有指针移动，以及当当前数组没有元素时将当前数组释放 将队首的满足一些性质的邻居加入到队尾：往当前数组尾部加元素，如果满了就申请新的存储数组 最后会队列为空，总共申请队列的存储大小是所有入队元素（图BFS的话一个顶点只会入队一次且一定会入队一次，则是顶点数目个元素），在走到empty的时候它们全部都释放完了 用vector：vector中存储每一层：一个level，一个next_level 初始时一个元素，然后不断：遍历level中所有元素（不用删除），把当前元素的满足一些性质的邻居加入到next_level中，level遍历完成之后，把next_level移动赋值给level（移动赋值：这样即把next_level的存储数据直接给level（即level的三个指针直接赋值为next_level三个指针的值），level原先的数据会被析构和释放） 初始时：数组长度为1的数组 遍历level：这个只是每次解引用下指针 向next_level中加入元素：每次next_level都是从没有元素开始，vector长度以翻倍的方式增长，每次翻倍都需要找新地方、拷贝、析构和释放之前 把next_level移动赋值给level：析构和释放level 最后队列为空，每次处理一层都会从零开始扩充一个vector（最终大小等于下一层大小），然后会释放这一层 根据上述粗略的分析，用vector实现多了每一层的从0开始扩张的拷贝开销，其他部分类似，因此用queue更优","categories":[{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language_deep","slug":"c/language-deep","permalink":"http://example.com/categories/c/language-deep/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"}],"author":"zhiqiuyuan"},{"title":"数据库表连接查询","slug":"数据库表连接查询","date":"2022-07-16T09:49:54.858Z","updated":"2022-12-10T15:18:24.294Z","comments":true,"path":"2022/07/16/数据库表连接查询/","link":"","permalink":"http://example.com/2022/07/16/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E8%BF%9E%E6%8E%A5%E6%9F%A5%E8%AF%A2/","excerpt":"","text":"数据库表连接（join）的简单解释 https://www.ruanyifeng.com/blog/2019/01/table-join.html 图解 SQL 中各种连接 JOIN - 知乎 (zhihu.com) 多表连接查询 内连接 外连接 交叉连接 连接查询是啥所谓”连接”，就是两张表根据关联字段，组合成一个数据集。 举例车站站点表。假设用的是关系型数据库（早期开发中估计这么干，现在估计用的都是图数据库） 我们建一张表 bus_sche，为了简单，表中只有上一站地点和下一站地点及唯一标识，然后插入一些模拟数据。 可以通过自连接查询上下站关系找到坐车线路 SELECT b.lastStation,b.nextStation,a.lastStation,a.nextStation FROM bus_sche a, bus_sche b WHERE b.nextStation = a.lastStation; 只在一张表中查询，表 bus_sche 使用了两个别名 bus_sche a, bus_sche b，因此相当于有两张表，用 WHERE条件连接查询 查询结果 四种连接（内外连接）字段不可以构成完全匹配的情况下： 只返回两张表匹配的记录，这叫内连接（inner join）。 返回匹配的记录，以及表 A 多余的记录，这叫左连接（left join）。 返回匹配的记录，以及表 B 多余的记录，这叫右连接（right join）。 返回匹配的记录，以及表 A 和表 B 各自的多余记录，这叫全连接（full join）。 这四种连接，又可以分成两大类：内连接（inner join）表示只包含匹配的记录，外连接（outer join）表示还包含不匹配的记录。所以，左连接、右连接、全连接都属于外连接。 颜色表示匹配关系（比如A.book_id&#x3D;B.book_id） 左连接的结果举例： SQL这四种连接的 SQL 语句如下。 SELECT * FROM A INNER JOIN B ON A.book_id=B.book_id; SELECT * FROM A LEFT JOIN B ON A.book_id=B.book_id; SELECT * FROM A RIGHT JOIN B ON A.book_id=B.book_id; SELECT * FROM A FULL JOIN B ON A.book_id=B.book_id; 上面的 SQL 语句还可以加上where条件从句，对记录进行筛选，比如只返回表 A 里面不匹配表 B 的记录。 SELECT * FROM A LEFT JOIN B ON A.book_id=B.book_id WHERE B.id IS null; 另一个例子，返回表 A 或表 B 所有不匹配的记录。 SELECT * FROM A FULL JOIN B ON A.book_id=B.book_id WHERE A.id IS null OR B.id IS null; 交叉连接“交叉连接”（cross join），指的是表 A 和表 B 不存在关联字段，这时表 A（共有 n 条记录）与表 B （共有 m 条记录）连接后，会产生一张包含 n x m 条记录的新表（见下图）。","categories":[{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"}],"tags":[]},{"title":"halo主题开发","slug":"halo主题开发","date":"2022-07-16T09:45:42.885Z","updated":"2022-12-10T15:19:23.529Z","comments":true,"path":"2022/07/16/halo主题开发/","link":"","permalink":"http://example.com/2022/07/16/halo%E4%B8%BB%E9%A2%98%E5%BC%80%E5%8F%91/","excerpt":"","text":"官方文档halo主题开发指南：Halo Documents侧边栏的开发者指南-主题开发（文档写得真好！） 基础 halo 博客深度定制与美化教程 (bestzuo.cn) 浏览器 F12 定位目标样式F12，然后&#96;&#96;ctrl+shift+c&#96;之后就可以 鼠标选择（指：鼠标悬停）界面元素定位html代码（“元素”tab中）和样式 同时还可以在右边开发者面板中临时修改样式查看效果 鼠标选择（指：鼠标悬停）html代码（“元素”tab中）定位界面元素 这个功能可以用来检查你写的元素有没有按预期显示 分析页面加载速度慢的原因以 Chrome 浏览器为例，F12 ，进入 NetWork 项，勾选 Disable cache，表示禁止浏览器缓存资源到本地，这样可以看到首次加载所有资源的耗时情况。 然后按 F5 刷新页面，点击 Time 进行排序，就可以看到每个资源的加载耗时情况，一般来说如字体这类比较大的资源加载慢是很正常的，而一些 js 如果加载时间靠后则说明该资源可能需要 CDN 加速或者更换加载源。 由于网络差异，上面所述页面资源加载时间并非在所有地区都相同，但是也可以提供一个参考 准备工作搭建开发环境准备工作 | Halo Documents 装java 下载.jar包：见Halo的“快速开始” java -jar halo-1.5.4.jar --spring.profiles.active=dev 启动完成之后，在用户目录即可看到 halo-dev 文件夹（如果是windows是C:\\user\\&lt;user_name&gt;\\目录下面有&#96;&#96;halo-dev&#96;文件夹） 如果是java -jar halo-1.5.4.jar，则在用户目录看到的是 .halo 文件夹 在启动halo的本机浏览器访问http://localhost:8090即可访问你的博客 vscode装前端开发插件 FreeMarker JS &amp; CSS Minifier：JS 和 CSS 压缩插件，其它如编译 Sass 或者 Less 的插件需要自己自行安装。 新建主题准备工作 | Halo Documents 在 ~/halo-dev/templates/themes 下新建一个文件夹，该文件夹就是你所新建的主题目录 非开发方式启动也可以以这种方式应用主题：直接把主题文件夹放到themes下面即可 开发约定准备工作 | Halo Documents 开发样板准备工作 | Halo Documents 目录结构官方示例目录结构准备工作 | Halo Documents ├── module // 公共模板目录 │ ├── comment.ftl // 比如：评论模板 │ ├── layout.ftl // 比如：布局模板 ├── source // 静态资源目录 │ ├── css // 样式目录 │ ├── images // 图片目录 │ ├── js // JS 脚本目录 │ └── plugins // 前端库目录 ├── index.ftl // 首页 ├── post.ftl // 文章页 ├── post_xxx.ftl // 自定义文章模板，如：post_diary.ftl。可在后台发布文章时选择。 ├── sheet.ftl // 自定义页面 ├── sheet_xxx.ftl // 自定义模板，如：sheet_search.ftl、sheet_author.ftl。可在后台发布页面时选择。 ├── archives.ftl // 归档页 ├── categories.ftl // 分类目录页 ├── category.ftl // 单个分类的所属文章页 ├── tags.ftl // 标签页面 ├── tag.ftl // 单个标签的所属文章页 ├── search.ftl // 搜索结果页 ├── links.ftl // 内置页面：友情链接 ├── photos.ftl // 内置页面：图库 ├── journals.ftl // 内置页面：日志 ├── 404.ftl // 404 页 ├── 500.ftl // 500 页 ├── README.md // README，一般用于主题介绍或说明 ├── screenshot.png // 主题预览图 ├── settings.yaml // 主题选项配置文件 └── theme.yaml // 主题描述文件 less min.cssLess是一门扩展性的 CSS 预处理语言，在 CSS 基础上增加了函数、变量等一些便于写代码并且易于读懂的功能，而 CSS 可以由 Less 编辑而成。也就是上面的 main.css 是由 main.less 通过编译所有子模块的 less 文件而成，**main.min.css 则是由 main.css 压缩而成。以上 Less 编译和 CSS 压缩都可以交由 Vscode 插件完成** 全局 CSS 文件代指 main.css，你需要将该 CSS 压缩为 main.min.css 并覆盖之前的 main.min.css 即可在页面生效；将会作用于所有页面 ftlHalo 的模板引擎为 FreeMarker，文件后缀名为ftl 可以参考FreeMarker Java Template Engine (apache.org) Freemark控制生成文本，比如满足条件的就会抄过去生成文本 配置文件（生成“主题设置”界面 如何获取设置值）配置文件 | Halo Documents 全局变量全局变量 | Halo Documents 公共宏模块公共宏模板 | Halo Documents 页面变量页面变量 | Halo Documents 模板标签模板标签 | Halo Documents","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"}]},{"title":"红黑树","slug":"红黑树","date":"2022-07-10T14:55:20.655Z","updated":"2022-12-10T15:21:14.326Z","comments":true,"path":"2022/07/10/红黑树/","link":"","permalink":"http://example.com/2022/07/10/%E7%BA%A2%E9%BB%91%E6%A0%91/","excerpt":"","text":"The-Art-Of-Programming-By-July&#x2F;03.01.md at master · julycoding&#x2F;The-Art-Of-Programming-By-July (github.com) 红黑树本质上是一棵近似平衡的二叉查找树 红黑树的查找、插入、删除的时间复杂度最坏为O(log n) 回顾：二叉查找树 若任意结点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若任意结点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意结点的左、右子树也分别为二叉查找树。 没有键值相等的结点（no duplicate nodes）。 红黑树性质红黑树的5条性质： 每个结点要么是红的，要么是黑的。 根结点是黑的。 每个叶结点（叶结点即指树尾端NIL指针）是黑的。 如果一个结点是红的，那么它的俩个儿子都是黑的。 对于任一结点而言，其到叶结点的每一条路径都包含相同数目的黑结点。 正是红黑树的这5条性质，使得一棵n个结点是红黑树始终保持了logn的高度 旋转 通过对结点进行重新着色，以及对树进行相关的旋转操作，即修改树中某些结点的颜色及指针结构，来达到对红黑树进行插入或删除结点等操作后，继续保持它的性质或平衡。 左旋在某个结点x上做左旋操作：以x到y（x的右孩子）之间的链为“支轴”进行，它使y成为该孩子树新的根，y的左孩子b成为x的右孩子 #p[v]是v的父亲，left[v]right[v]是v的左右孩子 def LEFT-ROTATE(T, x): #在x上做左旋 y ← right[x] #modify3 right[x] ← left[y] p[left[y]] ← x #modify1 p[y] ← p[x] if p[x] = nil[T] #x是根 then root[T] ← y else if x = left[p[x]] #x是其父亲的左孩子 then left[p[x]] ← y else right[p[x]] ← y #x是其父亲的右孩子 #modify2 left[y] ← x p[x] ← y 右旋在某个结点x上做右旋操作：以x到y（x的左孩子）之间的链为“支轴”进行，它使y成为该孩子树新的根，y的右孩子c成为x的左孩子","categories":[{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"gdb","slug":"gdb","date":"2022-07-10T07:06:13.000Z","updated":"2022-12-10T15:43:34.892Z","comments":true,"path":"2022/07/10/gdb/","link":"","permalink":"http://example.com/2022/07/10/gdb/","excerpt":"","text":"关注报错信息（搜索报错号） -rdynamic -g 编译，直接gdb运行（-rdynamic可以方便监控可能的段错误） 报错型bug调试建议：bt，从最靠近栈顶你写的函数，l那个函数和上一层函数，看p info这个函数的参数对不对（如果不好p info又没有写打印代码的话，先改源码在这个函数里面刚入口的地方加打印，然后r）不断向栈底看，直到参数没有问题的函数（就是它调用接下来的函数参数不对，而它自己传入的参数又没有问题，所以问题必然出在它里面到调用下一次函数之前），首先检查这个函数里面调用参数出错函数的代码有没有问题（检查传入的参数以及它们的来源。比如用来调用的参数不小心写混名字，参数在前面赋值的时候不小心赋错了用混了函数名），如果源码没有问题的话在这个函数处设条件断点（条件为参数取值为此时bt显示的值），然后r，到断点后单步 容器类型的参数要写打印代码（p info x都麻烦），注意把size也打印了（比如unorderedmap，没有分配的指针-&gt;size是奇怪值，但是for loop遍历打印内容可能却像空的一样） 逻辑型bug：断点从后往前以功能block为单位地设：如果运行到断点处值都正常，那说明问题只出在断点之后，如果不正常则要向前设断点（前面有地方有问题）（同时当前断点之后也不能保证没有问题），问题至少出在接下来的新断点之后 从后往前以功能为单位设断点的好处是，如果问题确实只出在最后一个功能block，那一下就定位问题所在了，前面不用都单步调试检查，不过这样要求你能够判断某个断点处各值是否正常，有时候这个是有难度的，而从头开始单步这个就比较简单 小规模代码的话可以把断点设很前，然后单步直到发现值不对劲发现问题 颜色和内容配置vim ~/.gdbinit gdbinit&#x2F;Gdbinit: Gdbinit for OS X, iOS and others - x86, x86_64 and ARM (github.com) r(un)在某处段错误后，打断点，然后可以r，这样程序会重新运行且你的断点还在（这样很好重新调试，一点点定位错误位置） 带参数调试调试带参数的程序：–args gdb --args ./main -d xxx -q xxx -f xxx 单步finish就是但单步执行到子函数内时，用step out就可以执行完子函数余下部分，并返回到上一层函数。在其他调试器中相当于step-out，作用是在栈中前进到到下一层，并在调用函数的下一行停止。 断点info b 查看当前设的断点 设断点bb test.c:9 b printNum 临时断点tb仅生效一次 tbreak test.c:l0 条件断点bb &lt;location&gt; if &lt;expression&gt; 的语法和c一样 假设程序某处发生崩溃，而崩溃的原因怀疑是某个地方出现了非期望的值，那么你就可以在这里断点观察，当出现该非法值时，程序断住。这个时候我们可以借助gdb来设置条件断点，例如： b test.c:23 if b==0 当在b等于0时，程序将会在第23行断住。它和condition有着类似的作用，假设上面的断点号为1，那么： condition 1 b==0 会使得b等于0时，产生断点1。而实际上可以很方便地用来改变断点产生的条件，例如，之前设置b&#x3D;&#x3D;0时产生该断点，那么使用condition可以修改断点产生的条件。 正则设置函数断点rbrbreak file:regex eg： rbreak printNum* #所有以printNum开头的函数都设置了断点 rbreak test.c:. #对test.c中的所有函数设置断点 rbreak test.c:^print #对以print开头的函数设置断点 watchpointwatch a 变量值被改写时断住 rwatch a 当变量值被读时断住 awatch a 被读或者被改写时断住 断点操作跳过断点ignore跳过次数 ignore 1 30 1是你要忽略的断点号，可以通过前面的方式查找到，30是需要跳过的次数。 禁用或启动断点disable有些断点暂时不想使用，但又不想删除，可以暂时禁用或启用。例如： disable #禁用所有断点 disable bnum #禁用标号为bnum的断点 enable #启用所有断点 enable bnum #启用标号为bnum的断点 enable delete bnum #启动标号为bnum的断点，并且在此之后删除该断点 保存读取断点保存 (gdb) save breakpoint &lt;文件名&gt;.bp 加载：使用-x参数指定断点文件 gdb &lt;可执行文件名&gt; -x &lt;bp文件名&gt;.bp 断点清除断点清除主要用到clear和delete命令。常见使用如下： clear #删除当前行所有breakpoints clear function #删除函数名为function处的断点 clear filename:function #删除文件filename中函数function处的断点 clear lineNum #删除行号为lineNum处的断点 clear f:lename：lineNum #删除文件filename中行号为lineNum处的断点 delete #删除所有breakpoints,watchpoints和catchpoints delete bnum #删除断点号为bnum的断点 查看变量值内存值有些复杂的结构体想看的话写个打印 格式控制格式控制字符如下： x 按十六进制格式显示变量。 d 按十进制格式显示变量。 u 按十六进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 p指定变量所在文件&#x2F;函数 p &#39;testGdb.h&#39;::a #testGdb.h文件中 p &#39;main&#39;::b #main函数中 打印指针所指多个值@ (gdb) p *d $2 = 0 (gdb) p *d@10 $3 = &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; (gdb) p *d@a #a是变量，当前值为10 $2 = &#123;0, 1, 2, 3, 4, 5, 6, 7, 8, 9&#125; (gdb) $可表示上一个变量 可使用下面方式不断打印链表内容： (gdb) p *linkNode (这里显示linkNode节点内容) (gdb) p *$.next #$指上一个变量，即指刚刚p的那个linkNode (这里显示linkNode节点下一个节点的内容) 定义一个类似UNIX环境变量，例如： (gdb) set $index=0 (gdb) p b[$index++] $11 = 1 (gdb) p b[$index++] $12 = 2 (gdb) p b[$index++] $13 = 3 打印格式 (gdb) p/x c $19 = &#123;0x68, 0x65, 0x6c, 0x6c, 0x6f, 0x2c, 0x73, 0x68, 0x6f, 0x75, 0x77, 0x61, 0x6e, 0x67, 0x0&#125; (gdb) 用这种方式查看浮点数的二进制格式是怎样的是不行的，因为p&#x2F;t首先会将其转换成整型再转换为二进制表示，因此最终会得到8： (gdb) p e $1 = 8.5 (gdb) p/t e $2 = 1000 (gdb) infoinfo args 打印出当前函数的参数名及其值 info locals 打印出当前函数中所有局部变量及其值 info reg 查看寄存器值 xx/[n][f][u] addr n 表示要显示的内存单元数，默认值为1 f 表示要打印的格式，前面已经提到了格式控制字符 u 要打印的单元长度 addr 内存地址 单元类型常见有如下： b 字节 h 半字，即双字节 w 字，即四字节 g 八字节 把float变量e按照二进制方式打印，并且打印单位是一字节： (gdb) x/4tb &amp;e 0x7fffffffdbd4: 00000000 00000000 00001000 01000001 (gdb) display程序断住时，就显示某个变量的值 (gdb) display e 1: e = 8.5 查看哪些变量被设置了display info (gdb)into display Auto-display expressions now in effect: Num Enb Expression 1: y b 2: y e delete delete display num #num为前面变量前的编号,不带num时清除所有。 disable disable display num #num为前面变量前的编号，不带num时去使能所有 查看源码l(gdb) l test.c:1 (gdb) l test.c:printNum1 指定文件指定行之间： (gdb) l test.c:1,test.c:3 查找段错误位置段错误：硬件设备MMU发现访问了一个非法的虚拟地址，通知操作系统内核给进程发送11号信号，进程收到了一个11号信号，导致进程异常终 方法一： -rdynamic编译 gcc -g -rdynamic编译 gdb 然后r [root@localhost TEST]# gcc -g -rdynamic test.c [root@localhost TEST]# gdb ./a.out ... (gdb) r Starting program: /root/桌面/TEST/./a.out Program received signal SIGSEGV, Segmentation fault. 0x00000000004007d2 in main () at test.c:7 7 *ptr = 1; Missing separate debuginfos, use: debuginfo-install glibc-2.17-105.el7.x86_64 (gdb) 不用一步步调试我们就找到了出错位置在test.c文件的第4行 从这里我们还发现进程是由于收到了SIGSEGV信号而结束的。通过进一步的查阅文档(man 7 signal)，我们知道SIGSEGV默认handler的动作是打印”段错误”的出错信息，并产生Core文件 方法二：core文件 gcc -g 编译（加上-rdynamic也可以） 设置coredump文件大小为无限制（在运行可执行文件之前） ulimit -c unlimit .&#x2F;a.out 出现core.&lt;数字&gt;文件 gdb .&#x2F;a.out core.15180（gdb 目标文件 核心转移文件） [root@localhost TEST]# ./a.out 段错误(吐核) [root@localhost TEST]# ls a.out core.15180 test test.c [root@localhost TEST]# gdb ./a.out core.15180 ... [New LWP 15180] Core was generated by `./a.out&#39;. Program terminated with signal 11, Segmentation fault. ##0 0x00000000004007d2 in main () at test.c:7 7 *ptr = 1; Missing separate debuginfos, use: debuginfo-install glibc-2.17-105.el7.x86_64 (gdb) 调试qemu 下文qemu-system-riscv64可以来自： 我们使用的计算机都是基于x86架构的。如何把程序编译到riscv64架构的汇编？这需要我们使用“目标语言为riscv64机器码的编译器”，在我们的电脑上进行交叉编译。 使用现有的riscv-gcc编译器：两种方法 源码编译 从https://github.com/riscv/riscv-gcc clone下来，然后在x86架构上编译riscv-gcc编译器为可执行的x86程序，就可以运行它，来把你的程序源代码编译成riscv架构的可执行文件了。这有点像绕口令，但只要有一点编译原理的基础就可以理解。不过，这个riscv-gcc仓库很大，而且自己编译工具链总是一件麻烦的事。 使用别人已经编译好的编译器的可执行文件 也就是所谓的预编译（prebuilt）工具链，下载下来解压，放在你喜欢的地方，配好路径（把编译器的位置加到系统的PATH环境变量里），就能在终端使用了。我们推荐使用sifive公司提供的预编译工具链，**下载“GNU Embedded Toolchain ”。** 配置好后，在终端输入riscv64-unknown-elf-gcc -v查看安装的gcc版本, 如果输出一大堆东西且最后一行有gcc version 某个数字.某个数字.某个数字，说明gcc配置成功 因为gdb和qemu是两个应用不能直接交流，比较常用的方法是以tcp进行通讯，也就是让qemu在localhost::1234端口上等待。 编译：在lab0文件夹下打开终端，运行 $ qemu-system-riscv64 -S -s -hda ./bin/ucore.img WARNING: Image format was not specified for &#39;./bin/ucore.img&#39; and probing guessed raw. Automatically detecting the format is dangerous for raw images, write operations on block 0 will be restricted. Specify the &#39;raw&#39; format explicitly to remove the restrictions. VNC server running on 127.0.0.1:5900 开始gdb：然后在该文件夹下重新打开一个终端，运行 $ riscv64-unknown-elf-gdb ./bin/kernel GNU gdb (SiFive GDB 8.3.0-2020.04.1) 8.3 Copyright (C) 2019 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot; and &quot;show warranty&quot; for details. This GDB was configured as &quot;--host=x86_64-linux-gnu --target=riscv64-unknown-elf&quot;. Type &quot;show configuration&quot; for configuration details. For bug reporting instructions, please see: &lt;https://github.com/sifive/freedom-tools/issues&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type &quot;help&quot;. Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;... Reading symbols from ./bin/kernel... (No debugging symbols found in ./bin/kernel) (gdb) 接着连接qemu： (gdb) target remote :1234 Remote debugging using :1234 0x0000000000001000 in ?? () 连接成功输入si就可以进行运行下一条指令 (gdb) si 0x0000000000001004 in ?? () CMake生成的可执行文件gdb调试 (14条消息) CMake生成的可执行文件能够gdb调试_漫游学海之旅-CSDN博客 1 首先在CMakeLists.txt中加入 SET(CMAKE_BUILD_TYPE &quot;Debug&quot;) 在下面加入： SET(CMAKE_CXX_FLAGS_DEBUG &quot;$ENV&#123;CXXFLAGS&#125; -O0 -Wall -g -ggdb&quot;) SET(CMAKE_CXX_FLAGS_RELEASE &quot;$ENV&#123;CXXFLAGS&#125; -O3 -Wall&quot;) 原因是CMake 中有一个变量 CMAKE_BUILD_TYPE ,可以的取值是 Debug Release RelWithDebInfo &gt;和 MinSizeRel。 当这个变量值为 Debug 的时候,CMake 会使用变量 CMAKE_CXX_FLAGS_DEBUG 和 CMAKE_C_FLAGS_DEBUG 中的字符串作为编译选项生成 Makefile; 2 重新编译 $ cmake -DCMAKE_BUILD_TYPE=Debug Path 注： Path 为源码的文件夹路径（比如在项目文件夹下建build，在build里面cmake的话，则Path是..）， 如果 需要 Release 版 也可以 -DCMAKE_BUILD_TYPE ＝ Release 然后， $ cd Path #好像不用，比如在build目录下make就可以 $ make 3 可以调试 $ gdb sample 注：sample 为该可执行文件 多线程调试GDB多线程多进程调试 - 云+社区 - 腾讯云 (tencent.com) gdb 多线程调试 - 阿笨猫 - 博客园 (cnblogs.com) 举例-rdynamic -g编译后r之后报错，然后bt（已经bt过，现在是重新bt只显示我自己写的文件） q_v:1 q_v_n:2 d_v:2 d_v_n:4 dmap: sz:2 (1:2) (0:1) qmap: sz:2 (1:1) (0:1) dmap: sz:6491032 (2:1) (1:1) qmap: sz:1 (3:1) //看最栈顶我自己写的函数map_cover的参数，参数是map指针，内容不好确定是否正确，于是结束调试去在map_cover中刚进来的地方加打印代码（这样在crash时已经输出了出错调用的参数），同时结合自己的代码逻辑，为了确定map内容对不对还需确定是哪两个顶点的哪种类型邻居，因此在调用map_cover的check_nlf_cover中加打印dmap和qmap来自哪个顶点的代码 //然后重新编译和r，此时显示上文信息 //查看map_cover报错处的源码，看到报错在打印语句之后，所以最靠近报错处的dmap和qmap打印即出错调用map_cover传入的参数 //看到dmap的sz奇怪，另外注意到已经输出一次dmapqmap因此这是out_nlf的map_cover调用，因此定位是out_nlf的map_cover调用中dmap有问题（也注意到d_v_n:4，这个是在源代码检查无误之后去检查的，看d_v_n:4的out_nlf在check_nlf_cover中对不对） //查看上一层的源码out_nlf的map_cover调用中dmap的代码，还有dmap的来源代码，发现错误 //继续看check_nlf_cover的参数，部分看出是对的，可以先改一个错误编译gdb运行看看 Program received signal SIGFPE, Arithmetic exception. 0x0000000000416a95 in std::__detail::_Mod_range_hashing::operator() (this=0x630c48, __num=3, __den=0) at /usr/include/c++/4.8.2/bits/hashtable_policy.h:345 345 &#123; return __num % __den; &#125; Missing separate debuginfos, use: debuginfo-install libgcc-4.8.5-44.el7.x86_64 libstdc++-4.8.5-44.el7.x86_64 (gdb) bt -5 //bt ##5 0x000000000041a42a in FilterVertices::map_cover (dmap=0x630c48, qmap=0x630be8) at src/FilterVertices.cpp:777 ##6 0x00000000004199c0 in FilterVertices::check_nlf_cover (d_v=2, j=0, q_v=1, in_count=2, d_in_count=2, q_in_neighbors=0x62e228, d_in_neighbors=0x62e82c, query_graph=0x62e400, data_graph=0x62c300, candidates=0x631180) at src/FilterVertices.cpp:127 ##7 0x00000000004196e8 in FilterVertices::NLFFilter_1step (data_graph=0x62c300, query_graph=0x62e400, candidates=@0x7fffffffdd08: 0x631180, candidates_count=@0x7fffffffdd00: 0x631160) at src/FilterVertices.cpp:91 ##8 0x000000000041b244 in bulkq_nlf_filterCandi (qfilename_prefix=&quot;/media/data/hnu2022/yuanzhiqiu/DFiso_example/query_graph/query_&quot;, nlf_ave_candiScale=@0x7fffffffe0e8: 3.1974663790792123e-317, data_graph=0x62c300, qVScale=4, jb=1, je=2, one_step=true) at src/FilterQueryHelp.cpp:402 ##9 0x0000000000420f33 in main (argc=9, argv=0x7fffffffe448) at main.cpp:327 (gdb) l src/FilterVertices.cpp:777 //看map_cover打印是否在出错之前 772 return 0; 773 &#125; 774 775 for (auto qit : *qmap) 776 &#123; 777 auto it = dmap-&gt;find(qit.first); 778 if (it == dmap-&gt;end() || (it-&gt;second) &lt; qit.second) 779 &#123; 780 return 0; 781 &#125; (gdb) l src/FilterVertices.cpp:127 //看check_nlf_cover中out_nlf调用map_cover的源码（或者编辑器里面看也行） 122 &#123; 123 124 const std::unordered_map&lt;LabelID, ui&gt; *d_in_map = data_graph-&gt;getVertexInNLF(d_v_n); 125 const std::unordered_map&lt;LabelID, ui&gt; *d_out_map = query_graph-&gt;getVertexOutNLF(d_v_n);//d_out_map的来源，可以看到data_graph写成了query_graph，也发现下面一行也写错了 126 const std::unordered_map&lt;LabelID, ui&gt; *d_bi_map = query_graph-&gt;getVertexBiNLF(d_v_n); 127 if (map_cover(d_in_map, q_in_map) &amp;&amp; map_cover(d_out_map, q_out_map) &amp;&amp; map_cover(d_bi_map, q_bi_map))//看这第二个Map_cover调用，两个参数传入代码没有问题 128 &#123; 129 break; 130 &#125; 131 &#125; (gdb)","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"linux下源码编译安装 设置环境变量","slug":"linux下源码编译安装 设置环境变量","date":"2022-07-10T04:53:49.000Z","updated":"2022-12-10T15:55:05.675Z","comments":true,"path":"2022/07/10/linux下源码编译安装 设置环境变量/","link":"","permalink":"http://example.com/2022/07/10/linux%E4%B8%8B%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%20%E8%AE%BE%E7%BD%AE%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/","excerpt":"","text":"设置环境变量先学习下如何设置环境变量 To make the variable settings effect for each bash shell, put the exporting command to your ~/.bashrc, the individual per-interactive-shell startup file. bash中用于设置环境变量的语法如下 export VARIABLE=value Note that there is no space among the variable, the equals sign (“&#x3D;”) and the value. If the value has spaces, the value should be put in quotes. 比如 export PATH=$PATH:/home/yuanzhiqiu/Downloads/built/qemu-5.0.0 要检查它： echo $VARIABLE 让当前shell也配置生效 或者重启一个shell source ~/.bashrc 若系统如下设置：**$PATH在前，优先使用系统的。（因为系统在环境变量中查找目标文件时，找到第一个发现的位置就会停止搜索**） JAVA_HOME=/usr/local/java8 GCC8_HOME=/usr/local/gcc7 export PATH=$PATH:$JAVA_HOME/bin:$GCC8_HOME/bin 若将$PATH放在后面：这样优先使用自己安装的。 export PATH=$JAVA_HOME/bin:$GCC8_HOME/bin:$PATH https://blog.csdn.net/jhsword/article/details/95258625 linux非ROOT用户安装软件 源码编译安装安装流程非root用户没有权限，所以不能用apt-get命令一键安装，一般非root用户的安装流程为： wget命令下载软件源码，如：wget http://mama.indstate.edu/users/ice/tree/src/tree-1.7.0.tgz 解压：tar -zxvf ~ mkdir build &amp;&amp; cd build 配置安装目录和安装： 方法一：ccmake：ccmake .. 这样会出现让你配置cmake的界面，比如配置安装目录，这里设置下安装目录（默认是&#x2F;usr&#x2F;local） 然后make &amp;&amp; make install 方法二： 使用DESTDIR为make install指定安装目录：cmake.. 然后make &amp;&amp; make DESTDIR=/home/yuanzhiqiu/.local install 方法三：configure指定prefix：有configure文件的可以：先./configure --prefix=~/.local/usr/local/git/再make &amp;&amp; make install 修改 ~&#x2F;.bashrc 文件，配置环境变量，加入可执行文件路径，如: export PATH=/home/test/software1/bin:$PATH 注意一般都会在最后加上$PATH，这里是为了把在这之前设置的PATH都加入到PATH中，不然之前设置的PATH都会被覆盖，另外要注意liunx的配置文件路径分割符为冒号:,window 为分号；。 最后在已经开启且需要$PATH生效的shell中激活配置文件： source ~/.bashrc 通常非root用户的安装路径我习惯安装在 ~/local/usr/&lt;package_name&gt;/bin（ /home/&lt;usr_name&gt;/local/usr/&lt;package_name&gt;/bin）或者bin替换成sbin 因此会在 ~/local/usr/&lt;package_name&gt;/下执行源码下载命令（源码下载到哪个目录其实没关系的，指定好安装prefix即可），这样该目录下会出现一个&lt;package_name&gt;-&lt;version&gt;的源码目录，进入该目录进行编译安装，指定prefix为 ~/local/usr/&lt;package_name&gt;/（ /home/&lt;usr_name&gt;/local/usr/&lt;package_name&gt;/）","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"strace 输出所有系统调用","slug":"strace 输出所有系统调用","date":"2022-07-10T03:48:11.000Z","updated":"2022-12-10T15:56:12.458Z","comments":true,"path":"2022/07/10/strace 输出所有系统调用/","link":"","permalink":"http://example.com/2022/07/10/strace%20%E8%BE%93%E5%87%BA%E6%89%80%E6%9C%89%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8/","excerpt":"","text":"strace &lt;a.out&gt;","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"计算机保研面试2分钟英语自我介绍","slug":"计算机保研面试2分钟英语自我介绍","date":"2022-07-09T15:28:33.411Z","updated":"2022-12-10T16:01:37.303Z","comments":true,"path":"2022/07/09/计算机保研面试2分钟英语自我介绍/","link":"","permalink":"http://example.com/2022/07/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BF%9D%E7%A0%94%E9%9D%A2%E8%AF%952%E5%88%86%E9%92%9F%E8%8B%B1%E8%AF%AD%E8%87%AA%E6%88%91%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"没有复杂句式和高级词汇（记不住），两分钟版本 姓名学校专业+总纲 Good Morning teachers. I am xxx from xxx University, majored in xxx.Next, I’d like to introduce myself from three aspects: major learning, scientific research, and student work. 专业学习：排名+绩点+荣誉 First, major learning.I ranked first in the major for 3 consecutive years with a GPA of 3.82.And I have won national scholarship and other honors. 科研经历2分钟时间可以展开来讲你希望老师问你的项目：内容(项目名称)+成果+贡献 Second, scientific research. The first work to mention is xxx(项目英文名称),First, my submission to CCKS was accepted, I was the first author.Second, I carried out experiments in C++, the code is about 3500 lines. My second work is xxx(项目英文名称),I carried out this project under professor X.(这个项目是跟着在面试的学院的一个老师做的，这位老师建议我可以在自我介绍或者问到项目的时候提一下是跟他做的)In this project, I First conducted literature research.Second, I carried out benchmark experiments in c++, and implemented the optimal complexity paper, the code is about 3800 lines. 这是不希望老师详细问的项目（和想去的研究方向关系很小+偏开发），带过（为什么提？hh凑时长+国家级奖项自己干了实际工作） In addition, I also worked in the embedded system and have won two national second prizes, mainly responsible for chip development. 学工：带过一下为啥要提？毕竟老师将来是要和你这个人相处的嘛~ Third, student work.I have served as the party secretary of my class for 3 yearsand the leader of the welcoming freshmen team.also, I am a member of my department volleyball team. 结束 That’s all. Thank you!","categories":[{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"个人博客后台服务器宕机解决","slug":"个人博客后台服务器宕机解决","date":"2022-07-09T15:25:19.314Z","updated":"2022-12-10T16:01:48.652Z","comments":true,"path":"2022/07/09/个人博客后台服务器宕机解决/","link":"","permalink":"http://example.com/2022/07/09/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E5%90%8E%E5%8F%B0%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%AE%95%E6%9C%BA%E8%A7%A3%E5%86%B3/","excerpt":"","text":"宕机恢复后如何重启服务服务器上重启博客后台服务： 检查是否有进程的comm是“java” ps -eo pid,comm | grep &quot;java&quot; 若无则运行halo jar包 nohup java -jar halo-1.5.4.jar &amp; 检查是否有进程的comm是“nginx”，若无则重启nginx服务 nginx -s reload #可能由于一些排错/usr/local/nginx/logs/nginx.pid文件会被清空或者被删除，则需先nginx -c /usr/local/nginx/conf/nginx.conf再reload 宕机原因和解决宕机现象直接现象：浏览器访问个人博客提示服务器拒绝连接，ssh远程连接工具无法连接上云服务器 真死机 服务器确确实实宕机了，导致服务不可用，无法访问。 假死机 由于硬件资源暂时性地被消耗殆尽，因而无法对外部指令进行响应的现象，比如CPU、内存、带宽被占满、磁盘空间耗尽。 宕机原因 访问量过高，超出系统承载能力，包括正常的短暂性突增，或者异常访问，比如黑客攻击等； 服务器配置过低，导致即便访问量不算太高也超出了系统承载能力，需要提高配置； 应用程序本身存在bug，比如死循环，消耗系统资源的逻辑导致资源耗尽； 某些系统参数配置不合理，比如fd个数或允许连接数过低等； 多线程造成的死锁现象，互相等待对方释放资源； 服务器硬件故障，比如内存故障，需要更换； 系统内核bug，比如软死锁等，需要升级内核； 人为误操作； 宕机排查和解决 首先判断是真死还是假死，如果假死，那等一段时间或手动杀死进程即可（当然建议检查杀死的高消耗进程对应的程序逻辑是否有不合理的地方），如果真死则需要进一步排查； 查看系统日志 &#x2F;var&#x2F;log&#x2F;messages，分析宕机时间前后的系统日志，看看是否有明显的报错，比如oom或内核bug； 如果启用了kdump，也可以查看宕机生成的crash文件，默认&#x2F;var&#x2F;crash目录下，注意生成时间是否对应； 查看监控数据，在宕机前有没有指标异常，比如CPU或内存突增，可能短暂突发上量超过系统承载能力； 也有可能是硬件故障，可以看下&#x2F;var&#x2F;log&#x2F;dmesg，或者登录远控查看系统日志，比如内存故障等，可能需要更换 没有办法的办法：重启云服务器的话一般控制台有重启按键，重启云服务器 所有日志文件 /var/log/messages — 包括整体系统信息，其中也包含系统启动期间的日志。此外，mail，cron，daemon，kern和auth等内容也记录在var/log/messages日志中。 /var/log/dmesg — 包含内核缓冲信息（kernel ring buffer）。在系统启动时，会在屏幕上显示许多与硬件有关的信息。可以用dmesg查看它们 /var/log/boot.log — 包含系统启动时的日志。 /var/log/daemon.log — 包含各种系统后台守护进程日志信息。 /var/log/dpkg.log – 包括安装或dpkg命令清除软件包的日志。 /var/log/kern.log – 包含内核产生的日志，有助于在定制内核时解决问题。 /var/log/lastlog — 记录所有用户的最近信息。这不是一个ASCII文件，因此需要用lastlog命令查看内容。 /var/log/maillog /var/log/mail.log — 包含来着系统运行电子邮件服务器的日志信息。例如，sendmail日志信息就全部送到这个文件中。 /var/log/user.log — 记录所有等级用户信息的日志 /var/log/Xorg.x.log — 来自X的日志信息 /var/log/alternatives.log – 更新替代信息都记录在这个文件中 /var/log/btmp – 记录所有失败登录信息。使用last命令可以查看btmp文件。例如，”last -f /var/log/btmp | more“ /var/log/cups — 涉及所有打印信息的日志 /var/log/anaconda.log — 在安装Linux时，所有安装信息都储存在这个文件中 /var/log/yum.log — 包含使用yum安装的软件包信息 /var/log/cron — 每当cron进程开始一个工作时，就会将相关信息记录在这个文件中 /var/log/secure — 包含验证和授权方面信息。例如，sshd会将所有信息记录（其中包括失败登录）在这里 /var/log/wtmp或/var/log/utmp — 包含登录信息。使用wtmp可以找出谁正在登陆进入系统，谁使用命令显示这个文件或信息等 /var/log/faillog – 包含用户登录失败信息。此外，错误登录命令也会记录在本文件中 /var/log/httpd/或/var/log/apache2 — 包含服务器access_log和error_log信息 /var/log/lighttpd/ — 包含light HTTPD的access_log和error_log /var/log/mail/ – 这个子目录包含邮件服务器的额外日志 /var/log/prelink/ — 包含.so文件被prelink修改的信息 /var/log/audit/ — 包含被 Linux audit daemon储存的信息 /var/log/samba/ – 包含由samba存储的信息 /var/log/sa/ — 包含每日由sysstat软件包收集的sar文件 /var/log/sssd/ – 用于守护进程安全服务","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"计算机保研简历面准备","slug":"计算机保研简历面准备","date":"2022-07-09T13:50:14.641Z","updated":"2022-12-10T16:01:59.896Z","comments":true,"path":"2022/07/09/计算机保研简历面准备/","link":"","permalink":"http://example.com/2022/07/09/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%BF%9D%E7%A0%94%E7%AE%80%E5%8E%86%E9%9D%A2%E5%87%86%E5%A4%87/","excerpt":"","text":"我当时是按这个准备的面试~ 准备了我的两个科研项目，面试的时候项目相关问题基本全部覆盖（开放性问题除外，这个当场思考下）2022北叉大数据计科专业面经 成功上岸 对于每个打算被问的项目梳理如下内容： 情境：研究的什么问题，这个项目大概是干啥的（或输入输出，架构和各模块的大致设计）），研究的问题有什么实际应用场景 我在这个项目中贡献了什么：写了哪些代码，代码量多少，调研了哪些论文，完成了什么功能模块，有什么收获，（提出idea和证明，论文撰写） 结果：成果有哪些，实验结果怎么样（数据拿出来） 收获 如果是科研项目还需对如下每个阶段你干了什么、产出怎么样进行梳理：调研-实验（实验设计，数据集）-分析和结论-下一步方向 如果科研项目中是你提出的idea，则你需要复习你的idea： 解决什么问题 为什么能解决问题 怎么解决问题的 为什么实验可以证明你的idea可以解决问题，具体的效果怎么样 idea灵感怎么来的 对于每个打算被问的项目大致准备下如下问题：具体的问题： 介绍下这个项目 项目的亮点（比如处理的数据规模达百亿级别，你怎么做到的） 遇到了什么困难怎么解决的 一类的问题： 为什么这样做（每一个选择，比如为什么你的idea中选择3个顶点的图拓扑而不是4个或更多顶点，为什么实验进行对比的时候选择这些算法，为什么不选其他算法来做对比） 夏令营申请材料和面试时会呈现给老师的材料（如简历、申请表、个人陈述、ppt）中涉及到的概念和技术点，至少能说出其概念、原理、作用、优点 比如子图匹配：子图匹配是什么，有什么应用场景，通用解决的框架是什么 ppt和自我介绍指导： 自我介绍的 PPT 里体现自己所做的工作，例如写了哪些代码，代码量多少，调研了哪些论文，完成了什么功能模块，有什么收获，有什么收获，++拿出证据来++ 简洁+突出重点（不会的别提，很会的则引导过去） 关于语速，慢一点好","categories":[{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"linux源码阅读开发环境搭建","slug":"linux源码阅读开发环境搭建","date":"2022-07-09T13:10:10.809Z","updated":"2022-12-10T16:03:09.781Z","comments":true,"path":"2022/07/09/linux源码阅读开发环境搭建/","link":"","permalink":"http://example.com/2022/07/09/linux%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","excerpt":"","text":"vscode阅读linux源码方法一 一站式配置vscode目前存在的问题：仍然有一些红线报错，但是不影响跳转定义 vscode 安装插件 Remote-SSH：本机安装 C&#x2F;C++ 插件：remote安装（在remote安装插件的方法：先Remote-SSH连接上remote） 编译内核源码[编译内核（简单版）](# 编译内核（简单版）) 获取.vscode和生成compile_commands.jsonamezin&#x2F;vscode-linux-kernel: Visual Studio Code project&#x2F;compile_commands.json generator for Linux kernel sources and out-of-tree modules (github.com) 然后就可以了 完成之后打开某参与编译的c文件后，需要一段时间（大概5分钟）等建立索引，然后就可以支持跳转、悬停显示了 方法二Global（找不到u32等的定义） VSCode 阅读 Linux 代码怎么才不卡顿？这样做才能快的飞起！-51CTO.COM u32等的定义在v5.10中有22处的样子，所以其真正的定义来源要看你的编译，而这种方法没有利用编译信息 远程主机安装 global 工具apt install global 安装完之后，确认两个二进制文件，global，gtags， 一般在 &#x2F;usr&#x2F;bin&#x2F; 目录下。有这两个文件，就说明 OK 。 Linux 源码下载，库支持下载和生成 源码放到远程的目录 库支持参见编译的环境依赖 还是有头文件需要编译才生成： c - Can’t find the source of some “asm”, “generated” header files in linux kernel? - Unix &amp; Linux Stack Exchange I don’t have any idea where to look for these files: #include &lt;generated/timeconst.h&gt; /* /include/linux/jiffies.h */ #include &lt;generated/bounds.h&gt; #include &lt;generated/autoconf.h&gt; /* /include/linux/kconfig.h */ #include &lt;generated/asm-offsets.h&gt; 解答： You’ll find the header files used by your build in /lib/modules/$(uname -r)/build/, see for example find /lib/modules/$(uname -r)/build/ -name timeconst.h All these files are generated during the build, in various ways; timeconst.h is built by kernel/time/timeconst.bc. /lib/modules/$(uname -r)/build/ stores the generated headers (and a few other files) corresponding to the running kernel; the intention is to make them available for external module builds in particular. If you’re building a new kernel, you’ll find the generated files in your build tree (after a kernel build, or an in-tree-module build). vscode 安装插件 Remote-SSH：本机 C&#x2F;C++ 插件：remote（在remote安装插件的方法：先Remote-SSH连接上remote），如果首次安装在remote上需要配置 C&#x2F;C++ GNU Global：用于符号解析，remote vscode 配置 global 路径vscode 的settings(ssh)里： 在 vscode 的 settings.json 配置里，指定 global 的相关路径。 &quot;gnuGlobal.globalExecutable&quot;: &quot;/usr/bin/global&quot;, &quot;gnuGlobal.gtagsExecutable&quot;: &quot;/usr/bin/gtags&quot;, // 指明生成的符号表存放在哪个位置 &quot;gnuGlobal.objDirPrefix&quot;: &quot;/mnt/.global&quot; 注意：”gnuGlobal.objDirPrefix” 的路径必须要手动创建好（一个这个名字的空文件即可），如果不存在，会导致后续 Rebuild 的失败。 比如： 在当前目录下创建一个.global文件夹，里面创建一个gnuGlobal.objDirPrefix文件，然后配置”gnuGlobal.objDirPrefix”: “.global” 测试是否成功执行远程主机上的 Gtags测试一下安装配置的是否正确。shift + command + P 把命令面板掉出来，执行 Global: Show GNU Global Version 命令，看是否能成功显示版本。在右下角显示版本号，那么就说明一切就绪： global (GNU GLOBAL) 6.6.4 生成符号表 shift + command + P 把命令面板调出来，执行 Global: Rebuild Gtags Database 命令。等待右下角的通知，如果显示： Build tag files successfully 那么就说明符号表解析完成了。符号表生成成功会在 “gnuGlobal.objDirPrefix” 的路径里生成三个文件： root@ubuntu20:/mnt/opensource/linux-3.10# ll -lh /mnt/.global/mnt/opensource/linux-3.10/ total 395M drwxr-xr-x 2 root root 4.0K Feb 14 19:06 ./ drwxr-xr-x 3 root root 4.0K Feb 14 18:33 ../ -rw-r--r-- 1 root root 7.6M Feb 14 19:06 GPATH -rw-r--r-- 1 root root 278M Feb 14 19:06 GRTAGS -rw-r--r-- 1 root root 109M Feb 14 19:06 GTAGS 1.2.3.4.5.6.7. 方法三clangd（无法定义跳转） https://blog.csdn.net/xhnmdlfl/article/details/117911630 vscode 安装插件 Remote-SSH：本机 clangd：remote和本机（在remote安装插件的方法：先Remote-SSH连接上remote），如果首次安装在remote上需要配置 安装clangd在VSCode Extension组件页搜索clangd，在插件介绍界面点击安装即可。 需要注意的是clangd有两个安装选项，一个是安装到本地，也就是windows系统上，也可以选择安装到远程服务器上，比如页面显示可以看到有个”Install in SSH: 192.168.50.170”安装选项，这两个都需要安装。 linux远程服务器上的clangd默认是安装到~&#x2F;.vscode-server&#x2F;目录下。 VSCode在安装linux版本的clangd时是在github上下载安装包然后通过ssh导入到服务器上，正常途径访问不了github的同学这一步可能会超时安装失败，可以通过其他途径到clangd的 github发布页 按平台下载安装包，安装包在linux系统上解压出来，然后手动拷贝到对应系统目录即可。如果没有系统权限，参考vscode默认方式安装到自己的home目录也可以（可能需要自己导出路径到环境变量）。 需要注意的是如果VSCode之前安装过C++ Intellisense插件需要禁用或者卸载掉，因为会和clangd插件有冲突。 vscode 插件配置配置clangd在已安装的Extension组件页选中clangd，点击图标旁边的齿轮打开设置页，User和Remote标签页中的Clangd Arguments都按照下面设置（点击Add Item，一个item输入下面的一行） –compile-commands-dir&#x3D;${workspaceFolder}–background-index–completion-style&#x3D;detailed–header-insertion&#x3D;never-log&#x3D;info 设置完后关掉设置页面即可，vs会自动保存。 生成compile_commands.json在当前目录就会生成compile_commands.json： bear make 或 amezin&#x2F;vscode-linux-kernel: Visual Studio Code project&#x2F;compile_commands.json generator for Linux kernel sources and out-of-tree modules (github.com) 触发clangd工作内核源码根目录，也就是compile_commands.json所在的目录，这个目录就作为我们的worksapce了。 在左边文件列表里双击任何一个.c内核源文件（需要是参与编译的），这个时候你就可以看到最下面状态栏clangd开始执行indexing了，也就是解析workspace下compile_commands.json文件里描述的所有源文件，创建索引数据库（保存在workspace目录下的.cache&#x2F;clangd目录下），待所有索引文件创建完成再回到代码窗口可以看到#include后面的头文件名下面都有了下划线，这个时候代码里的函数、变量、宏定义和头文件就可以通过Ctrl+鼠标左键点击来跳转查看定义了，指针悬停在这些地方也会显示出预览了。 相比source insight创建index，感觉clangd要快不少，而且创建的index数据库也比较小。后续如果文件改动了，clangd在启动的时候会自动重新同步并生成新的index，但是如果新增了文件的话就需要重新执行bear make去生成新的compile_commands.json，这样新的文件才会被索引。 编译内核（简单版）[详细版（含安装内核）](# How to compile and install Linux Kernel 5.16.9) 在远程主机上 [安装编译环境](# Step 4. Install the required compilers and other tools) 下载源码和解压缩 wget -c https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz unxz -v linux-5.16.9.tar.xz tar xvf linux-5.16.9.tar 配置内核features：照抄远程主机linux内核的 cd linux-5.16.9 cp -v /boot/config-$(uname -r) .config 编译（在linux-5.16.9目录下） make 或者指定线程数目 make -j $(nproc) #系统核数 修改源码后编译也是make，亲测初次编译后，8核编译时间2分钟 [详细版编译安装内核]How to compile and install Linux Kernel 5.16.9 How to compile and install Linux Kernel 5.16.9 from source code - nixCraft (cyberciti.biz) This step by step howt o covers compiling Linux kernel version 5.16.9 under an Ubuntu or Debian Linux. The following instructions successfully tested on an RHEL CentOS 7&#x2F;8 (and clones), Debian Linux, Ubuntu Linux and Fedora Linux 31&#x2F;32. However, instructions remain the same for any other Linux distribution. The procedure to build (compile) and install the latest Linux kernel from source is as follows: Grab the latest kernel from kernel.org Verify kernel Untar the kernel tarball Copy existing Linux kernel config file Compile and build Linux kernel 5.16.9 Install Linux kernel and modules (drivers) Update Grub configuration Reboot the system 你将需要至少 12 GB 的本地可用磁盘空间来完成内核的编译过程 Step 1. Get the latest Linux kernel source codeThe filename would be linux-x.y.z.tar.xz, where x.y.z is actual Linux kernel version number. For example file linux-5.16.9.tar.xz represents Linux kernel version 5.16.9. Use the wget command to download Linux kernel source code:$ wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.xz Step 2. Extract tar.xz fileYou really don’t have to extract the source code in &#x2F;usr&#x2F;src. You can extract the source code in your $HOME directory or any other directory using the following unzx command or xz command:$ unxz -v linux-5.16.9.tar.xz OR$ xz -d -v linux-5.16.9.tar.xz 这个是得到.tar文件 Verify Linux kernel tartball with pgp（如果不用安装而只是编译的话不用这步）First grab the PGP signature for linux-5.16.9.tar:$ wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.16.9.tar.signTry to verify it:$ gpg --verify linux-5.16.9.tar.signSample outputs: gpg: assuming signed data in &#39;linux-5.16.9.tar&#39; gpg: Signature made Sun 12 Aug 2018 04:00:28 PM CDT gpg: using RSA key 79BE3E4300411886 gpg: Can&#39;t check signature: No public key Grab the public key from the PGP keyserver in order to verify the signature i.e. RSA key ID 79BE3E4300411886 (from the above outputs):$ gpg --recv-keys 79BE3E4300411886Sample outputs: gpg: key 79BE3E4300411886: 7 duplicate signatures removed gpg: key 79BE3E4300411886: 172 signatures not checked due to missing keys gpg: /home/vivek/.gnupg/trustdb.gpg: trustdb created gpg: key 79BE3E4300411886: public key &quot;Linus Torvalds &lt;torvalds@kernel.org&gt;&quot; imported gpg: no ultimately trusted keys found gpg: Total number processed: 1 gpg: imported: 1 Now verify gpg key again with the gpg command:$ gpg --verify linux-5.16.9.tar.signSample outputs: gpg: assuming signed data in &#39;linux-5.16.9.tar&#39; gpg: Signature made Sun 12 Aug 2018 04:00:28 PM CDT gpg: using RSA key 79BE3E4300411886 gpg: Good signature from &quot;Linus Torvalds &lt;torvalds@kernel.org&gt;&quot; [unknown] gpg: aka &quot;Linus Torvalds &lt;torvalds@linux-foundation.org&gt;&quot; [unknown] gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: ABAF 11C6 5A29 70B1 30AB E3C4 79BE 3E43 0041 1886 If you do not get “BAD signature” output from the “gpg –verify” command, untar&#x2F;extract the Linux kernel tarball using the tar command, enter:$ tar xvf linux-5.16.9.tar Step 3. Configure the Linux kernel features and modulesBefore start building the kernel, one must configure Linux kernel features. You must also specify which kernel modules (drivers) needed for your system. The task can be overwhelming for a new user. I suggest that you copy existing config file using the cp command:$ cd linux-5.16.9 $ cp -v /boot/config-$(uname -r) .configSample outputs: &#39;/boot/config-4.15.0-30-generic&#39; -&gt; &#39;.config&#39; Step 4. Install the required compilers and other toolsYou must have development tools such as GCC compilers and related tools installed to compile the Linux kernel. How to install GCC and development tools on a Debian&#x2F;Ubuntu LinuxType the following apt command or apt-get command to install the same:$ sudo apt-get install build-essential libncurses-dev bison flex libssl-dev libelf-devSee “Ubuntu Linux Install GNU GCC Compiler and Development Environment” for more info. How to install GCC and development tools on a CentOS&#x2F;RHEL&#x2F;Oracle&#x2F;Scientific LinuxTry yum command:$ sudo yum group install &quot;Development Tools&quot;OR$ sudo yum groupinstall &quot;Development Tools&quot;Additional packages too:$ sudo yum install ncurses-devel bison flex elfutils-libelf-devel openssl-devel How to install GCC and development tools on a Fedora LinuxRun the following dnf command:$ sudo dnf group install &quot;Development Tools&quot;$ sudo dnf install ncurses-devel bison flex elfutils-libelf-devel openssl-devel Step 5. Configuring the kernel[optional]Now you can start the kernel configuration by typing any one of the following command in source code directory: $ make menuconfig – Text based color menus, radiolists &amp; dialogs. This option also useful on remote server if you wanna compile kernel remotely. $ make xconfig – X windows (Qt) based configuration tool, works best under KDE desktop $ make gconfig – X windows (Gtk) based configuration tool, works best under Gnome Dekstop. For example, run make menuconfig command launches following screen:$ make menuconfigYou have to select different options as per your need. Each configuration option has HELP button associated with it so select help button to get help. Please note that ‘make menuconfig’ is optional. I used it here to demonstration purpose only. You can enable or disable certain features or kernel driver with this option. It is easy to remove support for a device driver or option and end up with a broken kernel. For example, if the ext4 driver is removed from the kernel configuration file, a system may not boot. When in doubt, just leave support in the kernel. Step 5. How to compile a Linux KernelbuildStart compiling and tocreate a compressed kernel image, enter:$ makeTo speed up compile time, pass the -j as follows:## use 4 core/thread ## $ make -j 4 ## get thread or cpu core count using nproc command ## $ make -j $(nproc)Compiling and building the Linux kernel going take a significant amount of time. The build time depends upon your system’s resources such as available CPU core and the current system load. So have some patience. build之前会有很多选项要你选择（网络、IO、…），我一路默认（除了内核压缩模式，我下载的是.xz所以选择对应的） Install the Linux kernel modules$ sudo make modules_install Install the Linux kernelSo far we have compiled the Linux kernel and installed kernel modules. It is time to install the kernel itself:$ sudo make install It will install three files into &#x2F;boot directory as well as modification to your kernel grub configuration file: initramfs-5.16.9.img System.map-5.16.9 vmlinuz-5.16.9 Step 6. Update grub configYou need to modify Grub 2 boot loader configurations. Type the following command at a shell prompt as per your Linux distro: CentOS&#x2F;RHEL&#x2F;Oracle&#x2F;Scientific and Fedora Linux$ sudo grub2-mkconfig -o /boot/grub2/grub.cfg$ sudo grubby --set-default /boot/vmlinuz-5.16.9` You can confirm the details with the following commands: `grubby --info=ALL | moregrubby --default-indexgrubby --default-kernel Debian&#x2F;Ubuntu LinuxThe following commands are optional as make install does everything for your but included here for historical reasons only:$ sudo update-initramfs -c -k 5.16.9$ sudo update-grub How to build and install the latest Linux kernel from source codeYou have compiled a Linux kernel. The process takes some time, however now you have a custom Linux kernel for your system. Let us reboot the system. Reboot Linux computer and boot into your new kernelJust issue the reboot command or shutdown command:# rebootVerify new Linux kernel version after reboot:$ uname -mrsSample outputs: Linux 5.16.9 x86_64 Conclusion – Linux Compile Kernel version 5.16.9Configurations! You completed various steps to build the Linux kernel from source code and compiled kernel should be running on your system. I strongly suggest that you always keep backup of essential data and visit the kernel.org page here for more info.","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"powershell","slug":"powershell","date":"2022-07-09T12:58:18.393Z","updated":"2022-12-10T16:06:20.247Z","comments":true,"path":"2022/07/09/powershell/","link":"","permalink":"http://example.com/2022/07/09/powershell/","excerpt":"","text":"删除文件（夹）rmdir递归删除 rmdir /s folder 查看所有文件dir查看包含隐藏文件的所有文件 dir /A *","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"tmux","slug":"tmux","date":"2022-07-09T12:54:32.169Z","updated":"2022-12-10T16:06:48.935Z","comments":true,"path":"2022/07/09/tmux/","link":"","permalink":"http://example.com/2022/07/09/tmux/","excerpt":"","text":"Tmux所有快捷键都要通过前缀键（Ctrl+b）唤起，在tmux窗口中可以使用； tmux命令在普通终端和tmux窗口中均可以使用； 多个会话，每个会话可以创建多个窗口，每个窗口可以划分为多个窗格； 以会话为单位attach上某个会话 新建tmux #新建一个会话，编号从0开始 tmux new -t &lt;session-name&gt; Tmux 窗口底部有一个状态栏。状态栏的左侧是窗口信息（编号和名称），右侧是系统信息 重新接入tmux a[ttach] -t &lt;num or session-name&gt; 帮助Ctrl+b ? 退出Ctrl+b d 退出当前 Tmux 窗口，但是会话和里面的进程仍然在后台运行 查看（从而切换）会话Ctrl+b s 查看当前所有的 Tmux 会话（有些不会列出来） tmux list-s(ession) 查看所有的 Tmux 会话 杀死您可以tmux kill-server用来干净利落地杀死所有tmux打开的会话（和服务器）。 如果您要保留在tmux会话中，请使用tmux kill-session -a来关闭所有其他会话。 要关闭特定会话，请使用tmux list-s(essions)查看要终止的会话，然后使用tmux kill-session -t targetSession终止该特定会话。 您也可以使用彻底杀死所有tmux进程pkill -f tmux。 重命名Ctrl+b $ 重命名当前会话；重命名指定会话 tmux rename-session -t &lt;num or session-name&gt; &lt;new-name&gt; 鼠标开启： 先按Ctrl + B， 松开以后，输入冒号，输入set -g mouse on 回车 解除： 先按Ctrl + B， 松开以后，输入冒号，输入set -g mouse off 回车 窗格操作 窗格操作：对于当前窗口window Ctrl+b % 左右划分 Ctrl+b “ 上下划分 Ctrl+b &lt;方向键&gt; 切换当前窗格 Ctrl+b x 删除当前窗格 Ctrl+b { 当前窗格左移； Ctrl+b } 当前窗格右移 Ctrl+b q 显示当前会话所有窗格的编号 窗口操作： Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息 Ctrl+b p：（previous）切换到上一个窗口（按照状态栏上的顺序） Ctrl+b n：（next）切换到下一个窗口。 Ctrl+b &lt;number&gt;：切换到指定编号的窗口，其中的&lt;number&gt;是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。 Ctrl+b ,：窗口重命名。 列出当前所有 Tmux 会话的信息 tmux info 重新加载当前的 Tmux 配置 tmux source-file ~/.tmux.con Xshell断开连接后仍保持服务器程序执行的方法（tmux）tmux比nohup方便，建议使用tmux。 先安装tmux：sudo apt-get install tmux 然后用命令：tmux new -s session_name 新开一个会话 在会话里启动进程后，回到原本界面的方法： 先按下ctrl+b，然后再单独按d 此时会话里的进程仍然在运行 重新回到会话里查看进程的方法：tmux a -t session_name 查看会话中历史记录：先按ctrl+b，然后按Page Up ，Page Down 可以同时新建多个会话s1,s2,s3 在会话间切换的命令： 先按ctrl+b ，再按s，然后就可以在会话间选择其中一个，按enter进入。 即使关闭xhsell，会话也仍然存在，如果里面有进程，会持续运行。 除非进入会话中把进程关闭掉。 关闭会话的方法： tmux kill-session -t session_name","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"git","slug":"git","date":"2022-07-09T12:48:53.716Z","updated":"2022-12-10T16:07:02.453Z","comments":true,"path":"2022/07/09/git/","link":"","permalink":"http://example.com/2022/07/09/git/","excerpt":"","text":"git 廖雪峰 跟踪文本文件的改动 不要使用Windows自带的记事本编辑任何文本文件。原因是Microsoft开发记事本的团队使用了一个非常弱智的行为来保存UTF-8编码的文件，他们自作聪明地在每个文件开头添加了0xefbbbf（十六进制）的字符 基础用法1.git init把当前目录变成Git可以管理的仓库： $ mkdir learngit $ cd learngit $ git init Initialized empty Git repository in /Users/michael/learngit/.git/ 2.git add commit git add $ git add readme.txt git commit $ git commit -m &quot;wrote a readme file&quot; [master (root-commit) eaadf4e] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt -m后面输入的是本次提交的说明 查看 git status diff log查看工作区状态 $ git status 查看文件变化 $ git diff readme.txt diff --git a/readme.txt b/readme.txt index 46d49bf..9247db6 100644 --- a/readme.txt +++ b/readme.txt @@ -1,2 +1,2 @@ -Git is a version control system. +Git is a distributed version control system. Git is free software. 查看日志 git log命令显示从最近到最远的提交日志 $ git log $ git log --pretty=oneline 1094adb7b9b3807259d8cb349e7df1d4d6477073 (HEAD -&gt; master) append GPL e475afc93c209a690c39c13a46716e8fa000c366 add distributed eaadf4e385e865d25c48e7ca9c8395c3f7dfaef0 wrote a readme file 一大串类似1094adb...的是commit id（版本号），Git的commit id是一个SHA1计算出来的一个非常大的数字，用十六进制表示 版本切换git reset 在Git中，用HEAD表示当前版本，也就是最新的提交，上一个版本就是HEAD^，上上一个版本就是HEAD^^，往上100个版本写成HEAD~100 回退到上一版本 $ git reset --hard HEAD^ HEAD is now at e475afc add distributed 提供版本号（比如刚刚回退之前的最新版本的版本号开头是1094a，想到那个版本） 版本号没必要写全，前几位就可以了，Git会自动去找 $ git reset --hard 1094a HEAD is now at 83b0afe append GPL 原理 Git的版本回退速度非常快，因为Git在内部有个指向当前版本的HEAD指针，当你回退版本的时候，Git仅仅是把HEAD从指向append GPL： ┌────┐ │HEAD│ └────┘ │ └──&gt; ○ append GPL │ ○ add distributed │ ○ wrote a readme file 改为指向add distributed： ┌────┐ │HEAD│ └────┘ │ │ ○ append GPL │ │ └──&gt; ○ add distributed │ ○ wrote a readme file 然后顺便把工作区的文件更新了。 git refloggit reflog查看你的每一次命令： $ git reflog e475afc HEAD@&#123;1&#125;: reset: moving to HEAD^ 1094adb (HEAD -&gt; master) HEAD@&#123;2&#125;: commit: append GPL e475afc HEAD@&#123;3&#125;: commit: add distributed eaadf4e HEAD@&#123;4&#125;: commit (initial): wrote a readme file 第一列是版本号 丢弃修改git checkout reset git checkout -- file 用版本库里的版本替换工作区的版本（让这个文件回到最近一次git commit或git add时的状态） $ git checkout -- readme.txt 命令git checkout -- readme.txt意思就是，把readme.txt文件 用版本库里的版本替换工作区的版本，这里有两种情况： 一种是readme.txt自修改后还没有被放到暂存区，现在，撤销修改就回到和版本库一模一样的状态； 一种是readme.txt已经添加到暂存区后，又作了修改，现在，撤销修改就回到添加到暂存区后的状态。 git reset HEAD &lt;file&gt;可以把暂存区的修改撤销掉（unstage），重新放回工作区： $ git reset HEAD readme.txt Unstaged changes after reset: M readme.txt 删除文件$ rm test.txt 把工作区文件删除之后（test.txt是已经提交了的）， 用命令git rm删掉，并且git commit： $ git rm test.txt rm &#39;test.txt&#39; $ git commit -m &quot;remove test.txt&quot; [master d46f35e] remove test.txt 1 file changed, 1 deletion(-) delete mode 100644 test.txt 现在，文件就从版本库中被删除了。 远程仓库设置user name和email如果你是第一次使用，或者还没有配置过的话需要操作一下命令，自行替换相应字段。 git config --global user.name &quot;Luke.Deng&quot; git config --global user.email &quot;xiangshuo1992@gmail.com&quot; git config –list 查看当前Git环境所有配置，还可以配置一些命令别名之类的。 远程仓库地址操作添加远程仓库：进入本地仓库执行：origin是给远程源的一个命名，你可以随便取 git remote add origin &lt;远程仓库git的地址&gt; 修改远程仓库地址： git remote set-url origin &lt;remote-url&gt; 仓库路径查询查询： git remote -v 删除指定的远程仓库： git remote rm origin git push 本地仓库推送到远程仓库（已关联）将本地当前分支 推送到 远程指定分支上（分支名字方向是 按**数据传输方向 -&gt;**）： git push &lt;远程仓库“名字”，在remote add的时候取的名字&gt; &lt;本地分支名&gt;:&lt;远程分支名&gt; #若两个分支名字只写一个，则默认这俩分支名都是它 比如： git push origin master # 将当前仓库的master分支推送到origin的master分支 git push origin main baseline # 将当前仓库的main分支推送到origin的baseline分支 -f：强制推送到远程仓库，且覆盖远程代码库 git push -f origin master git pull 从远程获取代码并合并本地的版本分支名字方向是 按**数据传输方向 -&gt;**： git pull &lt;远程仓库“名字”，在remote add的时候取的名字&gt; &lt;远程分支名&gt;:&lt;本地分支名&gt; 比如： git pull origin master git clone远程仓库进入本地目录： git clone &lt;远程仓库git地址&gt; 这样执行git clone的目录下fork来的那个目录就是一个git目录了，并且自动关联远程仓库 克隆指定分支 git clone -b &lt;指定分支名&gt; &lt;远程仓库git地址&gt; gitignore在项目开发过程中个，一般都会添加 .gitignore 文件，规则很简单，但有时会发现，规则不生效。原因是 .gitignore 只能忽略那些原来没有被track的文件，如果某些文件已经被纳入了版本管理中，则修改.gitignore是无效的。那么解决方法就是先把本地缓存删除（改变成未track状态），然后再提交。 git rm -r --cached . git add . git commit -m &quot;update .gitignore&quot; 本地仓库关联git服务器上的.gitstep1 git服务器上操作下文用表示git服务器的外网ip地址 附：root如何创建用户： 例如创建“张三”用户： useradd zhangsan passwd hnuzs [可选]ssh免登陆操作 此步骤是为了在本地服务器连接远程git服务器时免于输入用户密码，具体操作如下： 将本地服务器的公钥id_rsa.pub传入远程git服务器的&#x2F;home&#x2F;&#x2F;.ssh&#x2F;authorized_keys认证文件中。 cat id_rsa.pub &gt;&gt; authorized_keys #pwd:/home/&lt;user_name&gt;/.ssh 创建并初始化git仓库 首先创建一个目录作为git仓库并赋予所属用户： cd /home/&lt;user_name&gt; mkdir zsgitrepo chown &lt;user_name&gt;:&lt;user_name&gt; zsgitrepo/ 接着使用git命令创建一个裸仓库，服务器上的git仓库通常以.git结尾，并更改仓库所属用户： cd zsgitrepo git init --bare zsrepo.git chown -R &lt;user_name&gt;:&lt;user_name&gt; zsrepo.git step2 本地服务器上操作 添加远程版本库 git remote add origin git@&lt;git_server_ip&gt;:/home/&lt;user_name&gt;/xxrepo/xx.git # git@&lt;git_server_ip&gt;:&lt;absolute path to your .git on git server&gt; 关联后举例：git clone克隆仓库注意clone的.git的地址 $ git clone &lt;user_name&gt;@&lt;git_server_ip&gt;:/home/&lt;user_name&gt;/zsgitrepo/zsrepo.git Cloning into &#39;zsrepo&#39;... 公匙解决 remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. 解决方法： 本地服务器生成公匙并上传到远程服务器上，具体操作： linux下生成公匙，传公匙到github上：参考链接 windows下生成公匙：见下文 上传到其他git服务器上：见下文 然后remote用ssh的地址，不用http的地址 linux下公匙私匙生成公匙上传githubwindows下公匙私匙生成 SSH-key 在Windows下如何生成公钥和私钥 在centos上搭建git服务器并自动同步代码 - 云+社区 - 腾讯云 (tencent.com) git安装好后 右键选择Git GUI Here-&gt;Help-&gt;Show SSH Key 就能得到私钥和公钥 公钥上传远程git服务器的认证文件中cat id_rsa.pub &gt;&gt; authorized_keys #pwd:/home/&lt;user_name&gt;/.ssh/ 如果没有~&#x2F;.ssh&#x2F;authorized_keys就新建一个 cd /home/&lt;user_name&gt; mkdir .ssh chmod 700 .ssh touch .ssh/authorized_keys chmod 600 .ssh/authorized_keys git原理暂存区工作区（Working Directory）：比如刚刚git init所在的那个目录 版本库（Repository）：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库 Git的版本库里存了很多东西，其中最重要的就是称为stage（或者叫index）的暂存区，还有Git为我们自动创建的第一个分支master，以及指向master的一个指针叫HEAD。 把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用 git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用 git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。现在改成main了 gitflow流程概念 错误示范： 不知道他怎么搞的，直接 push 到 master 分支去了，直接跨过开发分支和测试分支，直接合到 master 发布分支上去了（一般来说，master都是有保护的！）。 这还不算什么。。。如果只是这样就还好，关键是他看有写代码冲突就直接在 master 分支上对已经成功发版的代码增删改！！！ 一般来说，团队合作开发的话，每个人都需要在自己的功能分支 feat&#x2F;XXX 上开发，最后一起合并到总的开发分支 dev 上，然后将开发分支 dev 合并到测试分支上，最后将测试分支合并到正式发布分支上。 其中总的开发分支一般叫做 dev 分支，正式发布分支一般是叫 main&#x2F;master&#x2F;release 分支。 一般的开发流程： 比如说有 A、B、C 三个人协助进行功能开发： 1、首先 A、B、C 三位小伙伴从总开发分支 Dev 上开辟自己的功能分支，分别是 feat&#x2F;AXXX、feat&#x2F;BXXX、feat&#x2F;CXXX，也就是图中 feat&#x2F;AXXX、feat&#x2F;BXXX、feat&#x2F;CXXX 的三条线； 2、然后在自己的开发机上进行开发，这里的开发机可以是本地环境也可以是一些云端的开发机。开发完毕后，再分别合到总开发分支 dev 上，也就是图中蓝色的三条线，在这个过程中可能会产生一些代码冲突，挨个 solve 即可； 3、接着在 dev 分支上确认所有功能开发完毕，进行简单自测，fix 一些 bug 后再向测试分支上进行合并； 4、这个时候就可以艾特测试组的同学来进行测试，测试通过后再合到 master 分支进行发布。 GitFlow流程 - 简书 (jianshu.com) git提交-m规范type （scope）: message 参数介绍： 1、type：指的代码的提交类型，不同的提交类型表示对应不同的代码改动，比如： feat：新功能的开发 fix：bug的修复 docs：文档格式的改动 style：代码格式改变 refactor：对已有的功能进行重构 perf：性能优化 test：增加测试 build：改变了build工具 revert：撤销上一次的commit提交 chore：构建过程或辅助工具的变动 2、scope：用于说明commit影响的范围，比如：权限模块、还是首页 3、message： 对提交的代码做一个简短的说明，不能过长。 fix（系统菜单图标）：添加缺少的图标 问题git: Failed to connect to 127.0.0.1 port 1080: Connection refused在git init顶层目录下 git config --global --unset http.proxy git config --global --unset https.proxy OpenSSL SSL_read: Connection was reset, errno 10054git config --global http.sslVerify &quot;false&quot; Failed to connect to github.com port 443 after 21114 ms: Timed out用ssh的那个地址","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"}],"author":"zhiqiuyuan"},{"title":"netstat 查看udptcp连接","slug":"netstat 查看udptcp连接","date":"2022-07-09T07:23:48.608Z","updated":"2022-12-10T16:07:18.976Z","comments":true,"path":"2022/07/09/netstat 查看udptcp连接/","link":"","permalink":"http://example.com/2022/07/09/netstat%20%E6%9F%A5%E7%9C%8Budptcp%E8%BF%9E%E6%8E%A5/","excerpt":"","text":"netstatnetstat -nt —&gt;&gt;&gt;查看tcp连接 netstat -nua —&gt;&gt;&gt;查看udp连接 [root@dbserver ~]# netstat -nt ---&gt;&gt;&gt;查看tcp连接 Active Internet connections (w/o servers) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 52 192.168.80.187:22 192.168.80.1:54458 ESTABLISHED tcp 0 0 192.168.80.187:22 192.168.80.1:54455 ESTABLISHED tcp 0 0 192.168.80.187:22 192.168.80.1:52256 ESTABLISHED tcp 0 0 192.168.80.187:22 192.168.80.1:52264 ESTABLISHED tcp 0 0 192.168.80.187:7432 192.168.80.1:54515 ESTABLISHED [root@dbserver ~]# netstat -nua ---&gt;&gt;&gt;查看udp连接 Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State udp 0 0 0.0.0.0:5353 0.0.0.0:* udp 0 0 0.0.0.0:41277 0.0.0.0:* udp 0 0 127.0.0.1:323 0.0.0.0:* udp 0 0 0.0.0.0:978 0.0.0.0:* udp 0 0 192.168.122.1:53 0.0.0.0:* udp 0 0 0.0.0.0:67 0.0.0.0:* udp 0 0 0.0.0.0:111 0.0.0.0:* udp6 0 0 ::1:323 :::* udp6 0 0 ::1:61020 ::1:61020 ESTABLISHED udp6 0 0 :::978 :::* udp6 0 0 :::111 :::* [root@dbserver ~]# 如下取自man netstat的结果： Recv-Q Established: The count of bytes not copied by the user program connected to this socket. Listening: Since Kernel 2.6.18 this column contains the current syn backlog. Send-Q Established: The count of bytes not acknowledged by the remote host. Listening: Since Kernel 2.6.18 this column contains the maximum size of the syn backlog.","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"npm","slug":"npm","date":"2022-07-09T06:45:08.601Z","updated":"2022-12-10T16:07:54.221Z","comments":true,"path":"2022/07/09/npm/","link":"","permalink":"http://example.com/2022/07/09/npm/","excerpt":"","text":"创建项目 给项目添加package.json文件 npm init index.html放public目录下 js放src目录下 运行npm install #安装依赖 npm start #u 安装模块到指定目录默认情况下（即npm install XXX），在哪个文件夹下运行npm，npm就在当前目录创建一个文件夹node_modules，然后将要安装的程序安装到文件夹node_modules里面 如果将安装的程序安装到我们指定的目录而不是当前目录： 设置npm安装程序时的默认位置 npm config set prefix &quot;C:\\Users\\Default\\AppData\\Roaming\\npm\\node_modules&quot; 设置npm安装程序时的缓存位置 npm config set cache &quot;C:\\Users\\Default\\AppData\\Roaming\\npm\\node_cache&quot; 设置环境变量NODE_PATH NODE_PATH = C:\\Users\\Default\\AppData\\Roaming\\npm\\node_global\\node_modules 然后在使用npm安装程序时在后面加一个参数-g即可将安装的程序安装到我们指定的目录（比如npm install XXX -g）C:\\Users\\Default\\AppData\\Roaming\\npm\\node_modules","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"vim操作","slug":"vim操作","date":"2022-07-09T06:10:04.849Z","updated":"2022-12-10T16:09:22.202Z","comments":true,"path":"2022/07/09/vim操作/","link":"","permalink":"http://example.com/2022/07/09/vim%E6%93%8D%E4%BD%9C/","excerpt":"","text":"配置you should modify the vim configuration file. The file is called vimrc, and it is located under /etc/vim directory. We first make a copy of it to the home directory by cp command: cp /etc/vim/vimrc ~/.vimrc open .vimrc using vim: vim ~/.vimrc builtin help system报错&#x2F;etc&#x2F;apt&#x2F;sources.list” E212: Can’t open file for writing Running :h E212 inside Vim :h &lt; 全选复制粘贴缓冲区Vim 中的复制、删除的内容默认都会被存放到默认（未命名）寄存器中，之后可以通过粘贴操作读取默认寄存器中的内容。寄存器是完成这一过程的中转站，Vim 支持的寄存器非常多，其中常用的有 a-zA-Z0-9+&quot;。 其中： 0-9：表示数字寄存器，是 Vim 用来保存最近复制、删除等操作的内容，其中 0 号寄存器保存的是最近一次的操作内容。 a-zA-Z：表示用户寄存器，Vim 不会读写这部分寄存器 &quot;（单个双引号）：未命名的寄存器，是 Vim 的默认寄存器，例如删除、复制等操作的内容都会被保存到这里。 +：剪切板寄存器，关联系统剪切板，保存在这个寄存器中的内容可以被系统其他程序访问，也可以通过这个寄存器访问其他程序保存到剪切板中的内容。 全选并复制到系统剪切板【好像没用？】gg 到首行，然后 &quot;+yG 把行首到行尾的内容复制到 + 寄存器。 &quot;+yy // 复制当前行到剪切板 &quot;+p // 将剪切板内容粘贴到光标后面 &quot;ayy // 复制当前行到寄存器 a &quot;ap // 将寄存器 a 中的内容粘贴到光标后面 根据平台不同，要分两种情况。先用下面命令确定你属于哪一种， vim --version | grep clipboard 不支持系统粘贴板情况一， 如果结果里你找到加号开头的**+clipboard**， 恭喜你，你的vim没问题，是你姿势问题。 用**&quot;+y** 代替y将选中的内容复制到系统剪贴板，效果和ctrl-c一致。 用**&quot;+p**代替p将剪贴板内容复制到指定位置，也可以用ctrl-v。 d，x，c，s也一样，用之前前面加**&quot;+**。 如果想偷懒用y直接把内容复制到系统剪贴板，需要到vim配置文件.vimrc里加一行属性。用下面命令开始配置， vim ~/.vimrc 然后，加入下面这行， set clipboard=unnamed 现在你的y，d，x，p已经能和 ctrl-c和ctrl-v 一个效果，并且能互相混用。 情况二， 如果找到的是负号开头的**-clipboard，**说明你的vim不支持系统剪切板，我的MacOS系统自带vim就不支持，所以跑来了。需要先重新安装vim， Linux系统， sudo apt install vim-gtk MacOS， brew install vim 安装好之后，重复情况一的操作即可。 命令 选定文本块。使用v进入可视模式，移动光标键选定内容。 复制的命令是y，即yank（提起） ，常用的命令如下：y 在使用v模式选定了某一块的时候，复制选定块到缓冲区用；yy 复制整行（nyy或者yny ，复制n行，n为数字）；y^ 复制当前到行头的内容；y$ 复制当前到行尾的内容；yw 复制一个word （nyw或者ynw，复制n个word，n为数字）；yG 复制至档尾（nyG或者ynG，复制到第n行，例如1yG或者y1G，复制到档尾） 剪切的命令是d，即delete，d与y命令基本类似，所以两个命令用法一样，包括含有数字的用法.d 剪切选定块到缓冲区；dd 剪切整行d^ 剪切至行首d$ 剪切至行尾dw 剪切一个worddG 剪切至档尾 粘贴的命令式p，即put（放下）p 小写p代表贴至游标后（下），因为游标是在具体字符的位置上，所以实际是在该字符的后面P 大写P代表贴至游标前（上）整行的复制粘贴在游标的上（下）一行，非整行的复制则是粘贴在游标的前（后） 全选：ggVG 注： 命令前面加数字表示重复的次数，加字母表示使用的缓冲区名称。使用英文句号”.”可以重复上一个命令。 navigate非编辑（normal）模式下： 行间shift+g 跳转到最后一行 gg 跳转到第一行 nG 移动光标到当前文件的第n行:n 移动光标到当前文件的第n行 (同上) 行内0 移动光标到当前行行首$ 移动光标到当前行行尾^ 移动光标到当前行的第一个非空字符 单词级w 移动到下一单词的开头b 移动到上一单词的开头e 移动到光标所在单词的末尾 查找1，查找 在normal模式下按下/即可进入查找模式，输入要查找的字符串并按下回车。 Vim会跳转到第一个匹配。按下n查找下一个，按下N查找上一个。 Vim查找支持正则表达式，例如/vim$匹配行尾的&quot;vim&quot;。 需要查找特殊字符需要转义，例如/vim\\$匹配&quot;vim$&quot;。 2，大小写敏感查找 在查找模式中加入\\c表示大小写不敏感查找，\\C表示大小写敏感查找。例如： /foo\\c 将会查找所有的&quot;foo&quot;,&quot;FOO&quot;,&quot;Foo&quot;等字符串。 3，查找当前单词 在normal模式下按下*即可查找光标所在单词（word）， 要求每次出现的前后为空白字符或标点符号。例如当前为foo， 可以匹配foo bar中的foo，但不可匹配foobar中的foo。 这在查找函数名、变量名时非常有用。 按下g*即可查找光标所在单词的字符序列，每次出现前后字符无要求。 即foo bar和foobar中的foo均可被匹配到。 替换:s（substitute）命令用来查找和替换字符串。语法如下： :&#123;作用范围&#125;s/&#123;目标&#125;/&#123;替换&#125;/&#123;替换标志&#125; 例如:%s/foo/bar/g会在全局范围(%)查找foo并替换为bar，所有出现都会被替换（g）。 :%s/blog_os/yzq_os/g 作用范围作用范围分为当前行、全文、选区等等。 当前行： :s/foo/bar/g 全文： :%s/foo/bar/g 选区，在Visual模式下选择区域后输入:，Vim即可自动补全为 :&#39;&lt;,&#39;&gt;。 :&#39;&lt;,&#39;&gt;s/foo/bar/g 2-11行： :5,12s/foo/bar/g 当前行.与接下来两行+2： :.,+2s/foo/bar/g 代码折叠在可折叠处（大括号中间）：1 zc 折叠2 zC 对所在范围内所有嵌套的折叠点进行折叠3 zo 展开折叠4 zO 对所在范围内所有嵌套的折叠点展开5 [z 到当前打开的折叠的开始处。6 ]z 到当前打开的折叠的末尾处。7 zj 向下移动。到达下一个折叠的开始处。关闭的折叠也被计入。8 zk 向上移动到前一折叠的结束处。关闭的折叠也被计入。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"vscode通用操作 vscode安装卸载","slug":"vscode通用操作 vscode安装卸载","date":"2022-07-09T06:09:18.684Z","updated":"2022-12-10T16:10:54.419Z","comments":true,"path":"2022/07/09/vscode通用操作 vscode安装卸载/","link":"","permalink":"http://example.com/2022/07/09/vscode%E9%80%9A%E7%94%A8%E6%93%8D%E4%BD%9C%20vscode%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD/","excerpt":"","text":"ubuntu20.04下安装和启动ubuntu20.04使用 apt 安装Visual Studio Code 在官方的微软 Apt 源仓库中可用。想要安装它，按照下面的步骤来： 以 sudo 用户身份运行下面的命令，更新软件包索引，并且安装依赖软件： sudo apt update sudo apt install software-properties-common apt-transport-https wget 使用 wget 命令插入 Microsoft GPG key ： wget -q https://packages.microsoft.com/keys/microsoft.asc -O- | sudo apt-key add - 启用 Visual Studio Code 源仓库，输入： sudo add-apt-repository &quot;deb [arch=amd64] https://packages.microsoft.com/repos/vscode stable main&quot; 一旦 apt 软件源被启用，安装 Visual Studio Code 软件包： sudo apt install code 当一个新版本被发布时，你可以通过你的桌面标准软件工具，或者在你的终端运行命令，来升级 Visual Studio Code 软件包： sudo apt update sudo apt upgrade ubuntu20.04启动VS Code 也可以通过在终端命令行输入code进行启动。 快捷键折叠展开 折叠所有 Ctrl+K, 0. 展开所有 Ctrl+K, J. windows彻底卸载字体比较好看的一种： settings-&gt;搜索font font family填： Consolas, &#39;Courier New&#39;, monospace 关闭保存时自动格式化 https://www.jianshu.com/p/9e7589a0153a 方法一： 看看自己的编辑器插件里面有没有安装Prettier – Code formatter这个插件，如果有的话，直接禁用。 方法二： 打开vs code首选项里面的设置，分别搜索editor.formatOnSave以及editor.formatOnType，将对应设置前的选择框取消勾选。","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"python安装模块","slug":"python安装模块","date":"2022-07-09T04:45:21.248Z","updated":"2022-12-10T16:11:26.801Z","comments":true,"path":"2022/07/09/python安装模块/","link":"","permalink":"http://example.com/2022/07/09/python%E5%AE%89%E8%A3%85%E6%A8%A1%E5%9D%97/","excerpt":"","text":"python3 pipwindows pip install &lt;package_name&gt; linuxpython3: pip3 install &lt;package_name&gt; 网上搜一下，不一定和import的一样 –user 仅为当前用户安装10.13 安装私有的包 — python3-cookbook 3.0.0 文档 Python有一个用户安装目录，通常类似”~&#x2F;.local&#x2F;lib&#x2F;python3.3&#x2F;site-packages”。 要强制在这个目录中安装包，可使用安装选项“–user”","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"}],"tags":[{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"}],"author":"zhiqiuyuan"},{"title":"ubuntu+virtualbox虚拟机安装后操作","slug":"ubuntu+virtualbox虚拟机安装后操作","date":"2022-07-09T04:39:00.743Z","updated":"2022-12-10T16:11:40.683Z","comments":true,"path":"2022/07/09/ubuntu+virtualbox虚拟机安装后操作/","link":"","permalink":"http://example.com/2022/07/09/ubuntu+virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85%E5%90%8E%E6%93%8D%E4%BD%9C/","excerpt":"","text":"装ubuntu虚拟机参考网上教程 [可选]装ubuntu虚拟机后virtualbox安装增强功能设备-&gt;安装增强功能 sudo su cd /media mkdir cdrom mount /dev/cdrom /media/cdrom 然后跑去根目录找一下VBoxLinuxAdditions.run在哪里，应该在&#x2F;media&#x2F;cdrom中 cd / sudo find -name &quot;*VBoxLinuxAdditions*&quot; 运行它 sudo apt-get install linux-headers-$(uname -r) #先这个 sudo ./media/cdrom/VBoxLinuxAddition.run #r 换源在ubuntu下执行sudo apt-get update时，经常会遇到报错： 1 Err http://security.ubuntu.com precise-security InRelease 2 3 Err http://security.ubuntu.com precise-security Release.gpg 4 Temporary failure resolving &#39;security.ubuntu.com&#39; 5 Err http://cn.archive.ubuntu.com precise InRelease 6 7 Err http://cn.archive.ubuntu.com precise-updates InRelease 8 9 Err http://cn.archive.ubuntu.com precise-backports InRelease 10 11 Err http://cn.archive.ubuntu.com precise Release.gpg 12 Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 13 Err http://cn.archive.ubuntu.com precise-updates Release.gpg 14 Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 15 Err http://cn.archive.ubuntu.com precise-backports Release.gpg 16 Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 17 Reading package lists... Done 18 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise/InRelease 19 20 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise-updates/InRelease 21 22 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise-backports/InRelease 23 24 W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/precise-security/InRelease 25 26 W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/precise-security/Release.gpg Temporary failure resolving &#39;security.ubuntu.com&#39; 27 28 W: Failed to fetch http://cn.archive.ubuntu.com/ubuntu/dists/precise/Release.gpg Temporary failure resolving &#39;cn.archive.ubuntu.com&#39; 这是因为镜像源除出了问题，一般都会推荐使用国内的镜像源，比如163或者阿里云或者清华大学的镜像服务器 （强烈建议使用清华镜像） 清华镜像源官网：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 将下列文本添加到&#x2F;etc&#x2F;apt&#x2F;sources.list文件里 # 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释 deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-security main restricted universe multiverse # 预发布软件源，不建议启用 # deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse # deb-src https://mirrors.tuna.tsinghua.edu.cn/ubuntu/ trusty-proposed main restricted universe multiverse 或者进入repogen.simplylinux.ch 选择合适的Ubuntu版本后，在ubuntu Branches下全选 拉至网页最下，点击生产，复制list下内容，添加到&#x2F;etc&#x2F;apt&#x2F;sources.list中即可 具体参考https://jingyan.baidu.com/article/afd8f4de66efcf34e286e993.html?st=2&amp;os=0&amp;bd_page_type=1&amp;net_type=2 修改镜像源之后需要重新更新： sudo apt-get update sudo apt-get upgrade 如果执行sudo apt-get update仍然报错，问题在于DNS没有配置好。按下方配置 配置DNS解决方法： sudo vi /etc/resolv.conf 在其中添加： # Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 127.0.1.1 #这里用的是阿里云的DNS服务器 nameserver 223.5.5.5 nameserver 223.6.6.6 设置字体命令行设置系统字体 sudo dpkg-reconfigure console-setup gnome-tweaks 装中文输入法 谷歌输入法ubuntu20.04 安装fcitx-googlepinyinsudo apt-get install fcitx-googlepinyin 配置language support安装完成后打开菜单栏（按键盘上ctrl和alt之间的那个键，就是windows里的win键，在ubuntu里叫super），键盘输入language support并打开。 第一次打开会显示语言支持没有完全安装，点击安装并输入密码开始安装。 安装好后就能进入语言支持界面，最下面一行Keyboard input method system，默认是iBus，点击下拉单切换到fcitx（系统初始没有fctix，安装fcitx-googlepinyin的时候会装好fcitx）。然后重启电脑。 输入法配置重启之后在右上角状态栏点击键盘图标，在下拉单里选择倒数第三个Configure进入配置界面。 点击输入方法设置左下角的+号，进入添加输入方法界面。取消“只显示当前语言”选项的勾选，输入pinyin搜索到系统现有的拼音输入法。选择Google Pinyin并点击OK确认。 关闭设置，谷歌输入法配置完成。可以点击右上角状态栏的键盘图片切换到谷歌输入法，切换输入法的快捷键是ctrl+space，可以在刚关闭的输入方法设置界面里第二项Global Config里修改快捷键。 ping通主机和虚拟机 网络地址转换设置端口转发（推荐） 这样配置之后主机直接连接192.168.56.1:5556会自动转发到虚拟机的3325端口 192.168.56.1来自：本机ipconfig 效果比如 虚拟机上运行server程序 ip_port = (&#39;&#39;, 3325) sk = socket.socket() sk.bind(ip_port) sk.listen(5) while True: print(&#39;server waiting...&#39;) conn, addr = sk.accept() client_data = conn.recv(1024) print(client_data.decode()) conn.sendall(&#39;不要回答,不要回答,不要回答&#39;.encode()) conn.close() 本机运行client程序可以成功通信 ip_port = (&#39;192.168.56.1&#39;, 5556) sk = socket.socket() sk.connect(ip_port) sk.sendall(&#39;请求占领地球&#39;.encode()) server_reply = sk.recv(1024) print(server_reply.decode()) sk.close() 终端快捷键ctrl+alt+t 打开终端 ctrl + shift + t 添加终端多标签 alt+1 alt+2切换多标签","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"}],"author":"zhiqiuyuan"},{"title":"访问github和google","slug":"访问github和google","date":"2022-07-09T04:25:46.538Z","updated":"2022-12-10T16:11:54.868Z","comments":true,"path":"2022/07/09/访问github和google/","link":"","permalink":"http://example.com/2022/07/09/%E8%AE%BF%E9%97%AEgithub%E5%92%8Cgoogle/","excerpt":"","text":"Github访问加速访问网址加速dev-sidecar fastGithub（目前在用它，好用） git clone push等加速用ssh的地址，不用http的 访问谷歌 插件 edge浏览器IGG谷歌访问助手插件 谷歌镜像 全渠道搜索_思谋上网导航 (scmor.com) 翻墙vpn","categories":[{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"halo文章分类","slug":"halo文章分类","date":"2022-07-09T00:13:11.043Z","updated":"2022-12-10T16:12:26.307Z","comments":true,"path":"2022/07/09/halo文章分类/","link":"","permalink":"http://example.com/2022/07/09/halo%E6%96%87%E7%AB%A0%E5%88%86%E7%B1%BB/","excerpt":"","text":"可能用到的管理后台功能后台中 “文章”-“分类目录”可以创建分类（发布文章的时候也可以） “外观”-“菜单设置”可以设置博客顶部菜单栏的内容，以及每一项的路径 由于允许指定每一项的路径，因此可以将这里的路径指向自定义页面","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"}],"author":"zhiqiuyuan"},{"title":"nginx排错","slug":"nginx排错","date":"2022-07-08T23:58:43.160Z","updated":"2022-12-10T16:12:34.168Z","comments":true,"path":"2022/07/09/nginx排错/","link":"","permalink":"http://example.com/2022/07/09/nginx%E6%8E%92%E9%94%99/","excerpt":"","text":"比如502 Bad GateWay 查看nginx目录下logs下的error.log这个是debug开始，找到对应问题出现时间的报错信息 解决举例比如大概07:30:04时访问我的博客后台报错nginx 502，于是查看error.log： 2022/07/09 07:30:04 [error] 41038#0: *3286 connect() failed (111: Connection refused) while connecting to upstream, client: 182.109.237.75, server: zhiqiuyuan.site, request: &quot;GET /admin HTTP/1.1&quot;, upstream: &quot;http://127.0.0.1:8090/admin&quot;, host: &quot;120.48.116.29&quot; 这说明我服务器ip120.48.116.29上端口8090连接不上 所以先检查我服务器上端口8090运行的服务还在不（我在端口8090运行halo jar包） ps -eo pid,comm | grep &quot;java&quot; 发现没有进程，所以重新nohup运行halo jar包 等1min后解决","categories":[{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"2022北大叉院 大数据科学研究中心 计科 夏令营面经","slug":"2022北大叉院 大数据科学研究中心 计科 夏令营面经","date":"2022-07-08T14:12:48.202Z","updated":"2022-12-10T16:12:43.171Z","comments":true,"path":"2022/07/08/2022北大叉院 大数据科学研究中心 计科 夏令营面经/","link":"","permalink":"http://example.com/2022/07/08/2022%E5%8C%97%E5%A4%A7%E5%8F%89%E9%99%A2%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E7%A0%94%E7%A9%B6%E4%B8%AD%E5%BF%83%20%E8%AE%A1%E7%A7%91%20%E5%A4%8F%E4%BB%A4%E8%90%A5%E9%9D%A2%E7%BB%8F/","excerpt":"","text":"本人情况 末985 rank1 两项科研经历，第一项有一篇中文一作在投，第二项没发表成果 面试前一天被接收了于是自我介绍里面改成被接收了，不管怎么说，中文的，很菜 一些可以忽略不计的竞赛（两项很水的国二，一项很水的省二，全部都偏开发） 由于机缘巧合大概今年2月份联系到了北叉的老师，上述第二项科研工作是在老师的指导下干的。想去北大建议提前联系老师，争取能够在老师那做科研项目，既可以学东西又可以证明自己 面经硕士层次面试20分钟没有机试没有笔试2022.7.4倒数第二个，大概下午2点40开始 英文自我介绍2min 通知邮件说可以用ppt，然后现场不准用ppt 感觉老师们都面累了 我还坚持了一会我想用ppt因为之前没有准备过不带ppt的英语自我介绍(哭 然后老师们不让 最后还好练得次数足够多可以把稿子背出来orz 问项目。先让我讲一个印象最深刻的项目，然后抓着这个项目问你提出的方法是啥，有没有和典型方法进行对比，实验结果怎么样 我讲的是我发了文章的那个项目，因为有自己提出的idea所有老师可能就一直抓着这个来尝试听懂了 还有老师们没有做我这个方向的hhh然后很艰难地问我问题，我的解答老师好像没有听懂(哭 好不容易撑到了10分钟感觉 问我专业啥情况，怎么排名的 我专业是试验班，大二分流去的智能，所以老师问咋招生以及咋排名的 尬住了，老师不知道要问什么，在看我的申请材料 麻，重来一次我一定这个时候主动开始bb我调研的那些文献用的什么方法、有什么共性、有什么改进，以及多提一下之前和北大老师合作的项目 问数学：线性代数（特征值和特征向量是啥，正定矩阵是啥） 继续尬住 我申请表上有个实验是在十亿规模的图上的，问我有没有什么算法设计上和普通规模的图要考虑的不一样的点 答：没有（呜呜呜服务器内存大就没有问题），只是在开发上运行时间比较长有采取应对服务器中途断开的一些方法 寄 继续尬住，看手表，好，时间到了你走吧 被移出会议室 END 第一场夏令营面试，寄 结果2022.7.5 更新：联系的北大老师昨晚来确认名额了，今天下午也接到北叉秘书电话了，拿到优营 总结2022.7.6更新： 提前联系老师挺重要的，不是说和老师邮件几句话很重要，而是争取到在老师指导下做科研的机会（如果你有一定的实力，在这个过程中可以很好地让老师看到你的潜力，提前占坑，另外也是对于老师的一个考核，看ta风格你喜不喜欢），所以2月份可以开始联系老师了 大佬另说，有很多大佬没有联系老师也入营且拿到优营了，菜鸡自知所以提早争取机会呜呜呜 rk也挺重要的，我当时联系老师的时候老师有确认过两次我是否rk1 可能是末9的原因，学校水平稍低的情况下看rk来判断你的专业知识水平也可以理解了hh 开发类竞赛对于保研的重要程度似乎远小于上述两点，我的开发类竞赛面试的时候老师没有提到过，时间有限的情况下推荐科研&gt;竞赛（ACM另说，这个真的牛，机试菜鸡仰望） u1s1，可能是我参加的开发类竞赛过于水+答辩成分过重+自我驱动能力欠缺，感觉参加三四个比赛学到的东西不如搞一个没有产出的科研项目学到的东西多； 另外，也是u1s1，任何一个项目，不管是课设还是竞赛还是科研还是参与开源项目还是实习还是你自己写的工具，如果你在其中确实做出了很有含金量的工作，那这个就是很好的履历，是你可以被老师反复提问和与老师交流的点，说科研重要个人认为大概是出于一种概率的说法（即平均来讲，你本科阶段能接触到的各种项目中，在科研项目中你做出高含金量工作的可能性相对比较大）+对于研究生阶段所需能力的直接检验","categories":[{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[],"author":"zhiqiuyuan"},{"title":"halo+云服务器(centos)搭建个人博客","slug":"halo+云服务器(centos)搭建个人博客","date":"2022-07-08T13:57:05.695Z","updated":"2022-12-10T16:12:52.913Z","comments":true,"path":"2022/07/08/halo+云服务器(centos)搭建个人博客/","link":"","permalink":"http://example.com/2022/07/08/halo+%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8(centos)%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"鸣谢codesheep的教程 Why do you need a personal blog? show who you are and what you can do When you complete a project, you can put it in your portfolio for all to see 1.购买云服务器我选择的是百度智能云，操作系统为centos 得到服务器的公网ip地址，下称 2.云服务器安装环境java11 用于运行halo jar包 yum install java-11-openjdk -y 查看版本 java -version nginx 用于配置端口转发 源码编译安装 下载源码压缩包 官网下载：nginx: download 比如nginx-1.17.10版本的 下载nginx-1.17.10.tar.gz到&#x2F;root目录下（下面以此为例） 安装依赖 yum install gcc yum install pcre-devel yum install openssl openssl-devel 源码编译安装 创建目录和源码解压（目标是把nginx可可执行文件放在目录&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;下面） cd /usr/local/ mkdir nginx cd nginx tar zxvf /root/nginx-1.17.10.tar.gz -C ./ 进入源码目录，编译安装 cd nginx-1.17.10 ./configure # 如果后面需要配置成https的话，nginx需要安装https支持，则要加参数： # ./configure --with-http_ssl_module make &amp;&amp; make install # make会输出可执行文件到当前目录/objs/下面，make install其实可选 安装完成后，Nginx的可执⾏⽂件位置位于/usr/local/nginx/sbin/nginx 添加环境变量（可选） 可以把上述可执行文件位置添加到环境变量$PATH（这样直接nginx的话shell找得到nginx的可执行文件在哪里），或者以后运行的时候指定路径 在~&#x2F;.bashrc最后添加一行 export PATH=$PATH:/usr/local/nginx/sbin/ 然后使得配置在当前shell生效： source ~/.bashrc 可以检查一下$PATH内容： echo $PATH 3.运行halo和配置端口转发 参考Halo和几分钟，拥有⾃⼰的⾼颜值网站！代码都不用写_哔哩哔哩_bilibili 获取和后台运行jar包wget -c https://dl.halo.run/release/halo-1.5.4.jar nohup java -jar halo-1.5.4.jar &amp; #nohup，no hang up（不挂起），用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行 #&amp;的意思是后台运行 此时浏览器访问http:&#x2F;&#x2F;:8090会进入首次配置界面，填写信息后会进入管理后台 以后访问http:&#x2F;&#x2F;:8090是你的博客界面，http:&#x2F;&#x2F;:8090&#x2F;admin是后台管理界面 [可选]配置端口转发如果想直接http:&#x2F;&#x2F;访问的就是你的博客界面： 修改nginx配置文件 按如上方式安装的nginx则配置文件在&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf下面，是nginx.conf 新增upstream，并将server监听的端口80转发到upstream上 upstream halo &#123; server 127.0.0.1:8090; &#125; server &#123; listen 80; server_name localhost; client_max_body_size 1024m; #设置允许上上传文件的大小，因为nginx默认的是限制1M location / &#123; proxy_pass http://halo; #这个halo和上面的upstream名字一致 proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125; 重启nginx服务 nginx -s reload [可选]4.域名http://www.访问的就是你的博客，则需购买域名并绑定域名到公网ip 注册域名我选的是腾讯云注册域名 域名需要备案 绑定域名到公网ip以腾讯云为例，其他的可以搜官方文档 进入我的域名 - 域名注册 - 控制台 (tencent.com)，对要绑定的域名点击“解析” “添加记录” 主机记录：www 记录类型：A 线路类型：默认 记录值： TTL：600 点击”确定“ 点击新出现记录的三角形图标，启动解析 过大约10分钟之后，ping www.如果ping通则ok了 [可选]5.配置httpsSSL证书 申请免费ssl证书和下载证书 一般在注册域名的网站都有申请免费SSL证书的入口 比如腾讯云可以直接搜索”ssl证书“然后有入口，按指示操作即可，认证挺快的 证书申请成功后请下载对应服务器类型的证书文件，这里使用的是Nginx 上传 .key 与 .pem 后缀的两个文件，上传到服务器中 比如nginx目录下cert目录下（按上述nginx安装方式即目录&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;cert&#x2F;下） 配置nginx.conf 如下修改nginx.conf文件（主要注意改域名和证书文件路径） upstream halo &#123; server 127.0.0.1:8090; &#125; ## 配置http转发到https server &#123; listen 80; # 将demo.uanin.com改为您自己的域名 server_name demo.uanin.com; # 上传文件大小的限制 client_max_body_size 1024m; # 将所有http请求通过rewrite重定向到https。 rewrite ^(.*)$ https://$host$1 permanent; &#125; ## 配置demo.uanin.com的ssl server &#123; listen 443 ssl; # 将demo.uanin.com改为您自己的域名 server_name demo.uanin.com; # 上传文件大小的限制 client_max_body_size 1024m; # 将证书文件存放路径和证书的密钥文件名替换成自己存放路径与证书的密钥文件名。 ssl_certificate /usr/local/nginx/cert/3977015_demo.uanin.com.pem; ssl_certificate_key /usr/local/nginx/cert/3977015_demo.uanin.com.key; ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; ssl_prefer_server_ciphers on; location / &#123; proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://halo; #这个halo和上面的upstream名字一致 &#125; &#125; nginx reload重新生效nginx -s reload 可能报错解决 如果之前安装nginx时没有参数指定安装https支持的话，会报错nginx: [emerg] the “ssl“ parameter requires ngx_http_ssl_module，解决法： 先获取之前编译安装nginx的参数，然后再加上–with-http_ssl_module的参数重新configure-make（获取之前参数主要是希望重新编译安装得到的可执行文件只是比之前多了https支持，而不是少了些东西）： nginx -V #显示的configure arguments:后面的内容即之前nginx的make参数 重新源码编译 # 进入nginx源码目录，然后 ./configure &lt;之前安装给configure的参数&gt; --with-http_ssl_module make #这会输出可执行文件到当前目录/objs/下面 然后将原先&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx覆盖为新的可执行文件 nginx -s stop #先停止运行，才能覆盖成功的 cp ./objs/nginx /usr/local/nginx/sbin/nginx 此时nginx -s reload可能会报错nginx: [error] invalid PID number “” in “&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;logs&#x2F;nginx.pid 因为reload会从nginx.pid文件中读取进程pid，此时如果nginx.pid没有内容，则会报错如上， 所以可以重新指定一下配置文件，然后reload： nginx -c /usr/local/nginx/conf/nginx.conf #这样之后nginx.pid里面就有一个pid了 nginx -s reload 检查配置完成上述之后，浏览器访问或者www.的话浏览器会自动请求https:&#x2F;&#x2F;开头的url 此时访问后台和博客的url： https://&lt;your_server_ip&gt; #博客 https://&lt;your_server_ip&gt;/admin #后台 https://www.&lt;your_domain_name&gt; #博客 https://www.&lt;your_domain_name&gt;/admin #后台 注意halo后台“系统”-“博客设置”(-“基础选项”-“常规设置”)-“博客地址”更新http为https 其他操作备份和迁移比如迁移服务器：把旧服务器中的&#x2F;.halo目录整个迁移为新服务器的&#x2F;.halo目录，然后新服务器重新运行halo jar包 旧服务器备份：把~&#x2F;.halo压缩 tar -zvcf ~/.halo.tar.gz ~/.halo # 得到~/.halo.tar.gz 移到新服务器中 在旧服务器上运行 scp ~/.halo.tar.gz &lt;新服务器用户名&gt;@&lt;新服务器ip地址&gt;:~/.halo.tar.gz #scp即secure copy，是用来进行远程文件拷贝的。数据传输使用 ssh，并且和ssh 使用相同的认证方式，提供相同的安全保证 scp也可以直接目录拷贝，scp -r递归拷贝，但是亲测感觉压缩之后传输快一点 新服务器中解压 在~&#x2F;目录下 tar -zvxf .halo.tar.gz 新服务器上重新执行上文步骤2、3、4、5 可能问题 访问后台的时候加载不出来，F12报错net::ERR_ABORTED 404 (Not Found)： 先确认下服务器上halo jar包还在运行不 ps -eo pid,comm | grep &quot;java&quot; #搜索被java命令唤起的进程 如果还在，可能需要重新清除缓存，然后重新登录后台","categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"}],"tags":[{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"}],"author":"zhiqiuyuan"}],"categories":[{"name":"play","slug":"play","permalink":"http://example.com/categories/play/"},{"name":"db","slug":"db","permalink":"http://example.com/categories/db/"},{"name":"graph","slug":"graph","permalink":"http://example.com/categories/graph/"},{"name":"c++","slug":"c","permalink":"http://example.com/categories/c/"},{"name":"language","slug":"c/language","permalink":"http://example.com/categories/c/language/"},{"name":"tool","slug":"tool","permalink":"http://example.com/categories/tool/"},{"name":"python","slug":"python","permalink":"http://example.com/categories/python/"},{"name":"language","slug":"python/language","permalink":"http://example.com/categories/python/language/"},{"name":"debug","slug":"python/debug","permalink":"http://example.com/categories/python/debug/"},{"name":"debug","slug":"c/debug","permalink":"http://example.com/categories/c/debug/"},{"name":"linux","slug":"tool/linux","permalink":"http://example.com/categories/tool/linux/"},{"name":"debug","slug":"debug","permalink":"http://example.com/categories/debug/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/categories/SIMD/"},{"name":"SIMD","slug":"c/SIMD","permalink":"http://example.com/categories/c/SIMD/"},{"name":"plan","slug":"plan","permalink":"http://example.com/categories/plan/"},{"name":"tool","slug":"plan/tool","permalink":"http://example.com/categories/plan/tool/"},{"name":"course","slug":"course","permalink":"http://example.com/categories/course/"},{"name":"rust","slug":"rust","permalink":"http://example.com/categories/rust/"},{"name":"language","slug":"rust/language","permalink":"http://example.com/categories/rust/language/"},{"name":"tool","slug":"rust/tool","permalink":"http://example.com/categories/rust/tool/"},{"name":"windows","slug":"tool/windows","permalink":"http://example.com/categories/tool/windows/"},{"name":"fix_error","slug":"fix-error","permalink":"http://example.com/categories/fix-error/"},{"name":"math","slug":"math","permalink":"http://example.com/categories/math/"},{"name":"ML","slug":"ML","permalink":"http://example.com/categories/ML/"},{"name":"paper","slug":"paper","permalink":"http://example.com/categories/paper/"},{"name":"linux_syscall","slug":"c/linux-syscall","permalink":"http://example.com/categories/c/linux-syscall/"},{"name":"db","slug":"graph/db","permalink":"http://example.com/categories/graph/db/"},{"name":"GPU","slug":"GPU","permalink":"http://example.com/categories/GPU/"},{"name":"algorithm","slug":"algorithm","permalink":"http://example.com/categories/algorithm/"},{"name":"gcc","slug":"c/gcc","permalink":"http://example.com/categories/c/gcc/"},{"name":"os","slug":"course/os","permalink":"http://example.com/categories/course/os/"},{"name":"c++并发编程实践2ed","slug":"c/c-并发编程实践2ed","permalink":"http://example.com/categories/c/c-%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E5%AE%9E%E8%B7%B52ed/"},{"name":"language_deep","slug":"c/language-deep","permalink":"http://example.com/categories/c/language-deep/"},{"name":"生活随记","slug":"生活随记","permalink":"http://example.com/categories/%E7%94%9F%E6%B4%BB%E9%9A%8F%E8%AE%B0/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"graph","slug":"graph","permalink":"http://example.com/tags/graph/"},{"name":"c++","slug":"c","permalink":"http://example.com/tags/c/"},{"name":"python","slug":"python","permalink":"http://example.com/tags/python/"},{"name":"linux","slug":"linux","permalink":"http://example.com/tags/linux/"},{"name":"bash","slug":"bash","permalink":"http://example.com/tags/bash/"},{"name":"SIMD","slug":"SIMD","permalink":"http://example.com/tags/SIMD/"},{"name":"tool","slug":"tool","permalink":"http://example.com/tags/tool/"},{"name":"rust","slug":"rust","permalink":"http://example.com/tags/rust/"},{"name":"概统","slug":"概统","permalink":"http://example.com/tags/%E6%A6%82%E7%BB%9F/"},{"name":"GPU","slug":"GPU","permalink":"http://example.com/tags/GPU/"},{"name":"rocksdb","slug":"rocksdb","permalink":"http://example.com/tags/rocksdb/"},{"name":"concurrency","slug":"concurrency","permalink":"http://example.com/tags/concurrency/"},{"name":"halo","slug":"halo","permalink":"http://example.com/tags/halo/"},{"name":"git","slug":"git","permalink":"http://example.com/tags/git/"}]}